{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPngHXUFLa+GKAUFY0hxnzH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoAlexandreFerreira/RNA/blob/main/Visualiza%C3%A7%C3%A3o_dos_Custos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "MENtmaUTLn9l"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.metrics import  MeanRelativeError"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregando o dataset e separando em teste e treino\n",
        "df = pd.read_csv('data_cov.csv')\n",
        "y = df['cov']\n",
        "x = df.drop('cov', axis = 1)\n",
        "\n",
        "x_treino, x_teste = x[0:86], x[86:]\n",
        "y_treino, y_teste = y[0:86], y[86:]\n",
        "'''\n",
        "x_treino.insert(5, 'Cov',y_treino)\n",
        "x_treino = x_treino.sort_values(by='flow_distance_ratio')\n",
        "\n",
        "y_treino = x_treino['Cov']\n",
        "x_treino = x_treino.drop('Cov', axis = 1)\n",
        "'''\n",
        "scaler = MinMaxScaler()\n",
        "x_treino_normalizado = scaler.fit_transform(x_treino)\n",
        "x_teste_normalizado = scaler.transform(x_teste)"
      ],
      "metadata": {
        "id": "uFUv6sEYLtZ2"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "funcoes = ['tanh', 'relu', 'sigmoid', 'LeakyReLU']\n",
        "taxas = [0.005, 0.01, 0.05]"
      ],
      "metadata": {
        "id": "ENoqT1EbAhZV"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modelo_RNA(x, activation, nos, camadas_ocultas):\n",
        "  modelo = Sequential()\n",
        "  modelo.add(tf.keras.layers.Input(shape=(x.shape[1],)))\n",
        "  #modelo.add(keras.layers.Dense(nos, activation='relu', input_shape=x.shape))\n",
        "  for i in range(camadas_ocultas):\n",
        "    modelo.add(keras.layers.Dense(nos, activation=activation))\n",
        "    modelo.add(keras.layers.Dropout(0.2))\n",
        "  modelo.add(keras.layers.Dense(1, activation= 'linear'))\n",
        "  modelo.summary()\n",
        "\n",
        "  return modelo\n",
        "\n",
        "def treino_modelo(modelo, optimizer, loss, metrics, x_treino, y_treino, x_teste, y_teste, itr):\n",
        "  modelo.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "  resultado = modelo.fit(x_treino, y_treino, epochs=itr, batch_size=5, validation_data=(x_teste, y_teste))\n",
        "\n",
        "  return resultado, modelo\n",
        "\n",
        "def erro_relativo(y_pred, y_true):\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true))"
      ],
      "metadata": {
        "id": "8xNyVan9_5x-"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = list()\n",
        "erros_relativos = list()\n",
        "for i in funcoes:\n",
        "  #modelo = modelo_RNA(x_treino, i, 40, 11)\n",
        "  for j in taxas:\n",
        "      otimizador = tf.keras.optimizers.Adam(learning_rate=j)\n",
        "      modelo = modelo_RNA(x_treino, i, 40, 11)\n",
        "      resultado, modelo = treino_modelo(modelo, 'adam', 'mse', ['mae'], x_treino, y_treino, x_teste, y_teste, 350)\n",
        "      resultado = pd.DataFrame(resultado.history)\n",
        "      resultados.append(resultado)\n",
        "      y_pred = modelo.predict(x_treino)\n",
        "      y_pred = pd.DataFrame(y_pred)\n",
        "      erro = erro_relativo(y_pred, y_treino)\n",
        "      erros_relativos.append(erro)\n",
        "      '''\n",
        "      plt.plot(resultado.history['loss'])\n",
        "      plt.plot(resultado.history['val_loss'])\n",
        "      plt.title('Histórico de Treinamento')\n",
        "      plt.ylabel('Loss (MSE)')\n",
        "      plt.xlabel('Épocas de treinamento')\n",
        "      plt.legend(['Erro treino', 'Erro teste'])\n",
        "      plt.show()\n",
        "      '''"
      ],
      "metadata": {
        "id": "sStelzMt_8ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "eaa08807-937a-44e3-bcd8-30f6423cf8a9"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_63\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_636 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_573 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_637 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_574 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_638 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_575 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_639 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_576 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_640 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_577 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_641 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_578 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_642 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_579 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_643 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_580 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_644 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_581 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_645 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_582 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_646 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_583 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_647 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 5s 131ms/step - loss: 0.1986 - mae: 0.3575 - val_loss: 0.0067 - val_mae: 0.0791\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1151 - mae: 0.2666 - val_loss: 6.8948e-04 - val_mae: 0.0181\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.1210 - mae: 0.2725 - val_loss: 0.0089 - val_mae: 0.0920\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0662 - mae: 0.2097 - val_loss: 4.7463e-04 - val_mae: 0.0146\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0821 - mae: 0.2202 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0555 - mae: 0.1757 - val_loss: 7.3278e-04 - val_mae: 0.0192\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0526 - mae: 0.1786 - val_loss: 0.0042 - val_mae: 0.0612\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0614 - mae: 0.1925 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0498 - mae: 0.1814 - val_loss: 5.6169e-04 - val_mae: 0.0153\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0416 - mae: 0.1632 - val_loss: 0.0035 - val_mae: 0.0554\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0420 - mae: 0.1616 - val_loss: 0.0031 - val_mae: 0.0516\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0344 - mae: 0.1484 - val_loss: 0.0042 - val_mae: 0.0614\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0352 - mae: 0.1470 - val_loss: 0.0030 - val_mae: 0.0501\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0235 - mae: 0.1148 - val_loss: 8.3422e-04 - val_mae: 0.0215\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0279 - mae: 0.1290 - val_loss: 5.1681e-04 - val_mae: 0.0147\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0269 - mae: 0.1236 - val_loss: 7.0919e-04 - val_mae: 0.0186\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0325 - mae: 0.1334 - val_loss: 6.8356e-04 - val_mae: 0.0179\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0224 - mae: 0.1192 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0330 - mae: 0.1359 - val_loss: 4.7553e-04 - val_mae: 0.0148\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0258 - mae: 0.1257 - val_loss: 7.6918e-04 - val_mae: 0.0251\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0301 - mae: 0.1354 - val_loss: 0.0018 - val_mae: 0.0371\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0205 - mae: 0.1040 - val_loss: 5.1711e-04 - val_mae: 0.0147\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0230 - mae: 0.1136 - val_loss: 4.8766e-04 - val_mae: 0.0146\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0244 - mae: 0.1152 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0223 - mae: 0.1123 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0239 - mae: 0.1118 - val_loss: 9.1645e-04 - val_mae: 0.0231\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0199 - mae: 0.1093 - val_loss: 7.2483e-04 - val_mae: 0.0190\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0211 - mae: 0.1105 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0189 - mae: 0.1022 - val_loss: 0.0035 - val_mae: 0.0552\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0201 - mae: 0.1037 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0204 - mae: 0.1103 - val_loss: 5.3781e-04 - val_mae: 0.0150\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0166 - mae: 0.0955 - val_loss: 5.7098e-04 - val_mae: 0.0154\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0180 - mae: 0.1042 - val_loss: 5.5125e-04 - val_mae: 0.0184\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0145 - mae: 0.0905 - val_loss: 5.2091e-04 - val_mae: 0.0148\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0200 - mae: 0.1034 - val_loss: 5.5915e-04 - val_mae: 0.0153\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - mae: 0.0901 - val_loss: 7.1459e-04 - val_mae: 0.0187\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - mae: 0.0824 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - mae: 0.0859 - val_loss: 9.7031e-04 - val_mae: 0.0241\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0866 - val_loss: 6.3438e-04 - val_mae: 0.0165\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - mae: 0.0850 - val_loss: 7.5691e-04 - val_mae: 0.0198\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - mae: 0.0828 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - mae: 0.0834 - val_loss: 6.2244e-04 - val_mae: 0.0163\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.0884 - val_loss: 0.0019 - val_mae: 0.0381\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0847 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.0818 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0827 - val_loss: 0.0024 - val_mae: 0.0435\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0984 - val_loss: 0.0026 - val_mae: 0.0464\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0921 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0725 - val_loss: 7.2730e-04 - val_mae: 0.0191\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0911 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0873 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0761 - val_loss: 6.7047e-04 - val_mae: 0.0175\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0816 - val_loss: 0.0023 - val_mae: 0.0433\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0781 - val_loss: 7.4091e-04 - val_mae: 0.0194\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0737 - val_loss: 7.1818e-04 - val_mae: 0.0188\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0636 - val_loss: 8.7871e-04 - val_mae: 0.0224\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0672 - val_loss: 5.7568e-04 - val_mae: 0.0154\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0767 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0729 - val_loss: 7.2977e-04 - val_mae: 0.0191\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0723 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0609 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0697 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.0721 - val_loss: 4.9309e-04 - val_mae: 0.0155\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0709 - val_loss: 5.8774e-04 - val_mae: 0.0157\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0109 - mae: 0.0689 - val_loss: 7.3751e-04 - val_mae: 0.0193\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0100 - mae: 0.0651 - val_loss: 9.3878e-04 - val_mae: 0.0236\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - mae: 0.0562 - val_loss: 8.0578e-04 - val_mae: 0.0209\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - mae: 0.0558 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0614 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0576 - val_loss: 8.9418e-04 - val_mae: 0.0227\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0654 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0593 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - mae: 0.0548 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0647 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0547 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - mae: 0.0607 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0608 - val_loss: 9.8249e-04 - val_mae: 0.0243\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0083 - mae: 0.0624 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0593 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0564 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0612 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0590 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0606 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0549 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - mae: 0.0538 - val_loss: 7.7834e-04 - val_mae: 0.0203\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0468 - val_loss: 8.8951e-04 - val_mae: 0.0226\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - mae: 0.0492 - val_loss: 9.9446e-04 - val_mae: 0.0246\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0486 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0529 - val_loss: 7.7929e-04 - val_mae: 0.0203\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0557 - val_loss: 7.3767e-04 - val_mae: 0.0193\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0443 - val_loss: 6.8996e-04 - val_mae: 0.0181\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0443 - val_loss: 6.5289e-04 - val_mae: 0.0170\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0477 - val_loss: 9.3842e-04 - val_mae: 0.0235\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0459 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0499 - val_loss: 8.0615e-04 - val_mae: 0.0209\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0077 - mae: 0.0463 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0436 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - mae: 0.0502 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0080 - mae: 0.0541 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0059 - mae: 0.0460 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0064 - mae: 0.0511 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0078 - mae: 0.0520 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - mae: 0.0500 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0049 - mae: 0.0419 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0062 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0071 - mae: 0.0509 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0049 - mae: 0.0400 - val_loss: 8.3919e-04 - val_mae: 0.0216\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0059 - mae: 0.0459 - val_loss: 8.7271e-04 - val_mae: 0.0223\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0060 - mae: 0.0417 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0066 - mae: 0.0503 - val_loss: 9.4082e-04 - val_mae: 0.0236\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0061 - mae: 0.0399 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0062 - mae: 0.0427 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - mae: 0.0402 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - mae: 0.0360 - val_loss: 7.7421e-04 - val_mae: 0.0202\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0407 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0352 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0363 - val_loss: 9.1446e-04 - val_mae: 0.0230\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0440 - val_loss: 8.1049e-04 - val_mae: 0.0209\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0340 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0407 - val_loss: 8.6195e-04 - val_mae: 0.0220\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0438 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0407 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0413 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0412 - val_loss: 8.4497e-04 - val_mae: 0.0217\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0460 - val_loss: 8.6146e-04 - val_mae: 0.0221\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0427 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0389 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0418 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0388 - val_loss: 7.9718e-04 - val_mae: 0.0206\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0406 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0407 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0351 - val_loss: 9.5476e-04 - val_mae: 0.0239\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0365 - val_loss: 6.0421e-04 - val_mae: 0.0160\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0382 - val_loss: 8.5366e-04 - val_mae: 0.0219\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0353 - val_loss: 8.6891e-04 - val_mae: 0.0222\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0378 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0396 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0373 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0356 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - mae: 0.0401 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0368 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0348 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0385 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0350 - val_loss: 9.7004e-04 - val_mae: 0.0240\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0344 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0377 - val_loss: 9.2544e-04 - val_mae: 0.0233\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0379 - val_loss: 8.7446e-04 - val_mae: 0.0223\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0381 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0334 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0360 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0362 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0371 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0327 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0352 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0386 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0334 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0363 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0340 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0323 - val_loss: 9.4195e-04 - val_mae: 0.0236\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0332 - val_loss: 9.3236e-04 - val_mae: 0.0234\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0368 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0340 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0341 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0360 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0329 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0327 - val_loss: 9.6489e-04 - val_mae: 0.0240\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0320 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0354 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0342 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0329 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0316 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0331 - val_loss: 8.6137e-04 - val_mae: 0.0220\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0337 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0360 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0319 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0334 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0400 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0372 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0323 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0340 - val_loss: 0.0018 - val_mae: 0.0356\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0343 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0384 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0341 - val_loss: 8.5942e-04 - val_mae: 0.0220\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0348 - val_loss: 8.5402e-04 - val_mae: 0.0219\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0341 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0322 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0343 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0319 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0294 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0299 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0322 - val_loss: 9.8867e-04 - val_mae: 0.0244\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0317 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0289 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0299 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0315 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0283 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0310 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0314 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0328 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0303 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0307 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0323 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0286 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0307 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0272 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0295 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0282 - val_loss: 0.0016 - val_mae: 0.0328\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0335 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0303 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0338 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0258 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0307 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0301 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0306 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0266 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0291 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0268 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0294 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0279 - val_loss: 0.0016 - val_mae: 0.0328\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0300 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0295 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0261 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0274 - val_loss: 0.0019 - val_mae: 0.0370\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0299 - val_loss: 0.0022 - val_mae: 0.0409\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0020 - val_mae: 0.0384\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0307 - val_loss: 0.0018 - val_mae: 0.0356\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0257 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0303 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0313 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0298 - val_loss: 0.0033 - val_mae: 0.0529\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0303 - val_loss: 0.0028 - val_mae: 0.0486\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0304 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0302 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0271 - val_loss: 0.0021 - val_mae: 0.0403\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0277 - val_loss: 0.0021 - val_mae: 0.0397\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0376 - val_loss: 0.0048 - val_mae: 0.0659\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0333 - val_loss: 0.0023 - val_mae: 0.0426\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0349 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0358 - val_loss: 0.0025 - val_mae: 0.0450\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0359 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0330 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0305 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0040 - mae: 0.0307 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0301 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0038 - mae: 0.0273 - val_loss: 0.0030 - val_mae: 0.0501\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 0.0035 - val_mae: 0.0547\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0308 - val_loss: 0.0024 - val_mae: 0.0443\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0038 - mae: 0.0273 - val_loss: 0.0026 - val_mae: 0.0465\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0323 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0040 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0294 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0263 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0287 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 0.0023 - val_mae: 0.0422\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0267 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0038 - mae: 0.0279 - val_loss: 0.0030 - val_mae: 0.0507\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0276 - val_loss: 0.0036 - val_mae: 0.0557\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0037 - mae: 0.0297 - val_loss: 0.0031 - val_mae: 0.0512\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0033 - mae: 0.0283 - val_loss: 0.0033 - val_mae: 0.0530\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0320 - val_loss: 0.0024 - val_mae: 0.0437\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0298 - val_loss: 0.0030 - val_mae: 0.0503\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0321 - val_loss: 0.0022 - val_mae: 0.0418\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0296 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0039 - mae: 0.0286 - val_loss: 0.0018 - val_mae: 0.0369\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.0018 - val_mae: 0.0357\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0282 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0264 - val_loss: 0.0030 - val_mae: 0.0499\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0287 - val_loss: 0.0031 - val_mae: 0.0514\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0323 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0273 - val_loss: 0.0018 - val_mae: 0.0371\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0286 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0033 - mae: 0.0281 - val_loss: 0.0028 - val_mae: 0.0484\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0291 - val_loss: 0.0032 - val_mae: 0.0520\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0036 - mae: 0.0254 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0274 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0036 - mae: 0.0299 - val_loss: 0.0032 - val_mae: 0.0519\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0299 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0261 - val_loss: 0.0034 - val_mae: 0.0545\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0033 - mae: 0.0319 - val_loss: 0.0032 - val_mae: 0.0525\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0300 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0035 - mae: 0.0310 - val_loss: 0.0044 - val_mae: 0.0625\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0032 - mae: 0.0260 - val_loss: 0.0030 - val_mae: 0.0500\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0301 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0314 - val_loss: 0.0032 - val_mae: 0.0519\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0348 - val_loss: 0.0031 - val_mae: 0.0514\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0328 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0273 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0301 - val_loss: 0.0036 - val_mae: 0.0555\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0256 - val_loss: 0.0032 - val_mae: 0.0521\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0285 - val_loss: 0.0024 - val_mae: 0.0436\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0270 - val_loss: 0.0028 - val_mae: 0.0478\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0276 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0271 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0283 - val_loss: 0.0035 - val_mae: 0.0554\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0035 - mae: 0.0286 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0277 - val_loss: 0.0024 - val_mae: 0.0435\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0318 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0033 - mae: 0.0269 - val_loss: 0.0033 - val_mae: 0.0530\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0035 - mae: 0.0293 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0291 - val_loss: 0.0026 - val_mae: 0.0459\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0035 - mae: 0.0334 - val_loss: 0.0047 - val_mae: 0.0651\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0370 - val_loss: 0.0025 - val_mae: 0.0450\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0372 - val_loss: 0.0037 - val_mae: 0.0565\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0297 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0324 - val_loss: 0.0034 - val_mae: 0.0540\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0036 - mae: 0.0315 - val_loss: 0.0025 - val_mae: 0.0445\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0278 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0034 - mae: 0.0258 - val_loss: 0.0026 - val_mae: 0.0466\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0036 - mae: 0.0296 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0036 - mae: 0.0296 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0303 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0255 - val_loss: 0.0021 - val_mae: 0.0408\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0252 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0249 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0033 - mae: 0.0274 - val_loss: 0.0029 - val_mae: 0.0489\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0039 - mae: 0.0274 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0034 - mae: 0.0265 - val_loss: 0.0032 - val_mae: 0.0527\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0033 - mae: 0.0283 - val_loss: 0.0027 - val_mae: 0.0470\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0035 - mae: 0.0283 - val_loss: 0.0028 - val_mae: 0.0481\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0037 - mae: 0.0322 - val_loss: 0.0029 - val_mae: 0.0490\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0305 - val_loss: 0.0019 - val_mae: 0.0373\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0297 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0036 - mae: 0.0270 - val_loss: 0.0027 - val_mae: 0.0475\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0327 - val_loss: 0.0035 - val_mae: 0.0552\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_64\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_648 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_584 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_649 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_585 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_650 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_586 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_651 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_587 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_652 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_588 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_653 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_589 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_654 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_590 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_655 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_591 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_656 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_592 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_657 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_593 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_658 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_594 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_659 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 23ms/step - loss: 0.1965 - mae: 0.3404 - val_loss: 5.0180e-04 - val_mae: 0.0179\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1429 - mae: 0.2883 - val_loss: 0.0014 - val_mae: 0.0315\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0914 - mae: 0.2353 - val_loss: 0.0034 - val_mae: 0.0551\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0772 - mae: 0.2229 - val_loss: 6.8756e-04 - val_mae: 0.0202\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0624 - mae: 0.2049 - val_loss: 0.0162 - val_mae: 0.1257\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0588 - mae: 0.1982 - val_loss: 4.7128e-04 - val_mae: 0.0147\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0622 - mae: 0.1950 - val_loss: 4.0046e-04 - val_mae: 0.0143\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0487 - mae: 0.1687 - val_loss: 0.0081 - val_mae: 0.0878\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0481 - mae: 0.1756 - val_loss: 0.0063 - val_mae: 0.0768\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0452 - mae: 0.1627 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0315 - mae: 0.1400 - val_loss: 4.8669e-04 - val_mae: 0.0151\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0443 - mae: 0.1568 - val_loss: 0.0036 - val_mae: 0.0558\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0356 - mae: 0.1459 - val_loss: 5.2968e-04 - val_mae: 0.0145\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0402 - mae: 0.1499 - val_loss: 6.6802e-04 - val_mae: 0.0173\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - mae: 0.1284 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0252 - mae: 0.1185 - val_loss: 0.0021 - val_mae: 0.0401\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0320 - mae: 0.1337 - val_loss: 5.3958e-04 - val_mae: 0.0148\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0284 - mae: 0.1309 - val_loss: 5.2216e-04 - val_mae: 0.0146\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.1209 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0266 - mae: 0.1165 - val_loss: 5.0430e-04 - val_mae: 0.0146\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0368 - mae: 0.1421 - val_loss: 4.7951e-04 - val_mae: 0.0151\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0217 - mae: 0.1148 - val_loss: 5.2449e-04 - val_mae: 0.0149\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0227 - mae: 0.1127 - val_loss: 8.3071e-04 - val_mae: 0.0215\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0220 - mae: 0.1075 - val_loss: 4.7461e-04 - val_mae: 0.0149\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - mae: 0.1024 - val_loss: 4.8251e-04 - val_mae: 0.0146\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.1114 - val_loss: 0.0020 - val_mae: 0.0386\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - mae: 0.0858 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0236 - mae: 0.1100 - val_loss: 5.1900e-04 - val_mae: 0.0150\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0179 - mae: 0.1001 - val_loss: 5.7044e-04 - val_mae: 0.0179\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0159 - mae: 0.0981 - val_loss: 9.6400e-04 - val_mae: 0.0239\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0203 - mae: 0.1066 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0211 - mae: 0.0995 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - mae: 0.0906 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0182 - mae: 0.0975 - val_loss: 5.5238e-04 - val_mae: 0.0146\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - mae: 0.1072 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0138 - mae: 0.0858 - val_loss: 0.0023 - val_mae: 0.0420\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - mae: 0.0896 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - mae: 0.0937 - val_loss: 9.8160e-04 - val_mae: 0.0241\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - mae: 0.0850 - val_loss: 8.9302e-04 - val_mae: 0.0222\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.0778 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0842 - val_loss: 7.7342e-04 - val_mae: 0.0202\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0140 - mae: 0.0808 - val_loss: 7.9966e-04 - val_mae: 0.0205\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0828 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - mae: 0.0809 - val_loss: 6.2071e-04 - val_mae: 0.0163\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0770 - val_loss: 9.1080e-04 - val_mae: 0.0232\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0708 - val_loss: 9.3739e-04 - val_mae: 0.0236\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - mae: 0.0783 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.0741 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - mae: 0.0768 - val_loss: 9.9971e-04 - val_mae: 0.0248\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0114 - mae: 0.0742 - val_loss: 8.0462e-04 - val_mae: 0.0210\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0097 - mae: 0.0677 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0122 - mae: 0.0727 - val_loss: 6.7637e-04 - val_mae: 0.0176\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - mae: 0.0599 - val_loss: 7.8683e-04 - val_mae: 0.0204\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0119 - mae: 0.0671 - val_loss: 7.4245e-04 - val_mae: 0.0191\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0103 - mae: 0.0647 - val_loss: 6.0048e-04 - val_mae: 0.0158\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0091 - mae: 0.0615 - val_loss: 8.0593e-04 - val_mae: 0.0205\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - mae: 0.0632 - val_loss: 8.3936e-04 - val_mae: 0.0213\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - mae: 0.0648 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0641 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - mae: 0.0709 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0077 - mae: 0.0620 - val_loss: 8.9801e-04 - val_mae: 0.0223\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0109 - mae: 0.0703 - val_loss: 0.0014 - val_mae: 0.0298\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0619 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0614 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0598 - val_loss: 0.0017 - val_mae: 0.0342\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0583 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0551 - val_loss: 9.1934e-04 - val_mae: 0.0231\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0538 - val_loss: 6.6016e-04 - val_mae: 0.0173\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0579 - val_loss: 7.2024e-04 - val_mae: 0.0191\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0592 - val_loss: 0.0020 - val_mae: 0.0385\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - mae: 0.0664 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0527 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.0627 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0540 - val_loss: 9.8416e-04 - val_mae: 0.0240\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - mae: 0.0586 - val_loss: 7.7664e-04 - val_mae: 0.0202\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0485 - val_loss: 9.3039e-04 - val_mae: 0.0234\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0582 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0527 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - mae: 0.0507 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0523 - val_loss: 6.9103e-04 - val_mae: 0.0179\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0510 - val_loss: 9.5868e-04 - val_mae: 0.0237\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0528 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0450 - val_loss: 9.8934e-04 - val_mae: 0.0243\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0448 - val_loss: 7.3011e-04 - val_mae: 0.0191\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0503 - val_loss: 9.9486e-04 - val_mae: 0.0246\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0559 - val_loss: 8.6803e-04 - val_mae: 0.0223\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0530 - val_loss: 9.1116e-04 - val_mae: 0.0230\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0513 - val_loss: 8.6102e-04 - val_mae: 0.0221\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0483 - val_loss: 8.6882e-04 - val_mae: 0.0222\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0521 - val_loss: 6.9989e-04 - val_mae: 0.0181\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0445 - val_loss: 7.7627e-04 - val_mae: 0.0201\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0505 - val_loss: 7.4710e-04 - val_mae: 0.0192\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0404 - val_loss: 6.4725e-04 - val_mae: 0.0166\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0458 - val_loss: 8.9520e-04 - val_mae: 0.0225\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0538 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0471 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0462 - val_loss: 8.6873e-04 - val_mae: 0.0219\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - mae: 0.0504 - val_loss: 9.5155e-04 - val_mae: 0.0235\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0428 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0405 - val_loss: 9.3839e-04 - val_mae: 0.0234\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - mae: 0.0446 - val_loss: 8.1680e-04 - val_mae: 0.0209\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0469 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0410 - val_loss: 8.4789e-04 - val_mae: 0.0215\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0406 - val_loss: 0.0010 - val_mae: 0.0246\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0405 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0470 - val_loss: 9.7731e-04 - val_mae: 0.0243\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0453 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0409 - val_loss: 7.7493e-04 - val_mae: 0.0200\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0450 - val_loss: 8.9071e-04 - val_mae: 0.0224\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0430 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0435 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0354 - val_loss: 9.9742e-04 - val_mae: 0.0243\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0405 - val_loss: 9.5786e-04 - val_mae: 0.0236\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0425 - val_loss: 8.3859e-04 - val_mae: 0.0213\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0403 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0406 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0384 - val_loss: 8.6659e-04 - val_mae: 0.0221\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0400 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0388 - val_loss: 9.6441e-04 - val_mae: 0.0237\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0425 - val_loss: 8.5546e-04 - val_mae: 0.0215\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0422 - val_loss: 9.4006e-04 - val_mae: 0.0233\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0419 - val_loss: 9.6192e-04 - val_mae: 0.0238\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0443 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0357 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0398 - val_loss: 9.4504e-04 - val_mae: 0.0236\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0399 - val_loss: 8.8671e-04 - val_mae: 0.0225\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0437 - val_loss: 8.4669e-04 - val_mae: 0.0217\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0374 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0366 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0368 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0343 - val_loss: 9.9742e-04 - val_mae: 0.0246\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0053 - mae: 0.0361 - val_loss: 9.7635e-04 - val_mae: 0.0242\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - mae: 0.0396 - val_loss: 8.4552e-04 - val_mae: 0.0217\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0055 - mae: 0.0346 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0055 - mae: 0.0384 - val_loss: 8.5233e-04 - val_mae: 0.0218\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0380 - val_loss: 7.9010e-04 - val_mae: 0.0204\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0348 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0052 - mae: 0.0355 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0396 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0342 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0053 - mae: 0.0344 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0362 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0050 - mae: 0.0335 - val_loss: 0.0012 - val_mae: 0.0270\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0050 - mae: 0.0359 - val_loss: 8.5140e-04 - val_mae: 0.0217\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0341 - val_loss: 9.4631e-04 - val_mae: 0.0236\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0334 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0303 - val_loss: 9.3861e-04 - val_mae: 0.0234\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0354 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0360 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0324 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0347 - val_loss: 9.4546e-04 - val_mae: 0.0236\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0339 - val_loss: 9.5501e-04 - val_mae: 0.0238\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0318 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0358 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0351 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0330 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0328 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0345 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0328 - val_loss: 9.5224e-04 - val_mae: 0.0237\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0337 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0351 - val_loss: 8.8401e-04 - val_mae: 0.0224\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0346 - val_loss: 8.9319e-04 - val_mae: 0.0225\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0312 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0317 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0303 - val_loss: 9.4352e-04 - val_mae: 0.0235\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0315 - val_loss: 8.6816e-04 - val_mae: 0.0220\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0320 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0332 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0327 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0309 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0324 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0270\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0281 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0303 - val_loss: 0.0011 - val_mae: 0.0253\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0291 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0299 - val_loss: 0.0017 - val_mae: 0.0342\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0301 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0348 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0306 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0320 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0342 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0300 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0277 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0293 - val_loss: 0.0016 - val_mae: 0.0327\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0308 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0309 - val_loss: 0.0017 - val_mae: 0.0342\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0299\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 0.0016 - val_mae: 0.0326\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0279 - val_loss: 0.0019 - val_mae: 0.0381\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0318 - val_loss: 0.0018 - val_mae: 0.0358\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0323 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0284 - val_loss: 0.0018 - val_mae: 0.0364\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0335 - val_loss: 0.0021 - val_mae: 0.0396\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0301 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0322 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0299 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0309 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0287 - val_loss: 0.0018 - val_mae: 0.0365\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0300 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0314 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0307 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0283 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0272 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0293 - val_loss: 0.0018 - val_mae: 0.0357\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0304 - val_loss: 0.0024 - val_mae: 0.0432\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0340 - val_loss: 0.0027 - val_mae: 0.0467\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0278 - val_loss: 0.0024 - val_mae: 0.0435\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0299 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0304 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0035 - mae: 0.0265 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0305 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0050 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 9.6617e-04 - val_mae: 0.0240\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 9.6970e-04 - val_mae: 0.0241\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0256 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0297 - val_loss: 9.4646e-04 - val_mae: 0.0237\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0241 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 9.6646e-04 - val_mae: 0.0241\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0246 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 0.0018 - val_mae: 0.0358\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0297 - val_loss: 9.9243e-04 - val_mae: 0.0245\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0294 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0241 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0248 - val_loss: 0.0019 - val_mae: 0.0371\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 0.0016 - val_mae: 0.0328\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0250 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0276 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0256 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0238 - val_loss: 0.0018 - val_mae: 0.0357\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0040 - mae: 0.0251 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0260 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0252 - val_loss: 0.0029 - val_mae: 0.0487\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0342 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0282 - val_loss: 0.0022 - val_mae: 0.0409\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0269 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0255 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0258 - val_loss: 0.0020 - val_mae: 0.0384\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0267 - val_loss: 0.0019 - val_mae: 0.0371\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0275 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0040 - mae: 0.0250 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0276 - val_loss: 0.0027 - val_mae: 0.0466\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0036 - mae: 0.0287 - val_loss: 0.0026 - val_mae: 0.0457\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0039 - mae: 0.0307 - val_loss: 0.0033 - val_mae: 0.0527\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0034 - mae: 0.0270 - val_loss: 0.0025 - val_mae: 0.0445\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0327 - val_loss: 0.0018 - val_mae: 0.0357\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0037 - mae: 0.0273 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0314 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0042 - mae: 0.0321 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0040 - mae: 0.0277 - val_loss: 0.0027 - val_mae: 0.0477\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0041 - mae: 0.0256 - val_loss: 0.0021 - val_mae: 0.0402\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0035 - mae: 0.0242 - val_loss: 0.0025 - val_mae: 0.0456\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0039 - mae: 0.0264 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0036 - mae: 0.0260 - val_loss: 0.0024 - val_mae: 0.0435\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0035 - mae: 0.0273 - val_loss: 0.0023 - val_mae: 0.0426\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0310 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0306 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0285 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0269 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 0.0021 - val_mae: 0.0405\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0264 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0250 - val_loss: 0.0021 - val_mae: 0.0398\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0283 - val_loss: 0.0027 - val_mae: 0.0474\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0289 - val_loss: 0.0027 - val_mae: 0.0469\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0039 - mae: 0.0286 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0036 - mae: 0.0285 - val_loss: 0.0032 - val_mae: 0.0520\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0036 - mae: 0.0255 - val_loss: 0.0026 - val_mae: 0.0467\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0329 - val_loss: 0.0028 - val_mae: 0.0480\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0260 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0039 - mae: 0.0265 - val_loss: 0.0023 - val_mae: 0.0426\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0033 - mae: 0.0278 - val_loss: 0.0031 - val_mae: 0.0517\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0300 - val_loss: 0.0032 - val_mae: 0.0525\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0351 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0287 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0271 - val_loss: 0.0021 - val_mae: 0.0405\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0320 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0338 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0250 - val_loss: 0.0028 - val_mae: 0.0482\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0284 - val_loss: 0.0025 - val_mae: 0.0452\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0265 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0296 - val_loss: 0.0026 - val_mae: 0.0457\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0289 - val_loss: 0.0024 - val_mae: 0.0443\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0357 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0324 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0251 - val_loss: 0.0027 - val_mae: 0.0470\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0239 - val_loss: 0.0021 - val_mae: 0.0403\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0037 - mae: 0.0270 - val_loss: 0.0032 - val_mae: 0.0518\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0266 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0273 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0269 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0252 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0256 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0247 - val_loss: 0.0026 - val_mae: 0.0461\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0275 - val_loss: 0.0026 - val_mae: 0.0466\n",
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_65\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_660 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_595 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_661 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_596 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_662 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_597 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_663 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_598 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_664 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_599 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_665 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_600 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_666 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_601 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_667 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_602 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_668 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_603 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_669 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_604 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_670 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_605 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_671 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 4s 34ms/step - loss: 0.1613 - mae: 0.3138 - val_loss: 0.0065 - val_mae: 0.0780\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1208 - mae: 0.2704 - val_loss: 0.0188 - val_mae: 0.1354\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0911 - mae: 0.2425 - val_loss: 0.0066 - val_mae: 0.0783\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0883 - mae: 0.2418 - val_loss: 0.0022 - val_mae: 0.0445\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0848 - mae: 0.2310 - val_loss: 6.8080e-04 - val_mae: 0.0179\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0570 - mae: 0.1926 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0889 - mae: 0.2397 - val_loss: 5.6229e-04 - val_mae: 0.0153\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0411 - mae: 0.1611 - val_loss: 0.0082 - val_mae: 0.0878\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0633 - mae: 0.2032 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0386 - mae: 0.1558 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0559 - mae: 0.1874 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0364 - mae: 0.1481 - val_loss: 5.9256e-04 - val_mae: 0.0197\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0532 - mae: 0.1810 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0359 - mae: 0.1498 - val_loss: 4.9232e-04 - val_mae: 0.0153\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0343 - mae: 0.1463 - val_loss: 4.7558e-04 - val_mae: 0.0149\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0406 - mae: 0.1507 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0245 - mae: 0.1245 - val_loss: 5.4180e-04 - val_mae: 0.0149\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0329 - mae: 0.1415 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0288 - mae: 0.1292 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0340 - mae: 0.1316 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - mae: 0.1016 - val_loss: 9.6812e-04 - val_mae: 0.0243\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0214 - mae: 0.1107 - val_loss: 7.5246e-04 - val_mae: 0.0199\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - mae: 0.1117 - val_loss: 4.8037e-04 - val_mae: 0.0147\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0217 - mae: 0.1100 - val_loss: 6.5044e-04 - val_mae: 0.0222\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0298 - mae: 0.1300 - val_loss: 5.3012e-04 - val_mae: 0.0151\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0195 - mae: 0.1023 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 0.1112 - val_loss: 4.3092e-04 - val_mae: 0.0149\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - mae: 0.1106 - val_loss: 5.0553e-04 - val_mae: 0.0148\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - mae: 0.0959 - val_loss: 0.0018 - val_mae: 0.0375\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0219 - mae: 0.1070 - val_loss: 0.0017 - val_mae: 0.0358\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - mae: 0.1037 - val_loss: 0.0043 - val_mae: 0.0622\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0962 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0209 - mae: 0.1076 - val_loss: 7.9931e-04 - val_mae: 0.0210\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0153 - mae: 0.0911 - val_loss: 6.0086e-04 - val_mae: 0.0160\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0196 - mae: 0.1009 - val_loss: 5.7936e-04 - val_mae: 0.0157\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0955 - val_loss: 7.4842e-04 - val_mae: 0.0198\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0949 - val_loss: 5.4890e-04 - val_mae: 0.0152\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0157 - mae: 0.0911 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0782 - val_loss: 8.9631e-04 - val_mae: 0.0225\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0876 - val_loss: 5.6046e-04 - val_mae: 0.0152\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0985 - val_loss: 8.9108e-04 - val_mae: 0.0226\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0131 - mae: 0.0805 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0641 - val_loss: 6.4923e-04 - val_mae: 0.0169\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - mae: 0.0882 - val_loss: 5.2260e-04 - val_mae: 0.0148\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.0769 - val_loss: 8.4062e-04 - val_mae: 0.0217\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0152 - mae: 0.0801 - val_loss: 0.0018 - val_mae: 0.0357\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - mae: 0.0805 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - mae: 0.0813 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0960 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0709 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0702 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0776 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - mae: 0.0739 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - mae: 0.0768 - val_loss: 6.7847e-04 - val_mae: 0.0175\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - mae: 0.0707 - val_loss: 7.6067e-04 - val_mae: 0.0195\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0774 - val_loss: 5.1732e-04 - val_mae: 0.0145\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0706 - val_loss: 5.5385e-04 - val_mae: 0.0180\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0682 - val_loss: 6.9156e-04 - val_mae: 0.0179\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0098 - mae: 0.0593 - val_loss: 9.4972e-04 - val_mae: 0.0236\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - mae: 0.0657 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0654 - val_loss: 7.6049e-04 - val_mae: 0.0197\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0618 - val_loss: 7.3249e-04 - val_mae: 0.0191\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0671 - val_loss: 8.3843e-04 - val_mae: 0.0216\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0556 - val_loss: 8.0721e-04 - val_mae: 0.0209\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - mae: 0.0746 - val_loss: 7.2584e-04 - val_mae: 0.0189\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0618 - val_loss: 8.2717e-04 - val_mae: 0.0212\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0587 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0598 - val_loss: 7.4264e-04 - val_mae: 0.0193\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0679 - val_loss: 6.0352e-04 - val_mae: 0.0159\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0628 - val_loss: 7.5401e-04 - val_mae: 0.0195\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0630 - val_loss: 7.8891e-04 - val_mae: 0.0204\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - mae: 0.0663 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0624 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0578 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0625 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0659 - val_loss: 8.0679e-04 - val_mae: 0.0209\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0535 - val_loss: 6.1800e-04 - val_mae: 0.0162\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0592 - val_loss: 8.1073e-04 - val_mae: 0.0212\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0603 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0080 - mae: 0.0543 - val_loss: 9.4164e-04 - val_mae: 0.0237\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - mae: 0.0551 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0084 - mae: 0.0521 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0072 - mae: 0.0491 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - mae: 0.0487 - val_loss: 7.7050e-04 - val_mae: 0.0204\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0091 - mae: 0.0567 - val_loss: 5.3993e-04 - val_mae: 0.0152\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - mae: 0.0469 - val_loss: 5.6596e-04 - val_mae: 0.0154\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0056 - mae: 0.0458 - val_loss: 8.0430e-04 - val_mae: 0.0210\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0076 - mae: 0.0540 - val_loss: 8.1926e-04 - val_mae: 0.0212\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0074 - mae: 0.0572 - val_loss: 0.0010 - val_mae: 0.0246\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0473 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - mae: 0.0500 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - mae: 0.0512 - val_loss: 8.0863e-04 - val_mae: 0.0209\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0490 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0511 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0480 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0472 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0467 - val_loss: 5.3265e-04 - val_mae: 0.0149\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0477 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0456 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0474 - val_loss: 8.8784e-04 - val_mae: 0.0226\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0484 - val_loss: 7.5919e-04 - val_mae: 0.0199\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0442 - val_loss: 9.6747e-04 - val_mae: 0.0242\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0488 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0483 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - mae: 0.0509 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0490 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - mae: 0.0440 - val_loss: 7.2465e-04 - val_mae: 0.0187\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0499 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0437 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0436 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0418 - val_loss: 8.8250e-04 - val_mae: 0.0225\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0437 - val_loss: 8.9691e-04 - val_mae: 0.0228\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0449 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0416 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0417 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0515 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0446 - val_loss: 9.8123e-04 - val_mae: 0.0243\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0352 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0419 - val_loss: 8.8910e-04 - val_mae: 0.0225\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0443 - val_loss: 9.4199e-04 - val_mae: 0.0236\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0441 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0408 - val_loss: 9.9358e-04 - val_mae: 0.0246\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0419 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0398 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0405 - val_loss: 9.7361e-04 - val_mae: 0.0241\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0396 - val_loss: 9.2383e-04 - val_mae: 0.0232\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0393 - val_loss: 9.9640e-04 - val_mae: 0.0246\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - mae: 0.0447 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0399 - val_loss: 8.5014e-04 - val_mae: 0.0217\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0346 - val_loss: 7.8416e-04 - val_mae: 0.0203\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0363 - val_loss: 7.7232e-04 - val_mae: 0.0200\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0428 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0360 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0408 - val_loss: 8.5600e-04 - val_mae: 0.0219\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0362 - val_loss: 9.6129e-04 - val_mae: 0.0240\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0373 - val_loss: 6.0373e-04 - val_mae: 0.0160\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0418 - val_loss: 9.9040e-04 - val_mae: 0.0245\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0339 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0393 - val_loss: 9.0770e-04 - val_mae: 0.0229\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0408 - val_loss: 8.5403e-04 - val_mae: 0.0219\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0398 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0325 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0376 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0390 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0370 - val_loss: 9.3419e-04 - val_mae: 0.0234\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0385 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0333 - val_loss: 9.8290e-04 - val_mae: 0.0243\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0359 - val_loss: 8.5189e-04 - val_mae: 0.0218\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0363 - val_loss: 8.0011e-04 - val_mae: 0.0207\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0347 - val_loss: 7.6133e-04 - val_mae: 0.0198\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0346 - val_loss: 8.8764e-04 - val_mae: 0.0225\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0389 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0382 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0384 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0370 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0303 - val_loss: 9.1114e-04 - val_mae: 0.0230\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0343 - val_loss: 7.6949e-04 - val_mae: 0.0200\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0333 - val_loss: 9.1420e-04 - val_mae: 0.0230\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0361 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0342 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0333 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0323 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0409 - val_loss: 5.0874e-04 - val_mae: 0.0145\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0054 - mae: 0.0411 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - mae: 0.0373 - val_loss: 7.9048e-04 - val_mae: 0.0204\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - mae: 0.0420 - val_loss: 8.7879e-04 - val_mae: 0.0223\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0053 - mae: 0.0368 - val_loss: 9.8145e-04 - val_mae: 0.0243\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0323 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0054 - mae: 0.0328 - val_loss: 7.8621e-04 - val_mae: 0.0204\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0346 - val_loss: 8.1151e-04 - val_mae: 0.0209\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0315 - val_loss: 7.9034e-04 - val_mae: 0.0205\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0330 - val_loss: 7.0627e-04 - val_mae: 0.0185\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 8.2894e-04 - val_mae: 0.0214\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0328 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0342 - val_loss: 6.5717e-04 - val_mae: 0.0172\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0319 - val_loss: 7.6026e-04 - val_mae: 0.0199\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0388 - val_loss: 6.2634e-04 - val_mae: 0.0164\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0361 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0314 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0344 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0310 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0316 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0330 - val_loss: 8.8153e-04 - val_mae: 0.0224\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0373 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0303 - val_loss: 9.9840e-04 - val_mae: 0.0247\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0307 - val_loss: 9.1560e-04 - val_mae: 0.0231\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0324 - val_loss: 9.9493e-04 - val_mae: 0.0246\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0321 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0332 - val_loss: 9.2537e-04 - val_mae: 0.0233\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0321 - val_loss: 9.3832e-04 - val_mae: 0.0235\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0292 - val_loss: 9.4401e-04 - val_mae: 0.0237\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0288 - val_loss: 9.5584e-04 - val_mae: 0.0239\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0312 - val_loss: 8.1368e-04 - val_mae: 0.0210\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0318 - val_loss: 9.1767e-04 - val_mae: 0.0232\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 9.2545e-04 - val_mae: 0.0233\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0306 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0315 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 8.7499e-04 - val_mae: 0.0223\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0295 - val_loss: 7.5286e-04 - val_mae: 0.0197\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0310 - val_loss: 9.6417e-04 - val_mae: 0.0241\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 8.6699e-04 - val_mae: 0.0222\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0300 - val_loss: 8.9742e-04 - val_mae: 0.0228\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0334 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0301 - val_loss: 9.1340e-04 - val_mae: 0.0231\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0302 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0325 - val_loss: 9.7451e-04 - val_mae: 0.0242\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0278 - val_loss: 8.6711e-04 - val_mae: 0.0222\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0305 - val_loss: 9.8376e-04 - val_mae: 0.0244\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0298 - val_loss: 7.3687e-04 - val_mae: 0.0194\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 9.3539e-04 - val_mae: 0.0235\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0364 - val_loss: 5.4194e-04 - val_mae: 0.0151\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0376 - val_loss: 8.8803e-04 - val_mae: 0.0226\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0299 - val_loss: 9.7577e-04 - val_mae: 0.0242\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 9.8330e-04 - val_mae: 0.0244\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0301 - val_loss: 9.4107e-04 - val_mae: 0.0236\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0303 - val_loss: 9.1468e-04 - val_mae: 0.0231\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0289 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0272 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.6472e-04 - val_mae: 0.0240\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0272 - val_loss: 9.4489e-04 - val_mae: 0.0237\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 9.4813e-04 - val_mae: 0.0237\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0254 - val_loss: 9.7916e-04 - val_mae: 0.0243\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 8.8023e-04 - val_mae: 0.0225\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0296 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0300 - val_loss: 8.4742e-04 - val_mae: 0.0218\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 8.8939e-04 - val_mae: 0.0226\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 9.3843e-04 - val_mae: 0.0236\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 9.4611e-04 - val_mae: 0.0237\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0047 - mae: 0.0293 - val_loss: 9.7493e-04 - val_mae: 0.0242\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 9.5750e-04 - val_mae: 0.0239\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0263 - val_loss: 9.2259e-04 - val_mae: 0.0233\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0280 - val_loss: 9.4990e-04 - val_mae: 0.0238\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 8.9843e-04 - val_mae: 0.0228\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.9223e-04 - val_mae: 0.0245\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0260 - val_loss: 9.8964e-04 - val_mae: 0.0245\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0301 - val_loss: 5.7505e-04 - val_mae: 0.0155\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0316 - val_loss: 8.2261e-04 - val_mae: 0.0213\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0305 - val_loss: 9.4890e-04 - val_mae: 0.0238\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.3161e-04 - val_mae: 0.0235\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 9.6083e-04 - val_mae: 0.0240\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.4307e-04 - val_mae: 0.0237\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0245 - val_loss: 8.5735e-04 - val_mae: 0.0220\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0287 - val_loss: 9.2276e-04 - val_mae: 0.0233\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.6716e-04 - val_mae: 0.0241\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0269 - val_loss: 8.7912e-04 - val_mae: 0.0225\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0234 - val_loss: 9.5051e-04 - val_mae: 0.0238\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0250 - val_loss: 9.5914e-04 - val_mae: 0.0240\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0283 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0287 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0291 - val_loss: 8.2147e-04 - val_mae: 0.0213\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0241 - val_loss: 8.7419e-04 - val_mae: 0.0224\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0237 - val_loss: 9.5187e-04 - val_mae: 0.0238\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 9.1223e-04 - val_mae: 0.0231\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.7347e-04 - val_mae: 0.0242\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0395 - val_loss: 9.2510e-04 - val_mae: 0.0234\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0296 - val_loss: 0.0018 - val_mae: 0.0371\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0338 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0345 - val_loss: 9.3152e-04 - val_mae: 0.0234\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0304 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0310 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0278 - val_loss: 9.5322e-04 - val_mae: 0.0238\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0299 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0296 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0260 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0040 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0254 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0246 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0373 - val_loss: 7.7064e-04 - val_mae: 0.0201\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0349 - val_loss: 0.0019 - val_mae: 0.0383\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0291 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0253 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 0.0017 - val_mae: 0.0356\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0040 - mae: 0.0257 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0316 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0269 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0301 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0276 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0037 - mae: 0.0213 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0279 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0261 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0279 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0302 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0246 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0315 - val_loss: 0.0025 - val_mae: 0.0455\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0284 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0354 - val_loss: 0.0016 - val_mae: 0.0343\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0309 - val_loss: 0.0026 - val_mae: 0.0463\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0290 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0266 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0034 - mae: 0.0269 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0335 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 0.0022 - val_mae: 0.0411\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0246 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0251 - val_loss: 0.0022 - val_mae: 0.0422\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0259 - val_loss: 0.0031 - val_mae: 0.0509\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0280 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0278 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "3/3 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_66\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_672 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_606 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_673 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_607 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_674 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_608 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_675 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_609 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_676 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_610 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_677 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_611 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_678 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_612 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_679 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_613 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_680 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_614 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_681 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_615 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_682 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_616 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_683 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 23ms/step - loss: 5.0847 - mae: 1.6566 - val_loss: 0.0939 - val_mae: 0.3058\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4790 - mae: 0.8262 - val_loss: 0.0149 - val_mae: 0.1197\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5088 - mae: 0.5827 - val_loss: 0.0097 - val_mae: 0.0959\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7135 - mae: 0.5232 - val_loss: 0.0128 - val_mae: 0.1111\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2309 - mae: 0.3319 - val_loss: 0.0096 - val_mae: 0.0954\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2950 - mae: 0.4223 - val_loss: 0.0101 - val_mae: 0.0979\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2233 - mae: 0.3314 - val_loss: 0.0077 - val_mae: 0.0850\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1426 - mae: 0.2712 - val_loss: 0.0070 - val_mae: 0.0807\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1799 - mae: 0.2921 - val_loss: 0.0061 - val_mae: 0.0749\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1077 - mae: 0.2429 - val_loss: 0.0061 - val_mae: 0.0748\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1499 - mae: 0.2608 - val_loss: 0.0058 - val_mae: 0.0730\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1686 - mae: 0.2862 - val_loss: 0.0050 - val_mae: 0.0676\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1046 - mae: 0.2023 - val_loss: 0.0040 - val_mae: 0.0596\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0782 - mae: 0.1852 - val_loss: 0.0048 - val_mae: 0.0663\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0535 - mae: 0.1696 - val_loss: 0.0050 - val_mae: 0.0675\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0775 - mae: 0.1760 - val_loss: 0.0052 - val_mae: 0.0688\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0742 - mae: 0.1795 - val_loss: 0.0049 - val_mae: 0.0661\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0847 - mae: 0.1988 - val_loss: 0.0045 - val_mae: 0.0638\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0353 - mae: 0.1404 - val_loss: 0.0041 - val_mae: 0.0607\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0564 - mae: 0.1690 - val_loss: 0.0041 - val_mae: 0.0603\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0437 - mae: 0.1489 - val_loss: 0.0039 - val_mae: 0.0586\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0537 - mae: 0.1506 - val_loss: 0.0036 - val_mae: 0.0558\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0334 - mae: 0.1330 - val_loss: 0.0033 - val_mae: 0.0529\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0565 - mae: 0.1613 - val_loss: 0.0035 - val_mae: 0.0546\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0492 - mae: 0.1503 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0311 - mae: 0.1228 - val_loss: 0.0031 - val_mae: 0.0514\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0323 - mae: 0.1212 - val_loss: 0.0030 - val_mae: 0.0503\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0242 - mae: 0.0987 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0177 - mae: 0.0904 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0295 - mae: 0.1169 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0205 - mae: 0.0958 - val_loss: 0.0030 - val_mae: 0.0499\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0266 - mae: 0.1129 - val_loss: 0.0028 - val_mae: 0.0487\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0189 - mae: 0.0931 - val_loss: 0.0028 - val_mae: 0.0477\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0214 - mae: 0.0828 - val_loss: 0.0025 - val_mae: 0.0455\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - mae: 0.0820 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - mae: 0.0859 - val_loss: 0.0024 - val_mae: 0.0437\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0130 - mae: 0.0728 - val_loss: 0.0024 - val_mae: 0.0436\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0248 - mae: 0.0986 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0826 - val_loss: 0.0026 - val_mae: 0.0459\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0139 - mae: 0.0733 - val_loss: 0.0026 - val_mae: 0.0465\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0894 - val_loss: 0.0025 - val_mae: 0.0452\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0756 - val_loss: 0.0025 - val_mae: 0.0448\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0731 - val_loss: 0.0024 - val_mae: 0.0436\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0170 - mae: 0.0871 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.0765 - val_loss: 0.0024 - val_mae: 0.0440\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0644 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0792 - val_loss: 0.0024 - val_mae: 0.0433\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0801 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0679 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0816 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.0669 - val_loss: 0.0025 - val_mae: 0.0448\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0188 - mae: 0.0829 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - mae: 0.0836 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - mae: 0.0677 - val_loss: 0.0024 - val_mae: 0.0440\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0611 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0714 - val_loss: 0.0021 - val_mae: 0.0405\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - mae: 0.0590 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.0688 - val_loss: 0.0020 - val_mae: 0.0397\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0524 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - mae: 0.0602 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - mae: 0.0493 - val_loss: 0.0019 - val_mae: 0.0383\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - mae: 0.0649 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0548 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0478 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0118 - mae: 0.0587 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - mae: 0.0514 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0537 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0494 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - mae: 0.0496 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0460 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0142 - mae: 0.0636 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0544 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0585 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - mae: 0.0453 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0504 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0453 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0458 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - mae: 0.0449 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0407 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0535 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0433 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0423 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0460 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0371 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0417 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0479 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0419 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0390 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.0551 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0395 - val_loss: 9.3256e-04 - val_mae: 0.0234\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0425 - val_loss: 9.3127e-04 - val_mae: 0.0234\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0378 - val_loss: 9.7022e-04 - val_mae: 0.0241\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0456 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0352 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0393 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0392 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - mae: 0.0357 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - mae: 0.0427 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - mae: 0.0400 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0344 - val_loss: 9.7780e-04 - val_mae: 0.0243\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0379 - val_loss: 9.8073e-04 - val_mae: 0.0243\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0390 - val_loss: 9.8907e-04 - val_mae: 0.0245\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0339 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0452 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0321 - val_loss: 9.8753e-04 - val_mae: 0.0244\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - mae: 0.0375 - val_loss: 9.6438e-04 - val_mae: 0.0240\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0382 - val_loss: 9.3909e-04 - val_mae: 0.0236\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0325 - val_loss: 9.5574e-04 - val_mae: 0.0239\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0369 - val_loss: 9.1476e-04 - val_mae: 0.0231\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0347 - val_loss: 9.8780e-04 - val_mae: 0.0244\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0051 - mae: 0.0324 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0063 - mae: 0.0383 - val_loss: 9.8245e-04 - val_mae: 0.0244\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0334 - val_loss: 9.9064e-04 - val_mae: 0.0245\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0056 - mae: 0.0371 - val_loss: 9.4460e-04 - val_mae: 0.0237\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0333 - val_loss: 9.6053e-04 - val_mae: 0.0240\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - mae: 0.0349 - val_loss: 9.5023e-04 - val_mae: 0.0238\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - mae: 0.0393 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0287 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0057 - mae: 0.0364 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0294 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0055 - mae: 0.0338 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0068 - mae: 0.0402 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0330 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0363 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0355 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0339 - val_loss: 9.5350e-04 - val_mae: 0.0238\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0395 - val_loss: 9.4466e-04 - val_mae: 0.0237\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0296 - val_loss: 9.5713e-04 - val_mae: 0.0239\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0362 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0304 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0317 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0374 - val_loss: 9.0944e-04 - val_mae: 0.0230\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0317 - val_loss: 9.2045e-04 - val_mae: 0.0232\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0383 - val_loss: 9.5160e-04 - val_mae: 0.0238\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0258 - val_loss: 9.6064e-04 - val_mae: 0.0240\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0309 - val_loss: 9.7058e-04 - val_mae: 0.0241\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0312 - val_loss: 9.4040e-04 - val_mae: 0.0236\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0304 - val_loss: 9.3417e-04 - val_mae: 0.0235\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 9.5751e-04 - val_mae: 0.0239\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0320 - val_loss: 9.7009e-04 - val_mae: 0.0241\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0341 - val_loss: 8.8152e-04 - val_mae: 0.0225\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0299 - val_loss: 9.3854e-04 - val_mae: 0.0235\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0251 - val_loss: 9.5631e-04 - val_mae: 0.0239\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0334 - val_loss: 9.6660e-04 - val_mae: 0.0241\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.7246e-04 - val_mae: 0.0242\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0314 - val_loss: 9.9119e-04 - val_mae: 0.0245\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0262 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0330 - val_loss: 9.8393e-04 - val_mae: 0.0244\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 9.8685e-04 - val_mae: 0.0244\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0334 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0280 - val_loss: 9.6663e-04 - val_mae: 0.0241\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 9.3324e-04 - val_mae: 0.0235\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0329 - val_loss: 9.1611e-04 - val_mae: 0.0231\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0284 - val_loss: 9.1358e-04 - val_mae: 0.0231\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0276 - val_loss: 9.1477e-04 - val_mae: 0.0231\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 9.1168e-04 - val_mae: 0.0231\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0303 - val_loss: 9.0082e-04 - val_mae: 0.0228\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 8.5063e-04 - val_mae: 0.0218\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0309 - val_loss: 8.9793e-04 - val_mae: 0.0228\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0261 - val_loss: 8.7567e-04 - val_mae: 0.0223\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0248 - val_loss: 8.8058e-04 - val_mae: 0.0224\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 8.1946e-04 - val_mae: 0.0212\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0296 - val_loss: 8.8227e-04 - val_mae: 0.0225\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0293 - val_loss: 8.9977e-04 - val_mae: 0.0228\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0297 - val_loss: 9.3789e-04 - val_mae: 0.0235\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0263 - val_loss: 9.0503e-04 - val_mae: 0.0229\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0232 - val_loss: 9.2480e-04 - val_mae: 0.0233\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 9.8786e-04 - val_mae: 0.0244\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 9.8076e-04 - val_mae: 0.0243\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0280 - val_loss: 9.4721e-04 - val_mae: 0.0237\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0675e-04 - val_mae: 0.0229\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0290 - val_loss: 8.8044e-04 - val_mae: 0.0224\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0303 - val_loss: 8.4398e-04 - val_mae: 0.0217\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 8.8526e-04 - val_mae: 0.0225\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0284 - val_loss: 8.6860e-04 - val_mae: 0.0222\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.1183e-04 - val_mae: 0.0230\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 9.4542e-04 - val_mae: 0.0237\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0299 - val_loss: 9.6359e-04 - val_mae: 0.0240\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 9.2558e-04 - val_mae: 0.0233\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 9.5618e-04 - val_mae: 0.0239\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0275 - val_loss: 9.0760e-04 - val_mae: 0.0230\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 8.8756e-04 - val_mae: 0.0226\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.2175e-04 - val_mae: 0.0232\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0297 - val_loss: 8.8047e-04 - val_mae: 0.0224\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0302 - val_loss: 9.9585e-04 - val_mae: 0.0246\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0045 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.6754e-04 - val_mae: 0.0241\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0245 - val_loss: 9.6076e-04 - val_mae: 0.0240\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 8.9506e-04 - val_mae: 0.0227\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.6104e-04 - val_mae: 0.0220\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 8.6127e-04 - val_mae: 0.0221\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 8.6980e-04 - val_mae: 0.0222\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 8.9309e-04 - val_mae: 0.0227\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0261 - val_loss: 8.8758e-04 - val_mae: 0.0226\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.6334e-04 - val_mae: 0.0221\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 8.5433e-04 - val_mae: 0.0219\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0036 - mae: 0.0246 - val_loss: 8.7580e-04 - val_mae: 0.0223\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0275 - val_loss: 9.1201e-04 - val_mae: 0.0230\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.6697e-04 - val_mae: 0.0222\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0038 - mae: 0.0239 - val_loss: 8.5599e-04 - val_mae: 0.0219\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.4309e-04 - val_mae: 0.0217\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 8.0939e-04 - val_mae: 0.0210\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 8.0857e-04 - val_mae: 0.0209\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 8.3193e-04 - val_mae: 0.0214\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0311 - val_loss: 8.8529e-04 - val_mae: 0.0225\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0270 - val_loss: 9.1754e-04 - val_mae: 0.0231\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0285 - val_loss: 9.0605e-04 - val_mae: 0.0229\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0243 - val_loss: 9.5991e-04 - val_mae: 0.0239\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0259 - val_loss: 9.9018e-04 - val_mae: 0.0245\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.1748e-04 - val_mae: 0.0231\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.3931e-04 - val_mae: 0.0236\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 9.7739e-04 - val_mae: 0.0243\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.7725e-04 - val_mae: 0.0242\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.1272e-04 - val_mae: 0.0231\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.1818e-04 - val_mae: 0.0232\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0259 - val_loss: 9.3205e-04 - val_mae: 0.0234\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.6415e-04 - val_mae: 0.0240\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.4587e-04 - val_mae: 0.0237\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 9.0548e-04 - val_mae: 0.0229\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.8783e-04 - val_mae: 0.0226\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0254 - val_loss: 8.5226e-04 - val_mae: 0.0219\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.8923e-04 - val_mae: 0.0226\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.7446e-04 - val_mae: 0.0242\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0267 - val_loss: 9.1672e-04 - val_mae: 0.0231\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 6.8132e-04 - val_mae: 0.0179\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0303 - val_loss: 6.9007e-04 - val_mae: 0.0181\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 7.3097e-04 - val_mae: 0.0191\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0300 - val_loss: 8.4236e-04 - val_mae: 0.0217\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 8.5750e-04 - val_mae: 0.0220\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.8705e-04 - val_mae: 0.0226\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.1492e-04 - val_mae: 0.0231\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0268 - val_loss: 8.4443e-04 - val_mae: 0.0217\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0359e-04 - val_mae: 0.0229\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0051e-04 - val_mae: 0.0228\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0242 - val_loss: 9.0394e-04 - val_mae: 0.0229\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.3878e-04 - val_mae: 0.0236\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0238 - val_loss: 9.6564e-04 - val_mae: 0.0241\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0244 - val_loss: 9.7867e-04 - val_mae: 0.0243\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.2780e-04 - val_mae: 0.0234\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.6172e-04 - val_mae: 0.0240\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.5789e-04 - val_mae: 0.0239\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0245 - val_loss: 9.6250e-04 - val_mae: 0.0240\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.6198e-04 - val_mae: 0.0240\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 9.5245e-04 - val_mae: 0.0238\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.5843e-04 - val_mae: 0.0239\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 9.0102e-04 - val_mae: 0.0228\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.0318e-04 - val_mae: 0.0229\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 8.8924e-04 - val_mae: 0.0226\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.5991e-04 - val_mae: 0.0239\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0243 - val_loss: 8.9844e-04 - val_mae: 0.0228\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 8.6219e-04 - val_mae: 0.0221\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.9717e-04 - val_mae: 0.0228\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0239 - val_loss: 9.5805e-04 - val_mae: 0.0239\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0427e-04 - val_mae: 0.0229\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.7204e-04 - val_mae: 0.0242\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.3107e-04 - val_mae: 0.0234\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.6075e-04 - val_mae: 0.0240\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0240 - val_loss: 9.3710e-04 - val_mae: 0.0235\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 9.2026e-04 - val_mae: 0.0232\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0222 - val_loss: 9.6338e-04 - val_mae: 0.0240\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.5062e-04 - val_mae: 0.0238\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.5206e-04 - val_mae: 0.0238\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.2939e-04 - val_mae: 0.0234\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.2796e-04 - val_mae: 0.0234\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0242 - val_loss: 8.7254e-04 - val_mae: 0.0223\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.7094e-04 - val_mae: 0.0222\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 8.9699e-04 - val_mae: 0.0228\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.5163e-04 - val_mae: 0.0238\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.4590e-04 - val_mae: 0.0237\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.0183e-04 - val_mae: 0.0229\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 9.6278e-04 - val_mae: 0.0240\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.1096e-04 - val_mae: 0.0230\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.1428e-04 - val_mae: 0.0231\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0267 - val_loss: 9.2021e-04 - val_mae: 0.0232\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0265 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.8281e-04 - val_mae: 0.0244\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 8.9845e-04 - val_mae: 0.0228\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.6160e-04 - val_mae: 0.0221\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.1001e-04 - val_mae: 0.0230\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 8.7895e-04 - val_mae: 0.0224\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.1336e-04 - val_mae: 0.0231\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.7650e-04 - val_mae: 0.0224\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0649e-04 - val_mae: 0.0229\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.8764e-04 - val_mae: 0.0244\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.5200e-04 - val_mae: 0.0238\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.9320e-04 - val_mae: 0.0245\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.0400e-04 - val_mae: 0.0229\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.3643e-04 - val_mae: 0.0235\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0222 - val_loss: 9.5996e-04 - val_mae: 0.0239\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 8.9922e-04 - val_mae: 0.0228\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.2996e-04 - val_mae: 0.0234\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0239 - val_loss: 9.0032e-04 - val_mae: 0.0228\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.8790e-04 - val_mae: 0.0226\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.1720e-04 - val_mae: 0.0232\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0230 - val_loss: 8.5255e-04 - val_mae: 0.0219\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.7885e-04 - val_mae: 0.0224\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.8972e-04 - val_mae: 0.0226\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 9.0373e-04 - val_mae: 0.0229\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0245 - val_loss: 9.2823e-04 - val_mae: 0.0234\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 9.8582e-04 - val_mae: 0.0244\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.3740e-04 - val_mae: 0.0235\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 9.9996e-04 - val_mae: 0.0247\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.1708e-04 - val_mae: 0.0232\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.6959e-04 - val_mae: 0.0241\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 9.0335e-04 - val_mae: 0.0229\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.6761e-04 - val_mae: 0.0241\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.4826e-04 - val_mae: 0.0237\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.3235e-04 - val_mae: 0.0234\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.1720e-04 - val_mae: 0.0232\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.8863e-04 - val_mae: 0.0245\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0252 - val_loss: 9.0722e-04 - val_mae: 0.0230\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0243 - val_loss: 9.1529e-04 - val_mae: 0.0231\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.3583e-04 - val_mae: 0.0235\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.1232e-04 - val_mae: 0.0231\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.2314e-04 - val_mae: 0.0233\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.8294e-04 - val_mae: 0.0244\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.2777e-04 - val_mae: 0.0234\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.3837e-04 - val_mae: 0.0236\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.9275e-04 - val_mae: 0.0227\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.1870e-04 - val_mae: 0.0232\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.5816e-04 - val_mae: 0.0239\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.7083e-04 - val_mae: 0.0241\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.4196e-04 - val_mae: 0.0236\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.8375e-04 - val_mae: 0.0244\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0240 - val_loss: 9.8249e-04 - val_mae: 0.0244\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.9146e-04 - val_mae: 0.0245\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 8.9093e-04 - val_mae: 0.0226\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0241 - val_loss: 9.5270e-04 - val_mae: 0.0238\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.7269e-04 - val_mae: 0.0242\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0250 - val_loss: 9.5719e-04 - val_mae: 0.0239\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0228 - val_loss: 9.6630e-04 - val_mae: 0.0241\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.4869e-04 - val_mae: 0.0237\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0914e-04 - val_mae: 0.0230\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.5809e-04 - val_mae: 0.0239\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c51a47ae4d0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_67\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_684 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_617 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_685 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_618 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_686 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_619 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_687 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_620 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_688 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_621 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_689 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_622 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_690 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_623 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_691 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_624 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_692 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_625 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_693 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_626 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_694 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_627 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_695 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 22ms/step - loss: 21.3167 - mae: 2.7500 - val_loss: 0.0578 - val_mae: 0.2392\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 3.4560 - mae: 1.4803 - val_loss: 0.0295 - val_mae: 0.1700\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.0762 - mae: 1.0742 - val_loss: 0.0033 - val_mae: 0.0519\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.1417 - mae: 0.8304 - val_loss: 0.0027 - val_mae: 0.0461\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4600 - mae: 0.8327 - val_loss: 0.0035 - val_mae: 0.0534\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4518 - mae: 0.5106 - val_loss: 0.0027 - val_mae: 0.0448\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6210 - mae: 0.5956 - val_loss: 0.0035 - val_mae: 0.0536\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4154 - mae: 0.4776 - val_loss: 0.0033 - val_mae: 0.0527\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6467 - mae: 0.5313 - val_loss: 0.0049 - val_mae: 0.0666\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4021 - mae: 0.4852 - val_loss: 0.0057 - val_mae: 0.0726\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2764 - mae: 0.3893 - val_loss: 0.0044 - val_mae: 0.0632\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2790 - mae: 0.3972 - val_loss: 0.0041 - val_mae: 0.0604\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1912 - mae: 0.3276 - val_loss: 0.0031 - val_mae: 0.0511\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2136 - mae: 0.3008 - val_loss: 0.0033 - val_mae: 0.0533\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2172 - mae: 0.3327 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2234 - mae: 0.2776 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1421 - mae: 0.2736 - val_loss: 0.0022 - val_mae: 0.0414\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1704 - mae: 0.2701 - val_loss: 0.0029 - val_mae: 0.0486\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1564 - mae: 0.2981 - val_loss: 0.0036 - val_mae: 0.0553\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0734 - mae: 0.1903 - val_loss: 0.0040 - val_mae: 0.0591\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1101 - mae: 0.2401 - val_loss: 0.0042 - val_mae: 0.0612\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1683 - mae: 0.2686 - val_loss: 0.0035 - val_mae: 0.0553\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1348 - mae: 0.2392 - val_loss: 0.0042 - val_mae: 0.0608\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0912 - mae: 0.2213 - val_loss: 0.0044 - val_mae: 0.0625\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1182 - mae: 0.2605 - val_loss: 0.0044 - val_mae: 0.0626\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0696 - mae: 0.1740 - val_loss: 0.0044 - val_mae: 0.0629\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0631 - mae: 0.1896 - val_loss: 0.0042 - val_mae: 0.0610\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0908 - mae: 0.2032 - val_loss: 0.0040 - val_mae: 0.0597\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0559 - mae: 0.1747 - val_loss: 0.0043 - val_mae: 0.0614\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0652 - mae: 0.1813 - val_loss: 0.0040 - val_mae: 0.0592\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0580 - mae: 0.1761 - val_loss: 0.0037 - val_mae: 0.0565\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0560 - mae: 0.1627 - val_loss: 0.0035 - val_mae: 0.0551\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0659 - mae: 0.1633 - val_loss: 0.0036 - val_mae: 0.0557\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0394 - mae: 0.1347 - val_loss: 0.0033 - val_mae: 0.0527\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0896 - mae: 0.1867 - val_loss: 0.0033 - val_mae: 0.0533\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0318 - mae: 0.1258 - val_loss: 0.0035 - val_mae: 0.0547\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0645 - mae: 0.1522 - val_loss: 0.0037 - val_mae: 0.0569\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0333 - mae: 0.1243 - val_loss: 0.0037 - val_mae: 0.0571\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0296 - mae: 0.1207 - val_loss: 0.0035 - val_mae: 0.0550\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0309 - mae: 0.1218 - val_loss: 0.0034 - val_mae: 0.0542\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0441 - mae: 0.1447 - val_loss: 0.0037 - val_mae: 0.0566\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0371 - mae: 0.1361 - val_loss: 0.0039 - val_mae: 0.0585\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0327 - mae: 0.1343 - val_loss: 0.0040 - val_mae: 0.0593\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0426 - mae: 0.1367 - val_loss: 0.0040 - val_mae: 0.0593\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0509 - mae: 0.1494 - val_loss: 0.0038 - val_mae: 0.0577\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0366 - mae: 0.1249 - val_loss: 0.0035 - val_mae: 0.0552\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - mae: 0.0908 - val_loss: 0.0033 - val_mae: 0.0527\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0443 - mae: 0.1452 - val_loss: 0.0031 - val_mae: 0.0514\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0269 - mae: 0.1118 - val_loss: 0.0032 - val_mae: 0.0524\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0210 - mae: 0.0957 - val_loss: 0.0031 - val_mae: 0.0515\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0233 - mae: 0.1034 - val_loss: 0.0031 - val_mae: 0.0514\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0197 - mae: 0.0944 - val_loss: 0.0032 - val_mae: 0.0524\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0238 - mae: 0.1097 - val_loss: 0.0034 - val_mae: 0.0538\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0190 - mae: 0.0913 - val_loss: 0.0034 - val_mae: 0.0540\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0251 - mae: 0.1049 - val_loss: 0.0032 - val_mae: 0.0525\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0851 - mae: 0.1411 - val_loss: 0.0032 - val_mae: 0.0525\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0264 - mae: 0.1027 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0329 - mae: 0.1251 - val_loss: 0.0033 - val_mae: 0.0529\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0215 - mae: 0.0943 - val_loss: 0.0031 - val_mae: 0.0512\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - mae: 0.0976 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0207 - mae: 0.1023 - val_loss: 0.0028 - val_mae: 0.0486\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.0942 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.0933 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.0862 - val_loss: 0.0029 - val_mae: 0.0495\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - mae: 0.0863 - val_loss: 0.0028 - val_mae: 0.0480\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.0773 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.0925 - val_loss: 0.0027 - val_mae: 0.0469\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.0827 - val_loss: 0.0027 - val_mae: 0.0474\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.1029 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0806 - val_loss: 0.0027 - val_mae: 0.0473\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0738 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0241 - mae: 0.0810 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0790 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0092 - mae: 0.0573 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0176 - mae: 0.0826 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.0620 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - mae: 0.0717 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - mae: 0.0663 - val_loss: 0.0020 - val_mae: 0.0387\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0639 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.0667 - val_loss: 0.0017 - val_mae: 0.0356\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0121 - mae: 0.0752 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0156 - mae: 0.0709 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0705 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0611 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - mae: 0.0592 - val_loss: 0.0018 - val_mae: 0.0365\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0539 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0539 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0658 - val_loss: 0.0020 - val_mae: 0.0395\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0553 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0204 - mae: 0.0881 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0686 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0745 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0649 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0141 - mae: 0.0575 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0556 - val_loss: 0.0018 - val_mae: 0.0369\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0521 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0218 - mae: 0.0710 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0513 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0584 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0493 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0561 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - mae: 0.0549 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0505 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0339 - mae: 0.0695 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0489 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0549 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0566 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0496 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0545 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0516 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0475 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0562 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0442 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0594 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0496 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0483 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0444 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0524 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0537 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0433 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0495 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0487 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0461 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0346 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0499 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0459 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0371 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0468 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0526 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.0496 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - mae: 0.0566 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0371 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0349 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0453 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0357 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0463 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0385 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0396 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - mae: 0.0433 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0346 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - mae: 0.0403 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0366 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - mae: 0.0408 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0326 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0068 - mae: 0.0393 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0327 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0343 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0053 - mae: 0.0309 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - mae: 0.0376 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0437 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0427 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0423 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0349 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0359 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0363 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0307 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0308 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0419 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0259 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0363 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0369 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0028 - mae: 0.0336 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0333 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0407 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0364 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0337 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0331 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0398 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0376 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0312 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0339 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0317 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0361 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0296 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0335 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0348 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0332 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0364 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0347 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - mae: 0.0365 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0332 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0377 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0304 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0317 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0323 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0316 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0350 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0304 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0298 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0293 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0306 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0307 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0325 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0315 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0304 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0363 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 8.0133e-04 - val_mae: 0.0208\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 8.4123e-04 - val_mae: 0.0216\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0340 - val_loss: 9.1419e-04 - val_mae: 0.0231\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 9.5476e-04 - val_mae: 0.0239\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.4257e-04 - val_mae: 0.0236\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0248 - val_loss: 9.5379e-04 - val_mae: 0.0238\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0047 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0049 - mae: 0.0289 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0054 - mae: 0.0310 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0284 - val_loss: 8.5885e-04 - val_mae: 0.0220\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0294 - val_loss: 8.4513e-04 - val_mae: 0.0217\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 8.8760e-04 - val_mae: 0.0226\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 9.0044e-04 - val_mae: 0.0228\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0051 - mae: 0.0298 - val_loss: 9.4800e-04 - val_mae: 0.0237\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0040 - mae: 0.0255 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 9.9262e-04 - val_mae: 0.0245\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0328 - val_loss: 9.8921e-04 - val_mae: 0.0245\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0282 - val_loss: 8.7962e-04 - val_mae: 0.0224\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 8.7139e-04 - val_mae: 0.0223\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.1240e-04 - val_mae: 0.0231\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 9.7312e-04 - val_mae: 0.0242\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.5883e-04 - val_mae: 0.0239\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 9.7484e-04 - val_mae: 0.0242\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 9.6762e-04 - val_mae: 0.0241\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.4829e-04 - val_mae: 0.0237\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 9.9478e-04 - val_mae: 0.0246\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - mae: 0.0282 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.5691e-04 - val_mae: 0.0239\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0262 - val_loss: 9.6140e-04 - val_mae: 0.0240\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0223 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0026 - mae: 0.0227 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0234 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0252 - val_loss: 9.8104e-04 - val_mae: 0.0243\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0280 - val_loss: 9.9212e-04 - val_mae: 0.0245\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 9.4989e-04 - val_mae: 0.0238\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0275 - val_loss: 9.6639e-04 - val_mae: 0.0241\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0283 - val_loss: 9.3318e-04 - val_mae: 0.0235\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0287 - val_loss: 9.8372e-04 - val_mae: 0.0244\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0293 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.8258e-04 - val_mae: 0.0244\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0261 - val_loss: 9.5162e-04 - val_mae: 0.0238\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.5285e-04 - val_mae: 0.0238\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0289 - val_loss: 9.2018e-04 - val_mae: 0.0232\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.1738e-04 - val_mae: 0.0232\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.4224e-04 - val_mae: 0.0236\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.3027e-04 - val_mae: 0.0234\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0233 - val_loss: 9.6885e-04 - val_mae: 0.0241\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0264 - val_loss: 9.6712e-04 - val_mae: 0.0241\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.7227e-04 - val_mae: 0.0242\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 8.6514e-04 - val_mae: 0.0221\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 8.6322e-04 - val_mae: 0.0221\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 8.7261e-04 - val_mae: 0.0223\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.9594e-04 - val_mae: 0.0227\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.1521e-04 - val_mae: 0.0231\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1277e-04 - val_mae: 0.0231\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0244 - val_loss: 9.1802e-04 - val_mae: 0.0232\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.5121e-04 - val_mae: 0.0238\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.2382e-04 - val_mae: 0.0233\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.4645e-04 - val_mae: 0.0237\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 9.2769e-04 - val_mae: 0.0234\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.3750e-04 - val_mae: 0.0235\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 8.9283e-04 - val_mae: 0.0227\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 8.9757e-04 - val_mae: 0.0228\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.1225e-04 - val_mae: 0.0231\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 9.4215e-04 - val_mae: 0.0236\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0242 - val_loss: 9.2308e-04 - val_mae: 0.0233\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.9969e-04 - val_mae: 0.0247\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.2913e-04 - val_mae: 0.0234\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.3482e-04 - val_mae: 0.0235\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0041 - mae: 0.0230 - val_loss: 9.5978e-04 - val_mae: 0.0239\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.0642e-04 - val_mae: 0.0229\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.4602e-04 - val_mae: 0.0237\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.5603e-04 - val_mae: 0.0239\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.3174e-04 - val_mae: 0.0234\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.3825e-04 - val_mae: 0.0235\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 7.4762e-04 - val_mae: 0.0195\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 7.8633e-04 - val_mae: 0.0205\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 8.5415e-04 - val_mae: 0.0219\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.0391e-04 - val_mae: 0.0229\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.1731e-04 - val_mae: 0.0232\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.2531e-04 - val_mae: 0.0233\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 8.7910e-04 - val_mae: 0.0224\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.4764e-04 - val_mae: 0.0237\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.5072e-04 - val_mae: 0.0238\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.1169e-04 - val_mae: 0.0230\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0242 - val_loss: 9.7830e-04 - val_mae: 0.0243\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.5540e-04 - val_mae: 0.0239\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0233 - val_loss: 9.7425e-04 - val_mae: 0.0242\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0231 - val_loss: 9.8157e-04 - val_mae: 0.0243\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.9049e-04 - val_mae: 0.0245\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.8603e-04 - val_mae: 0.0244\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.8645e-04 - val_mae: 0.0244\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.7064e-04 - val_mae: 0.0241\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.9161e-04 - val_mae: 0.0245\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0238 - val_loss: 9.9720e-04 - val_mae: 0.0246\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.5878e-04 - val_mae: 0.0239\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.3798e-04 - val_mae: 0.0235\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.8895e-04 - val_mae: 0.0245\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0227 - val_loss: 9.8063e-04 - val_mae: 0.0243\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.9118e-04 - val_mae: 0.0245\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0252\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7c51a474a050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3/3 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_68\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_696 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_628 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_697 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_629 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_698 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_630 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_699 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_631 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_700 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_632 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_701 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_633 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_702 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_634 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_703 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_635 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_704 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_636 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_705 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_637 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_706 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_638 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_707 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 4s 21ms/step - loss: 8.4823 - mae: 1.9047 - val_loss: 0.0771 - val_mae: 0.2766\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.8573 - mae: 1.0060 - val_loss: 0.0042 - val_mae: 0.0594\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7039 - mae: 0.6023 - val_loss: 0.0040 - val_mae: 0.0550\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6135 - mae: 0.5719 - val_loss: 0.0010 - val_mae: 0.0301\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2745 - mae: 0.4041 - val_loss: 0.0059 - val_mae: 0.0722\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2213 - mae: 0.3459 - val_loss: 0.0062 - val_mae: 0.0757\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2580 - mae: 0.3535 - val_loss: 0.0065 - val_mae: 0.0777\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2004 - mae: 0.3305 - val_loss: 0.0026 - val_mae: 0.0472\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2134 - mae: 0.3274 - val_loss: 9.3092e-04 - val_mae: 0.0283\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1546 - mae: 0.2877 - val_loss: 5.7374e-04 - val_mae: 0.0202\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1555 - mae: 0.2698 - val_loss: 4.7325e-04 - val_mae: 0.0150\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0979 - mae: 0.2184 - val_loss: 7.0765e-04 - val_mae: 0.0191\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0908 - mae: 0.2094 - val_loss: 9.0211e-04 - val_mae: 0.0233\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1209 - mae: 0.2179 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0781 - mae: 0.1971 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0583 - mae: 0.1785 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0715 - mae: 0.1822 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0638 - mae: 0.1726 - val_loss: 0.0033 - val_mae: 0.0528\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0541 - mae: 0.1652 - val_loss: 0.0034 - val_mae: 0.0543\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0608 - mae: 0.1681 - val_loss: 0.0038 - val_mae: 0.0575\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0369 - mae: 0.1352 - val_loss: 0.0039 - val_mae: 0.0582\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0617 - mae: 0.1777 - val_loss: 0.0039 - val_mae: 0.0587\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0401 - mae: 0.1386 - val_loss: 0.0031 - val_mae: 0.0520\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0422 - mae: 0.1501 - val_loss: 0.0031 - val_mae: 0.0512\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0365 - mae: 0.1430 - val_loss: 0.0032 - val_mae: 0.0526\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0386 - mae: 0.1352 - val_loss: 0.0034 - val_mae: 0.0548\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0499 - mae: 0.1377 - val_loss: 0.0037 - val_mae: 0.0569\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0545 - mae: 0.1570 - val_loss: 0.0038 - val_mae: 0.0573\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0427 - mae: 0.1249 - val_loss: 0.0039 - val_mae: 0.0585\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0314 - mae: 0.1235 - val_loss: 0.0041 - val_mae: 0.0599\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0258 - mae: 0.1134 - val_loss: 0.0037 - val_mae: 0.0566\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0240 - mae: 0.0991 - val_loss: 0.0035 - val_mae: 0.0551\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0209 - mae: 0.0925 - val_loss: 0.0034 - val_mae: 0.0543\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0945 - val_loss: 0.0034 - val_mae: 0.0539\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0238 - mae: 0.1011 - val_loss: 0.0032 - val_mae: 0.0526\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0287 - mae: 0.1082 - val_loss: 0.0033 - val_mae: 0.0528\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0189 - mae: 0.0992 - val_loss: 0.0030 - val_mae: 0.0506\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0208 - mae: 0.0990 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - mae: 0.0884 - val_loss: 0.0024 - val_mae: 0.0437\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0223 - mae: 0.0914 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0233 - mae: 0.1078 - val_loss: 0.0024 - val_mae: 0.0438\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - mae: 0.0867 - val_loss: 0.0026 - val_mae: 0.0459\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - mae: 0.0773 - val_loss: 0.0026 - val_mae: 0.0465\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0325 - mae: 0.1102 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0150 - mae: 0.0800 - val_loss: 0.0026 - val_mae: 0.0466\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - mae: 0.0800 - val_loss: 0.0024 - val_mae: 0.0440\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - mae: 0.0755 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0697 - val_loss: 0.0024 - val_mae: 0.0435\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.0767 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0822 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0570 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0597 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0754 - val_loss: 0.0017 - val_mae: 0.0343\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0619 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0158 - mae: 0.0698 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0646 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0631 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0769 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0583 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0587 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0700 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0531 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0637 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0588 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0530 - val_loss: 0.0016 - val_mae: 0.0328\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0093 - mae: 0.0600 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - mae: 0.0564 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0060 - mae: 0.0430 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - mae: 0.0462 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - mae: 0.0548 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0098 - mae: 0.0509 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0388 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0136 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0094 - mae: 0.0553 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0522 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0416 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0083 - mae: 0.0512 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - mae: 0.0486 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0061 - mae: 0.0412 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - mae: 0.0476 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0401 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0434 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0471 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0395 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0469 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0428 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0379 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0415 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0364 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0368 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0361 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.0434 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0575 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0335 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0413 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0080 - mae: 0.0432 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - mae: 0.0394 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0343 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0402 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0370 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0356 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0471 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0338 - val_loss: 9.9111e-04 - val_mae: 0.0245\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0390 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0351 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0323 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0352 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0348 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0387 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0371 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0359 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0397 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0421 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0365 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0348 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0339 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0331 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0339 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0416 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0332 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0319 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - mae: 0.0351 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0306 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0347 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0302 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0311 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0310 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0308 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0351 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0290 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0332 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0313 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0329 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0303 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0313 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0288 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0310 - val_loss: 9.2038e-04 - val_mae: 0.0232\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0312 - val_loss: 8.9906e-04 - val_mae: 0.0228\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 9.4254e-04 - val_mae: 0.0236\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.6727e-04 - val_mae: 0.0241\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0049 - mae: 0.0295 - val_loss: 9.8248e-04 - val_mae: 0.0244\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 9.6630e-04 - val_mae: 0.0241\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 9.3085e-04 - val_mae: 0.0234\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.5120e-04 - val_mae: 0.0238\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.5797e-04 - val_mae: 0.0239\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 9.1951e-04 - val_mae: 0.0232\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 9.4898e-04 - val_mae: 0.0237\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0282 - val_loss: 9.6216e-04 - val_mae: 0.0240\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0307 - val_loss: 9.5066e-04 - val_mae: 0.0238\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0252 - val_loss: 9.6627e-04 - val_mae: 0.0241\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0303 - val_loss: 9.8425e-04 - val_mae: 0.0244\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0281 - val_loss: 9.9953e-04 - val_mae: 0.0247\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0255 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.5846e-04 - val_mae: 0.0239\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0325 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0263 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0291 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0285 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0270 - val_loss: 9.8746e-04 - val_mae: 0.0244\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0297 - val_loss: 8.3008e-04 - val_mae: 0.0214\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0288 - val_loss: 8.5210e-04 - val_mae: 0.0219\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0281 - val_loss: 9.2322e-04 - val_mae: 0.0233\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0291 - val_loss: 9.7608e-04 - val_mae: 0.0242\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0242 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 9.9376e-04 - val_mae: 0.0246\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 9.7012e-04 - val_mae: 0.0241\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.7392e-04 - val_mae: 0.0242\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0229 - val_loss: 9.7128e-04 - val_mae: 0.0242\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0237 - val_loss: 9.9996e-04 - val_mae: 0.0247\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.8750e-04 - val_mae: 0.0244\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0252 - val_loss: 9.8668e-04 - val_mae: 0.0244\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.5007e-04 - val_mae: 0.0238\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.3692e-04 - val_mae: 0.0235\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.4579e-04 - val_mae: 0.0237\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.7559e-04 - val_mae: 0.0242\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0241 - val_loss: 9.2143e-04 - val_mae: 0.0232\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0275 - val_loss: 9.5558e-04 - val_mae: 0.0239\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0286 - val_loss: 6.9962e-04 - val_mae: 0.0183\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0279 - val_loss: 7.1586e-04 - val_mae: 0.0188\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0266 - val_loss: 7.6122e-04 - val_mae: 0.0199\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0293 - val_loss: 7.7995e-04 - val_mae: 0.0203\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.4785e-04 - val_mae: 0.0218\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0272 - val_loss: 8.7281e-04 - val_mae: 0.0223\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0258e-04 - val_mae: 0.0229\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.2103e-04 - val_mae: 0.0232\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0249 - val_loss: 9.3090e-04 - val_mae: 0.0234\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.5076e-04 - val_mae: 0.0238\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 9.4757e-04 - val_mae: 0.0237\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.2537e-04 - val_mae: 0.0233\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.3079e-04 - val_mae: 0.0234\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0701e-04 - val_mae: 0.0230\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2348e-04 - val_mae: 0.0233\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.3018e-04 - val_mae: 0.0234\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 8.9939e-04 - val_mae: 0.0228\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.4998e-04 - val_mae: 0.0238\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0269 - val_loss: 9.5352e-04 - val_mae: 0.0238\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.7600e-04 - val_mae: 0.0242\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0234 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.8422e-04 - val_mae: 0.0244\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.6083e-04 - val_mae: 0.0240\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 9.1983e-04 - val_mae: 0.0232\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.7873e-04 - val_mae: 0.0243\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0221 - val_loss: 9.5234e-04 - val_mae: 0.0238\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.1449e-04 - val_mae: 0.0231\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.1882e-04 - val_mae: 0.0232\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.6898e-04 - val_mae: 0.0241\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0253 - val_loss: 9.7076e-04 - val_mae: 0.0241\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.3565e-04 - val_mae: 0.0235\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2439e-04 - val_mae: 0.0233\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.9596e-04 - val_mae: 0.0246\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 9.4807e-04 - val_mae: 0.0237\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0261 - val_loss: 7.5251e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0266 - val_loss: 7.6310e-04 - val_mae: 0.0199\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0250 - val_loss: 8.3345e-04 - val_mae: 0.0215\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 8.8324e-04 - val_mae: 0.0225\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.3334e-04 - val_mae: 0.0235\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 8.7419e-04 - val_mae: 0.0223\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.0462e-04 - val_mae: 0.0229\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.0802e-04 - val_mae: 0.0230\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.1479e-04 - val_mae: 0.0231\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.7682e-04 - val_mae: 0.0242\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0239 - val_loss: 9.3766e-04 - val_mae: 0.0235\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0225 - val_loss: 9.8470e-04 - val_mae: 0.0244\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.3674e-04 - val_mae: 0.0235\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.7742e-04 - val_mae: 0.0243\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.5976e-04 - val_mae: 0.0239\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0259 - val_loss: 9.2508e-04 - val_mae: 0.0233\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.6171e-04 - val_mae: 0.0240\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.9145e-04 - val_mae: 0.0245\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2490e-04 - val_mae: 0.0233\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.6372e-04 - val_mae: 0.0240\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0258 - val_loss: 8.9234e-04 - val_mae: 0.0227\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.3341e-04 - val_mae: 0.0235\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0250 - val_loss: 9.2314e-04 - val_mae: 0.0233\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0283 - val_loss: 9.9035e-04 - val_mae: 0.0245\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 9.1218e-04 - val_mae: 0.0231\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.3947e-04 - val_mae: 0.0236\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0250 - val_loss: 9.5008e-04 - val_mae: 0.0238\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.3736e-04 - val_mae: 0.0235\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.1696e-04 - val_mae: 0.0231\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.1212e-04 - val_mae: 0.0231\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.2956e-04 - val_mae: 0.0234\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0239 - val_loss: 9.9818e-04 - val_mae: 0.0246\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0222 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0253 - val_loss: 7.8267e-04 - val_mae: 0.0204\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.1143e-04 - val_mae: 0.0210\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.2751e-04 - val_mae: 0.0233\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 9.3135e-04 - val_mae: 0.0234\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.1335e-04 - val_mae: 0.0231\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.7445e-04 - val_mae: 0.0242\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0222 - val_loss: 9.7409e-04 - val_mae: 0.0242\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 8.1902e-04 - val_mae: 0.0212\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.5524e-04 - val_mae: 0.0219\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.3386e-04 - val_mae: 0.0235\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.7570e-04 - val_mae: 0.0242\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0222 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.6757e-04 - val_mae: 0.0241\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.5678e-04 - val_mae: 0.0239\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0231 - val_loss: 9.7553e-04 - val_mae: 0.0242\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.6245e-04 - val_mae: 0.0240\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.4881e-04 - val_mae: 0.0237\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.3796e-04 - val_mae: 0.0235\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0224 - val_loss: 9.7624e-04 - val_mae: 0.0242\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.3470e-04 - val_mae: 0.0235\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.5479e-04 - val_mae: 0.0239\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.1165e-04 - val_mae: 0.0230\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.0362e-04 - val_mae: 0.0229\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0243 - val_loss: 9.2649e-04 - val_mae: 0.0233\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0225 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0240 - val_loss: 9.9757e-04 - val_mae: 0.0246\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.2919e-04 - val_mae: 0.0234\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 8.7418e-04 - val_mae: 0.0223\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0239 - val_loss: 8.7797e-04 - val_mae: 0.0224\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.3126e-04 - val_mae: 0.0234\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.3997e-04 - val_mae: 0.0236\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.5836e-04 - val_mae: 0.0239\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.4891e-04 - val_mae: 0.0237\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.4863e-04 - val_mae: 0.0237\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.7909e-04 - val_mae: 0.0243\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0227 - val_loss: 9.6031e-04 - val_mae: 0.0240\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0217 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.7718e-04 - val_mae: 0.0243\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.3525e-04 - val_mae: 0.0235\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.2716e-04 - val_mae: 0.0233\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.4469e-04 - val_mae: 0.0237\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.4527e-04 - val_mae: 0.0237\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.3784e-04 - val_mae: 0.0235\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0224 - val_loss: 9.9533e-04 - val_mae: 0.0246\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.5924e-04 - val_mae: 0.0239\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.4148e-04 - val_mae: 0.0236\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.3966e-04 - val_mae: 0.0236\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_69\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_708 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_639 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_709 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_640 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_710 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_641 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_711 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_642 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_712 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_643 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_713 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_644 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_714 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_645 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_715 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_646 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_716 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_647 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_717 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_648 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_718 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_649 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_719 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 19ms/step - loss: 0.5388 - mae: 0.6070 - val_loss: 0.0110 - val_mae: 0.1027\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1757 - mae: 0.3385 - val_loss: 0.0248 - val_mae: 0.1560\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1564 - mae: 0.3246 - val_loss: 5.0371e-04 - val_mae: 0.0159\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1452 - mae: 0.2917 - val_loss: 5.6202e-04 - val_mae: 0.0188\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1561 - mae: 0.3342 - val_loss: 0.0094 - val_mae: 0.0947\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1154 - mae: 0.2600 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1236 - mae: 0.2797 - val_loss: 6.6120e-04 - val_mae: 0.0173\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0910 - mae: 0.2399 - val_loss: 6.2861e-04 - val_mae: 0.0213\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0830 - mae: 0.2203 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0718 - mae: 0.2112 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0858 - mae: 0.2243 - val_loss: 0.0028 - val_mae: 0.0482\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0872 - mae: 0.2410 - val_loss: 5.1345e-04 - val_mae: 0.0164\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1078 - mae: 0.2613 - val_loss: 0.0022 - val_mae: 0.0414\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0718 - mae: 0.2212 - val_loss: 0.0043 - val_mae: 0.0617\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0584 - mae: 0.1945 - val_loss: 4.7759e-04 - val_mae: 0.0146\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0837 - mae: 0.2411 - val_loss: 8.5523e-04 - val_mae: 0.0269\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0662 - mae: 0.2010 - val_loss: 7.8353e-04 - val_mae: 0.0254\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0661 - mae: 0.2038 - val_loss: 0.0130 - val_mae: 0.1120\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0646 - mae: 0.2002 - val_loss: 8.4264e-04 - val_mae: 0.0217\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0485 - mae: 0.1870 - val_loss: 5.2121e-04 - val_mae: 0.0148\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0493 - mae: 0.1795 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0468 - mae: 0.1652 - val_loss: 4.7618e-04 - val_mae: 0.0148\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0384 - mae: 0.1552 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0356 - mae: 0.1486 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0389 - mae: 0.1589 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0416 - mae: 0.1621 - val_loss: 4.7507e-04 - val_mae: 0.0146\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0349 - mae: 0.1420 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0272 - mae: 0.1299 - val_loss: 6.6181e-04 - val_mae: 0.0223\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0285 - mae: 0.1293 - val_loss: 6.6679e-04 - val_mae: 0.0224\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1287 - val_loss: 0.0019 - val_mae: 0.0373\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0269 - mae: 0.1278 - val_loss: 0.0033 - val_mae: 0.0529\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0289 - mae: 0.1277 - val_loss: 5.0189e-04 - val_mae: 0.0159\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0270 - mae: 0.1269 - val_loss: 4.9484e-04 - val_mae: 0.0146\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.1210 - val_loss: 7.2273e-04 - val_mae: 0.0239\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - mae: 0.1191 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0265 - mae: 0.1288 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0182 - mae: 0.0944 - val_loss: 7.5732e-04 - val_mae: 0.0198\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0196 - mae: 0.1137 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0217 - mae: 0.1095 - val_loss: 7.8192e-04 - val_mae: 0.0204\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.1015 - val_loss: 5.1206e-04 - val_mae: 0.0147\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0193 - mae: 0.0975 - val_loss: 8.5231e-04 - val_mae: 0.0219\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.0899 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0150 - mae: 0.0917 - val_loss: 5.4604e-04 - val_mae: 0.0151\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - mae: 0.0889 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0154 - mae: 0.0925 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0143 - mae: 0.0814 - val_loss: 9.4910e-04 - val_mae: 0.0237\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0137 - mae: 0.0838 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0185 - mae: 0.0971 - val_loss: 5.2475e-04 - val_mae: 0.0149\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0184 - mae: 0.0997 - val_loss: 8.1944e-04 - val_mae: 0.0262\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0139 - mae: 0.0826 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - mae: 0.0768 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0144 - mae: 0.0880 - val_loss: 6.2086e-04 - val_mae: 0.0163\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0085 - mae: 0.0685 - val_loss: 9.0249e-04 - val_mae: 0.0229\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0097 - mae: 0.0728 - val_loss: 6.9758e-04 - val_mae: 0.0183\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0121 - mae: 0.0715 - val_loss: 8.7237e-04 - val_mae: 0.0223\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0118 - mae: 0.0761 - val_loss: 5.7930e-04 - val_mae: 0.0155\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0107 - mae: 0.0767 - val_loss: 4.8546e-04 - val_mae: 0.0146\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.0680 - val_loss: 7.6233e-04 - val_mae: 0.0199\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - mae: 0.0676 - val_loss: 7.5592e-04 - val_mae: 0.0197\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.0740 - val_loss: 7.6558e-04 - val_mae: 0.0200\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0689 - val_loss: 9.3044e-04 - val_mae: 0.0234\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0697 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0645 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0684 - val_loss: 6.9871e-04 - val_mae: 0.0183\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0631 - val_loss: 6.7893e-04 - val_mae: 0.0178\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0654 - val_loss: 7.9821e-04 - val_mae: 0.0207\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0635 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0637 - val_loss: 9.1088e-04 - val_mae: 0.0230\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0644 - val_loss: 7.3565e-04 - val_mae: 0.0193\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0608 - val_loss: 7.1601e-04 - val_mae: 0.0188\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0548 - val_loss: 8.2232e-04 - val_mae: 0.0212\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0491 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0562 - val_loss: 8.8522e-04 - val_mae: 0.0225\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0096 - mae: 0.0656 - val_loss: 7.2648e-04 - val_mae: 0.0190\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0606 - val_loss: 7.3195e-04 - val_mae: 0.0192\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0566 - val_loss: 8.1749e-04 - val_mae: 0.0211\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0579 - val_loss: 8.2803e-04 - val_mae: 0.0214\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0480 - val_loss: 6.1472e-04 - val_mae: 0.0162\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0523 - val_loss: 6.4298e-04 - val_mae: 0.0167\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0588 - val_loss: 5.3588e-04 - val_mae: 0.0150\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0517 - val_loss: 5.7829e-04 - val_mae: 0.0155\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0488 - val_loss: 8.6041e-04 - val_mae: 0.0220\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0480 - val_loss: 7.0645e-04 - val_mae: 0.0185\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0496 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0511 - val_loss: 7.4236e-04 - val_mae: 0.0194\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0467 - val_loss: 9.7719e-04 - val_mae: 0.0243\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0536 - val_loss: 9.3642e-04 - val_mae: 0.0235\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0436 - val_loss: 9.0893e-04 - val_mae: 0.0230\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0444 - val_loss: 8.6931e-04 - val_mae: 0.0222\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0458 - val_loss: 6.7693e-04 - val_mae: 0.0177\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0516 - val_loss: 8.5156e-04 - val_mae: 0.0219\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0481 - val_loss: 7.3993e-04 - val_mae: 0.0194\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0471 - val_loss: 7.6596e-04 - val_mae: 0.0200\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0084 - mae: 0.0535 - val_loss: 5.9684e-04 - val_mae: 0.0158\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0468 - val_loss: 5.9068e-04 - val_mae: 0.0157\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0458 - val_loss: 7.5887e-04 - val_mae: 0.0198\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0474 - val_loss: 6.7265e-04 - val_mae: 0.0176\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0538 - val_loss: 7.2830e-04 - val_mae: 0.0191\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0494 - val_loss: 8.2559e-04 - val_mae: 0.0213\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0407 - val_loss: 7.5651e-04 - val_mae: 0.0198\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0386 - val_loss: 8.4770e-04 - val_mae: 0.0218\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0450 - val_loss: 8.3916e-04 - val_mae: 0.0216\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0429 - val_loss: 9.7254e-04 - val_mae: 0.0242\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0438 - val_loss: 7.7305e-04 - val_mae: 0.0201\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0446 - val_loss: 9.2649e-04 - val_mae: 0.0233\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0414 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0457 - val_loss: 6.9882e-04 - val_mae: 0.0183\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0427 - val_loss: 8.9706e-04 - val_mae: 0.0228\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0445 - val_loss: 7.9507e-04 - val_mae: 0.0206\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0401 - val_loss: 5.2528e-04 - val_mae: 0.0149\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0412 - val_loss: 7.7384e-04 - val_mae: 0.0202\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0390 - val_loss: 8.0387e-04 - val_mae: 0.0208\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0379 - val_loss: 8.7955e-04 - val_mae: 0.0224\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0409 - val_loss: 6.3428e-04 - val_mae: 0.0165\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0451 - val_loss: 7.1846e-04 - val_mae: 0.0188\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0354 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0396 - val_loss: 8.4156e-04 - val_mae: 0.0216\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - mae: 0.0394 - val_loss: 7.0703e-04 - val_mae: 0.0185\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0423 - val_loss: 9.0119e-04 - val_mae: 0.0228\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0366 - val_loss: 7.9705e-04 - val_mae: 0.0207\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0503 - val_loss: 5.1000e-04 - val_mae: 0.0146\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0379 - val_loss: 8.2916e-04 - val_mae: 0.0214\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0372 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0360 - val_loss: 7.4039e-04 - val_mae: 0.0194\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0374 - val_loss: 8.2514e-04 - val_mae: 0.0213\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0335 - val_loss: 9.7403e-04 - val_mae: 0.0242\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0357 - val_loss: 8.1354e-04 - val_mae: 0.0211\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0353 - val_loss: 9.6723e-04 - val_mae: 0.0241\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0354 - val_loss: 8.4885e-04 - val_mae: 0.0218\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0057 - mae: 0.0379 - val_loss: 8.8141e-04 - val_mae: 0.0225\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0408 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0361 - val_loss: 6.4023e-04 - val_mae: 0.0166\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0053 - mae: 0.0391 - val_loss: 8.5100e-04 - val_mae: 0.0218\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0323 - val_loss: 9.9462e-04 - val_mae: 0.0246\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0324 - val_loss: 9.1226e-04 - val_mae: 0.0231\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0054 - mae: 0.0378 - val_loss: 6.1657e-04 - val_mae: 0.0162\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0353 - val_loss: 7.7678e-04 - val_mae: 0.0202\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0355 - val_loss: 9.8641e-04 - val_mae: 0.0244\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0346 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0055 - mae: 0.0356 - val_loss: 9.1614e-04 - val_mae: 0.0231\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0359 - val_loss: 8.3089e-04 - val_mae: 0.0214\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0369 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0320 - val_loss: 9.1954e-04 - val_mae: 0.0232\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0061 - mae: 0.0405 - val_loss: 6.3364e-04 - val_mae: 0.0165\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0342 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0318 - val_loss: 7.7608e-04 - val_mae: 0.0202\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0325 - val_loss: 7.5307e-04 - val_mae: 0.0197\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0346 - val_loss: 7.9145e-04 - val_mae: 0.0206\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 7.5633e-04 - val_mae: 0.0198\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0338 - val_loss: 7.9016e-04 - val_mae: 0.0205\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0317 - val_loss: 9.2697e-04 - val_mae: 0.0233\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0292 - val_loss: 8.0950e-04 - val_mae: 0.0210\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0363 - val_loss: 8.5836e-04 - val_mae: 0.0220\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0311 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0310 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0302 - val_loss: 7.2898e-04 - val_mae: 0.0191\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0340 - val_loss: 9.3724e-04 - val_mae: 0.0235\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0320 - val_loss: 9.7029e-04 - val_mae: 0.0241\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0356 - val_loss: 8.7182e-04 - val_mae: 0.0223\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0338 - val_loss: 8.6890e-04 - val_mae: 0.0222\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0285 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0305 - val_loss: 7.8556e-04 - val_mae: 0.0204\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0342 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0294 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0329 - val_loss: 6.9549e-04 - val_mae: 0.0182\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0320 - val_loss: 8.4281e-04 - val_mae: 0.0217\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0354 - val_loss: 7.6247e-04 - val_mae: 0.0199\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 9.1485e-04 - val_mae: 0.0231\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0289 - val_loss: 7.6528e-04 - val_mae: 0.0200\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0341 - val_loss: 7.1656e-04 - val_mae: 0.0188\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0328 - val_loss: 7.3701e-04 - val_mae: 0.0193\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0308 - val_loss: 8.5931e-04 - val_mae: 0.0220\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 9.3270e-04 - val_mae: 0.0234\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0361 - val_loss: 8.9212e-04 - val_mae: 0.0227\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0341 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 9.9832e-04 - val_mae: 0.0246\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0296 - val_loss: 9.4581e-04 - val_mae: 0.0237\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0321 - val_loss: 8.8257e-04 - val_mae: 0.0225\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0326 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0308 - val_loss: 8.1967e-04 - val_mae: 0.0212\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 8.3558e-04 - val_mae: 0.0215\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 9.0769e-04 - val_mae: 0.0230\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0270 - val_loss: 8.0422e-04 - val_mae: 0.0209\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 9.6544e-04 - val_mae: 0.0240\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.2988e-04 - val_mae: 0.0234\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0320 - val_loss: 7.4587e-04 - val_mae: 0.0195\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 7.6051e-04 - val_mae: 0.0199\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0333 - val_loss: 6.4415e-04 - val_mae: 0.0168\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0292 - val_loss: 7.8229e-04 - val_mae: 0.0204\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 9.2414e-04 - val_mae: 0.0233\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0291 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0295 - val_loss: 6.5336e-04 - val_mae: 0.0170\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0336 - val_loss: 9.5576e-04 - val_mae: 0.0239\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0292 - val_loss: 8.8669e-04 - val_mae: 0.0226\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0328 - val_loss: 6.8053e-04 - val_mae: 0.0178\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0316 - val_loss: 8.3517e-04 - val_mae: 0.0215\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0300 - val_loss: 7.5682e-04 - val_mae: 0.0198\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0286 - val_loss: 8.4353e-04 - val_mae: 0.0217\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 9.9604e-04 - val_mae: 0.0246\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 6.7694e-04 - val_mae: 0.0177\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0313 - val_loss: 9.3029e-04 - val_mae: 0.0234\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 7.3679e-04 - val_mae: 0.0193\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0280 - val_loss: 8.2454e-04 - val_mae: 0.0213\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 8.8873e-04 - val_mae: 0.0226\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0347 - val_loss: 4.9853e-04 - val_mae: 0.0146\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0349 - val_loss: 8.0597e-04 - val_mae: 0.0209\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 8.1040e-04 - val_mae: 0.0210\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 8.2216e-04 - val_mae: 0.0212\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 8.4590e-04 - val_mae: 0.0217\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0300 - val_loss: 6.8922e-04 - val_mae: 0.0181\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0277 - val_loss: 9.4802e-04 - val_mae: 0.0237\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 8.3690e-04 - val_mae: 0.0216\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 8.5903e-04 - val_mae: 0.0220\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0296 - val_loss: 8.6743e-04 - val_mae: 0.0222\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 9.6140e-04 - val_mae: 0.0240\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0265 - val_loss: 9.7520e-04 - val_mae: 0.0242\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 8.7836e-04 - val_mae: 0.0224\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 8.0268e-04 - val_mae: 0.0208\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0303 - val_loss: 6.9883e-04 - val_mae: 0.0183\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 8.5911e-04 - val_mae: 0.0220\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0251 - val_loss: 9.0289e-04 - val_mae: 0.0229\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 9.2664e-04 - val_mae: 0.0233\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 8.7621e-04 - val_mae: 0.0224\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0284 - val_loss: 7.8072e-04 - val_mae: 0.0203\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0294 - val_loss: 8.8530e-04 - val_mae: 0.0225\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.9948e-04 - val_mae: 0.0246\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0291 - val_loss: 7.8283e-04 - val_mae: 0.0204\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 8.0664e-04 - val_mae: 0.0209\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0275 - val_loss: 8.9504e-04 - val_mae: 0.0227\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0292 - val_loss: 8.8626e-04 - val_mae: 0.0226\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 7.6817e-04 - val_mae: 0.0200\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0270 - val_loss: 9.2447e-04 - val_mae: 0.0233\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.2874e-04 - val_mae: 0.0214\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.2856e-04 - val_mae: 0.0234\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 9.3003e-04 - val_mae: 0.0234\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.7155e-04 - val_mae: 0.0242\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0247 - val_loss: 9.1814e-04 - val_mae: 0.0232\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0281 - val_loss: 8.5695e-04 - val_mae: 0.0220\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0277 - val_loss: 8.0298e-04 - val_mae: 0.0208\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0250 - val_loss: 8.8785e-04 - val_mae: 0.0226\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0287 - val_loss: 9.7843e-04 - val_mae: 0.0243\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.0645e-04 - val_mae: 0.0229\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 6.4269e-04 - val_mae: 0.0167\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0299 - val_loss: 7.9976e-04 - val_mae: 0.0208\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.4794e-04 - val_mae: 0.0237\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0255 - val_loss: 9.8076e-04 - val_mae: 0.0243\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.3505e-04 - val_mae: 0.0215\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0276 - val_loss: 9.2384e-04 - val_mae: 0.0233\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 9.9182e-04 - val_mae: 0.0245\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0273 - val_loss: 9.8584e-04 - val_mae: 0.0244\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 8.9676e-04 - val_mae: 0.0228\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 8.3524e-04 - val_mae: 0.0215\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0267 - val_loss: 8.7962e-04 - val_mae: 0.0224\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0310 - val_loss: 6.2388e-04 - val_mae: 0.0163\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 9.4692e-04 - val_mae: 0.0237\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 8.2712e-04 - val_mae: 0.0213\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 7.8794e-04 - val_mae: 0.0205\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 8.2717e-04 - val_mae: 0.0213\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.5555e-04 - val_mae: 0.0239\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.9788e-04 - val_mae: 0.0228\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.3695e-04 - val_mae: 0.0216\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.9431e-04 - val_mae: 0.0246\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 8.7124e-04 - val_mae: 0.0223\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 8.2854e-04 - val_mae: 0.0214\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.5369e-04 - val_mae: 0.0238\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.0869e-04 - val_mae: 0.0230\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 9.9652e-04 - val_mae: 0.0246\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0246 - val_loss: 8.6202e-04 - val_mae: 0.0221\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.7353e-04 - val_mae: 0.0223\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 8.5566e-04 - val_mae: 0.0219\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0245 - val_loss: 9.7005e-04 - val_mae: 0.0241\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.8832e-04 - val_mae: 0.0245\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 9.8430e-04 - val_mae: 0.0244\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 9.0992e-04 - val_mae: 0.0230\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0254 - val_loss: 8.9602e-04 - val_mae: 0.0227\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.3632e-04 - val_mae: 0.0215\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 8.7435e-04 - val_mae: 0.0223\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0210 - val_loss: 9.8002e-04 - val_mae: 0.0243\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0321 - val_loss: 4.8777e-04 - val_mae: 0.0146\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0326 - val_loss: 7.7128e-04 - val_mae: 0.0201\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0046 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.4992e-04 - val_mae: 0.0238\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0045 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.7982e-04 - val_mae: 0.0224\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.1168e-04 - val_mae: 0.0230\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.8288e-04 - val_mae: 0.0244\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0238 - val_loss: 9.2486e-04 - val_mae: 0.0233\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.3042e-04 - val_mae: 0.0234\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0229 - val_loss: 9.2761e-04 - val_mae: 0.0234\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.3292e-04 - val_mae: 0.0234\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 9.3959e-04 - val_mae: 0.0236\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 7.9580e-04 - val_mae: 0.0207\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 8.8603e-04 - val_mae: 0.0226\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0263 - val_loss: 8.4809e-04 - val_mae: 0.0218\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.4591e-04 - val_mae: 0.0237\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.1539e-04 - val_mae: 0.0231\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0255 - val_loss: 9.9080e-04 - val_mae: 0.0245\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0238 - val_loss: 9.1942e-04 - val_mae: 0.0232\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 8.9235e-04 - val_mae: 0.0227\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.9871e-04 - val_mae: 0.0228\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.2095e-04 - val_mae: 0.0232\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.9754e-04 - val_mae: 0.0246\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 8.1336e-04 - val_mae: 0.0211\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0258 - val_loss: 9.3532e-04 - val_mae: 0.0235\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 8.8072e-04 - val_mae: 0.0224\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.8431e-04 - val_mae: 0.0244\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0219 - val_loss: 9.2826e-04 - val_mae: 0.0234\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.2040e-04 - val_mae: 0.0232\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 8.5283e-04 - val_mae: 0.0219\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.1817e-04 - val_mae: 0.0232\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.1636e-04 - val_mae: 0.0211\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0241 - val_loss: 9.6787e-04 - val_mae: 0.0241\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.9978e-04 - val_mae: 0.0228\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.0343e-04 - val_mae: 0.0229\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 9.0173e-04 - val_mae: 0.0229\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0243 - val_loss: 9.0997e-04 - val_mae: 0.0230\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 9.7794e-04 - val_mae: 0.0243\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.8280e-04 - val_mae: 0.0244\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.1365e-04 - val_mae: 0.0231\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.5706e-04 - val_mae: 0.0239\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.2772e-04 - val_mae: 0.0234\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0237 - val_loss: 8.7866e-04 - val_mae: 0.0224\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0671e-04 - val_mae: 0.0230\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0004e-04 - val_mae: 0.0228\n",
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_70\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_720 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_650 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_721 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_651 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_722 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_652 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_723 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_653 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_724 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_654 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_725 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_655 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_726 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_656 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_727 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_657 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_728 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_658 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_729 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_659 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_730 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_660 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_731 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 21ms/step - loss: 0.2036 - mae: 0.3587 - val_loss: 6.0740e-04 - val_mae: 0.0160\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1900 - mae: 0.3601 - val_loss: 0.0149 - val_mae: 0.1200\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1456 - mae: 0.2997 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1352 - mae: 0.3126 - val_loss: 0.0053 - val_mae: 0.0692\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1140 - mae: 0.2649 - val_loss: 7.9807e-04 - val_mae: 0.0207\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0882 - mae: 0.2391 - val_loss: 5.4454e-04 - val_mae: 0.0180\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1018 - mae: 0.2512 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0844 - mae: 0.2287 - val_loss: 8.8987e-04 - val_mae: 0.0276\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0948 - mae: 0.2450 - val_loss: 6.7393e-04 - val_mae: 0.0226\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0751 - mae: 0.2071 - val_loss: 7.8606e-04 - val_mae: 0.0204\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0666 - mae: 0.2140 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0570 - mae: 0.1863 - val_loss: 0.0050 - val_mae: 0.0674\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0522 - mae: 0.1787 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0529 - mae: 0.1884 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0530 - mae: 0.1875 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0562 - mae: 0.1925 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0431 - mae: 0.1634 - val_loss: 0.0092 - val_mae: 0.0934\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0437 - mae: 0.1675 - val_loss: 0.0010 - val_mae: 0.0300\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0546 - mae: 0.1717 - val_loss: 6.1634e-04 - val_mae: 0.0162\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0396 - mae: 0.1575 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0393 - mae: 0.1537 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0287 - mae: 0.1282 - val_loss: 5.7175e-04 - val_mae: 0.0154\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1380 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0313 - mae: 0.1459 - val_loss: 5.1353e-04 - val_mae: 0.0147\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - mae: 0.1261 - val_loss: 5.2786e-04 - val_mae: 0.0172\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0243 - mae: 0.1192 - val_loss: 0.0033 - val_mae: 0.0528\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - mae: 0.1026 - val_loss: 4.8393e-04 - val_mae: 0.0151\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0270 - mae: 0.1283 - val_loss: 9.8602e-04 - val_mae: 0.0244\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0277 - mae: 0.1197 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0200 - mae: 0.1123 - val_loss: 0.0062 - val_mae: 0.0756\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0260 - mae: 0.1162 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0190 - mae: 0.0952 - val_loss: 5.3680e-04 - val_mae: 0.0150\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0175 - mae: 0.0891 - val_loss: 5.9108e-04 - val_mae: 0.0157\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.0966 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - mae: 0.0907 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0917 - val_loss: 6.2804e-04 - val_mae: 0.0164\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - mae: 0.0906 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.0838 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - mae: 0.0903 - val_loss: 5.6668e-04 - val_mae: 0.0154\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.0791 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0825 - val_loss: 5.5834e-04 - val_mae: 0.0153\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - mae: 0.0769 - val_loss: 5.1462e-04 - val_mae: 0.0147\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0678 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - mae: 0.0759 - val_loss: 7.9540e-04 - val_mae: 0.0207\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0647 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - mae: 0.0758 - val_loss: 9.7940e-04 - val_mae: 0.0243\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0681 - val_loss: 4.9232e-04 - val_mae: 0.0146\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0666 - val_loss: 5.2582e-04 - val_mae: 0.0149\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - mae: 0.0661 - val_loss: 9.6383e-04 - val_mae: 0.0240\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0554 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - mae: 0.0713 - val_loss: 5.8147e-04 - val_mae: 0.0156\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0627 - val_loss: 7.3559e-04 - val_mae: 0.0193\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0652 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0081 - mae: 0.0610 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0523 - val_loss: 9.1398e-04 - val_mae: 0.0231\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0646 - val_loss: 8.2475e-04 - val_mae: 0.0213\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0621 - val_loss: 9.8752e-04 - val_mae: 0.0244\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0560 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0604 - val_loss: 9.2770e-04 - val_mae: 0.0234\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0506 - val_loss: 9.6373e-04 - val_mae: 0.0240\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0595 - val_loss: 7.7111e-04 - val_mae: 0.0201\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0547 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0554 - val_loss: 6.0730e-04 - val_mae: 0.0160\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - mae: 0.0600 - val_loss: 8.3757e-04 - val_mae: 0.0216\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0519 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0587 - val_loss: 7.0697e-04 - val_mae: 0.0185\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0500 - val_loss: 8.1420e-04 - val_mae: 0.0211\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0487 - val_loss: 6.0134e-04 - val_mae: 0.0159\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0498 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0493 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0522 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0529 - val_loss: 7.7768e-04 - val_mae: 0.0203\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0459 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0415 - val_loss: 8.7173e-04 - val_mae: 0.0223\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0433 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0486 - val_loss: 7.4747e-04 - val_mae: 0.0195\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0503 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0497 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0445 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0415 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0430 - val_loss: 7.5692e-04 - val_mae: 0.0198\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0443 - val_loss: 7.9991e-04 - val_mae: 0.0208\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0494 - val_loss: 8.0563e-04 - val_mae: 0.0209\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0459 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0408 - val_loss: 9.8735e-04 - val_mae: 0.0244\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0357 - val_loss: 9.2631e-04 - val_mae: 0.0233\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0413 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0391 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0433 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0391 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0395 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - mae: 0.0430 - val_loss: 4.7685e-04 - val_mae: 0.0146\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0399 - val_loss: 9.1072e-04 - val_mae: 0.0230\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - mae: 0.0400 - val_loss: 9.8811e-04 - val_mae: 0.0245\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0055 - mae: 0.0335 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0399 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0055 - mae: 0.0390 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0358 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0055 - mae: 0.0378 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - mae: 0.0382 - val_loss: 8.7547e-04 - val_mae: 0.0223\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0063 - mae: 0.0436 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0055 - mae: 0.0346 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0054 - mae: 0.0389 - val_loss: 9.2165e-04 - val_mae: 0.0232\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0063 - mae: 0.0415 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0049 - mae: 0.0343 - val_loss: 8.4999e-04 - val_mae: 0.0218\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0057 - mae: 0.0410 - val_loss: 9.7883e-04 - val_mae: 0.0243\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0387 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0345 - val_loss: 7.4441e-04 - val_mae: 0.0195\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0388 - val_loss: 8.4803e-04 - val_mae: 0.0218\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0375 - val_loss: 8.3241e-04 - val_mae: 0.0215\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0376 - val_loss: 9.2263e-04 - val_mae: 0.0233\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0339 - val_loss: 6.9398e-04 - val_mae: 0.0182\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0059 - mae: 0.0377 - val_loss: 7.4335e-04 - val_mae: 0.0194\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0377 - val_loss: 9.7288e-04 - val_mae: 0.0242\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - mae: 0.0386 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0057 - mae: 0.0367 - val_loss: 9.0146e-04 - val_mae: 0.0229\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0337 - val_loss: 7.4596e-04 - val_mae: 0.0195\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0355 - val_loss: 9.5719e-04 - val_mae: 0.0239\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0053 - mae: 0.0362 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0057 - mae: 0.0331 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0308 - val_loss: 9.7626e-04 - val_mae: 0.0242\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0049 - mae: 0.0357 - val_loss: 7.7985e-04 - val_mae: 0.0203\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0370 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0052 - mae: 0.0355 - val_loss: 9.7484e-04 - val_mae: 0.0242\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0354 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0331 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0346 - val_loss: 8.7701e-04 - val_mae: 0.0224\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0333 - val_loss: 9.8467e-04 - val_mae: 0.0244\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0352 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0297 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0301 - val_loss: 9.0028e-04 - val_mae: 0.0228\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0348 - val_loss: 9.8887e-04 - val_mae: 0.0245\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0316 - val_loss: 9.6952e-04 - val_mae: 0.0241\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0303 - val_loss: 8.2841e-04 - val_mae: 0.0214\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0343 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0321 - val_loss: 7.0801e-04 - val_mae: 0.0186\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0335 - val_loss: 9.4483e-04 - val_mae: 0.0237\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0326 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0336 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0314 - val_loss: 8.0342e-04 - val_mae: 0.0208\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0327 - val_loss: 9.9524e-04 - val_mae: 0.0246\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0293 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0328 - val_loss: 9.9942e-04 - val_mae: 0.0246\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0389 - val_loss: 5.6211e-04 - val_mae: 0.0153\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 9.2893e-04 - val_mae: 0.0234\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0299 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0315 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0301 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0289 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0278 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0313 - val_loss: 9.2427e-04 - val_mae: 0.0233\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0307 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0323 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0314 - val_loss: 9.2384e-04 - val_mae: 0.0233\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0294 - val_loss: 9.7351e-04 - val_mae: 0.0242\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0268 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0310 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.4230e-04 - val_mae: 0.0236\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0297 - val_loss: 8.1750e-04 - val_mae: 0.0211\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0345 - val_loss: 9.7173e-04 - val_mae: 0.0242\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0327 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0307 - val_loss: 7.7272e-04 - val_mae: 0.0201\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0289 - val_loss: 9.8619e-04 - val_mae: 0.0244\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 9.8588e-04 - val_mae: 0.0244\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0272 - val_loss: 8.4447e-04 - val_mae: 0.0217\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 9.5665e-04 - val_mae: 0.0239\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 8.8704e-04 - val_mae: 0.0226\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0307 - val_loss: 7.8289e-04 - val_mae: 0.0204\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0280 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0295 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 7.8174e-04 - val_mae: 0.0203\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 9.5447e-04 - val_mae: 0.0238\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.6127e-04 - val_mae: 0.0240\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 7.9050e-04 - val_mae: 0.0205\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0268 - val_loss: 9.2002e-04 - val_mae: 0.0232\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0282 - val_loss: 9.2023e-04 - val_mae: 0.0232\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0262 - val_loss: 8.8744e-04 - val_mae: 0.0226\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.8179e-04 - val_mae: 0.0243\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0280 - val_loss: 9.1200e-04 - val_mae: 0.0231\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 9.6854e-04 - val_mae: 0.0241\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0285 - val_loss: 9.2589e-04 - val_mae: 0.0233\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0248 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 9.5662e-04 - val_mae: 0.0239\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 8.9559e-04 - val_mae: 0.0227\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.9392e-04 - val_mae: 0.0246\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0226 - val_loss: 8.0580e-04 - val_mae: 0.0209\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 9.7600e-04 - val_mae: 0.0242\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 9.5536e-04 - val_mae: 0.0239\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0264 - val_loss: 8.2797e-04 - val_mae: 0.0214\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0254 - val_loss: 9.9599e-04 - val_mae: 0.0246\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 7.9186e-04 - val_mae: 0.0206\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0262 - val_loss: 8.1558e-04 - val_mae: 0.0211\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0247 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.3325e-04 - val_mae: 0.0215\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0267 - val_loss: 9.7688e-04 - val_mae: 0.0243\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 7.6240e-04 - val_mae: 0.0199\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0286 - val_loss: 8.2026e-04 - val_mae: 0.0212\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 9.9358e-04 - val_mae: 0.0245\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0035 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.6745e-04 - val_mae: 0.0241\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0268 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 9.0403e-04 - val_mae: 0.0229\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0258 - val_loss: 9.0090e-04 - val_mae: 0.0228\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.5444e-04 - val_mae: 0.0219\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.9178e-04 - val_mae: 0.0245\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0244 - val_loss: 9.3411e-04 - val_mae: 0.0235\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 7.9688e-04 - val_mae: 0.0207\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0267 - val_loss: 9.7296e-04 - val_mae: 0.0242\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0248 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.2693e-04 - val_mae: 0.0233\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 9.3057e-04 - val_mae: 0.0234\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.8141e-04 - val_mae: 0.0225\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0273 - val_loss: 8.2776e-04 - val_mae: 0.0214\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0047 - mae: 0.0269 - val_loss: 7.7470e-04 - val_mae: 0.0202\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.2155e-04 - val_mae: 0.0232\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.6205e-04 - val_mae: 0.0240\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 6.9420e-04 - val_mae: 0.0182\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.5340e-04 - val_mae: 0.0238\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.8288e-04 - val_mae: 0.0244\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0249 - val_loss: 9.2625e-04 - val_mae: 0.0233\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 8.9047e-04 - val_mae: 0.0226\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0253 - val_loss: 8.0618e-04 - val_mae: 0.0209\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0261 - val_loss: 9.8337e-04 - val_mae: 0.0244\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0237 - val_loss: 9.4856e-04 - val_mae: 0.0237\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 8.5104e-04 - val_mae: 0.0218\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0272 - val_loss: 8.8375e-04 - val_mae: 0.0225\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 8.4458e-04 - val_mae: 0.0217\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 8.3154e-04 - val_mae: 0.0214\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 8.7943e-04 - val_mae: 0.0224\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 9.0940e-04 - val_mae: 0.0230\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.9886e-04 - val_mae: 0.0246\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 6.7269e-04 - val_mae: 0.0176\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.8224e-04 - val_mae: 0.0243\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.9975e-04 - val_mae: 0.0247\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.2629e-04 - val_mae: 0.0233\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.0786e-04 - val_mae: 0.0230\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.1824e-04 - val_mae: 0.0232\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.2782e-04 - val_mae: 0.0214\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 9.6468e-04 - val_mae: 0.0240\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0231 - val_loss: 8.9272e-04 - val_mae: 0.0227\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.6364e-04 - val_mae: 0.0240\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 8.5927e-04 - val_mae: 0.0220\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 8.6122e-04 - val_mae: 0.0221\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.7908e-04 - val_mae: 0.0243\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 8.3951e-04 - val_mae: 0.0216\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0253 - val_loss: 8.7628e-04 - val_mae: 0.0224\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0246 - val_loss: 9.0900e-04 - val_mae: 0.0230\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0244 - val_loss: 9.2686e-04 - val_mae: 0.0233\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0896e-04 - val_mae: 0.0230\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.6521e-04 - val_mae: 0.0240\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 8.4104e-04 - val_mae: 0.0216\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 9.4025e-04 - val_mae: 0.0236\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0230 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.6550e-04 - val_mae: 0.0221\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 8.2551e-04 - val_mae: 0.0213\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.5577e-04 - val_mae: 0.0219\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 9.0578e-04 - val_mae: 0.0229\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 9.5161e-04 - val_mae: 0.0238\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.0247e-04 - val_mae: 0.0229\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0238 - val_loss: 9.0990e-04 - val_mae: 0.0230\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.5394e-04 - val_mae: 0.0238\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.5567e-04 - val_mae: 0.0219\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9726e-04 - val_mae: 0.0228\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 9.8243e-04 - val_mae: 0.0243\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.6297e-04 - val_mae: 0.0240\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.8978e-04 - val_mae: 0.0245\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 8.7819e-04 - val_mae: 0.0224\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 9.8862e-04 - val_mae: 0.0245\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.3853e-04 - val_mae: 0.0236\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0228 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.6102e-04 - val_mae: 0.0240\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 9.4811e-04 - val_mae: 0.0237\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0047 - mae: 0.0252 - val_loss: 9.4673e-04 - val_mae: 0.0237\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.9419e-04 - val_mae: 0.0246\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0042 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_71\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_732 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_661 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_733 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_662 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_734 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_663 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_735 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_664 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_736 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_665 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_737 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_666 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_738 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_667 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_739 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_668 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_740 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_669 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_741 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_670 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_742 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_671 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_743 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 21ms/step - loss: 0.1711 - mae: 0.3287 - val_loss: 0.0076 - val_mae: 0.0843\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1150 - mae: 0.2810 - val_loss: 0.0055 - val_mae: 0.0711\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1048 - mae: 0.2545 - val_loss: 0.0051 - val_mae: 0.0680\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1079 - mae: 0.2504 - val_loss: 0.0049 - val_mae: 0.0667\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0848 - mae: 0.2321 - val_loss: 0.0026 - val_mae: 0.0478\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0896 - mae: 0.2316 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0841 - mae: 0.2291 - val_loss: 8.3880e-04 - val_mae: 0.0216\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0727 - mae: 0.2151 - val_loss: 5.0848e-04 - val_mae: 0.0161\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0552 - mae: 0.1871 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0735 - mae: 0.2180 - val_loss: 5.0837e-04 - val_mae: 0.0146\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0581 - mae: 0.1940 - val_loss: 7.8302e-04 - val_mae: 0.0254\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0626 - mae: 0.1999 - val_loss: 6.2653e-04 - val_mae: 0.0164\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0509 - mae: 0.1769 - val_loss: 0.0062 - val_mae: 0.0754\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0376 - mae: 0.1512 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0398 - mae: 0.1594 - val_loss: 5.7177e-04 - val_mae: 0.0192\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0324 - mae: 0.1417 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0311 - mae: 0.1370 - val_loss: 6.1418e-04 - val_mae: 0.0161\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1359 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0277 - mae: 0.1405 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0268 - mae: 0.1294 - val_loss: 9.6901e-04 - val_mae: 0.0241\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0266 - mae: 0.1189 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - mae: 0.1144 - val_loss: 4.7401e-04 - val_mae: 0.0146\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0249 - mae: 0.1222 - val_loss: 5.9865e-04 - val_mae: 0.0159\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0232 - mae: 0.1090 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0213 - mae: 0.1134 - val_loss: 9.4193e-04 - val_mae: 0.0236\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0237 - mae: 0.1123 - val_loss: 7.0067e-04 - val_mae: 0.0234\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - mae: 0.0949 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - mae: 0.1102 - val_loss: 5.8704e-04 - val_mae: 0.0157\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - mae: 0.0891 - val_loss: 9.3262e-04 - val_mae: 0.0234\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - mae: 0.0949 - val_loss: 7.2620e-04 - val_mae: 0.0190\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - mae: 0.0781 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0163 - mae: 0.0985 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0135 - mae: 0.0887 - val_loss: 6.3002e-04 - val_mae: 0.0164\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0785 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0627 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0665 - val_loss: 8.8754e-04 - val_mae: 0.0226\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0146 - mae: 0.0864 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0811 - val_loss: 7.9358e-04 - val_mae: 0.0206\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0698 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0740 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0712 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.0730 - val_loss: 7.2543e-04 - val_mae: 0.0190\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.0751 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0677 - val_loss: 4.7418e-04 - val_mae: 0.0146\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.0740 - val_loss: 5.9638e-04 - val_mae: 0.0158\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0659 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0580 - val_loss: 5.8670e-04 - val_mae: 0.0157\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0647 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0669 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0094 - mae: 0.0550 - val_loss: 8.2631e-04 - val_mae: 0.0213\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0109 - mae: 0.0673 - val_loss: 4.7400e-04 - val_mae: 0.0146\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0579 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - mae: 0.0553 - val_loss: 8.4866e-04 - val_mae: 0.0218\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - mae: 0.0533 - val_loss: 8.3548e-04 - val_mae: 0.0215\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - mae: 0.0478 - val_loss: 8.0150e-04 - val_mae: 0.0208\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - mae: 0.0532 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0087 - mae: 0.0539 - val_loss: 9.0889e-04 - val_mae: 0.0230\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0060 - mae: 0.0504 - val_loss: 7.0012e-04 - val_mae: 0.0183\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0072 - mae: 0.0469 - val_loss: 5.9436e-04 - val_mae: 0.0158\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0069 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - mae: 0.0479 - val_loss: 6.8714e-04 - val_mae: 0.0180\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - mae: 0.0515 - val_loss: 9.3921e-04 - val_mae: 0.0236\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - mae: 0.0483 - val_loss: 8.7715e-04 - val_mae: 0.0224\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - mae: 0.0480 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0058 - mae: 0.0458 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - mae: 0.0525 - val_loss: 5.8425e-04 - val_mae: 0.0156\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0485 - val_loss: 8.3926e-04 - val_mae: 0.0216\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0458 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0063 - mae: 0.0404 - val_loss: 8.2651e-04 - val_mae: 0.0213\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0457 - val_loss: 8.7472e-04 - val_mae: 0.0223\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0443 - val_loss: 8.9661e-04 - val_mae: 0.0228\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0427 - val_loss: 8.6131e-04 - val_mae: 0.0221\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0421 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0384 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - mae: 0.0453 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0401 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0398 - val_loss: 6.6284e-04 - val_mae: 0.0173\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0413 - val_loss: 8.9743e-04 - val_mae: 0.0228\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0396 - val_loss: 9.4868e-04 - val_mae: 0.0237\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0416 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0389 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0369 - val_loss: 9.7103e-04 - val_mae: 0.0241\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0383 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0370 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0384 - val_loss: 8.1919e-04 - val_mae: 0.0212\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0387 - val_loss: 9.0003e-04 - val_mae: 0.0228\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0357 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0367 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0375 - val_loss: 7.3731e-04 - val_mae: 0.0193\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0407 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0397 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0374 - val_loss: 9.1639e-04 - val_mae: 0.0231\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0339 - val_loss: 9.8800e-04 - val_mae: 0.0244\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0360 - val_loss: 9.3501e-04 - val_mae: 0.0235\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0402 - val_loss: 7.6800e-04 - val_mae: 0.0200\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0374 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0326 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0333 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 8.9082e-04 - val_mae: 0.0226\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0337 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0332 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0358 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0384 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0299 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0363 - val_loss: 7.1636e-04 - val_mae: 0.0188\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0362 - val_loss: 9.3103e-04 - val_mae: 0.0234\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0357 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0313 - val_loss: 9.4643e-04 - val_mae: 0.0237\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0365 - val_loss: 8.9224e-04 - val_mae: 0.0227\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0334 - val_loss: 9.9463e-04 - val_mae: 0.0246\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0310 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 8.6908e-04 - val_mae: 0.0222\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0326 - val_loss: 9.2346e-04 - val_mae: 0.0233\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0050 - mae: 0.0326 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0344 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0279 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0322 - val_loss: 9.7746e-04 - val_mae: 0.0243\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0321 - val_loss: 8.3215e-04 - val_mae: 0.0215\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0294 - val_loss: 9.3114e-04 - val_mae: 0.0234\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0276 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0308 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0337 - val_loss: 8.5179e-04 - val_mae: 0.0219\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0317 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0315 - val_loss: 8.5644e-04 - val_mae: 0.0220\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0317 - val_loss: 6.8054e-04 - val_mae: 0.0178\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0358 - val_loss: 9.3223e-04 - val_mae: 0.0234\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 9.2249e-04 - val_mae: 0.0233\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0289 - val_loss: 9.4931e-04 - val_mae: 0.0238\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0051 - mae: 0.0320 - val_loss: 9.7763e-04 - val_mae: 0.0243\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0279 - val_loss: 8.1090e-04 - val_mae: 0.0210\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0058 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0048 - mae: 0.0292 - val_loss: 8.6120e-04 - val_mae: 0.0221\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0046 - mae: 0.0306 - val_loss: 8.5720e-04 - val_mae: 0.0220\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0049 - mae: 0.0303 - val_loss: 9.4429e-04 - val_mae: 0.0237\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0048 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0313 - val_loss: 9.2276e-04 - val_mae: 0.0233\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0050 - mae: 0.0290 - val_loss: 8.6158e-04 - val_mae: 0.0221\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 9.8342e-04 - val_mae: 0.0244\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0284 - val_loss: 8.6476e-04 - val_mae: 0.0221\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0283 - val_loss: 9.3882e-04 - val_mae: 0.0236\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 8.2792e-04 - val_mae: 0.0214\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0301 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.9471e-04 - val_mae: 0.0246\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0333 - val_loss: 8.6261e-04 - val_mae: 0.0221\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0302 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0257 - val_loss: 8.6983e-04 - val_mae: 0.0222\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0397 - val_loss: 4.7366e-04 - val_mae: 0.0146\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0340 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 9.1181e-04 - val_mae: 0.0231\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0265 - val_loss: 9.7932e-04 - val_mae: 0.0243\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0270 - val_loss: 9.4388e-04 - val_mae: 0.0237\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0278 - val_loss: 9.7192e-04 - val_mae: 0.0242\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0258 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0281 - val_loss: 8.2374e-04 - val_mae: 0.0213\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 9.8727e-04 - val_mae: 0.0244\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0296 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 9.8593e-04 - val_mae: 0.0244\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 9.6948e-04 - val_mae: 0.0241\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 9.7503e-04 - val_mae: 0.0242\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 9.5250e-04 - val_mae: 0.0238\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.6559e-04 - val_mae: 0.0240\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0326e-04 - val_mae: 0.0229\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0270 - val_loss: 9.7845e-04 - val_mae: 0.0243\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0280 - val_loss: 9.8495e-04 - val_mae: 0.0244\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0254 - val_loss: 8.1496e-04 - val_mae: 0.0211\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 8.9660e-04 - val_mae: 0.0228\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 8.2415e-04 - val_mae: 0.0213\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0306 - val_loss: 9.7770e-04 - val_mae: 0.0243\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 9.9931e-04 - val_mae: 0.0246\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0262 - val_loss: 7.9318e-04 - val_mae: 0.0206\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.7424e-04 - val_mae: 0.0242\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 7.6731e-04 - val_mae: 0.0200\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0277 - val_loss: 9.9551e-04 - val_mae: 0.0246\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.4859e-04 - val_mae: 0.0237\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0266 - val_loss: 9.4324e-04 - val_mae: 0.0236\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 9.1073e-04 - val_mae: 0.0230\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 7.8482e-04 - val_mae: 0.0204\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0261 - val_loss: 8.9143e-04 - val_mae: 0.0227\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0248 - val_loss: 8.4145e-04 - val_mae: 0.0216\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0277 - val_loss: 8.4682e-04 - val_mae: 0.0218\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0238 - val_loss: 8.6642e-04 - val_mae: 0.0222\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0386 - val_loss: 4.7357e-04 - val_mae: 0.0146\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0344 - val_loss: 7.6985e-04 - val_mae: 0.0201\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.6950e-04 - val_mae: 0.0241\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0042 - mae: 0.0238 - val_loss: 9.2158e-04 - val_mae: 0.0232\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.7024e-04 - val_mae: 0.0241\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.0730e-04 - val_mae: 0.0230\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.4212e-04 - val_mae: 0.0236\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 7.7606e-04 - val_mae: 0.0202\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0046 - mae: 0.0249 - val_loss: 9.7150e-04 - val_mae: 0.0242\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 7.4817e-04 - val_mae: 0.0196\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0296 - val_loss: 7.7203e-04 - val_mae: 0.0201\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 8.8547e-04 - val_mae: 0.0225\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.3143e-04 - val_mae: 0.0234\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0270 - val_loss: 8.4217e-04 - val_mae: 0.0217\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.7086e-04 - val_mae: 0.0241\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0046 - mae: 0.0246 - val_loss: 8.7232e-04 - val_mae: 0.0223\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0045 - mae: 0.0238 - val_loss: 8.7619e-04 - val_mae: 0.0224\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 8.0556e-04 - val_mae: 0.0209\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0045 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0273 - val_loss: 7.7931e-04 - val_mae: 0.0203\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.3581e-04 - val_mae: 0.0235\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 8.2378e-04 - val_mae: 0.0213\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.4207e-04 - val_mae: 0.0236\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.7994e-04 - val_mae: 0.0224\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.4176e-04 - val_mae: 0.0236\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 7.7479e-04 - val_mae: 0.0202\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 7.9434e-04 - val_mae: 0.0206\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.3619e-04 - val_mae: 0.0235\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.1228e-04 - val_mae: 0.0210\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 7.9490e-04 - val_mae: 0.0206\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.1498e-04 - val_mae: 0.0231\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 8.0807e-04 - val_mae: 0.0209\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0262 - val_loss: 9.0550e-04 - val_mae: 0.0229\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 8.6486e-04 - val_mae: 0.0221\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.3773e-04 - val_mae: 0.0216\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.9579e-04 - val_mae: 0.0246\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.8564e-04 - val_mae: 0.0244\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 9.6969e-04 - val_mae: 0.0241\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 8.9826e-04 - val_mae: 0.0228\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0225 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.3713e-04 - val_mae: 0.0235\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 9.3634e-04 - val_mae: 0.0235\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0225 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.6174e-04 - val_mae: 0.0240\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 8.6160e-04 - val_mae: 0.0221\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.2142e-04 - val_mae: 0.0232\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.6902e-04 - val_mae: 0.0241\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.5016e-04 - val_mae: 0.0238\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.6627e-04 - val_mae: 0.0241\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 9.6567e-04 - val_mae: 0.0241\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 7.7929e-04 - val_mae: 0.0203\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.1495e-04 - val_mae: 0.0231\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0230 - val_loss: 8.6036e-04 - val_mae: 0.0220\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.1493e-04 - val_mae: 0.0231\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.7054e-04 - val_mae: 0.0222\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 8.8544e-04 - val_mae: 0.0225\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 8.9809e-04 - val_mae: 0.0228\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0222 - val_loss: 9.5265e-04 - val_mae: 0.0238\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 8.9038e-04 - val_mae: 0.0226\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.3808e-04 - val_mae: 0.0235\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.5793e-04 - val_mae: 0.0239\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 8.6647e-04 - val_mae: 0.0222\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.6532e-04 - val_mae: 0.0240\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 8.4801e-04 - val_mae: 0.0218\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0234 - val_loss: 8.8360e-04 - val_mae: 0.0225\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.1286e-04 - val_mae: 0.0231\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.2851e-04 - val_mae: 0.0234\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.9572e-04 - val_mae: 0.0246\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.6361e-04 - val_mae: 0.0240\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.7668e-04 - val_mae: 0.0242\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0045 - mae: 0.0244 - val_loss: 8.4274e-04 - val_mae: 0.0217\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0262 - val_loss: 8.3822e-04 - val_mae: 0.0216\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0045 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0044 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 9.6542e-04 - val_mae: 0.0240\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.6723e-04 - val_mae: 0.0222\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.6238e-04 - val_mae: 0.0240\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0042 - mae: 0.0233 - val_loss: 8.8920e-04 - val_mae: 0.0226\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.2797e-04 - val_mae: 0.0214\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.7506e-04 - val_mae: 0.0223\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.8107e-04 - val_mae: 0.0243\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0228 - val_loss: 9.6364e-04 - val_mae: 0.0240\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 8.7455e-04 - val_mae: 0.0223\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.1502e-04 - val_mae: 0.0231\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 9.5651e-04 - val_mae: 0.0239\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 8.6525e-04 - val_mae: 0.0221\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 8.2827e-04 - val_mae: 0.0214\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0225 - val_loss: 9.7791e-04 - val_mae: 0.0243\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 7.9783e-04 - val_mae: 0.0207\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.1978e-04 - val_mae: 0.0232\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.3797e-04 - val_mae: 0.0235\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.3717e-04 - val_mae: 0.0235\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.7141e-04 - val_mae: 0.0223\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.2212e-04 - val_mae: 0.0212\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.4458e-04 - val_mae: 0.0237\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.7642e-04 - val_mae: 0.0242\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0222 - val_loss: 9.7388e-04 - val_mae: 0.0242\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.2099e-04 - val_mae: 0.0232\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 7.2805e-04 - val_mae: 0.0191\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.5665e-04 - val_mae: 0.0239\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.4524e-04 - val_mae: 0.0237\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 8.7089e-04 - val_mae: 0.0222\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.7858e-04 - val_mae: 0.0224\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.9716e-04 - val_mae: 0.0246\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.2895e-04 - val_mae: 0.0234\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0224 - val_loss: 9.7092e-04 - val_mae: 0.0241\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.9125e-04 - val_mae: 0.0227\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 8.1358e-04 - val_mae: 0.0211\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.7649e-04 - val_mae: 0.0242\n",
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_72\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_744 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_672 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_745 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_673 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_746 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_674 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_747 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_675 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_748 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_676 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_749 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_677 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_750 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_678 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_751 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_679 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_752 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_680 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_753 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_681 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_754 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_682 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_755 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 29ms/step - loss: 23.4083 - mae: 3.4973 - val_loss: 0.1717 - val_mae: 0.4139\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 7.1156 - mae: 2.0026 - val_loss: 0.1405 - val_mae: 0.3742\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 2.6672 - mae: 1.2036 - val_loss: 0.0468 - val_mae: 0.2153\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 2.6304 - mae: 1.2009 - val_loss: 0.0200 - val_mae: 0.1400\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 1.6820 - mae: 0.9685 - val_loss: 0.0044 - val_mae: 0.0631\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.3240 - mae: 0.8585 - val_loss: 0.0127 - val_mae: 0.1109\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.5099 - mae: 0.9417 - val_loss: 0.0169 - val_mae: 0.1279\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.2735 - mae: 0.7899 - val_loss: 0.0137 - val_mae: 0.1148\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6657 - mae: 0.6184 - val_loss: 0.0172 - val_mae: 0.1295\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.6989 - mae: 0.6689 - val_loss: 0.0175 - val_mae: 0.1304\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.5162 - mae: 0.5368 - val_loss: 0.0125 - val_mae: 0.1098\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.0935 - mae: 0.7717 - val_loss: 0.0156 - val_mae: 0.1231\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 1.1357 - mae: 0.7496 - val_loss: 0.0148 - val_mae: 0.1198\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.6601 - mae: 0.5660 - val_loss: 0.0114 - val_mae: 0.1047\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.4623 - mae: 0.5394 - val_loss: 0.0085 - val_mae: 0.0900\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3765 - mae: 0.4493 - val_loss: 0.0042 - val_mae: 0.0616\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4936 - mae: 0.5345 - val_loss: 0.0030 - val_mae: 0.0510\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7369 - mae: 0.5275 - val_loss: 0.0055 - val_mae: 0.0710\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4199 - mae: 0.4614 - val_loss: 0.0124 - val_mae: 0.1093\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3460 - mae: 0.4048 - val_loss: 0.0118 - val_mae: 0.1068\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2229 - mae: 0.3377 - val_loss: 0.0129 - val_mae: 0.1112\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4216 - mae: 0.3871 - val_loss: 0.0100 - val_mae: 0.0978\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2328 - mae: 0.3601 - val_loss: 0.0069 - val_mae: 0.0803\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2192 - mae: 0.3393 - val_loss: 0.0056 - val_mae: 0.0720\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3071 - mae: 0.4002 - val_loss: 0.0034 - val_mae: 0.0543\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2332 - mae: 0.3553 - val_loss: 0.0045 - val_mae: 0.0632\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2294 - mae: 0.3411 - val_loss: 0.0051 - val_mae: 0.0680\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2721 - mae: 0.3817 - val_loss: 0.0053 - val_mae: 0.0697\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3672 - mae: 0.4118 - val_loss: 0.0059 - val_mae: 0.0737\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1264 - mae: 0.2800 - val_loss: 0.0051 - val_mae: 0.0678\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2541 - mae: 0.3617 - val_loss: 0.0042 - val_mae: 0.0609\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2292 - mae: 0.3195 - val_loss: 0.0036 - val_mae: 0.0560\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1515 - mae: 0.2920 - val_loss: 0.0048 - val_mae: 0.0655\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.1449 - mae: 0.2912 - val_loss: 0.0054 - val_mae: 0.0700\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4030 - mae: 0.3808 - val_loss: 0.0028 - val_mae: 0.0480\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1293 - mae: 0.2571 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2206 - mae: 0.2848 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1541 - mae: 0.2889 - val_loss: 0.0021 - val_mae: 0.0407\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1169 - mae: 0.2564 - val_loss: 0.0031 - val_mae: 0.0517\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1906 - mae: 0.2864 - val_loss: 0.0037 - val_mae: 0.0564\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2276 - mae: 0.3238 - val_loss: 0.0032 - val_mae: 0.0528\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0871 - mae: 0.2199 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0940 - mae: 0.2341 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0910 - mae: 0.2354 - val_loss: 0.0022 - val_mae: 0.0420\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2028 - mae: 0.3101 - val_loss: 0.0036 - val_mae: 0.0557\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1315 - mae: 0.2644 - val_loss: 0.0047 - val_mae: 0.0652\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1029 - mae: 0.2017 - val_loss: 0.0038 - val_mae: 0.0580\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1038 - mae: 0.2209 - val_loss: 0.0035 - val_mae: 0.0549\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0945 - mae: 0.2272 - val_loss: 0.0033 - val_mae: 0.0533\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0991 - mae: 0.2308 - val_loss: 0.0031 - val_mae: 0.0515\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1368 - mae: 0.2353 - val_loss: 0.0033 - val_mae: 0.0534\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0964 - mae: 0.2244 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0431 - mae: 0.1530 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0666 - mae: 0.1988 - val_loss: 0.0021 - val_mae: 0.0403\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1203 - mae: 0.2251 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0921 - mae: 0.2088 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0600 - mae: 0.1747 - val_loss: 0.0020 - val_mae: 0.0387\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1077 - mae: 0.2385 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0833 - mae: 0.2030 - val_loss: 0.0021 - val_mae: 0.0407\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0693 - mae: 0.1913 - val_loss: 0.0024 - val_mae: 0.0435\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0523 - mae: 0.1806 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1015 - mae: 0.2107 - val_loss: 0.0029 - val_mae: 0.0491\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1000 - mae: 0.2158 - val_loss: 0.0033 - val_mae: 0.0531\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0573 - mae: 0.1686 - val_loss: 0.0030 - val_mae: 0.0504\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0643 - mae: 0.1725 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0462 - mae: 0.1454 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0479 - mae: 0.1681 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0554 - mae: 0.1753 - val_loss: 0.0025 - val_mae: 0.0446\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0814 - mae: 0.1924 - val_loss: 0.0026 - val_mae: 0.0461\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0395 - mae: 0.1483 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0574 - mae: 0.1802 - val_loss: 0.0028 - val_mae: 0.0484\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0468 - mae: 0.1606 - val_loss: 0.0034 - val_mae: 0.0540\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1506 - val_loss: 0.0035 - val_mae: 0.0552\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0723 - mae: 0.1918 - val_loss: 0.0037 - val_mae: 0.0571\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0547 - mae: 0.1771 - val_loss: 0.0040 - val_mae: 0.0597\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0661 - mae: 0.1921 - val_loss: 0.0039 - val_mae: 0.0588\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0602 - mae: 0.1586 - val_loss: 0.0035 - val_mae: 0.0546\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0683 - mae: 0.1981 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0670 - mae: 0.1723 - val_loss: 0.0033 - val_mae: 0.0531\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0445 - mae: 0.1245 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0315 - mae: 0.1190 - val_loss: 0.0026 - val_mae: 0.0460\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0445 - mae: 0.1588 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0633 - mae: 0.1729 - val_loss: 0.0028 - val_mae: 0.0484\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0486 - mae: 0.1441 - val_loss: 0.0035 - val_mae: 0.0547\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0443 - mae: 0.1479 - val_loss: 0.0039 - val_mae: 0.0582\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0348 - mae: 0.1320 - val_loss: 0.0040 - val_mae: 0.0595\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0484 - mae: 0.1645 - val_loss: 0.0037 - val_mae: 0.0565\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0491 - mae: 0.1423 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0281 - mae: 0.1229 - val_loss: 0.0025 - val_mae: 0.0455\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0452 - mae: 0.1375 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0279 - mae: 0.1289 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0286 - mae: 0.1239 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0420 - mae: 0.1426 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0292 - mae: 0.1237 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0242 - mae: 0.1113 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0333 - mae: 0.1325 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0411 - mae: 0.1475 - val_loss: 0.0023 - val_mae: 0.0425\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0522 - mae: 0.1605 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0286 - mae: 0.1264 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0244 - mae: 0.1111 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0278 - mae: 0.1303 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0431 - mae: 0.1322 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0255 - mae: 0.1129 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0280 - mae: 0.1138 - val_loss: 0.0018 - val_mae: 0.0365\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0270 - mae: 0.1191 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0363 - mae: 0.1163 - val_loss: 0.0023 - val_mae: 0.0422\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0449 - mae: 0.1354 - val_loss: 0.0024 - val_mae: 0.0436\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0341 - mae: 0.1209 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0341 - mae: 0.1294 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0230 - mae: 0.1097 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0248 - mae: 0.1102 - val_loss: 0.0022 - val_mae: 0.0410\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0220 - mae: 0.0967 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0242 - mae: 0.1112 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0250 - mae: 0.1160 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0231 - mae: 0.1060 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0227 - mae: 0.1113 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0286 - mae: 0.1106 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0590 - mae: 0.1441 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - mae: 0.1001 - val_loss: 0.0020 - val_mae: 0.0385\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0250 - mae: 0.1173 - val_loss: 0.0021 - val_mae: 0.0397\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - mae: 0.1123 - val_loss: 0.0021 - val_mae: 0.0405\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0268 - mae: 0.1168 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - mae: 0.0875 - val_loss: 0.0019 - val_mae: 0.0373\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0384 - mae: 0.1324 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0168 - mae: 0.0930 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0252 - mae: 0.1134 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0255 - mae: 0.1112 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - mae: 0.0772 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0214 - mae: 0.1085 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - mae: 0.1001 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0149 - mae: 0.0895 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0193 - mae: 0.0903 - val_loss: 0.0016 - val_mae: 0.0343\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0267 - mae: 0.1145 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0254 - mae: 0.1036 - val_loss: 0.0020 - val_mae: 0.0395\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0218 - mae: 0.0918 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - mae: 0.0852 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0221 - mae: 0.0993 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0167 - mae: 0.0843 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0170 - mae: 0.0907 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0216 - mae: 0.1070 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0760 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0229 - mae: 0.1018 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0163 - mae: 0.0923 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0210 - mae: 0.1017 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - mae: 0.0921 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0797 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - mae: 0.0891 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0189 - mae: 0.0923 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0804 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - mae: 0.0813 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0149 - mae: 0.0821 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0134 - mae: 0.0806 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - mae: 0.0886 - val_loss: 0.0020 - val_mae: 0.0395\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0215 - mae: 0.0822 - val_loss: 0.0019 - val_mae: 0.0371\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0189 - mae: 0.0967 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0145 - mae: 0.0774 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0808 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0176 - mae: 0.0824 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - mae: 0.0780 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0680 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0157 - mae: 0.0864 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0101 - mae: 0.0653 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0145 - mae: 0.0787 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0189 - mae: 0.0883 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0139 - mae: 0.0753 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0152 - mae: 0.0817 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0146 - mae: 0.0764 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0106 - mae: 0.0646 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0125 - mae: 0.0691 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - mae: 0.0842 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0697 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0182 - mae: 0.0907 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - mae: 0.0627 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0161 - mae: 0.0848 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0154 - mae: 0.0796 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0154 - mae: 0.0727 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - mae: 0.0746 - val_loss: 0.0017 - val_mae: 0.0356\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.0669 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0716 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0781 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.0698 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - mae: 0.0703 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0123 - mae: 0.0779 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.0697 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0113 - mae: 0.0702 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.0664 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0108 - mae: 0.0661 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0134 - mae: 0.0770 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0689 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.0755 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.0656 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - mae: 0.0707 - val_loss: 9.4279e-04 - val_mae: 0.0236\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0567 - val_loss: 8.9863e-04 - val_mae: 0.0228\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.0680 - val_loss: 8.5836e-04 - val_mae: 0.0220\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0137 - mae: 0.0769 - val_loss: 8.8222e-04 - val_mae: 0.0225\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - mae: 0.0630 - val_loss: 9.9860e-04 - val_mae: 0.0246\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0777 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0111 - mae: 0.0668 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0699 - val_loss: 9.8357e-04 - val_mae: 0.0244\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0113 - mae: 0.0747 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0157 - mae: 0.0706 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0692 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0665 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.0633 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0657 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.0656 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0637 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0624 - val_loss: 8.8478e-04 - val_mae: 0.0225\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0712 - val_loss: 7.5526e-04 - val_mae: 0.0197\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0695 - val_loss: 6.1004e-04 - val_mae: 0.0161\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - mae: 0.0684 - val_loss: 6.6947e-04 - val_mae: 0.0175\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - mae: 0.0627 - val_loss: 8.4636e-04 - val_mae: 0.0217\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0547 - val_loss: 8.8843e-04 - val_mae: 0.0226\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0665 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - mae: 0.0584 - val_loss: 9.8039e-04 - val_mae: 0.0243\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - mae: 0.0670 - val_loss: 9.2599e-04 - val_mae: 0.0233\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0104 - mae: 0.0693 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0104 - mae: 0.0647 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - mae: 0.0693 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - mae: 0.0653 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0561 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0482 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - mae: 0.0566 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0237 - mae: 0.0636 - val_loss: 9.4682e-04 - val_mae: 0.0237\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0081 - mae: 0.0556 - val_loss: 8.4512e-04 - val_mae: 0.0217\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0575 - val_loss: 8.1476e-04 - val_mae: 0.0211\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0614 - val_loss: 6.6573e-04 - val_mae: 0.0174\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0611 - val_loss: 7.5048e-04 - val_mae: 0.0196\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0590 - val_loss: 8.4236e-04 - val_mae: 0.0217\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0573 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0131 - mae: 0.0652 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0536 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0522 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - mae: 0.0588 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0564 - val_loss: 0.0016 - val_mae: 0.0328\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0566 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0111 - mae: 0.0625 - val_loss: 9.7652e-04 - val_mae: 0.0242\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0579 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0565 - val_loss: 9.8363e-04 - val_mae: 0.0244\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0092 - mae: 0.0622 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0581 - val_loss: 9.7754e-04 - val_mae: 0.0243\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0077 - mae: 0.0538 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0070 - mae: 0.0472 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0095 - mae: 0.0528 - val_loss: 9.8082e-04 - val_mae: 0.0243\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0221 - mae: 0.0742 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0075 - mae: 0.0509 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - mae: 0.0637 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - mae: 0.0516 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0485 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0083 - mae: 0.0515 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0096 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0079 - mae: 0.0554 - val_loss: 9.4502e-04 - val_mae: 0.0237\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0067 - mae: 0.0463 - val_loss: 8.6820e-04 - val_mae: 0.0222\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0076 - mae: 0.0525 - val_loss: 9.7115e-04 - val_mae: 0.0241\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - mae: 0.0571 - val_loss: 8.6390e-04 - val_mae: 0.0221\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0078 - mae: 0.0512 - val_loss: 9.4251e-04 - val_mae: 0.0236\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - mae: 0.0479 - val_loss: 9.4953e-04 - val_mae: 0.0238\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - mae: 0.0557 - val_loss: 9.4643e-04 - val_mae: 0.0237\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - mae: 0.0454 - val_loss: 9.8296e-04 - val_mae: 0.0244\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0547 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - mae: 0.0534 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - mae: 0.0465 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0493 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - mae: 0.0515 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0466 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0450 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - mae: 0.0551 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - mae: 0.0450 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - mae: 0.0448 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0090 - mae: 0.0543 - val_loss: 9.9382e-04 - val_mae: 0.0245\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0516 - val_loss: 9.5291e-04 - val_mae: 0.0238\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0536 - val_loss: 8.0187e-04 - val_mae: 0.0208\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0415 - val_loss: 9.6962e-04 - val_mae: 0.0241\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0410 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - mae: 0.0477 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0491 - val_loss: 9.4406e-04 - val_mae: 0.0237\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0477 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - mae: 0.0495 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0509 - val_loss: 7.7284e-04 - val_mae: 0.0201\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0587 - val_loss: 6.5081e-04 - val_mae: 0.0170\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0495 - val_loss: 7.9590e-04 - val_mae: 0.0207\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0478 - val_loss: 9.8421e-04 - val_mae: 0.0244\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0461 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0437 - val_loss: 9.9932e-04 - val_mae: 0.0246\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0430 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0483 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0408 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0080 - mae: 0.0520 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0436 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0515 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - mae: 0.0499 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0431 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - mae: 0.0437 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0065 - mae: 0.0441 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0049 - mae: 0.0385 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0450 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0379 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0091 - mae: 0.0555 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0428 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - mae: 0.0496 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0454 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0467 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0435 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - mae: 0.0408 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0426 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0381 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0050 - mae: 0.0393 - val_loss: 9.4070e-04 - val_mae: 0.0236\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0416 - val_loss: 9.9577e-04 - val_mae: 0.0246\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - mae: 0.0463 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0394 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - mae: 0.0438 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0428 - val_loss: 9.6436e-04 - val_mae: 0.0240\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - mae: 0.0415 - val_loss: 9.2649e-04 - val_mae: 0.0233\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0389 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0376 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - mae: 0.0436 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0338 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0458 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0052 - mae: 0.0371 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0065 - mae: 0.0458 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0060 - mae: 0.0424 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0057 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0385 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0065 - mae: 0.0439 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - mae: 0.0458 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0061 - mae: 0.0415 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0058 - mae: 0.0380 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0067 - mae: 0.0455 - val_loss: 9.8086e-04 - val_mae: 0.0243\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0052 - mae: 0.0412 - val_loss: 9.7475e-04 - val_mae: 0.0242\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - mae: 0.0379 - val_loss: 9.4028e-04 - val_mae: 0.0236\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0053 - mae: 0.0422 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0335 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0034 - mae: 0.0374 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0058 - mae: 0.0403 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0060 - mae: 0.0378 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - mae: 0.0388 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0059 - mae: 0.0442 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0054 - mae: 0.0355 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0035 - mae: 0.0356 - val_loss: 9.9733e-04 - val_mae: 0.0246\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0368 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0372 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0408 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0406 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0400 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0354 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0368 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0374 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0390 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_73\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_756 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_683 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_757 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_684 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_758 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_685 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_759 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_686 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_760 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_687 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_761 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_688 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_762 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_689 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_763 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_690 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_764 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_691 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_765 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_692 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_766 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_693 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_767 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 23ms/step - loss: 34.3955 - mae: 4.0282 - val_loss: 0.4377 - val_mae: 0.6611\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 8.4825 - mae: 2.3786 - val_loss: 0.0019 - val_mae: 0.0341\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 4.1896 - mae: 1.6078 - val_loss: 0.0240 - val_mae: 0.1530\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 4.4899 - mae: 1.5705 - val_loss: 0.0075 - val_mae: 0.0828\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 3.8297 - mae: 1.3173 - val_loss: 0.0018 - val_mae: 0.0337\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 3.3532 - mae: 1.3483 - val_loss: 6.8804e-04 - val_mae: 0.0167\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.0776 - mae: 1.0473 - val_loss: 0.0045 - val_mae: 0.0628\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8005 - mae: 0.9369 - val_loss: 0.0034 - val_mae: 0.0536\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0722 - mae: 0.8012 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.8299 - mae: 0.6965 - val_loss: 5.7071e-04 - val_mae: 0.0148\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.2789 - mae: 0.8411 - val_loss: 0.0014 - val_mae: 0.0358\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.0253 - mae: 0.7202 - val_loss: 0.0026 - val_mae: 0.0487\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0625 - mae: 0.7284 - val_loss: 0.0030 - val_mae: 0.0515\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7318 - mae: 0.6292 - val_loss: 0.0020 - val_mae: 0.0425\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5509 - mae: 0.5395 - val_loss: 0.0028 - val_mae: 0.0494\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7052 - mae: 0.6379 - val_loss: 0.0012 - val_mae: 0.0327\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5033 - mae: 0.5308 - val_loss: 9.6615e-04 - val_mae: 0.0290\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8127 - mae: 0.6186 - val_loss: 0.0019 - val_mae: 0.0414\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6170 - mae: 0.6224 - val_loss: 0.0027 - val_mae: 0.0488\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.3373 - mae: 0.4450 - val_loss: 0.0019 - val_mae: 0.0417\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5331 - mae: 0.5557 - val_loss: 0.0019 - val_mae: 0.0416\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5876 - mae: 0.6012 - val_loss: 6.3626e-04 - val_mae: 0.0158\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3982 - mae: 0.4801 - val_loss: 6.1440e-04 - val_mae: 0.0167\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5118 - mae: 0.5069 - val_loss: 3.9460e-04 - val_mae: 0.0154\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3355 - mae: 0.4379 - val_loss: 3.9463e-04 - val_mae: 0.0154\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4860 - mae: 0.5269 - val_loss: 4.5727e-04 - val_mae: 0.0147\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.6218 - mae: 0.5272 - val_loss: 7.5214e-04 - val_mae: 0.0245\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3160 - mae: 0.4300 - val_loss: 4.8710e-04 - val_mae: 0.0148\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3563 - mae: 0.3994 - val_loss: 5.7813e-04 - val_mae: 0.0155\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2547 - mae: 0.3813 - val_loss: 5.7240e-04 - val_mae: 0.0153\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.3111 - mae: 0.4324 - val_loss: 4.8335e-04 - val_mae: 0.0145\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3330 - mae: 0.4161 - val_loss: 4.8661e-04 - val_mae: 0.0149\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.2473 - mae: 0.3674 - val_loss: 5.3272e-04 - val_mae: 0.0174\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.2125 - mae: 0.3248 - val_loss: 5.4906e-04 - val_mae: 0.0183\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.3173 - mae: 0.3903 - val_loss: 4.8754e-04 - val_mae: 0.0153\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2896 - mae: 0.3474 - val_loss: 4.8249e-04 - val_mae: 0.0146\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.2246 - mae: 0.3460 - val_loss: 4.7499e-04 - val_mae: 0.0146\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.1861 - mae: 0.3200 - val_loss: 4.9653e-04 - val_mae: 0.0157\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3073 - mae: 0.3855 - val_loss: 4.7754e-04 - val_mae: 0.0151\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1749 - mae: 0.3071 - val_loss: 4.7605e-04 - val_mae: 0.0146\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1404 - mae: 0.2677 - val_loss: 4.7991e-04 - val_mae: 0.0146\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1774 - mae: 0.2949 - val_loss: 5.2433e-04 - val_mae: 0.0149\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.2464 - mae: 0.3825 - val_loss: 6.0719e-04 - val_mae: 0.0160\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0978 - mae: 0.2501 - val_loss: 5.9825e-04 - val_mae: 0.0159\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1882 - mae: 0.3118 - val_loss: 5.0417e-04 - val_mae: 0.0146\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1731 - mae: 0.3055 - val_loss: 4.7710e-04 - val_mae: 0.0146\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1296 - mae: 0.2679 - val_loss: 4.7695e-04 - val_mae: 0.0151\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1528 - mae: 0.3063 - val_loss: 4.7192e-04 - val_mae: 0.0146\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1430 - mae: 0.2849 - val_loss: 5.6569e-04 - val_mae: 0.0153\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0924 - mae: 0.2150 - val_loss: 6.1248e-04 - val_mae: 0.0161\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1515 - mae: 0.2730 - val_loss: 5.6539e-04 - val_mae: 0.0154\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0911 - mae: 0.2217 - val_loss: 5.2544e-04 - val_mae: 0.0149\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1209 - mae: 0.2545 - val_loss: 4.7269e-04 - val_mae: 0.0146\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1210 - mae: 0.2422 - val_loss: 4.9950e-04 - val_mae: 0.0146\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1090 - mae: 0.2359 - val_loss: 5.6260e-04 - val_mae: 0.0154\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1654 - mae: 0.2526 - val_loss: 5.1331e-04 - val_mae: 0.0148\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1089 - mae: 0.2196 - val_loss: 5.5442e-04 - val_mae: 0.0153\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1002 - mae: 0.2145 - val_loss: 7.1817e-04 - val_mae: 0.0189\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0823 - mae: 0.2145 - val_loss: 7.3709e-04 - val_mae: 0.0194\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0925 - mae: 0.2304 - val_loss: 7.6751e-04 - val_mae: 0.0201\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0535 - mae: 0.1728 - val_loss: 7.7053e-04 - val_mae: 0.0201\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0989 - mae: 0.2122 - val_loss: 8.0286e-04 - val_mae: 0.0209\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0810 - mae: 0.2122 - val_loss: 7.5927e-04 - val_mae: 0.0199\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1058 - mae: 0.2302 - val_loss: 8.3687e-04 - val_mae: 0.0216\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0982 - mae: 0.2168 - val_loss: 8.6765e-04 - val_mae: 0.0223\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0929 - mae: 0.2177 - val_loss: 8.6493e-04 - val_mae: 0.0222\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0810 - mae: 0.2090 - val_loss: 7.2728e-04 - val_mae: 0.0192\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1196 - mae: 0.2611 - val_loss: 5.3606e-04 - val_mae: 0.0151\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1584 - mae: 0.2876 - val_loss: 5.6253e-04 - val_mae: 0.0154\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0562 - mae: 0.1817 - val_loss: 7.2955e-04 - val_mae: 0.0192\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0781 - mae: 0.1933 - val_loss: 7.1435e-04 - val_mae: 0.0189\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0797 - mae: 0.2159 - val_loss: 6.2329e-04 - val_mae: 0.0163\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0672 - mae: 0.1914 - val_loss: 5.7351e-04 - val_mae: 0.0155\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1151 - mae: 0.2402 - val_loss: 6.6316e-04 - val_mae: 0.0174\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0643 - mae: 0.1884 - val_loss: 7.7250e-04 - val_mae: 0.0202\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0863 - mae: 0.2017 - val_loss: 7.7816e-04 - val_mae: 0.0203\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0706 - mae: 0.1872 - val_loss: 9.3129e-04 - val_mae: 0.0235\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0953 - mae: 0.2058 - val_loss: 8.0494e-04 - val_mae: 0.0210\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0601 - mae: 0.1897 - val_loss: 8.9494e-04 - val_mae: 0.0228\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0695 - mae: 0.1848 - val_loss: 8.4114e-04 - val_mae: 0.0217\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0927 - mae: 0.2200 - val_loss: 9.9615e-04 - val_mae: 0.0246\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1119 - mae: 0.2271 - val_loss: 9.8517e-04 - val_mae: 0.0245\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0574 - mae: 0.1797 - val_loss: 8.6056e-04 - val_mae: 0.0221\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0845 - mae: 0.2118 - val_loss: 8.1771e-04 - val_mae: 0.0213\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1525 - val_loss: 7.9370e-04 - val_mae: 0.0207\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0467 - mae: 0.1670 - val_loss: 7.6508e-04 - val_mae: 0.0201\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0608 - mae: 0.1736 - val_loss: 9.9884e-04 - val_mae: 0.0247\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0423 - mae: 0.1526 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0962 - mae: 0.1934 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0474 - mae: 0.1556 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0688 - mae: 0.1763 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0628 - mae: 0.1623 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0658 - mae: 0.1777 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0650 - mae: 0.1912 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0458 - mae: 0.1404 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0588 - mae: 0.1699 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0379 - mae: 0.1573 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0521 - mae: 0.1764 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0497 - mae: 0.1515 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0407 - mae: 0.1404 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0495 - mae: 0.1588 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0394 - mae: 0.1403 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0453 - mae: 0.1465 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0567 - mae: 0.1784 - val_loss: 9.5032e-04 - val_mae: 0.0238\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0457 - mae: 0.1522 - val_loss: 9.3205e-04 - val_mae: 0.0234\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0574 - mae: 0.1566 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0491 - mae: 0.1442 - val_loss: 8.6485e-04 - val_mae: 0.0221\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0348 - mae: 0.1313 - val_loss: 7.5293e-04 - val_mae: 0.0197\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0803 - mae: 0.1904 - val_loss: 8.7113e-04 - val_mae: 0.0223\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0360 - mae: 0.1330 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0638 - mae: 0.1517 - val_loss: 9.3989e-04 - val_mae: 0.0236\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0404 - mae: 0.1426 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1392 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0341 - mae: 0.1318 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0331 - mae: 0.1343 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0340 - mae: 0.1317 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0333 - mae: 0.1265 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0343 - mae: 0.1289 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0543 - mae: 0.1627 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0396 - mae: 0.1366 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0303 - mae: 0.1282 - val_loss: 9.7604e-04 - val_mae: 0.0242\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0362 - mae: 0.1480 - val_loss: 8.9708e-04 - val_mae: 0.0228\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0409 - mae: 0.1421 - val_loss: 8.0773e-04 - val_mae: 0.0209\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0340 - mae: 0.1218 - val_loss: 9.4639e-04 - val_mae: 0.0237\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0508 - mae: 0.1492 - val_loss: 8.2959e-04 - val_mae: 0.0214\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0508 - mae: 0.1504 - val_loss: 7.7928e-04 - val_mae: 0.0203\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0366 - mae: 0.1435 - val_loss: 7.1475e-04 - val_mae: 0.0187\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0255 - mae: 0.1139 - val_loss: 5.7606e-04 - val_mae: 0.0155\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0265 - mae: 0.1188 - val_loss: 5.6398e-04 - val_mae: 0.0153\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0229 - mae: 0.1036 - val_loss: 5.7208e-04 - val_mae: 0.0154\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0278 - mae: 0.1243 - val_loss: 5.6413e-04 - val_mae: 0.0153\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0262 - mae: 0.1133 - val_loss: 5.8661e-04 - val_mae: 0.0157\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0284 - mae: 0.1279 - val_loss: 6.0875e-04 - val_mae: 0.0161\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - mae: 0.0983 - val_loss: 6.3255e-04 - val_mae: 0.0164\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0291 - mae: 0.1272 - val_loss: 7.5009e-04 - val_mae: 0.0196\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0251 - mae: 0.1022 - val_loss: 9.8185e-04 - val_mae: 0.0243\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0204 - mae: 0.0999 - val_loss: 9.8496e-04 - val_mae: 0.0244\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0206 - mae: 0.0998 - val_loss: 9.2825e-04 - val_mae: 0.0234\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0368 - mae: 0.1297 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0275 - mae: 0.1160 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0243 - mae: 0.1148 - val_loss: 9.0458e-04 - val_mae: 0.0229\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0371 - mae: 0.1368 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0262 - mae: 0.1198 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0301 - mae: 0.1211 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0227 - mae: 0.1106 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0274 - mae: 0.1133 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0245 - mae: 0.1096 - val_loss: 9.3249e-04 - val_mae: 0.0234\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0191 - mae: 0.1029 - val_loss: 8.5052e-04 - val_mae: 0.0218\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0221 - mae: 0.1036 - val_loss: 7.4418e-04 - val_mae: 0.0195\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0256 - mae: 0.1082 - val_loss: 6.9421e-04 - val_mae: 0.0182\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0287 - mae: 0.1179 - val_loss: 7.8812e-04 - val_mae: 0.0205\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0433 - mae: 0.1411 - val_loss: 8.6257e-04 - val_mae: 0.0221\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0219 - mae: 0.1003 - val_loss: 9.8184e-04 - val_mae: 0.0243\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0294 - mae: 0.1140 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0260 - mae: 0.1103 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - mae: 0.0871 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0253 - mae: 0.1122 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0296 - mae: 0.1092 - val_loss: 8.7490e-04 - val_mae: 0.0223\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0350 - mae: 0.1138 - val_loss: 7.6263e-04 - val_mae: 0.0199\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0188 - mae: 0.1008 - val_loss: 6.3222e-04 - val_mae: 0.0164\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0235 - mae: 0.1067 - val_loss: 7.1499e-04 - val_mae: 0.0187\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - mae: 0.1004 - val_loss: 8.3676e-04 - val_mae: 0.0216\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0309 - mae: 0.1188 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - mae: 0.1045 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0200 - mae: 0.0968 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0162 - mae: 0.0917 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0314 - mae: 0.1140 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0214 - mae: 0.0934 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0254 - mae: 0.1037 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0368 - mae: 0.1185 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0262 - mae: 0.1031 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - mae: 0.0962 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0125 - mae: 0.0797 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0216 - mae: 0.0935 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - mae: 0.0993 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0176 - mae: 0.0928 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0139 - mae: 0.0795 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0255 - mae: 0.1045 - val_loss: 0.0016 - val_mae: 0.0343\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0160 - mae: 0.0885 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.0818 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - mae: 0.0879 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0192 - mae: 0.0998 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0227 - mae: 0.1029 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0128 - mae: 0.0781 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.0840 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0709 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0120 - mae: 0.0731 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0212 - mae: 0.0821 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.0790 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - mae: 0.0836 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0171 - mae: 0.0893 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - mae: 0.0794 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0780 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0134 - mae: 0.0750 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - mae: 0.0704 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0132 - mae: 0.0748 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - mae: 0.0786 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0144 - mae: 0.0772 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - mae: 0.0750 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0277 - mae: 0.0983 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0130 - mae: 0.0776 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0105 - mae: 0.0685 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0129 - mae: 0.0790 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0167 - mae: 0.0829 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - mae: 0.0656 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0225 - mae: 0.0939 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - mae: 0.0686 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0148 - mae: 0.0728 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0182 - mae: 0.0844 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0233 - mae: 0.0935 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0156 - mae: 0.0859 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0116 - mae: 0.0718 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0195 - mae: 0.0910 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.0715 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0112 - mae: 0.0655 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0133 - mae: 0.0810 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.0685 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - mae: 0.0788 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0186 - mae: 0.0866 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - mae: 0.0747 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - mae: 0.0674 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0140 - mae: 0.0761 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0625 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0130 - mae: 0.0707 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - mae: 0.0710 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - mae: 0.0646 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - mae: 0.0766 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - mae: 0.0794 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0609 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - mae: 0.0694 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0527 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - mae: 0.0748 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0116 - mae: 0.0695 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0144 - mae: 0.0750 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0614 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - mae: 0.0613 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - mae: 0.0597 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.0656 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0118 - mae: 0.0616 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - mae: 0.0700 - val_loss: 0.0017 - val_mae: 0.0343\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - mae: 0.0582 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0147 - mae: 0.0690 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0643 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - mae: 0.0552 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0646 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0653 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0625 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0672 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.0756 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - mae: 0.0658 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - mae: 0.0680 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0566 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - mae: 0.0594 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - mae: 0.0593 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0558 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - mae: 0.0585 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0584 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0511 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0613 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.0595 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0499 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0095 - mae: 0.0626 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - mae: 0.0512 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0557 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - mae: 0.0569 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0071 - mae: 0.0520 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0647 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0603 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0526 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0587 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - mae: 0.0519 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0539 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - mae: 0.0466 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0079 - mae: 0.0550 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0078 - mae: 0.0603 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0072 - mae: 0.0489 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - mae: 0.0551 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - mae: 0.0588 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0105 - mae: 0.0611 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0082 - mae: 0.0524 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0077 - mae: 0.0491 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - mae: 0.0490 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - mae: 0.0547 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - mae: 0.0509 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - mae: 0.0496 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0085 - mae: 0.0532 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0082 - mae: 0.0510 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0101 - mae: 0.0616 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0092 - mae: 0.0590 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - mae: 0.0535 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0632 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0100 - mae: 0.0545 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0093 - mae: 0.0528 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - mae: 0.0591 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0092 - mae: 0.0578 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0084 - mae: 0.0579 - val_loss: 9.7616e-04 - val_mae: 0.0242\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - mae: 0.0494 - val_loss: 9.3429e-04 - val_mae: 0.0235\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0574 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0073 - mae: 0.0525 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - mae: 0.0470 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0533 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0528 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0504 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0524 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0392 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0462 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.0585 - val_loss: 8.9403e-04 - val_mae: 0.0227\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0519 - val_loss: 5.9088e-04 - val_mae: 0.0157\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0468 - val_loss: 6.1262e-04 - val_mae: 0.0161\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0454 - val_loss: 8.5282e-04 - val_mae: 0.0219\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0512 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - mae: 0.0475 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0494 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0444 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0458 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0088 - mae: 0.0539 - val_loss: 9.4408e-04 - val_mae: 0.0237\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - mae: 0.0438 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0477 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0056 - mae: 0.0424 - val_loss: 9.3664e-04 - val_mae: 0.0235\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0449 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - mae: 0.0454 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0059 - mae: 0.0430 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0078 - mae: 0.0511 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0098 - mae: 0.0506 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - mae: 0.0445 - val_loss: 8.2318e-04 - val_mae: 0.0213\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - mae: 0.0462 - val_loss: 7.1125e-04 - val_mae: 0.0186\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0482 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0442 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0063 - mae: 0.0447 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0416 - val_loss: 9.3160e-04 - val_mae: 0.0234\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0485 - val_loss: 9.2992e-04 - val_mae: 0.0234\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0479 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0067 - mae: 0.0424 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0489 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0506 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0398 - val_loss: 9.8843e-04 - val_mae: 0.0245\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0442 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - mae: 0.0424 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0385 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0509 - val_loss: 9.9774e-04 - val_mae: 0.0246\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0089 - mae: 0.0480 - val_loss: 9.0593e-04 - val_mae: 0.0229\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0430 - val_loss: 7.5978e-04 - val_mae: 0.0198\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.0546 - val_loss: 7.8507e-04 - val_mae: 0.0204\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - mae: 0.0551 - val_loss: 6.3092e-04 - val_mae: 0.0164\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - mae: 0.0480 - val_loss: 7.9309e-04 - val_mae: 0.0206\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0396 - val_loss: 9.5638e-04 - val_mae: 0.0239\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - mae: 0.0465 - val_loss: 8.8124e-04 - val_mae: 0.0225\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0438 - val_loss: 7.8406e-04 - val_mae: 0.0204\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0523 - val_loss: 9.8293e-04 - val_mae: 0.0244\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0390 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "3/3 [==============================] - 0s 7ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_74\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_768 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_694 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_769 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_695 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_770 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_696 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_771 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_697 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_772 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_698 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_773 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_699 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_774 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_700 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_775 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_701 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_776 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_702 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_777 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_703 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_778 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_704 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_779 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 4s 20ms/step - loss: 87.9223 - mae: 6.6089 - val_loss: 0.6291 - val_mae: 0.7929\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 11.9833 - mae: 2.7762 - val_loss: 0.0269 - val_mae: 0.1627\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 12.5250 - mae: 2.3167 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 6.8659 - mae: 1.7581 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 7.1471 - mae: 1.8288 - val_loss: 9.7335e-04 - val_mae: 0.0292\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.3843 - mae: 1.1480 - val_loss: 0.0020 - val_mae: 0.0424\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.4941 - mae: 1.1774 - val_loss: 9.4743e-04 - val_mae: 0.0285\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 2.9486 - mae: 1.1193 - val_loss: 5.2311e-04 - val_mae: 0.0160\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.7360 - mae: 0.9897 - val_loss: 8.6283e-04 - val_mae: 0.0267\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 1.4158 - mae: 0.9260 - val_loss: 0.0013 - val_mae: 0.0341\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.6571 - mae: 0.9683 - val_loss: 8.4261e-04 - val_mae: 0.0267\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8203 - mae: 0.6847 - val_loss: 5.5054e-04 - val_mae: 0.0189\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0812 - mae: 0.7283 - val_loss: 5.9957e-04 - val_mae: 0.0208\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.2476 - mae: 0.7894 - val_loss: 0.0013 - val_mae: 0.0336\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.8941 - mae: 0.9076 - val_loss: 0.0022 - val_mae: 0.0446\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.9999 - mae: 0.6963 - val_loss: 0.0016 - val_mae: 0.0377\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.9463 - mae: 0.6780 - val_loss: 0.0022 - val_mae: 0.0447\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.8021 - mae: 0.6361 - val_loss: 0.0018 - val_mae: 0.0403\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7346 - mae: 0.6505 - val_loss: 0.0016 - val_mae: 0.0380\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.9512 - mae: 0.7081 - val_loss: 0.0014 - val_mae: 0.0361\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5901 - mae: 0.6095 - val_loss: 0.0022 - val_mae: 0.0444\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.0811 - mae: 0.6986 - val_loss: 0.0034 - val_mae: 0.0546\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7310 - mae: 0.6215 - val_loss: 0.0020 - val_mae: 0.0422\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5033 - mae: 0.5397 - val_loss: 0.0011 - val_mae: 0.0319\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4919 - mae: 0.5364 - val_loss: 0.0012 - val_mae: 0.0333\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6164 - mae: 0.5689 - val_loss: 0.0016 - val_mae: 0.0378\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.7812 - mae: 0.6133 - val_loss: 0.0020 - val_mae: 0.0430\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.5140 - mae: 0.5130 - val_loss: 0.0017 - val_mae: 0.0393\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4188 - mae: 0.4477 - val_loss: 0.0015 - val_mae: 0.0369\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5286 - mae: 0.5152 - val_loss: 0.0022 - val_mae: 0.0444\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2922 - mae: 0.3861 - val_loss: 0.0028 - val_mae: 0.0499\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3709 - mae: 0.4449 - val_loss: 0.0022 - val_mae: 0.0442\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3881 - mae: 0.4708 - val_loss: 0.0025 - val_mae: 0.0469\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3898 - mae: 0.4258 - val_loss: 0.0031 - val_mae: 0.0521\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3766 - mae: 0.4483 - val_loss: 0.0038 - val_mae: 0.0575\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3444 - mae: 0.4308 - val_loss: 0.0042 - val_mae: 0.0610\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3978 - mae: 0.3810 - val_loss: 0.0044 - val_mae: 0.0628\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.4489 - mae: 0.4679 - val_loss: 0.0051 - val_mae: 0.0685\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2934 - mae: 0.4059 - val_loss: 0.0052 - val_mae: 0.0686\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2268 - mae: 0.3463 - val_loss: 0.0045 - val_mae: 0.0632\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3944 - mae: 0.4329 - val_loss: 0.0040 - val_mae: 0.0591\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2809 - mae: 0.4220 - val_loss: 0.0036 - val_mae: 0.0557\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3227 - mae: 0.4300 - val_loss: 0.0032 - val_mae: 0.0527\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1906 - mae: 0.3065 - val_loss: 0.0025 - val_mae: 0.0476\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2967 - mae: 0.3861 - val_loss: 0.0029 - val_mae: 0.0509\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2585 - mae: 0.3234 - val_loss: 0.0023 - val_mae: 0.0452\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2314 - mae: 0.3607 - val_loss: 0.0015 - val_mae: 0.0375\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1885 - mae: 0.3353 - val_loss: 0.0013 - val_mae: 0.0347\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.2448 - mae: 0.3728 - val_loss: 9.6114e-04 - val_mae: 0.0290\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1518 - mae: 0.2855 - val_loss: 8.9883e-04 - val_mae: 0.0278\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2090 - mae: 0.3416 - val_loss: 0.0013 - val_mae: 0.0342\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1623 - mae: 0.2997 - val_loss: 0.0013 - val_mae: 0.0349\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.4003 - mae: 0.3978 - val_loss: 0.0018 - val_mae: 0.0408\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1872 - mae: 0.3145 - val_loss: 0.0025 - val_mae: 0.0470\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1817 - mae: 0.3039 - val_loss: 0.0016 - val_mae: 0.0379\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.2179 - mae: 0.2989 - val_loss: 0.0014 - val_mae: 0.0355\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1794 - mae: 0.3227 - val_loss: 0.0015 - val_mae: 0.0366\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1363 - mae: 0.2649 - val_loss: 0.0012 - val_mae: 0.0328\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1211 - mae: 0.2531 - val_loss: 8.9682e-04 - val_mae: 0.0278\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1443 - mae: 0.2822 - val_loss: 0.0010 - val_mae: 0.0298\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1807 - mae: 0.2757 - val_loss: 0.0010 - val_mae: 0.0303\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.2569 - mae: 0.3156 - val_loss: 0.0011 - val_mae: 0.0307\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1850 - mae: 0.3152 - val_loss: 0.0011 - val_mae: 0.0317\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3153 - mae: 0.3619 - val_loss: 0.0011 - val_mae: 0.0317\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1931 - mae: 0.2624 - val_loss: 8.3963e-04 - val_mae: 0.0267\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1611 - mae: 0.2852 - val_loss: 5.6369e-04 - val_mae: 0.0193\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1033 - mae: 0.2466 - val_loss: 5.6135e-04 - val_mae: 0.0192\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.1886 - mae: 0.2548 - val_loss: 4.8450e-04 - val_mae: 0.0153\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1069 - mae: 0.2480 - val_loss: 4.8521e-04 - val_mae: 0.0153\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0914 - mae: 0.2352 - val_loss: 4.9189e-04 - val_mae: 0.0156\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0848 - mae: 0.2187 - val_loss: 4.8382e-04 - val_mae: 0.0152\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0916 - mae: 0.2260 - val_loss: 4.7047e-04 - val_mae: 0.0146\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.1808 - mae: 0.2889 - val_loss: 4.8095e-04 - val_mae: 0.0146\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1013 - mae: 0.2166 - val_loss: 5.2136e-04 - val_mae: 0.0148\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.3086 - mae: 0.2840 - val_loss: 5.0824e-04 - val_mae: 0.0147\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1204 - mae: 0.2622 - val_loss: 4.9905e-04 - val_mae: 0.0146\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.1061 - mae: 0.2402 - val_loss: 5.3072e-04 - val_mae: 0.0150\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.1031 - mae: 0.2154 - val_loss: 5.7965e-04 - val_mae: 0.0155\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.1280 - mae: 0.2708 - val_loss: 6.5853e-04 - val_mae: 0.0173\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0692 - mae: 0.2040 - val_loss: 6.3148e-04 - val_mae: 0.0165\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0847 - mae: 0.2046 - val_loss: 5.8764e-04 - val_mae: 0.0157\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1029 - mae: 0.2316 - val_loss: 5.5479e-04 - val_mae: 0.0153\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1122 - mae: 0.2150 - val_loss: 5.4205e-04 - val_mae: 0.0151\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0621 - mae: 0.1850 - val_loss: 5.8835e-04 - val_mae: 0.0157\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0684 - mae: 0.1895 - val_loss: 6.8009e-04 - val_mae: 0.0179\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1216 - mae: 0.2454 - val_loss: 6.5634e-04 - val_mae: 0.0172\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0930 - mae: 0.1920 - val_loss: 6.6864e-04 - val_mae: 0.0176\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0752 - mae: 0.1993 - val_loss: 6.5542e-04 - val_mae: 0.0172\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0740 - mae: 0.1954 - val_loss: 5.7918e-04 - val_mae: 0.0155\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0904 - mae: 0.2110 - val_loss: 5.1061e-04 - val_mae: 0.0147\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0646 - mae: 0.2004 - val_loss: 5.4020e-04 - val_mae: 0.0151\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1231 - mae: 0.2307 - val_loss: 6.3152e-04 - val_mae: 0.0165\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0734 - mae: 0.1802 - val_loss: 6.1967e-04 - val_mae: 0.0162\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0878 - mae: 0.2158 - val_loss: 5.6534e-04 - val_mae: 0.0154\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0708 - mae: 0.1800 - val_loss: 5.3022e-04 - val_mae: 0.0150\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0745 - mae: 0.1895 - val_loss: 5.1893e-04 - val_mae: 0.0148\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0780 - mae: 0.1968 - val_loss: 5.5311e-04 - val_mae: 0.0152\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0776 - mae: 0.1885 - val_loss: 5.5638e-04 - val_mae: 0.0153\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0689 - mae: 0.1948 - val_loss: 5.6885e-04 - val_mae: 0.0154\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0689 - mae: 0.1803 - val_loss: 5.3906e-04 - val_mae: 0.0151\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0436 - mae: 0.1559 - val_loss: 5.7460e-04 - val_mae: 0.0155\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0545 - mae: 0.1850 - val_loss: 6.1156e-04 - val_mae: 0.0161\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0697 - mae: 0.1908 - val_loss: 6.8528e-04 - val_mae: 0.0180\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0460 - mae: 0.1580 - val_loss: 7.2760e-04 - val_mae: 0.0191\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0638 - mae: 0.1815 - val_loss: 6.4301e-04 - val_mae: 0.0168\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0791 - mae: 0.1674 - val_loss: 5.7915e-04 - val_mae: 0.0155\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0600 - mae: 0.1741 - val_loss: 5.8345e-04 - val_mae: 0.0156\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0875 - mae: 0.2020 - val_loss: 6.1067e-04 - val_mae: 0.0161\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0688 - mae: 0.1686 - val_loss: 8.7642e-04 - val_mae: 0.0224\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0692 - mae: 0.1948 - val_loss: 7.8132e-04 - val_mae: 0.0204\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0802 - mae: 0.1955 - val_loss: 6.8750e-04 - val_mae: 0.0181\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0498 - mae: 0.1656 - val_loss: 7.7960e-04 - val_mae: 0.0203\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0699 - mae: 0.2081 - val_loss: 7.3542e-04 - val_mae: 0.0193\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0597 - mae: 0.1576 - val_loss: 6.6773e-04 - val_mae: 0.0175\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0585 - mae: 0.1838 - val_loss: 5.6224e-04 - val_mae: 0.0153\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0941 - mae: 0.2146 - val_loss: 4.8155e-04 - val_mae: 0.0146\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0462 - mae: 0.1675 - val_loss: 4.7491e-04 - val_mae: 0.0146\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0405 - mae: 0.1483 - val_loss: 4.7922e-04 - val_mae: 0.0146\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0685 - mae: 0.1707 - val_loss: 5.0591e-04 - val_mae: 0.0146\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0455 - mae: 0.1583 - val_loss: 5.1229e-04 - val_mae: 0.0147\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0472 - mae: 0.1672 - val_loss: 6.0158e-04 - val_mae: 0.0159\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1288 - val_loss: 5.4246e-04 - val_mae: 0.0151\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0775 - mae: 0.1931 - val_loss: 4.9074e-04 - val_mae: 0.0146\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0427 - mae: 0.1556 - val_loss: 5.3588e-04 - val_mae: 0.0150\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0806 - mae: 0.1795 - val_loss: 4.9587e-04 - val_mae: 0.0146\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0372 - mae: 0.1364 - val_loss: 5.0338e-04 - val_mae: 0.0146\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0790 - mae: 0.1845 - val_loss: 4.7207e-04 - val_mae: 0.0146\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0529 - mae: 0.1590 - val_loss: 5.0326e-04 - val_mae: 0.0159\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0504 - mae: 0.1623 - val_loss: 5.0616e-04 - val_mae: 0.0160\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0420 - mae: 0.1441 - val_loss: 4.7956e-04 - val_mae: 0.0150\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0568 - mae: 0.1585 - val_loss: 4.7262e-04 - val_mae: 0.0147\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0510 - mae: 0.1582 - val_loss: 4.7494e-04 - val_mae: 0.0148\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0766 - mae: 0.1536 - val_loss: 4.8039e-04 - val_mae: 0.0146\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0454 - mae: 0.1558 - val_loss: 5.2539e-04 - val_mae: 0.0149\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0494 - mae: 0.1642 - val_loss: 5.1852e-04 - val_mae: 0.0148\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0571 - mae: 0.1701 - val_loss: 5.3929e-04 - val_mae: 0.0150\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0512 - mae: 0.1733 - val_loss: 5.1481e-04 - val_mae: 0.0147\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0366 - mae: 0.1521 - val_loss: 5.0638e-04 - val_mae: 0.0146\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0519 - mae: 0.1593 - val_loss: 4.9596e-04 - val_mae: 0.0146\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0661 - mae: 0.1735 - val_loss: 4.8608e-04 - val_mae: 0.0146\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0268 - mae: 0.1169 - val_loss: 4.7610e-04 - val_mae: 0.0146\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0299 - mae: 0.1171 - val_loss: 4.7277e-04 - val_mae: 0.0146\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0329 - mae: 0.1276 - val_loss: 4.7289e-04 - val_mae: 0.0146\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0236 - mae: 0.1121 - val_loss: 4.7478e-04 - val_mae: 0.0146\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0401 - mae: 0.1324 - val_loss: 4.7352e-04 - val_mae: 0.0146\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0297 - mae: 0.1239 - val_loss: 4.7268e-04 - val_mae: 0.0146\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0424 - mae: 0.1459 - val_loss: 4.7494e-04 - val_mae: 0.0148\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0233 - mae: 0.1161 - val_loss: 4.7300e-04 - val_mae: 0.0146\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0208 - mae: 0.0982 - val_loss: 4.8043e-04 - val_mae: 0.0146\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0322 - mae: 0.1246 - val_loss: 5.2169e-04 - val_mae: 0.0148\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0257 - mae: 0.1092 - val_loss: 5.6684e-04 - val_mae: 0.0154\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0354 - mae: 0.1270 - val_loss: 5.6813e-04 - val_mae: 0.0154\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0272 - mae: 0.1235 - val_loss: 5.0240e-04 - val_mae: 0.0146\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0310 - mae: 0.1258 - val_loss: 5.0382e-04 - val_mae: 0.0146\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0311 - mae: 0.1237 - val_loss: 5.5817e-04 - val_mae: 0.0153\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0322 - mae: 0.1313 - val_loss: 5.4575e-04 - val_mae: 0.0151\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0865 - mae: 0.1523 - val_loss: 5.0619e-04 - val_mae: 0.0146\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0376 - mae: 0.1302 - val_loss: 4.7454e-04 - val_mae: 0.0146\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0281 - mae: 0.1201 - val_loss: 4.7959e-04 - val_mae: 0.0146\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0231 - mae: 0.1069 - val_loss: 5.1623e-04 - val_mae: 0.0148\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0310 - mae: 0.1332 - val_loss: 5.2703e-04 - val_mae: 0.0149\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0376 - mae: 0.1212 - val_loss: 4.8214e-04 - val_mae: 0.0146\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0263 - mae: 0.1054 - val_loss: 4.7675e-04 - val_mae: 0.0149\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0387 - mae: 0.1217 - val_loss: 4.9146e-04 - val_mae: 0.0146\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0293 - mae: 0.1305 - val_loss: 5.9413e-04 - val_mae: 0.0158\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0309 - mae: 0.1257 - val_loss: 6.8971e-04 - val_mae: 0.0181\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0225 - mae: 0.1111 - val_loss: 7.7120e-04 - val_mae: 0.0201\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - mae: 0.1057 - val_loss: 7.9199e-04 - val_mae: 0.0206\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0253 - mae: 0.1123 - val_loss: 8.5056e-04 - val_mae: 0.0219\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0440 - mae: 0.1217 - val_loss: 7.0774e-04 - val_mae: 0.0186\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1258 - val_loss: 7.3448e-04 - val_mae: 0.0193\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0351 - mae: 0.1249 - val_loss: 7.9987e-04 - val_mae: 0.0208\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.1146 - val_loss: 8.9120e-04 - val_mae: 0.0227\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0302 - mae: 0.1118 - val_loss: 8.3515e-04 - val_mae: 0.0215\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0239 - mae: 0.1174 - val_loss: 7.6872e-04 - val_mae: 0.0201\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0396 - mae: 0.1243 - val_loss: 7.9658e-04 - val_mae: 0.0207\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0234 - mae: 0.1119 - val_loss: 6.2909e-04 - val_mae: 0.0164\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0433 - mae: 0.1444 - val_loss: 5.2819e-04 - val_mae: 0.0149\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0191 - mae: 0.1001 - val_loss: 5.1154e-04 - val_mae: 0.0147\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0296 - mae: 0.1268 - val_loss: 5.5671e-04 - val_mae: 0.0153\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0193 - mae: 0.0995 - val_loss: 5.4057e-04 - val_mae: 0.0151\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0358 - mae: 0.1181 - val_loss: 5.0353e-04 - val_mae: 0.0146\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0417 - mae: 0.1289 - val_loss: 5.7130e-04 - val_mae: 0.0154\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0201 - mae: 0.1002 - val_loss: 7.1203e-04 - val_mae: 0.0187\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - mae: 0.1150 - val_loss: 7.7838e-04 - val_mae: 0.0203\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0255 - mae: 0.1071 - val_loss: 8.1852e-04 - val_mae: 0.0212\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0255 - mae: 0.1098 - val_loss: 8.6468e-04 - val_mae: 0.0221\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0179 - mae: 0.0997 - val_loss: 8.3857e-04 - val_mae: 0.0216\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0193 - mae: 0.0937 - val_loss: 8.7033e-04 - val_mae: 0.0223\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0337 - mae: 0.1105 - val_loss: 7.2072e-04 - val_mae: 0.0189\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0221 - mae: 0.1044 - val_loss: 6.2650e-04 - val_mae: 0.0164\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0244 - mae: 0.1068 - val_loss: 6.3250e-04 - val_mae: 0.0165\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0368 - mae: 0.1237 - val_loss: 7.0214e-04 - val_mae: 0.0184\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - mae: 0.0880 - val_loss: 6.5737e-04 - val_mae: 0.0172\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0297 - mae: 0.1074 - val_loss: 5.8231e-04 - val_mae: 0.0156\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0257 - mae: 0.1054 - val_loss: 5.6457e-04 - val_mae: 0.0153\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - mae: 0.0985 - val_loss: 6.6275e-04 - val_mae: 0.0173\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0243 - mae: 0.0994 - val_loss: 8.9638e-04 - val_mae: 0.0228\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0152 - mae: 0.0894 - val_loss: 8.6828e-04 - val_mae: 0.0222\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0220 - mae: 0.0942 - val_loss: 9.2906e-04 - val_mae: 0.0234\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0252 - mae: 0.0931 - val_loss: 9.5998e-04 - val_mae: 0.0240\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0196 - mae: 0.0933 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - mae: 0.1016 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0221 - mae: 0.1003 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0858 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0219 - mae: 0.0948 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0181 - mae: 0.0925 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0234 - mae: 0.1073 - val_loss: 9.2317e-04 - val_mae: 0.0233\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0157 - mae: 0.0826 - val_loss: 7.7907e-04 - val_mae: 0.0203\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0176 - mae: 0.0795 - val_loss: 7.0508e-04 - val_mae: 0.0185\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0152 - mae: 0.0875 - val_loss: 6.9485e-04 - val_mae: 0.0182\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0748 - val_loss: 7.3409e-04 - val_mae: 0.0192\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0228 - mae: 0.0961 - val_loss: 7.6414e-04 - val_mae: 0.0199\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - mae: 0.0921 - val_loss: 8.0552e-04 - val_mae: 0.0209\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0209 - mae: 0.0892 - val_loss: 8.4808e-04 - val_mae: 0.0218\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - mae: 0.0988 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - mae: 0.0826 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0178 - mae: 0.0925 - val_loss: 9.8143e-04 - val_mae: 0.0243\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0164 - mae: 0.0813 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0151 - mae: 0.0841 - val_loss: 8.8892e-04 - val_mae: 0.0226\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0170 - mae: 0.0884 - val_loss: 9.2430e-04 - val_mae: 0.0233\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0122 - mae: 0.0727 - val_loss: 9.7518e-04 - val_mae: 0.0242\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - mae: 0.0942 - val_loss: 9.0365e-04 - val_mae: 0.0229\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0148 - mae: 0.0840 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0197 - mae: 0.0902 - val_loss: 8.8373e-04 - val_mae: 0.0225\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0171 - mae: 0.0824 - val_loss: 8.6632e-04 - val_mae: 0.0222\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0211 - mae: 0.0902 - val_loss: 6.2767e-04 - val_mae: 0.0164\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0220 - mae: 0.0932 - val_loss: 5.4585e-04 - val_mae: 0.0151\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0215 - mae: 0.0782 - val_loss: 5.6516e-04 - val_mae: 0.0153\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0771 - val_loss: 5.5435e-04 - val_mae: 0.0152\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0171 - mae: 0.0944 - val_loss: 6.1874e-04 - val_mae: 0.0162\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0236 - mae: 0.1036 - val_loss: 8.5976e-04 - val_mae: 0.0220\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0170 - mae: 0.0930 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0147 - mae: 0.0812 - val_loss: 9.8851e-04 - val_mae: 0.0245\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0135 - mae: 0.0738 - val_loss: 8.8550e-04 - val_mae: 0.0225\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0134 - mae: 0.0856 - val_loss: 8.2633e-04 - val_mae: 0.0213\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0136 - mae: 0.0848 - val_loss: 8.0680e-04 - val_mae: 0.0209\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0171 - mae: 0.0822 - val_loss: 9.5692e-04 - val_mae: 0.0239\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - mae: 0.0707 - val_loss: 9.8134e-04 - val_mae: 0.0243\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0122 - mae: 0.0755 - val_loss: 8.8389e-04 - val_mae: 0.0225\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0123 - mae: 0.0763 - val_loss: 7.7224e-04 - val_mae: 0.0201\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0175 - mae: 0.0829 - val_loss: 8.9819e-04 - val_mae: 0.0228\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0221 - mae: 0.1007 - val_loss: 9.6043e-04 - val_mae: 0.0240\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0123 - mae: 0.0785 - val_loss: 9.6231e-04 - val_mae: 0.0240\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0156 - mae: 0.0841 - val_loss: 9.4115e-04 - val_mae: 0.0236\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0195 - mae: 0.0878 - val_loss: 9.6044e-04 - val_mae: 0.0240\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0096 - mae: 0.0660 - val_loss: 9.0976e-04 - val_mae: 0.0230\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0619 - val_loss: 8.1962e-04 - val_mae: 0.0212\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0161 - mae: 0.0812 - val_loss: 9.2165e-04 - val_mae: 0.0232\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0685 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - mae: 0.0744 - val_loss: 9.3322e-04 - val_mae: 0.0235\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0168 - mae: 0.0861 - val_loss: 9.5446e-04 - val_mae: 0.0239\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0119 - mae: 0.0695 - val_loss: 9.9580e-04 - val_mae: 0.0246\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0165 - mae: 0.0734 - val_loss: 8.9343e-04 - val_mae: 0.0227\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0194 - mae: 0.0861 - val_loss: 8.0122e-04 - val_mae: 0.0208\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0222 - mae: 0.0920 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0250 - mae: 0.0877 - val_loss: 9.9066e-04 - val_mae: 0.0245\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0654 - val_loss: 9.8593e-04 - val_mae: 0.0244\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0113 - mae: 0.0683 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0704 - val_loss: 7.8063e-04 - val_mae: 0.0203\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0651 - val_loss: 7.5765e-04 - val_mae: 0.0198\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0182 - mae: 0.0832 - val_loss: 7.4405e-04 - val_mae: 0.0195\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0679 - val_loss: 7.5922e-04 - val_mae: 0.0198\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.0721 - val_loss: 7.1212e-04 - val_mae: 0.0187\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0772 - val_loss: 6.8690e-04 - val_mae: 0.0180\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0173 - mae: 0.0788 - val_loss: 8.5087e-04 - val_mae: 0.0219\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - mae: 0.0835 - val_loss: 8.4550e-04 - val_mae: 0.0217\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0117 - mae: 0.0719 - val_loss: 7.6916e-04 - val_mae: 0.0201\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - mae: 0.0661 - val_loss: 6.6220e-04 - val_mae: 0.0173\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.0721 - val_loss: 7.5424e-04 - val_mae: 0.0197\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0093 - mae: 0.0632 - val_loss: 8.1316e-04 - val_mae: 0.0211\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0106 - mae: 0.0663 - val_loss: 9.5589e-04 - val_mae: 0.0239\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0106 - mae: 0.0686 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0680 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - mae: 0.0727 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0702 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0676 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0095 - mae: 0.0607 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0097 - mae: 0.0672 - val_loss: 8.9341e-04 - val_mae: 0.0227\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0087 - mae: 0.0592 - val_loss: 9.6736e-04 - val_mae: 0.0241\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0101 - mae: 0.0640 - val_loss: 9.5703e-04 - val_mae: 0.0239\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.0656 - val_loss: 9.1488e-04 - val_mae: 0.0231\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - mae: 0.0747 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0234 - mae: 0.0779 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.0660 - val_loss: 9.3831e-04 - val_mae: 0.0236\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0581 - val_loss: 7.9557e-04 - val_mae: 0.0207\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - mae: 0.0566 - val_loss: 8.5945e-04 - val_mae: 0.0220\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0541 - val_loss: 7.9237e-04 - val_mae: 0.0206\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0097 - mae: 0.0656 - val_loss: 8.1401e-04 - val_mae: 0.0211\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.0728 - val_loss: 9.6350e-04 - val_mae: 0.0240\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0086 - mae: 0.0577 - val_loss: 9.7022e-04 - val_mae: 0.0241\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0143 - mae: 0.0784 - val_loss: 7.8006e-04 - val_mae: 0.0203\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - mae: 0.0629 - val_loss: 7.1632e-04 - val_mae: 0.0188\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0091 - mae: 0.0601 - val_loss: 8.2365e-04 - val_mae: 0.0213\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - mae: 0.0659 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - mae: 0.0596 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0624 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0086 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - mae: 0.0613 - val_loss: 9.5958e-04 - val_mae: 0.0240\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0099 - mae: 0.0632 - val_loss: 8.9988e-04 - val_mae: 0.0228\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0583 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - mae: 0.0737 - val_loss: 7.7992e-04 - val_mae: 0.0203\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0120 - mae: 0.0707 - val_loss: 5.8924e-04 - val_mae: 0.0157\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0079 - mae: 0.0651 - val_loss: 6.0127e-04 - val_mae: 0.0159\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0124 - mae: 0.0760 - val_loss: 7.4830e-04 - val_mae: 0.0196\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0610 - val_loss: 8.0481e-04 - val_mae: 0.0209\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0089 - mae: 0.0625 - val_loss: 8.3217e-04 - val_mae: 0.0215\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0098 - mae: 0.0650 - val_loss: 9.7525e-04 - val_mae: 0.0242\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0089 - mae: 0.0599 - val_loss: 9.2170e-04 - val_mae: 0.0232\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0090 - mae: 0.0602 - val_loss: 7.1555e-04 - val_mae: 0.0188\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - mae: 0.0534 - val_loss: 7.6466e-04 - val_mae: 0.0200\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - mae: 0.0540 - val_loss: 8.7339e-04 - val_mae: 0.0223\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0078 - mae: 0.0532 - val_loss: 7.5544e-04 - val_mae: 0.0197\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0087 - mae: 0.0613 - val_loss: 9.4522e-04 - val_mae: 0.0237\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0280 - mae: 0.0676 - val_loss: 7.9999e-04 - val_mae: 0.0208\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0080 - mae: 0.0597 - val_loss: 8.6727e-04 - val_mae: 0.0222\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0095 - mae: 0.0652 - val_loss: 8.9189e-04 - val_mae: 0.0227\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0083 - mae: 0.0599 - val_loss: 9.8371e-04 - val_mae: 0.0244\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - mae: 0.0548 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0113 - mae: 0.0636 - val_loss: 8.7507e-04 - val_mae: 0.0224\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0095 - mae: 0.0609 - val_loss: 8.0238e-04 - val_mae: 0.0208\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0087 - mae: 0.0615 - val_loss: 7.6104e-04 - val_mae: 0.0199\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0078 - mae: 0.0562 - val_loss: 8.3884e-04 - val_mae: 0.0216\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0069 - mae: 0.0512 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0082 - mae: 0.0539 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0085 - mae: 0.0550 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0076 - mae: 0.0554 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0094 - mae: 0.0575 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0104 - mae: 0.0638 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0075 - mae: 0.0536 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0076 - mae: 0.0494 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0083 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0101 - mae: 0.0599 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0115 - mae: 0.0607 - val_loss: 8.7174e-04 - val_mae: 0.0223\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0102 - mae: 0.0637 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0092 - mae: 0.0616 - val_loss: 9.7478e-04 - val_mae: 0.0242\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - mae: 0.0563 - val_loss: 8.8624e-04 - val_mae: 0.0226\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0096 - mae: 0.0599 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0059 - mae: 0.0472 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - mae: 0.0556 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0071 - mae: 0.0504 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0098 - mae: 0.0515 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - mae: 0.0544 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0127 - mae: 0.0654 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0612 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0556 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0499 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0512 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0559 - val_loss: 6.7978e-04 - val_mae: 0.0178\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0602 - val_loss: 7.3130e-04 - val_mae: 0.0191\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UMWlDoax2IL",
        "outputId": "0f0b2e88-63de-49b7-a4d7-9f802148286c"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[         loss       mae  val_loss   val_mae\n",
              " 0    0.198609  0.357544  0.006729  0.079107\n",
              " 1    0.115094  0.266635  0.000689  0.018063\n",
              " 2    0.121010  0.272496  0.008941  0.092018\n",
              " 3    0.066210  0.209672  0.000475  0.014579\n",
              " 4    0.082080  0.220151  0.001921  0.038043\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004487  0.030542  0.001865  0.037303\n",
              " 346  0.004146  0.029669  0.002004  0.039121\n",
              " 347  0.003643  0.026968  0.002727  0.047479\n",
              " 348  0.003525  0.032702  0.003523  0.055219\n",
              " 349  0.004368  0.027134  0.001084  0.026064\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.196549  0.340449  0.000502  0.017862\n",
              " 1    0.142904  0.288283  0.001446  0.031523\n",
              " 2    0.091396  0.235260  0.003411  0.055094\n",
              " 3    0.077236  0.222933  0.000688  0.020236\n",
              " 4    0.062362  0.204886  0.016243  0.125728\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004224  0.026934  0.002336  0.043187\n",
              " 346  0.003700  0.025233  0.002506  0.045097\n",
              " 347  0.003967  0.025602  0.001716  0.035270\n",
              " 348  0.003710  0.024737  0.002595  0.046080\n",
              " 349  0.003699  0.027484  0.002642  0.046587\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.161285  0.313848  0.006543  0.078039\n",
              " 1    0.120762  0.270353  0.018827  0.135425\n",
              " 2    0.091117  0.242517  0.006590  0.078252\n",
              " 3    0.088318  0.241798  0.002198  0.044484\n",
              " 4    0.084817  0.230994  0.000681  0.017916\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.003983  0.024551  0.002695  0.047145\n",
              " 346  0.004117  0.025078  0.002250  0.042161\n",
              " 347  0.003802  0.025902  0.003067  0.050946\n",
              " 348  0.004172  0.028025  0.001987  0.038916\n",
              " 349  0.003888  0.027803  0.002537  0.045427\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    5.084693  1.656587  0.093946  0.305844\n",
              " 1    1.479018  0.826160  0.014883  0.119693\n",
              " 2    0.508811  0.582732  0.009672  0.095882\n",
              " 3    0.713538  0.523157  0.012799  0.111083\n",
              " 4    0.230877  0.331914  0.009594  0.095351\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004222  0.022837  0.000966  0.024061\n",
              " 346  0.004288  0.023390  0.000949  0.023740\n",
              " 347  0.004319  0.024507  0.000909  0.022999\n",
              " 348  0.004308  0.023316  0.001046  0.025439\n",
              " 349  0.004408  0.024036  0.000958  0.023912\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    21.316683  2.749954  0.057819  0.239206\n",
              " 1     3.456017  1.480344  0.029517  0.170003\n",
              " 2     2.076167  1.074160  0.003255  0.051943\n",
              " 3     1.141725  0.830373  0.002700  0.046125\n",
              " 4     1.459982  0.832695  0.003530  0.053411\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.004378  0.024439  0.001019  0.024988\n",
              " 346   0.004146  0.023983  0.001032  0.025211\n",
              " 347   0.004356  0.023186  0.001037  0.025294\n",
              " 348   0.004325  0.022808  0.001012  0.024869\n",
              " 349   0.004475  0.024954  0.001032  0.025200\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    8.482288  1.904675  0.077108  0.276615\n",
              " 1    1.857254  1.005998  0.004204  0.059377\n",
              " 2    0.703907  0.602348  0.003974  0.055020\n",
              " 3    0.613465  0.571947  0.001031  0.030105\n",
              " 4    0.274473  0.404053  0.005902  0.072249\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004316  0.023876  0.000938  0.023540\n",
              " 346  0.004288  0.022405  0.000995  0.024576\n",
              " 347  0.004298  0.022822  0.000959  0.023933\n",
              " 348  0.004426  0.024339  0.000941  0.023608\n",
              " 349  0.004308  0.023242  0.000940  0.023574\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.538807  0.606957  0.011017  0.102680\n",
              " 1    0.175667  0.338485  0.024807  0.155991\n",
              " 2    0.156414  0.324620  0.000504  0.015925\n",
              " 3    0.145239  0.291701  0.000562  0.018825\n",
              " 4    0.156101  0.334235  0.009448  0.094732\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004408  0.024047  0.000928  0.023352\n",
              " 346  0.004228  0.023688  0.000879  0.022405\n",
              " 347  0.004360  0.025441  0.000907  0.022953\n",
              " 348  0.004324  0.023377  0.001082  0.026029\n",
              " 349  0.004259  0.024315  0.000900  0.022824\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.203630  0.358693  0.000607  0.016031\n",
              " 1    0.190018  0.360060  0.014864  0.119961\n",
              " 2    0.145640  0.299738  0.002936  0.049621\n",
              " 3    0.135219  0.312638  0.005269  0.069246\n",
              " 4    0.113952  0.264904  0.000798  0.020715\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004333  0.022867  0.001077  0.025954\n",
              " 346  0.004689  0.025183  0.000947  0.023705\n",
              " 347  0.004295  0.023396  0.000994  0.024557\n",
              " 348  0.004237  0.022825  0.001020  0.025003\n",
              " 349  0.004344  0.022982  0.001020  0.024998\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.171144  0.328696  0.007574  0.084261\n",
              " 1    0.114952  0.281003  0.005532  0.071121\n",
              " 2    0.104836  0.254503  0.005099  0.068014\n",
              " 3    0.107910  0.250360  0.004919  0.066672\n",
              " 4    0.084841  0.232073  0.002559  0.047835\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004353  0.023623  0.000929  0.023375\n",
              " 346  0.004308  0.022379  0.000971  0.024144\n",
              " 347  0.004301  0.023728  0.000891  0.022653\n",
              " 348  0.004289  0.025908  0.000814  0.021055\n",
              " 349  0.004363  0.023597  0.000976  0.024244\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    23.408348  3.497270  0.171705  0.413891\n",
              " 1     7.115602  2.002642  0.140530  0.374221\n",
              " 2     2.667161  1.203568  0.046820  0.215261\n",
              " 3     2.630447  1.200946  0.020042  0.140005\n",
              " 4     1.681956  0.968473  0.004435  0.063135\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.005500  0.039964  0.001169  0.027397\n",
              " 346   0.005278  0.035391  0.001180  0.027567\n",
              " 347   0.006142  0.036764  0.001159  0.027252\n",
              " 348   0.006085  0.037428  0.001406  0.030729\n",
              " 349   0.007151  0.039038  0.001564  0.033018\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    34.395493  4.028244  0.437717  0.661114\n",
              " 1     8.482505  2.378587  0.001933  0.034069\n",
              " 2     4.189565  1.607813  0.024044  0.152982\n",
              " 3     4.489903  1.570478  0.007520  0.082848\n",
              " 4     3.829661  1.317316  0.001771  0.033708\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.005496  0.039557  0.000956  0.023882\n",
              " 346   0.006573  0.046529  0.000881  0.022457\n",
              " 347   0.005637  0.043827  0.000784  0.020401\n",
              " 348   0.007056  0.052322  0.000983  0.024359\n",
              " 349   0.004927  0.038983  0.001083  0.026056\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    87.922333  6.608862  0.629061  0.792894\n",
              " 1    11.983316  2.776236  0.026935  0.162681\n",
              " 2    12.525028  2.316715  0.001666  0.035177\n",
              " 3     6.865870  1.758058  0.002781  0.048462\n",
              " 4     7.147061  1.828842  0.000973  0.029245\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.007382  0.055633  0.001246  0.028540\n",
              " 346   0.007077  0.049923  0.001361  0.030133\n",
              " 347   0.007876  0.051233  0.001301  0.029314\n",
              " 348   0.008038  0.055937  0.000680  0.017794\n",
              " 349   0.009748  0.060182  0.000731  0.019147\n",
              " \n",
              " [350 rows x 4 columns]]"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(funcoes)):\n",
        "  for j in range(0, len(taxas)):\n",
        "    plt.plot(resultados[j]['loss'])\n",
        "    plt.plot(resultados[j]['val_loss'])\n",
        "  plt.title(funcoes[i])\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.xlabel('Épocas de treinamento')\n",
        "  plt.legend(['0.005 (loss)', '0.01 (loss)', '0.05 (loss)', '0.005 (val_loss)', '0.01 (val_loss)', '0.05 (val_loss)'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1lycZhUDlIMp",
        "outputId": "8e49a891-243d-44ab-8082-37ce7b66f571"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}