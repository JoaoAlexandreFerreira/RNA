{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JoaoAlexandreFerreira/RNA/blob/main/Visualiza%C3%A7%C3%A3o_dos_Custos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "MENtmaUTLn9l"
      },
      "outputs": [],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from keras.metrics import  MeanRelativeError"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Carregando o dataset e separando em teste e treino\n",
        "df = pd.read_csv('data_cov (1).csv')\n",
        "y = df['cov']\n",
        "x = df.drop('cov', axis = 1)\n",
        "\n",
        "x_treino, x_teste = x[0:86], x[86:]\n",
        "y_treino, y_teste = y[0:86], y[86:]\n",
        "'''\n",
        "x_treino.insert(5, 'Cov',y_treino)\n",
        "x_treino = x_treino.sort_values(by='flow_distance_ratio')\n",
        "\n",
        "y_treino = x_treino['Cov']\n",
        "x_treino = x_treino.drop('Cov', axis = 1)\n",
        "'''\n",
        "scaler = MinMaxScaler()\n",
        "x_treino_normalizado = scaler.fit_transform(x_treino)\n",
        "x_teste_normalizado = scaler.transform(x_teste)"
      ],
      "metadata": {
        "id": "uFUv6sEYLtZ2"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "funcoes = ['tanh', 'relu', 'sigmoid', 'LeakyReLU']\n",
        "taxas = [0.005, 0.01, 0.05]"
      ],
      "metadata": {
        "id": "ENoqT1EbAhZV"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def modelo_RNA(x, activation, nos, camadas_ocultas):\n",
        "  modelo = Sequential()\n",
        "  modelo.add(tf.keras.layers.Input(shape=(x.shape[1],)))\n",
        "  #modelo.add(keras.layers.Dense(nos, activation='relu', input_shape=x.shape))\n",
        "  for i in range(camadas_ocultas):\n",
        "    modelo.add(keras.layers.Dense(nos, activation=activation))\n",
        "    modelo.add(keras.layers.Dropout(0.2))\n",
        "  modelo.add(keras.layers.Dense(1, activation= 'linear'))\n",
        "  modelo.summary()\n",
        "\n",
        "  return modelo\n",
        "\n",
        "def treino_modelo(modelo, optimizer, loss, metrics, x_treino, y_treino, x_teste, y_teste, itr):\n",
        "  modelo.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n",
        "\n",
        "  resultado = modelo.fit(x_treino, y_treino, epochs=itr, batch_size=5, validation_data=(x_teste, y_teste))\n",
        "\n",
        "  return resultado, modelo\n",
        "\n",
        "def erro_relativo(y_pred, y_true):\n",
        "  return np.mean(np.abs((y_true - y_pred) / y_true))"
      ],
      "metadata": {
        "id": "8xNyVan9_5x-"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados = list()\n",
        "erros_relativos = list()\n",
        "for i in funcoes:\n",
        "  #modelo = modelo_RNA(x_treino, i, 40, 11)\n",
        "  for j in taxas:\n",
        "      otimizador = tf.keras.optimizers.Adam(learning_rate=j)\n",
        "      modelo = modelo_RNA(x_treino, i, 40, 11)\n",
        "      resultado, modelo = treino_modelo(modelo, 'adam', 'mse', ['mae'], x_treino, y_treino, x_teste, y_teste, 350)\n",
        "      resultado = pd.DataFrame(resultado.history)\n",
        "      resultados.append(resultado)\n",
        "      y_pred = modelo.predict(x_treino)\n",
        "      y_pred = pd.DataFrame(y_pred)\n",
        "      erro = erro_relativo(y_pred, y_treino)\n",
        "      erros_relativos.append(erro)\n",
        "      '''\n",
        "      plt.plot(resultado.history['loss'])\n",
        "      plt.plot(resultado.history['val_loss'])\n",
        "      plt.title('Histórico de Treinamento')\n",
        "      plt.ylabel('Loss (MSE)')\n",
        "      plt.xlabel('Épocas de treinamento')\n",
        "      plt.legend(['Erro treino', 'Erro teste'])\n",
        "      plt.show()\n",
        "      '''"
      ],
      "metadata": {
        "id": "sStelzMt_8ye",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3bacfc9-024d-4790-8b4d-c39451b25ecd"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_13\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_156 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_143 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_157 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_144 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_158 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_145 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_159 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_146 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_160 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_147 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_161 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_148 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_162 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_149 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_163 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_150 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_164 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_151 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_165 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_152 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_166 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_153 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_167 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 4s 17ms/step - loss: 0.1752 - mae: 0.3453 - val_loss: 0.0039 - val_mae: 0.0587\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0900 - mae: 0.2471 - val_loss: 0.0041 - val_mae: 0.0604\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.1006 - mae: 0.2558 - val_loss: 0.0015 - val_mae: 0.0370\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0643 - mae: 0.1958 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0624 - mae: 0.1876 - val_loss: 0.0029 - val_mae: 0.0488\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0467 - mae: 0.1670 - val_loss: 4.7914e-04 - val_mae: 0.0146\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0418 - mae: 0.1611 - val_loss: 0.0033 - val_mae: 0.0530\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0440 - mae: 0.1569 - val_loss: 5.2658e-04 - val_mae: 0.0147\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0384 - mae: 0.1586 - val_loss: 4.8290e-04 - val_mae: 0.0146\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0302 - mae: 0.1312 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0306 - mae: 0.1305 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0301 - mae: 0.1396 - val_loss: 6.1794e-04 - val_mae: 0.0162\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.1181 - val_loss: 7.5651e-04 - val_mae: 0.0194\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0243 - mae: 0.1245 - val_loss: 5.0154e-04 - val_mae: 0.0145\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1099 - val_loss: 5.5935e-04 - val_mae: 0.0152\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.1091 - val_loss: 5.3319e-04 - val_mae: 0.0150\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0901 - val_loss: 9.3541e-04 - val_mae: 0.0285\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0302 - mae: 0.1276 - val_loss: 5.0018e-04 - val_mae: 0.0158\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0209 - mae: 0.1161 - val_loss: 8.0009e-04 - val_mae: 0.0207\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0237 - mae: 0.1198 - val_loss: 6.6304e-04 - val_mae: 0.0170\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 0.1157 - val_loss: 5.3087e-04 - val_mae: 0.0150\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0218 - mae: 0.1094 - val_loss: 4.9443e-04 - val_mae: 0.0146\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0233 - mae: 0.1196 - val_loss: 0.0030 - val_mae: 0.0508\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.1009 - val_loss: 4.7936e-04 - val_mae: 0.0146\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0202 - mae: 0.1043 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0221 - mae: 0.1070 - val_loss: 8.5464e-04 - val_mae: 0.0219\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0181 - mae: 0.1077 - val_loss: 6.5624e-04 - val_mae: 0.0171\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1146 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0963 - val_loss: 0.0022 - val_mae: 0.0418\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0923 - val_loss: 5.7381e-04 - val_mae: 0.0154\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0913 - val_loss: 5.3842e-04 - val_mae: 0.0150\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0889 - val_loss: 5.1959e-04 - val_mae: 0.0148\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1055 - val_loss: 8.3609e-04 - val_mae: 0.0215\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0147 - mae: 0.0851 - val_loss: 7.5491e-04 - val_mae: 0.0197\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.1026 - val_loss: 6.2965e-04 - val_mae: 0.0165\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0835 - val_loss: 8.6752e-04 - val_mae: 0.0223\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0913 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0768 - val_loss: 0.0018 - val_mae: 0.0364\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0847 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0172 - mae: 0.0973 - val_loss: 7.5143e-04 - val_mae: 0.0196\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0133 - mae: 0.0742 - val_loss: 9.7574e-04 - val_mae: 0.0242\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0770 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0794 - val_loss: 5.8385e-04 - val_mae: 0.0156\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0732 - val_loss: 0.0025 - val_mae: 0.0450\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0808 - val_loss: 0.0026 - val_mae: 0.0463\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0098 - mae: 0.0669 - val_loss: 0.0032 - val_mae: 0.0524\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0783 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0795 - val_loss: 5.9898e-04 - val_mae: 0.0203\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0770 - val_loss: 5.7808e-04 - val_mae: 0.0155\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0762 - val_loss: 7.2034e-04 - val_mae: 0.0189\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0760 - val_loss: 5.1780e-04 - val_mae: 0.0166\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0613 - val_loss: 5.2174e-04 - val_mae: 0.0148\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0819 - val_loss: 4.7731e-04 - val_mae: 0.0146\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0608 - val_loss: 4.7561e-04 - val_mae: 0.0146\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0693 - val_loss: 8.8609e-04 - val_mae: 0.0225\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0680 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0597 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0639 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0616 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0127 - mae: 0.0743 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0610 - val_loss: 9.3518e-04 - val_mae: 0.0235\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0619 - val_loss: 7.8350e-04 - val_mae: 0.0204\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0631 - val_loss: 4.7264e-04 - val_mae: 0.0146\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0088 - mae: 0.0583 - val_loss: 4.9243e-04 - val_mae: 0.0146\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0555 - val_loss: 7.7893e-04 - val_mae: 0.0203\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0501 - val_loss: 8.8657e-04 - val_mae: 0.0226\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0552 - val_loss: 5.6959e-04 - val_mae: 0.0154\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - mae: 0.0572 - val_loss: 7.1282e-04 - val_mae: 0.0187\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0586 - val_loss: 5.6729e-04 - val_mae: 0.0154\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0658 - val_loss: 5.0775e-04 - val_mae: 0.0146\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0636 - val_loss: 7.3919e-04 - val_mae: 0.0194\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0566 - val_loss: 8.0833e-04 - val_mae: 0.0210\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0506 - val_loss: 5.4976e-04 - val_mae: 0.0152\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0584 - val_loss: 6.0407e-04 - val_mae: 0.0160\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0494 - val_loss: 9.6325e-04 - val_mae: 0.0240\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0456 - val_loss: 6.6046e-04 - val_mae: 0.0173\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0503 - val_loss: 6.7127e-04 - val_mae: 0.0176\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0091 - mae: 0.0572 - val_loss: 9.9115e-04 - val_mae: 0.0245\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0492 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0448 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0504 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0427 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0418 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0491 - val_loss: 7.7762e-04 - val_mae: 0.0203\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0511 - val_loss: 9.4380e-04 - val_mae: 0.0236\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0476 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0461 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0398 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0470 - val_loss: 6.7344e-04 - val_mae: 0.0176\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0469 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0521 - val_loss: 8.6982e-04 - val_mae: 0.0222\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0077 - mae: 0.0527 - val_loss: 7.9389e-04 - val_mae: 0.0206\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0496 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0489 - val_loss: 5.0976e-04 - val_mae: 0.0147\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0507 - val_loss: 8.7904e-04 - val_mae: 0.0224\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0480 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0433 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0430 - val_loss: 8.1369e-04 - val_mae: 0.0211\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0468 - val_loss: 8.4190e-04 - val_mae: 0.0217\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0464 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0470 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0386 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0487 - val_loss: 9.6885e-04 - val_mae: 0.0241\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0396 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0447 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0449 - val_loss: 9.3833e-04 - val_mae: 0.0235\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0462 - val_loss: 8.3788e-04 - val_mae: 0.0216\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0457 - val_loss: 8.4714e-04 - val_mae: 0.0218\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0444 - val_loss: 7.1715e-04 - val_mae: 0.0188\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0436 - val_loss: 6.2877e-04 - val_mae: 0.0164\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0445 - val_loss: 8.9673e-04 - val_mae: 0.0227\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0404 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0366 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0356 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0376 - val_loss: 9.7633e-04 - val_mae: 0.0242\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0407 - val_loss: 9.1319e-04 - val_mae: 0.0231\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0061 - mae: 0.0429 - val_loss: 8.7006e-04 - val_mae: 0.0222\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0419 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0434 - val_loss: 5.7018e-04 - val_mae: 0.0154\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0394 - val_loss: 8.4682e-04 - val_mae: 0.0217\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0346 - val_loss: 9.7502e-04 - val_mae: 0.0242\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0444 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0345 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0395 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0352 - val_loss: 9.1910e-04 - val_mae: 0.0232\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0436 - val_loss: 7.8118e-04 - val_mae: 0.0203\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0354 - val_loss: 7.4841e-04 - val_mae: 0.0196\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0357 - val_loss: 9.0762e-04 - val_mae: 0.0229\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0379 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0383 - val_loss: 8.0863e-04 - val_mae: 0.0209\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0379 - val_loss: 9.9029e-04 - val_mae: 0.0245\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0422 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0363 - val_loss: 8.3863e-04 - val_mae: 0.0216\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0360 - val_loss: 7.9943e-04 - val_mae: 0.0207\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0394 - val_loss: 7.7492e-04 - val_mae: 0.0202\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0367 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0364 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0310 - val_loss: 8.9434e-04 - val_mae: 0.0227\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0336 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0352 - val_loss: 8.5789e-04 - val_mae: 0.0220\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0350 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0347 - val_loss: 9.1510e-04 - val_mae: 0.0231\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0347 - val_loss: 9.0573e-04 - val_mae: 0.0229\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0333 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0366 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0334 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0322 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0316 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0335 - val_loss: 9.5994e-04 - val_mae: 0.0239\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0347 - val_loss: 9.8445e-04 - val_mae: 0.0244\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0329 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0324 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0307 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0332 - val_loss: 8.8028e-04 - val_mae: 0.0224\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0330 - val_loss: 9.6444e-04 - val_mae: 0.0240\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0289 - val_loss: 9.8892e-04 - val_mae: 0.0245\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0319 - val_loss: 9.1439e-04 - val_mae: 0.0231\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0303 - val_loss: 9.1820e-04 - val_mae: 0.0232\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0344 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0311 - val_loss: 9.6824e-04 - val_mae: 0.0241\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0318 - val_loss: 9.7369e-04 - val_mae: 0.0242\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0333 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0326 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0325 - val_loss: 9.5813e-04 - val_mae: 0.0239\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0349 - val_loss: 8.8823e-04 - val_mae: 0.0226\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0286 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0321 - val_loss: 8.9983e-04 - val_mae: 0.0228\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 9.2908e-04 - val_mae: 0.0234\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0326 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 9.6546e-04 - val_mae: 0.0240\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0311 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0307 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0289 - val_loss: 8.3170e-04 - val_mae: 0.0215\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0314 - val_loss: 8.5209e-04 - val_mae: 0.0219\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0336 - val_loss: 9.7224e-04 - val_mae: 0.0242\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0302 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0299 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0283 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0301 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0321 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0305 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0275 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0319 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0303 - val_loss: 9.4302e-04 - val_mae: 0.0236\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0329 - val_loss: 9.2959e-04 - val_mae: 0.0234\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0258 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0274 - val_loss: 9.4913e-04 - val_mae: 0.0237\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0313 - val_loss: 9.2858e-04 - val_mae: 0.0234\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0288 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 9.4462e-04 - val_mae: 0.0237\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 8.9253e-04 - val_mae: 0.0227\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0309 - val_loss: 9.6777e-04 - val_mae: 0.0241\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0283 - val_loss: 9.0144e-04 - val_mae: 0.0229\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0303 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 8.1750e-04 - val_mae: 0.0211\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0283 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0255 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.8662e-04 - val_mae: 0.0244\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.1073e-04 - val_mae: 0.0230\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0261 - val_loss: 9.6639e-04 - val_mae: 0.0241\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.0141e-04 - val_mae: 0.0229\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0277 - val_loss: 8.2927e-04 - val_mae: 0.0214\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 9.8461e-04 - val_mae: 0.0244\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0263 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0238 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0274 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0269 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0300 - val_loss: 9.9637e-04 - val_mae: 0.0246\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0300 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0271 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0243 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0263 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0278 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0267 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0283 - val_loss: 0.0018 - val_mae: 0.0369\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0287 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0276 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 0.0018 - val_mae: 0.0371\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0310 - val_loss: 0.0018 - val_mae: 0.0369\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0262 - val_loss: 0.0021 - val_mae: 0.0403\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0255 - val_loss: 0.0024 - val_mae: 0.0434\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0280 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0268 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0259 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0419 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0319 - val_loss: 0.0031 - val_mae: 0.0512\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0311 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0284 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0280 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 0.0022 - val_mae: 0.0412\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0266 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 0.0025 - val_mae: 0.0445\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0290 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0258 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0272 - val_loss: 0.0019 - val_mae: 0.0381\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0282 - val_loss: 0.0024 - val_mae: 0.0433\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0302 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0281 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0275 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0265 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0275 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0267 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0291 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0271 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0274 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0298 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0328 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0237 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0289 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0323 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0036 - mae: 0.0259 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0040 - mae: 0.0318 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0284 - val_loss: 0.0021 - val_mae: 0.0400\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0276 - val_loss: 0.0022 - val_mae: 0.0410\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0291 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0284 - val_loss: 0.0021 - val_mae: 0.0397\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0276 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0222 - val_loss: 0.0021 - val_mae: 0.0400\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0260 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0309 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0363 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0289 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 0.0019 - val_mae: 0.0383\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0274 - val_loss: 0.0022 - val_mae: 0.0410\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0263 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0249 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0261 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0255 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0242 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0251 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0265 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0265 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0283 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0274 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0288 - val_loss: 0.0022 - val_mae: 0.0414\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0264 - val_loss: 0.0021 - val_mae: 0.0398\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0282 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0267 - val_loss: 0.0020 - val_mae: 0.0386\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0217 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0247 - val_loss: 0.0021 - val_mae: 0.0403\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0268 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0423 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0329 - val_loss: 0.0033 - val_mae: 0.0527\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0345 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "Model: \"sequential_14\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_168 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_154 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_169 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_155 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_170 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_156 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_171 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_157 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_172 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_158 (Dropout)       (None, 40)                0         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dense_173 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_159 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_174 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_160 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_175 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_161 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_176 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_162 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_177 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_163 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_178 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_164 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_179 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 0.1886 - mae: 0.3409 - val_loss: 0.0283 - val_mae: 0.1666\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1535 - mae: 0.2915 - val_loss: 0.0630 - val_mae: 0.2499\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1359 - mae: 0.2975 - val_loss: 0.0022 - val_mae: 0.0443\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0819 - mae: 0.2361 - val_loss: 0.0042 - val_mae: 0.0611\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0892 - mae: 0.2356 - val_loss: 0.0041 - val_mae: 0.0606\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0848 - mae: 0.2353 - val_loss: 0.0214 - val_mae: 0.1445\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0919 - mae: 0.2275 - val_loss: 0.0065 - val_mae: 0.0775\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0549 - mae: 0.1911 - val_loss: 0.0058 - val_mae: 0.0728\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0444 - mae: 0.1672 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0544 - mae: 0.1809 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0459 - mae: 0.1712 - val_loss: 0.0052 - val_mae: 0.0686\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0468 - mae: 0.1716 - val_loss: 4.9332e-04 - val_mae: 0.0146\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0337 - mae: 0.1406 - val_loss: 5.9517e-04 - val_mae: 0.0158\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0538 - mae: 0.1889 - val_loss: 6.8160e-04 - val_mae: 0.0176\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0437 - mae: 0.1634 - val_loss: 0.0017 - val_mae: 0.0393\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0316 - mae: 0.1400 - val_loss: 9.9140e-04 - val_mae: 0.0247\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0335 - mae: 0.1392 - val_loss: 0.0033 - val_mae: 0.0538\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0400 - mae: 0.1585 - val_loss: 6.9928e-04 - val_mae: 0.0180\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0293 - mae: 0.1303 - val_loss: 0.0033 - val_mae: 0.0533\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0312 - mae: 0.1316 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1409 - val_loss: 0.0042 - val_mae: 0.0609\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0209 - mae: 0.1127 - val_loss: 0.0033 - val_mae: 0.0535\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0254 - mae: 0.1185 - val_loss: 5.3333e-04 - val_mae: 0.0150\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - mae: 0.1117 - val_loss: 6.7204e-04 - val_mae: 0.0176\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.1052 - val_loss: 5.8455e-04 - val_mae: 0.0156\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - mae: 0.1028 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0241 - mae: 0.1207 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0217 - mae: 0.1085 - val_loss: 7.2781e-04 - val_mae: 0.0191\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0257 - mae: 0.1224 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0235 - mae: 0.1185 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0197 - mae: 0.1092 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0167 - mae: 0.1005 - val_loss: 6.7717e-04 - val_mae: 0.0180\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - mae: 0.0925 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0202 - mae: 0.0975 - val_loss: 8.3603e-04 - val_mae: 0.0216\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0906 - val_loss: 7.3361e-04 - val_mae: 0.0192\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0160 - mae: 0.0949 - val_loss: 9.2619e-04 - val_mae: 0.0233\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0203 - mae: 0.1097 - val_loss: 9.7131e-04 - val_mae: 0.0242\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0884 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0806 - val_loss: 7.6572e-04 - val_mae: 0.0199\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0183 - mae: 0.1002 - val_loss: 5.7095e-04 - val_mae: 0.0195\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0870 - val_loss: 6.6840e-04 - val_mae: 0.0176\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0175 - mae: 0.0933 - val_loss: 0.0020 - val_mae: 0.0384\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0787 - val_loss: 0.0030 - val_mae: 0.0496\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0906 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0768 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0741 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0087 - mae: 0.0751 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0764 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0768 - val_loss: 0.0025 - val_mae: 0.0448\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0847 - val_loss: 0.0020 - val_mae: 0.0399\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0771 - val_loss: 5.1389e-04 - val_mae: 0.0148\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0817 - val_loss: 0.0035 - val_mae: 0.0548\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0747 - val_loss: 0.0028 - val_mae: 0.0476\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0784 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0729 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0139 - mae: 0.0860 - val_loss: 0.0016 - val_mae: 0.0327\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0793 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0715 - val_loss: 5.0761e-04 - val_mae: 0.0146\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0724 - val_loss: 6.5675e-04 - val_mae: 0.0171\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0707 - val_loss: 7.3593e-04 - val_mae: 0.0193\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0096 - mae: 0.0689 - val_loss: 0.0022 - val_mae: 0.0418\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0737 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0677 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0666 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0698 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0644 - val_loss: 5.8584e-04 - val_mae: 0.0156\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0653 - val_loss: 8.6484e-04 - val_mae: 0.0220\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0117 - mae: 0.0731 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0620 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0504 - val_loss: 5.3421e-04 - val_mae: 0.0151\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0659 - val_loss: 7.1395e-04 - val_mae: 0.0188\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0670 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0638 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0612 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0634 - val_loss: 6.6985e-04 - val_mae: 0.0176\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0578 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0571 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0608 - val_loss: 8.8531e-04 - val_mae: 0.0226\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0588 - val_loss: 4.9915e-04 - val_mae: 0.0145\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0609 - val_loss: 9.6328e-04 - val_mae: 0.0239\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0593 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0589 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0578 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0547 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0635 - val_loss: 7.6700e-04 - val_mae: 0.0202\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0569 - val_loss: 9.8129e-04 - val_mae: 0.0244\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0554 - val_loss: 9.5522e-04 - val_mae: 0.0239\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0514 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0451 - val_loss: 8.8408e-04 - val_mae: 0.0226\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0531 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0502 - val_loss: 7.0707e-04 - val_mae: 0.0188\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0531 - val_loss: 6.7514e-04 - val_mae: 0.0181\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0485 - val_loss: 9.4209e-04 - val_mae: 0.0238\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0503 - val_loss: 5.5168e-04 - val_mae: 0.0153\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0472 - val_loss: 7.3542e-04 - val_mae: 0.0196\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0550 - val_loss: 4.4610e-04 - val_mae: 0.0148\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0524 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0531 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0498 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0500 - val_loss: 7.6043e-04 - val_mae: 0.0202\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0070 - mae: 0.0526 - val_loss: 4.3348e-04 - val_mae: 0.0151\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0345\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0067 - mae: 0.0514 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0463 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0553 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0548 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0532 - val_loss: 8.8413e-04 - val_mae: 0.0227\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0519 - val_loss: 8.6886e-04 - val_mae: 0.0224\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0529 - val_loss: 6.1484e-04 - val_mae: 0.0164\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0516 - val_loss: 6.6853e-04 - val_mae: 0.0177\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0518 - val_loss: 8.8739e-04 - val_mae: 0.0226\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0489 - val_loss: 9.9370e-04 - val_mae: 0.0246\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0445 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0453 - val_loss: 9.7110e-04 - val_mae: 0.0242\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0434 - val_loss: 9.8840e-04 - val_mae: 0.0245\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0431 - val_loss: 9.6557e-04 - val_mae: 0.0241\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0434 - val_loss: 9.0772e-04 - val_mae: 0.0230\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0414 - val_loss: 7.6355e-04 - val_mae: 0.0201\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0072 - mae: 0.0500 - val_loss: 8.6517e-04 - val_mae: 0.0222\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0414 - val_loss: 9.7244e-04 - val_mae: 0.0242\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0485 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0450 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0376 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0444 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0440 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0410 - val_loss: 8.0072e-04 - val_mae: 0.0209\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0386 - val_loss: 9.9709e-04 - val_mae: 0.0246\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0376 - val_loss: 8.5524e-04 - val_mae: 0.0218\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0373 - val_loss: 9.2294e-04 - val_mae: 0.0232\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0430 - val_loss: 4.7413e-04 - val_mae: 0.0146\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0461 - val_loss: 6.7393e-04 - val_mae: 0.0177\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0466 - val_loss: 9.8687e-04 - val_mae: 0.0245\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0407 - val_loss: 9.9359e-04 - val_mae: 0.0246\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0395 - val_loss: 7.4815e-04 - val_mae: 0.0197\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0364 - val_loss: 9.0814e-04 - val_mae: 0.0231\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0365 - val_loss: 8.4349e-04 - val_mae: 0.0218\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0404 - val_loss: 9.1346e-04 - val_mae: 0.0231\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0393 - val_loss: 9.7551e-04 - val_mae: 0.0242\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0382 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0357 - val_loss: 8.3453e-04 - val_mae: 0.0216\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0392 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0386 - val_loss: 8.4862e-04 - val_mae: 0.0219\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0347 - val_loss: 8.7817e-04 - val_mae: 0.0225\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0401 - val_loss: 7.9566e-04 - val_mae: 0.0208\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0398 - val_loss: 9.8123e-04 - val_mae: 0.0244\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0365 - val_loss: 9.8719e-04 - val_mae: 0.0245\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0417 - val_loss: 7.1679e-04 - val_mae: 0.0189\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0369 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0337 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0375 - val_loss: 8.0384e-04 - val_mae: 0.0210\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0372 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0363 - val_loss: 9.1574e-04 - val_mae: 0.0232\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0350 - val_loss: 7.1956e-04 - val_mae: 0.0190\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0328 - val_loss: 8.7561e-04 - val_mae: 0.0224\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0349 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0381 - val_loss: 8.6950e-04 - val_mae: 0.0223\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0345 - val_loss: 8.2853e-04 - val_mae: 0.0214\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0338 - val_loss: 9.2977e-04 - val_mae: 0.0234\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0384 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0354 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0363 - val_loss: 9.5322e-04 - val_mae: 0.0239\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0397 - val_loss: 9.5155e-04 - val_mae: 0.0239\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0320 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0384 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0324 - val_loss: 9.4695e-04 - val_mae: 0.0237\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0329 - val_loss: 9.2020e-04 - val_mae: 0.0232\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0359 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0438 - val_loss: 5.4645e-04 - val_mae: 0.0150\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0419 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0378 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0351 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0373 - val_loss: 9.5225e-04 - val_mae: 0.0238\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0379 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0429 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0361 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0374 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0365 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 15ms/step - loss: 0.0048 - mae: 0.0334 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0044 - mae: 0.0351 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0051 - mae: 0.0342 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0346 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0340 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0338 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0335 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0356 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0313 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0333 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0353 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0300 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0318 - val_loss: 9.9078e-04 - val_mae: 0.0245\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0301 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0303 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0358 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0351 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0322 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0332 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0328 - val_loss: 0.0018 - val_mae: 0.0357\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 0.0011 - val_mae: 0.0254\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0316 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0323 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0295 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0349 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0331 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0313 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0319 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0322 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0337 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0346 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0298 - val_loss: 0.0015 - val_mae: 0.0331\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0323 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0338 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0309 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0334 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0336 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0311 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0301 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0287 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0304 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0298 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0308 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0314 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0375 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0346 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0332 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0042 - mae: 0.0308 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0322 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 0.0017 - val_mae: 0.0360\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0268 - val_loss: 0.0014 - val_mae: 0.0316\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0265 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0324 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0305 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0308 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0312 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0346 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0307 - val_loss: 0.0019 - val_mae: 0.0385\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0327 - val_loss: 0.0021 - val_mae: 0.0410\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0320 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0329 - val_loss: 0.0020 - val_mae: 0.0397\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0345 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0295 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0304 - val_loss: 0.0022 - val_mae: 0.0422\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0289 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0314 - val_loss: 0.0019 - val_mae: 0.0385\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0031 - mae: 0.0313 - val_loss: 0.0025 - val_mae: 0.0458\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0315 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0318 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0316 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0289 - val_loss: 0.0024 - val_mae: 0.0437\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0313 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0320 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0246 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0301 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0309 - val_loss: 0.0019 - val_mae: 0.0383\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0335 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0287 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0288 - val_loss: 0.0016 - val_mae: 0.0343\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0303 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0314 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0323 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0308 - val_loss: 0.0018 - val_mae: 0.0374\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0272 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0286 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0290 - val_loss: 0.0017 - val_mae: 0.0359\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0288 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0298 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0279 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0326 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0301 - val_loss: 0.0019 - val_mae: 0.0386\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0305 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0296 - val_loss: 0.0024 - val_mae: 0.0446\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0321 - val_loss: 0.0023 - val_mae: 0.0428\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0250 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0274 - val_loss: 0.0021 - val_mae: 0.0410\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0279 - val_loss: 0.0031 - val_mae: 0.0513\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0274 - val_loss: 0.0034 - val_mae: 0.0540\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0319 - val_loss: 0.0030 - val_mae: 0.0509\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0274 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0323 - val_loss: 0.0022 - val_mae: 0.0423\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0302 - val_loss: 0.0023 - val_mae: 0.0426\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0032 - mae: 0.0283 - val_loss: 0.0021 - val_mae: 0.0408\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0309 - val_loss: 0.0027 - val_mae: 0.0473\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0461 - val_loss: 0.0021 - val_mae: 0.0414\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0418 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0309 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0284 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0323 - val_loss: 0.0031 - val_mae: 0.0519\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0314 - val_loss: 0.0032 - val_mae: 0.0526\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0313 - val_loss: 0.0020 - val_mae: 0.0397\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0324 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0289 - val_loss: 0.0028 - val_mae: 0.0489\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0307 - val_loss: 0.0021 - val_mae: 0.0410\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0302 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0312 - val_loss: 0.0021 - val_mae: 0.0410\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0320 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0308 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0320 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0317 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0263 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0275 - val_loss: 0.0023 - val_mae: 0.0425\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0270 - val_loss: 0.0032 - val_mae: 0.0523\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0364 - val_loss: 0.0026 - val_mae: 0.0465\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0286 - val_loss: 0.0025 - val_mae: 0.0448\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0321 - val_loss: 0.0018 - val_mae: 0.0364\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0277 - val_loss: 0.0023 - val_mae: 0.0434\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0354 - val_loss: 0.0034 - val_mae: 0.0548\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0392 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0365 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0332 - val_loss: 0.0028 - val_mae: 0.0487\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0341 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0305 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0283 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0299 - val_loss: 0.0031 - val_mae: 0.0513\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0346 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0030 - mae: 0.0291 - val_loss: 0.0028 - val_mae: 0.0489\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0293 - val_loss: 0.0041 - val_mae: 0.0602\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0300 - val_loss: 0.0019 - val_mae: 0.0381\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0324 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0029 - mae: 0.0258 - val_loss: 0.0027 - val_mae: 0.0477\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0310 - val_loss: 0.0032 - val_mae: 0.0527\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0335 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0333 - val_loss: 0.0025 - val_mae: 0.0457\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0326 - val_loss: 0.0020 - val_mae: 0.0395\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0279 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0272 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0279 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0266 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0250 - val_loss: 0.0022 - val_mae: 0.0422\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0287 - val_loss: 0.0025 - val_mae: 0.0457\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0033 - mae: 0.0301 - val_loss: 0.0036 - val_mae: 0.0562\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0270 - val_loss: 0.0028 - val_mae: 0.0486\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0304 - val_loss: 0.0023 - val_mae: 0.0425\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0317 - val_loss: 0.0028 - val_mae: 0.0488\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0274 - val_loss: 0.0027 - val_mae: 0.0470\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0031 - mae: 0.0278 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0027 - mae: 0.0256 - val_loss: 0.0033 - val_mae: 0.0537\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0376 - val_loss: 0.0022 - val_mae: 0.0422\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0325 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0032 - mae: 0.0271 - val_loss: 0.0036 - val_mae: 0.0564\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_15\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_180 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_165 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_181 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_166 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_182 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_167 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_183 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_168 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_184 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_169 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_185 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_170 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_186 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_171 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_187 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_172 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_188 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_173 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_189 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_174 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_190 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_175 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_191 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 0.2543 - mae: 0.4170 - val_loss: 0.0378 - val_mae: 0.1933\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1575 - mae: 0.3078 - val_loss: 0.0023 - val_mae: 0.0458\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1321 - mae: 0.2771 - val_loss: 0.0042 - val_mae: 0.0607\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0858 - mae: 0.2304 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1026 - mae: 0.2516 - val_loss: 0.0068 - val_mae: 0.0793\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0694 - mae: 0.2193 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0684 - mae: 0.2041 - val_loss: 0.0035 - val_mae: 0.0553\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0613 - mae: 0.2044 - val_loss: 9.3869e-04 - val_mae: 0.0236\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0530 - mae: 0.1819 - val_loss: 0.0045 - val_mae: 0.0635\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0492 - mae: 0.1901 - val_loss: 0.0054 - val_mae: 0.0700\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0651 - mae: 0.1974 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0483 - mae: 0.1755 - val_loss: 9.6987e-04 - val_mae: 0.0291\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0336 - mae: 0.1432 - val_loss: 0.0033 - val_mae: 0.0532\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0477 - mae: 0.1792 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0597 - mae: 0.1919 - val_loss: 0.0023 - val_mae: 0.0454\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0347 - mae: 0.1476 - val_loss: 7.5271e-04 - val_mae: 0.0197\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0347 - mae: 0.1397 - val_loss: 5.0080e-04 - val_mae: 0.0146\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0263 - mae: 0.1235 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.1364 - val_loss: 0.0040 - val_mae: 0.0594\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0244 - mae: 0.1247 - val_loss: 0.0074 - val_mae: 0.0831\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0381 - mae: 0.1488 - val_loss: 6.0205e-04 - val_mae: 0.0159\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1360 - val_loss: 4.7641e-04 - val_mae: 0.0146\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.1299 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0151 - mae: 0.1021 - val_loss: 0.0028 - val_mae: 0.0481\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1294 - val_loss: 9.4778e-04 - val_mae: 0.0237\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1150 - val_loss: 8.8278e-04 - val_mae: 0.0225\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0262 - mae: 0.1296 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0258 - mae: 0.1271 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1281 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0156 - mae: 0.0921 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0235 - mae: 0.1119 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0160 - mae: 0.1024 - val_loss: 0.0028 - val_mae: 0.0481\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1059 - val_loss: 0.0049 - val_mae: 0.0667\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1044 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 0.1076 - val_loss: 7.5125e-04 - val_mae: 0.0196\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.1112 - val_loss: 5.6585e-04 - val_mae: 0.0153\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0227 - mae: 0.1115 - val_loss: 0.0026 - val_mae: 0.0459\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0182 - mae: 0.0994 - val_loss: 7.0951e-04 - val_mae: 0.0186\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0991 - val_loss: 5.5109e-04 - val_mae: 0.0152\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0901 - val_loss: 4.8006e-04 - val_mae: 0.0150\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0174 - mae: 0.1011 - val_loss: 4.9876e-04 - val_mae: 0.0146\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0898 - val_loss: 5.8174e-04 - val_mae: 0.0156\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0905 - val_loss: 9.4861e-04 - val_mae: 0.0237\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0929 - val_loss: 9.9073e-04 - val_mae: 0.0245\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.1009 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0134 - mae: 0.0883 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0160 - mae: 0.0934 - val_loss: 6.1537e-04 - val_mae: 0.0162\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0151 - mae: 0.0882 - val_loss: 5.3609e-04 - val_mae: 0.0150\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0851 - val_loss: 6.5461e-04 - val_mae: 0.0171\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0751 - val_loss: 5.7893e-04 - val_mae: 0.0155\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0807 - val_loss: 6.8637e-04 - val_mae: 0.0180\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0828 - val_loss: 6.8711e-04 - val_mae: 0.0180\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0852 - val_loss: 5.4876e-04 - val_mae: 0.0152\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0905 - val_loss: 8.0035e-04 - val_mae: 0.0208\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0808 - val_loss: 7.4611e-04 - val_mae: 0.0195\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0138 - mae: 0.0795 - val_loss: 9.6343e-04 - val_mae: 0.0240\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0824 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0859 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0734 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0747 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0668 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0786 - val_loss: 6.8624e-04 - val_mae: 0.0180\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0732 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0754 - val_loss: 8.0826e-04 - val_mae: 0.0209\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0682 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0735 - val_loss: 0.0020 - val_mae: 0.0397\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0717 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0565 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0758 - val_loss: 9.3075e-04 - val_mae: 0.0234\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0702 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0589 - val_loss: 6.6999e-04 - val_mae: 0.0175\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0579 - val_loss: 7.8091e-04 - val_mae: 0.0203\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0670 - val_loss: 7.2724e-04 - val_mae: 0.0190\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0622 - val_loss: 8.2081e-04 - val_mae: 0.0212\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0680 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0595 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0593 - val_loss: 8.4052e-04 - val_mae: 0.0216\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0602 - val_loss: 9.7344e-04 - val_mae: 0.0242\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0605 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - mae: 0.0656 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - mae: 0.0554 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - mae: 0.0553 - val_loss: 8.3258e-04 - val_mae: 0.0215\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0587 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0581 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.0621 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0617 - val_loss: 8.8358e-04 - val_mae: 0.0225\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0097 - mae: 0.0614 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0506 - val_loss: 7.7886e-04 - val_mae: 0.0203\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0572 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0547 - val_loss: 9.3183e-04 - val_mae: 0.0234\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0560 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0534 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0524 - val_loss: 8.1121e-04 - val_mae: 0.0210\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0561 - val_loss: 6.5093e-04 - val_mae: 0.0170\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0542 - val_loss: 8.8981e-04 - val_mae: 0.0226\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0489 - val_loss: 5.7949e-04 - val_mae: 0.0155\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0584 - val_loss: 7.0332e-04 - val_mae: 0.0184\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0570 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0076 - mae: 0.0497 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0553 - val_loss: 7.3721e-04 - val_mae: 0.0193\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 14ms/step - loss: 0.0085 - mae: 0.0620 - val_loss: 8.7517e-04 - val_mae: 0.0223\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 17ms/step - loss: 0.0073 - mae: 0.0541 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0082 - mae: 0.0609 - val_loss: 8.5033e-04 - val_mae: 0.0218\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0483 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0520 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0526 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0592 - val_loss: 8.3042e-04 - val_mae: 0.0214\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0499 - val_loss: 6.5044e-04 - val_mae: 0.0169\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0457 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0492 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0521 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0473 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0468 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0471 - val_loss: 8.3314e-04 - val_mae: 0.0215\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0516 - val_loss: 6.3514e-04 - val_mae: 0.0165\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0491 - val_loss: 6.3325e-04 - val_mae: 0.0165\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0470 - val_loss: 8.3794e-04 - val_mae: 0.0216\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 8.1466e-04 - val_mae: 0.0211\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0459 - val_loss: 7.6681e-04 - val_mae: 0.0200\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0458 - val_loss: 9.5179e-04 - val_mae: 0.0238\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0425 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0425 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0421 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0511 - val_loss: 9.6247e-04 - val_mae: 0.0240\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0500 - val_loss: 9.2817e-04 - val_mae: 0.0234\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0431 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0441 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0425 - val_loss: 8.8651e-04 - val_mae: 0.0226\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0471 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0419 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0431 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0437 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0427 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0388 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0389 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0406 - val_loss: 9.0199e-04 - val_mae: 0.0229\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0373 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0379 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0379 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0354 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0355 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0385 - val_loss: 8.8938e-04 - val_mae: 0.0226\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0458 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0403 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0354 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0405 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0390 - val_loss: 8.3984e-04 - val_mae: 0.0216\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0420 - val_loss: 8.6093e-04 - val_mae: 0.0220\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0439 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0365 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0369 - val_loss: 8.5200e-04 - val_mae: 0.0219\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0390 - val_loss: 7.2044e-04 - val_mae: 0.0189\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0384 - val_loss: 8.6541e-04 - val_mae: 0.0221\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0404 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0393 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0386 - val_loss: 9.8980e-04 - val_mae: 0.0245\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0409 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0356 - val_loss: 8.1629e-04 - val_mae: 0.0211\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0385 - val_loss: 7.1606e-04 - val_mae: 0.0188\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0364 - val_loss: 8.7048e-04 - val_mae: 0.0222\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0370 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0309 - val_loss: 7.9129e-04 - val_mae: 0.0206\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0346 - val_loss: 7.2316e-04 - val_mae: 0.0189\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0359 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0390 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0373 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0297 - val_loss: 8.8544e-04 - val_mae: 0.0225\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0334 - val_loss: 8.8562e-04 - val_mae: 0.0225\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0347 - val_loss: 8.9827e-04 - val_mae: 0.0228\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0326 - val_loss: 9.2495e-04 - val_mae: 0.0233\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0351 - val_loss: 9.8523e-04 - val_mae: 0.0244\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0356 - val_loss: 9.2057e-04 - val_mae: 0.0232\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0323 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0333 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0346 - val_loss: 8.9415e-04 - val_mae: 0.0227\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0348 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0350 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0368 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0375 - val_loss: 7.8995e-04 - val_mae: 0.0205\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0348 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0332 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0399 - val_loss: 9.4769e-04 - val_mae: 0.0237\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0311 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0342 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0368 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0361 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0358 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0334 - val_loss: 9.6715e-04 - val_mae: 0.0241\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0340 - val_loss: 9.2541e-04 - val_mae: 0.0233\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0307 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0335 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 9.1223e-04 - val_mae: 0.0231\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0335 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0325 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0329 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0310 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0314 - val_loss: 7.2042e-04 - val_mae: 0.0189\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0343 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0328 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 9.8903e-04 - val_mae: 0.0245\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0316 - val_loss: 9.7918e-04 - val_mae: 0.0243\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0317 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0325 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0328 - val_loss: 8.4541e-04 - val_mae: 0.0217\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0285 - val_loss: 9.0374e-04 - val_mae: 0.0229\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0336 - val_loss: 9.0093e-04 - val_mae: 0.0228\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0310 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0289 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0309 - val_loss: 9.5933e-04 - val_mae: 0.0239\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0338 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0324 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0312 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0306 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0283 - val_loss: 9.1904e-04 - val_mae: 0.0232\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0318 - val_loss: 9.5934e-04 - val_mae: 0.0239\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0317 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0313 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0292 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0314 - val_loss: 9.1672e-04 - val_mae: 0.0231\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0313 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0307 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0292 - val_loss: 9.5283e-04 - val_mae: 0.0238\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0336 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0328 - val_loss: 9.3543e-04 - val_mae: 0.0235\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0315 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0313 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0308 - val_loss: 9.5694e-04 - val_mae: 0.0239\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0329 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0269 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0284 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0300 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0288 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0306 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0295 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0337 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0289 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0301 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0334 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0285 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0282 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0297 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0320 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0291 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0291 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0327 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0302 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0287 - val_loss: 9.1651e-04 - val_mae: 0.0231\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0323 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0308 - val_loss: 0.0018 - val_mae: 0.0364\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0308 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0288 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0302 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0298 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0326 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0283 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0275 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0286 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0311 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0289 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0315 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0331 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0349 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0345 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0293 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0305 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0329 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0336 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0287 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0304 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0273 - val_loss: 0.0023 - val_mae: 0.0428\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0287 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0294 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0296 - val_loss: 0.0019 - val_mae: 0.0371\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0308 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0297 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0315 - val_loss: 0.0022 - val_mae: 0.0414\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0035 - mae: 0.0277 - val_loss: 0.0029 - val_mae: 0.0496\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0308 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0316 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0311 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0295 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0307 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0306 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0290 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0290 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0302 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0305 - val_loss: 0.0018 - val_mae: 0.0371\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0263 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0037 - mae: 0.0264 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0258 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0280 - val_loss: 0.0021 - val_mae: 0.0408\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0268 - val_loss: 0.0026 - val_mae: 0.0456\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0268 - val_loss: 0.0021 - val_mae: 0.0408\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0282 - val_loss: 0.0027 - val_mae: 0.0473\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0302 - val_loss: 0.0023 - val_mae: 0.0433\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0285 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0286 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0287 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0312 - val_loss: 0.0019 - val_mae: 0.0371\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0288 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0266 - val_loss: 0.0028 - val_mae: 0.0484\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0305 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0289 - val_loss: 0.0025 - val_mae: 0.0448\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0313 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0283 - val_loss: 0.0019 - val_mae: 0.0383\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0279 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0295 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0284 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0270 - val_loss: 0.0030 - val_mae: 0.0501\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0313 - val_loss: 0.0031 - val_mae: 0.0513\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0288 - val_loss: 0.0026 - val_mae: 0.0460\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0034 - mae: 0.0322 - val_loss: 0.0036 - val_mae: 0.0563\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0282 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0294 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0306 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0248 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0254 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0296 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0262 - val_loss: 0.0021 - val_mae: 0.0400\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0250 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0294 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0283 - val_loss: 0.0030 - val_mae: 0.0505\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0412 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0413 - val_loss: 0.0039 - val_mae: 0.0587\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0030 - mae: 0.0311 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_16\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_192 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_176 (Dropout)       (None, 40)                0         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dense_193 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_177 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_194 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_178 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_195 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_179 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_196 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_180 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_197 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_181 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_198 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_182 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_199 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_183 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_200 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_184 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_201 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_185 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_202 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_186 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_203 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 16ms/step - loss: 12.6555 - mae: 2.4158 - val_loss: 0.0099 - val_mae: 0.0962\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1552 - mae: 0.8121 - val_loss: 0.0067 - val_mae: 0.0783\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8953 - mae: 0.6811 - val_loss: 0.0085 - val_mae: 0.0895\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4857 - mae: 0.4760 - val_loss: 0.0054 - val_mae: 0.0693\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4564 - mae: 0.4961 - val_loss: 0.0036 - val_mae: 0.0556\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3173 - mae: 0.4245 - val_loss: 0.0045 - val_mae: 0.0636\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2873 - mae: 0.3893 - val_loss: 0.0057 - val_mae: 0.0719\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1816 - mae: 0.3266 - val_loss: 0.0093 - val_mae: 0.0937\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1734 - mae: 0.2895 - val_loss: 0.0099 - val_mae: 0.0972\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1496 - mae: 0.2989 - val_loss: 0.0086 - val_mae: 0.0900\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1255 - mae: 0.2646 - val_loss: 0.0064 - val_mae: 0.0764\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1274 - mae: 0.2725 - val_loss: 0.0051 - val_mae: 0.0677\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2454 - mae: 0.3258 - val_loss: 0.0079 - val_mae: 0.0863\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2009 - mae: 0.3082 - val_loss: 0.0075 - val_mae: 0.0837\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1028 - mae: 0.2367 - val_loss: 0.0074 - val_mae: 0.0829\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0664 - mae: 0.1837 - val_loss: 0.0072 - val_mae: 0.0818\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0908 - mae: 0.2251 - val_loss: 0.0061 - val_mae: 0.0746\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0539 - mae: 0.1675 - val_loss: 0.0058 - val_mae: 0.0725\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0832 - mae: 0.2173 - val_loss: 0.0065 - val_mae: 0.0770\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0611 - mae: 0.1889 - val_loss: 0.0069 - val_mae: 0.0795\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0558 - mae: 0.1660 - val_loss: 0.0064 - val_mae: 0.0766\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0553 - mae: 0.1757 - val_loss: 0.0062 - val_mae: 0.0751\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0266 - mae: 0.1206 - val_loss: 0.0056 - val_mae: 0.0711\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0511 - mae: 0.1559 - val_loss: 0.0051 - val_mae: 0.0674\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0714 - mae: 0.1947 - val_loss: 0.0050 - val_mae: 0.0665\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0451 - mae: 0.1616 - val_loss: 0.0047 - val_mae: 0.0647\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0357 - mae: 0.1330 - val_loss: 0.0045 - val_mae: 0.0633\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0369 - mae: 0.1425 - val_loss: 0.0045 - val_mae: 0.0632\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0379 - mae: 0.1455 - val_loss: 0.0040 - val_mae: 0.0593\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0473 - mae: 0.1589 - val_loss: 0.0034 - val_mae: 0.0539\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0675 - mae: 0.1584 - val_loss: 0.0029 - val_mae: 0.0492\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0365 - mae: 0.1416 - val_loss: 0.0030 - val_mae: 0.0502\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0259 - mae: 0.1122 - val_loss: 0.0031 - val_mae: 0.0515\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0277 - mae: 0.1116 - val_loss: 0.0030 - val_mae: 0.0499\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.1139 - val_loss: 0.0030 - val_mae: 0.0498\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.0899 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0255 - mae: 0.1100 - val_loss: 0.0028 - val_mae: 0.0480\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.1193 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0244 - mae: 0.1098 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0216 - mae: 0.0908 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1142 - val_loss: 0.0019 - val_mae: 0.0385\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0250 - mae: 0.0985 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0278 - mae: 0.1170 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0911 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.0915 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.0936 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0915 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0267 - mae: 0.1031 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.0899 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0729 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0805 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0298 - mae: 0.0989 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0195 - mae: 0.0848 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0333 - mae: 0.1047 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0844 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0197 - mae: 0.0846 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0663 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0159 - mae: 0.0770 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0727 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0131 - mae: 0.0740 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0123 - mae: 0.0740 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0605 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0682 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0754 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - mae: 0.0740 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0606 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0605 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0583 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0587 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0529 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0522 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0593 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0626 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0571 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0528 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0551 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0608 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0580 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0534 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0579 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0549 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0544 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0530 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.0656 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0492 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0450 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0494 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0613 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0551 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - mae: 0.0438 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0449 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0373 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0420 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0383 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0525 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0472 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - mae: 0.0450 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0470 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0495 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - mae: 0.0504 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0389 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0440 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0355 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0413 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0442 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0354 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0446 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0494 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0155 - mae: 0.0552 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0354 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0347 - val_loss: 9.6840e-04 - val_mae: 0.0241\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0437 - val_loss: 9.9057e-04 - val_mae: 0.0245\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0323 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0430 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0346 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0399 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0444 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0420 - val_loss: 9.6322e-04 - val_mae: 0.0240\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0382 - val_loss: 9.6155e-04 - val_mae: 0.0240\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0379 - val_loss: 8.4298e-04 - val_mae: 0.0217\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0340 - val_loss: 8.3277e-04 - val_mae: 0.0215\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0388 - val_loss: 8.4409e-04 - val_mae: 0.0217\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0386 - val_loss: 8.7421e-04 - val_mae: 0.0223\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0373 - val_loss: 8.6416e-04 - val_mae: 0.0221\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0385 - val_loss: 8.7498e-04 - val_mae: 0.0223\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0295 - val_loss: 8.7102e-04 - val_mae: 0.0223\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0440 - val_loss: 8.7808e-04 - val_mae: 0.0224\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0348 - val_loss: 8.9838e-04 - val_mae: 0.0228\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0316 - val_loss: 9.1510e-04 - val_mae: 0.0231\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0334 - val_loss: 9.4508e-04 - val_mae: 0.0237\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0349 - val_loss: 9.9665e-04 - val_mae: 0.0246\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0369 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0327 - val_loss: 9.7894e-04 - val_mae: 0.0243\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0343 - val_loss: 9.9566e-04 - val_mae: 0.0246\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0342 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0362 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0319 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0318 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0378 - val_loss: 9.6166e-04 - val_mae: 0.0240\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0404 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0344 - val_loss: 9.5989e-04 - val_mae: 0.0239\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0386 - val_loss: 9.4137e-04 - val_mae: 0.0236\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0355 - val_loss: 9.3121e-04 - val_mae: 0.0234\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0363 - val_loss: 8.9854e-04 - val_mae: 0.0228\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0310 - val_loss: 9.0391e-04 - val_mae: 0.0229\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 7.6321e-04 - val_mae: 0.0199\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0370 - val_loss: 7.4628e-04 - val_mae: 0.0195\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0328 - val_loss: 7.2492e-04 - val_mae: 0.0190\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0341 - val_loss: 7.9183e-04 - val_mae: 0.0206\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0335 - val_loss: 8.7390e-04 - val_mae: 0.0223\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0304 - val_loss: 9.4089e-04 - val_mae: 0.0236\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 9.4635e-04 - val_mae: 0.0237\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0372 - val_loss: 9.8728e-04 - val_mae: 0.0244\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0374 - val_loss: 9.9920e-04 - val_mae: 0.0246\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0316 - val_loss: 9.5607e-04 - val_mae: 0.0239\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0294 - val_loss: 9.9296e-04 - val_mae: 0.0245\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0287 - val_loss: 9.7312e-04 - val_mae: 0.0242\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0275 - val_loss: 9.5993e-04 - val_mae: 0.0239\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0312 - val_loss: 9.7518e-04 - val_mae: 0.0242\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0294 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0286 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0312 - val_loss: 9.7197e-04 - val_mae: 0.0242\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0292 - val_loss: 9.3155e-04 - val_mae: 0.0234\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0350 - val_loss: 8.7908e-04 - val_mae: 0.0224\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0318 - val_loss: 9.3009e-04 - val_mae: 0.0234\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0309 - val_loss: 8.7598e-04 - val_mae: 0.0223\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0323 - val_loss: 8.6833e-04 - val_mae: 0.0222\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0281 - val_loss: 8.8404e-04 - val_mae: 0.0225\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0266 - val_loss: 8.7227e-04 - val_mae: 0.0223\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0300 - val_loss: 9.0554e-04 - val_mae: 0.0229\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0304e-04 - val_mae: 0.0229\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0255 - val_loss: 9.2160e-04 - val_mae: 0.0232\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0284 - val_loss: 9.3424e-04 - val_mae: 0.0235\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 9.0543e-04 - val_mae: 0.0229\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0275 - val_loss: 9.4553e-04 - val_mae: 0.0237\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.1137e-04 - val_mae: 0.0230\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0299 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0274 - val_loss: 9.3298e-04 - val_mae: 0.0234\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0316 - val_loss: 9.4632e-04 - val_mae: 0.0237\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 9.7136e-04 - val_mae: 0.0242\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0306 - val_loss: 9.8709e-04 - val_mae: 0.0244\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0273 - val_loss: 9.9631e-04 - val_mae: 0.0246\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0278 - val_loss: 9.9696e-04 - val_mae: 0.0246\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 9.7125e-04 - val_mae: 0.0241\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0266 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0267 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0299 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0275 - val_loss: 9.8473e-04 - val_mae: 0.0244\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.1081e-04 - val_mae: 0.0230\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.1322e-04 - val_mae: 0.0231\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0284 - val_loss: 8.2695e-04 - val_mae: 0.0213\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0289 - val_loss: 8.1958e-04 - val_mae: 0.0212\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 9.0273e-04 - val_mae: 0.0229\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.1479e-04 - val_mae: 0.0231\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.2764e-04 - val_mae: 0.0233\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0258 - val_loss: 9.2015e-04 - val_mae: 0.0232\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0230 - val_loss: 9.1879e-04 - val_mae: 0.0232\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0264 - val_loss: 9.2866e-04 - val_mae: 0.0234\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.1501e-04 - val_mae: 0.0231\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.1230e-04 - val_mae: 0.0231\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0257 - val_loss: 8.5371e-04 - val_mae: 0.0219\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 8.7756e-04 - val_mae: 0.0224\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 9.1032e-04 - val_mae: 0.0230\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 9.5557e-04 - val_mae: 0.0239\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.6741e-04 - val_mae: 0.0241\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 9.7110e-04 - val_mae: 0.0241\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 9.8147e-04 - val_mae: 0.0243\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0283 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0257 - val_loss: 9.9121e-04 - val_mae: 0.0245\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 9.3238e-04 - val_mae: 0.0234\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0269 - val_loss: 9.0634e-04 - val_mae: 0.0229\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0257 - val_loss: 9.4238e-04 - val_mae: 0.0236\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.3564e-04 - val_mae: 0.0235\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0268 - val_loss: 9.3868e-04 - val_mae: 0.0236\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.6961e-04 - val_mae: 0.0241\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 7.0238e-04 - val_mae: 0.0184\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0308 - val_loss: 5.4901e-04 - val_mae: 0.0152\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0340 - val_loss: 5.9461e-04 - val_mae: 0.0158\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0306 - val_loss: 6.9935e-04 - val_mae: 0.0183\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0337 - val_loss: 7.7980e-04 - val_mae: 0.0203\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0248 - val_loss: 8.6799e-04 - val_mae: 0.0222\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0288 - val_loss: 8.5381e-04 - val_mae: 0.0219\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 9.1083e-04 - val_mae: 0.0230\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.1120e-04 - val_mae: 0.0230\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 8.8305e-04 - val_mae: 0.0225\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0248 - val_loss: 8.8734e-04 - val_mae: 0.0226\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.3771e-04 - val_mae: 0.0235\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 9.4264e-04 - val_mae: 0.0236\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0257 - val_loss: 9.7004e-04 - val_mae: 0.0241\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0266 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.5695e-04 - val_mae: 0.0239\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.3557e-04 - val_mae: 0.0235\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0245 - val_loss: 9.1882e-04 - val_mae: 0.0232\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 8.9506e-04 - val_mae: 0.0227\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.6259e-04 - val_mae: 0.0240\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0229 - val_loss: 9.8828e-04 - val_mae: 0.0245\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 9.9980e-04 - val_mae: 0.0247\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0249 - val_loss: 9.2246e-04 - val_mae: 0.0233\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2624e-04 - val_mae: 0.0233\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0256 - val_loss: 9.6184e-04 - val_mae: 0.0240\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.7432e-04 - val_mae: 0.0242\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.7411e-04 - val_mae: 0.0242\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0237 - val_loss: 9.4332e-04 - val_mae: 0.0236\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 9.6713e-04 - val_mae: 0.0241\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.8401e-04 - val_mae: 0.0244\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.7179e-04 - val_mae: 0.0242\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.9122e-04 - val_mae: 0.0245\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0263 - val_loss: 9.9800e-04 - val_mae: 0.0246\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0264 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0280 - val_loss: 9.4413e-04 - val_mae: 0.0237\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 8.6160e-04 - val_mae: 0.0221\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.8263e-04 - val_mae: 0.0225\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.2103e-04 - val_mae: 0.0232\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.7029e-04 - val_mae: 0.0241\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.6917e-04 - val_mae: 0.0241\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.9073e-04 - val_mae: 0.0245\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.6810e-04 - val_mae: 0.0241\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0234 - val_loss: 9.4411e-04 - val_mae: 0.0237\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.7279e-04 - val_mae: 0.0242\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 9.1151e-04 - val_mae: 0.0230\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 9.4632e-04 - val_mae: 0.0237\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.8950e-04 - val_mae: 0.0245\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.8594e-04 - val_mae: 0.0244\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.8007e-04 - val_mae: 0.0243\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.7241e-04 - val_mae: 0.0242\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 6.8653e-04 - val_mae: 0.0180\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0280 - val_loss: 7.1772e-04 - val_mae: 0.0188\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 7.9792e-04 - val_mae: 0.0207\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 8.6891e-04 - val_mae: 0.0222\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 9.1636e-04 - val_mae: 0.0231\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0221 - val_loss: 9.6860e-04 - val_mae: 0.0241\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.5744e-04 - val_mae: 0.0239\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.8383e-04 - val_mae: 0.0244\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.8505e-04 - val_mae: 0.0244\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0238 - val_loss: 9.6697e-04 - val_mae: 0.0241\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.5321e-04 - val_mae: 0.0238\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.8368e-04 - val_mae: 0.0244\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0219 - val_loss: 9.9195e-04 - val_mae: 0.0245\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.3631e-04 - val_mae: 0.0235\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.3427e-04 - val_mae: 0.0235\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.5844e-04 - val_mae: 0.0239\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.6216e-04 - val_mae: 0.0240\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0254 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.9212e-04 - val_mae: 0.0245\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.7311e-04 - val_mae: 0.0242\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.6782e-04 - val_mae: 0.0241\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2899e-04 - val_mae: 0.0234\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0230 - val_loss: 9.6716e-04 - val_mae: 0.0241\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.5565e-04 - val_mae: 0.0239\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.1106e-04 - val_mae: 0.0230\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.9323e-04 - val_mae: 0.0245\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.1622e-04 - val_mae: 0.0231\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.7191e-04 - val_mae: 0.0242\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 9.8169e-04 - val_mae: 0.0243\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.9882e-04 - val_mae: 0.0228\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.3783e-04 - val_mae: 0.0235\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1831e-04 - val_mae: 0.0232\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.8201e-04 - val_mae: 0.0243\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.7983e-04 - val_mae: 0.0243\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.7964e-04 - val_mae: 0.0243\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.6228e-04 - val_mae: 0.0240\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.8929e-04 - val_mae: 0.0245\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.9948e-04 - val_mae: 0.0247\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0229 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.4779e-04 - val_mae: 0.0237\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0229 - val_loss: 9.8335e-04 - val_mae: 0.0244\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.6643e-04 - val_mae: 0.0241\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 8.9494e-04 - val_mae: 0.0227\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.2454e-04 - val_mae: 0.0233\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.4592e-04 - val_mae: 0.0237\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.3916e-04 - val_mae: 0.0236\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0252 - val_loss: 9.7698e-04 - val_mae: 0.0243\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.6280e-04 - val_mae: 0.0240\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0245 - val_loss: 9.4121e-04 - val_mae: 0.0236\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 8.7657e-04 - val_mae: 0.0224\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 8.8583e-04 - val_mae: 0.0225\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0292 - val_loss: 6.1569e-04 - val_mae: 0.0162\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 7.0429e-04 - val_mae: 0.0185\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 7.9827e-04 - val_mae: 0.0207\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 8.6517e-04 - val_mae: 0.0221\n",
            "3/3 [==============================] - 0s 7ms/step\n",
            "Model: \"sequential_17\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_204 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_187 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_205 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_188 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_206 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_189 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_207 (Dense)           (None, 40)                1640      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dropout_190 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_208 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_191 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_209 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_192 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_210 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_193 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_211 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_194 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_212 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_195 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_213 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_196 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_214 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_197 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_215 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 55.0241 - mae: 3.9570 - val_loss: 0.0356 - val_mae: 0.1874\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 5.2114 - mae: 1.6906 - val_loss: 0.0177 - val_mae: 0.1309\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.7108 - mae: 1.1942 - val_loss: 0.0069 - val_mae: 0.0804\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4925 - mae: 0.9492 - val_loss: 0.0011 - val_mae: 0.0303\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.5481 - mae: 0.9182 - val_loss: 0.0019 - val_mae: 0.0337\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1335 - mae: 0.6794 - val_loss: 0.0089 - val_mae: 0.0913\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.4331 - mae: 0.6842 - val_loss: 0.0035 - val_mae: 0.0548\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7840 - mae: 0.6140 - val_loss: 0.0026 - val_mae: 0.0459\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8214 - mae: 0.6843 - val_loss: 0.0048 - val_mae: 0.0651\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5782 - mae: 0.5506 - val_loss: 0.0051 - val_mae: 0.0678\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4831 - mae: 0.4560 - val_loss: 0.0048 - val_mae: 0.0655\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6775 - mae: 0.5960 - val_loss: 0.0052 - val_mae: 0.0688\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3902 - mae: 0.4286 - val_loss: 0.0060 - val_mae: 0.0740\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3122 - mae: 0.4215 - val_loss: 0.0056 - val_mae: 0.0719\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4107 - mae: 0.4788 - val_loss: 0.0050 - val_mae: 0.0672\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2101 - mae: 0.3631 - val_loss: 0.0050 - val_mae: 0.0674\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2788 - mae: 0.3274 - val_loss: 0.0057 - val_mae: 0.0726\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5126 - mae: 0.4126 - val_loss: 0.0053 - val_mae: 0.0694\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1547 - mae: 0.2974 - val_loss: 0.0053 - val_mae: 0.0697\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1780 - mae: 0.3078 - val_loss: 0.0052 - val_mae: 0.0691\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2582 - mae: 0.3502 - val_loss: 0.0059 - val_mae: 0.0739\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0924 - mae: 0.2285 - val_loss: 0.0054 - val_mae: 0.0703\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3500 - mae: 0.3819 - val_loss: 0.0049 - val_mae: 0.0665\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1348 - mae: 0.2507 - val_loss: 0.0046 - val_mae: 0.0642\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1733 - mae: 0.2901 - val_loss: 0.0052 - val_mae: 0.0685\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1417 - mae: 0.2671 - val_loss: 0.0043 - val_mae: 0.0619\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1424 - mae: 0.2528 - val_loss: 0.0041 - val_mae: 0.0602\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1588 - mae: 0.2281 - val_loss: 0.0038 - val_mae: 0.0573\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1644 - mae: 0.2566 - val_loss: 0.0026 - val_mae: 0.0459\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0741 - mae: 0.2000 - val_loss: 0.0027 - val_mae: 0.0467\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0940 - mae: 0.2119 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0945 - mae: 0.2196 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0993 - mae: 0.2031 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0980 - mae: 0.2082 - val_loss: 0.0031 - val_mae: 0.0510\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0844 - mae: 0.1837 - val_loss: 0.0030 - val_mae: 0.0501\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1010 - mae: 0.1689 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1022 - mae: 0.2133 - val_loss: 0.0022 - val_mae: 0.0411\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0416 - mae: 0.1595 - val_loss: 0.0020 - val_mae: 0.0392\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0859 - mae: 0.1992 - val_loss: 0.0021 - val_mae: 0.0402\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0658 - mae: 0.1720 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0612 - mae: 0.1620 - val_loss: 0.0020 - val_mae: 0.0384\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1092 - mae: 0.2009 - val_loss: 0.0019 - val_mae: 0.0373\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0770 - mae: 0.1676 - val_loss: 0.0022 - val_mae: 0.0418\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0812 - mae: 0.1810 - val_loss: 0.0026 - val_mae: 0.0458\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0502 - mae: 0.1529 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0756 - mae: 0.1712 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0460 - mae: 0.1435 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0807 - mae: 0.1841 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0350 - mae: 0.1284 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0561 - mae: 0.1369 - val_loss: 0.0023 - val_mae: 0.0425\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0322 - mae: 0.1213 - val_loss: 0.0022 - val_mae: 0.0420\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0285 - mae: 0.1194 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0622 - mae: 0.1482 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0492 - mae: 0.1359 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0412 - mae: 0.1310 - val_loss: 0.0018 - val_mae: 0.0364\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0369 - mae: 0.1311 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0331 - mae: 0.1204 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0199 - mae: 0.0941 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1081 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0281 - mae: 0.1132 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0520 - mae: 0.1494 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0311 - mae: 0.1176 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0268 - mae: 0.1123 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0319 - mae: 0.1136 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0267 - mae: 0.1080 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0307 - mae: 0.1108 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0866 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 0.1034 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.0968 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0195 - mae: 0.0927 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0913 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.0915 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0270 - mae: 0.0959 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0831 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0309 - mae: 0.1000 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.0916 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0234 - mae: 0.0957 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0156 - mae: 0.0810 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0183 - mae: 0.0838 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0091 - mae: 0.0598 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0749 - val_loss: 0.0018 - val_mae: 0.0364\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.0750 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0233 - mae: 0.0931 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0233 - mae: 0.0852 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0739 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0242 - mae: 0.0946 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.0809 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.0704 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0788 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0782 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0171 - mae: 0.0829 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0660 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0186 - mae: 0.0784 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0780 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0588 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0786 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.0799 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0581 - val_loss: 9.7588e-04 - val_mae: 0.0242\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0270 - mae: 0.0808 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0464 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0521 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0158 - mae: 0.0742 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.0680 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0648 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.0728 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0151 - mae: 0.0698 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0638 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0678 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0739 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0680 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0583 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0539 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0546 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0616 - val_loss: 9.7500e-04 - val_mae: 0.0242\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0628 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.0662 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0592 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0608 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0657 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0608 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0576 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0465 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0540 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0445 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0462 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0457 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0553 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0566 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0484 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0571 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0466 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0515 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0495 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0477 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0578 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0494 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0493 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0447 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0417 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0453 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0377 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0392 - val_loss: 9.9940e-04 - val_mae: 0.0247\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0468 - val_loss: 9.8035e-04 - val_mae: 0.0243\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0494 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0518 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0454 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0438 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0481 - val_loss: 9.9866e-04 - val_mae: 0.0246\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0476 - val_loss: 9.8492e-04 - val_mae: 0.0244\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0349 - val_loss: 9.7301e-04 - val_mae: 0.0242\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0413 - val_loss: 9.8277e-04 - val_mae: 0.0244\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0426 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0423 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0421 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0351 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0377 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0380 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0374 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0378 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0478 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0414 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0397 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0377 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0384 - val_loss: 9.9917e-04 - val_mae: 0.0247\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0367 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0341 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0381 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0443 - val_loss: 9.9306e-04 - val_mae: 0.0245\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0433 - val_loss: 9.4328e-04 - val_mae: 0.0237\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0415 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0392 - val_loss: 9.8732e-04 - val_mae: 0.0244\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0418 - val_loss: 9.7060e-04 - val_mae: 0.0241\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0351 - val_loss: 9.2294e-04 - val_mae: 0.0233\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0379 - val_loss: 9.1855e-04 - val_mae: 0.0232\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0336 - val_loss: 9.1652e-04 - val_mae: 0.0232\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0423 - val_loss: 9.4098e-04 - val_mae: 0.0236\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0361 - val_loss: 9.9997e-04 - val_mae: 0.0247\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0342 - val_loss: 9.3331e-04 - val_mae: 0.0235\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0350 - val_loss: 8.8321e-04 - val_mae: 0.0225\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0387 - val_loss: 9.1352e-04 - val_mae: 0.0231\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0348 - val_loss: 9.6057e-04 - val_mae: 0.0240\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0351 - val_loss: 9.9656e-04 - val_mae: 0.0246\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0397 - val_loss: 9.5068e-04 - val_mae: 0.0238\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0323 - val_loss: 9.3263e-04 - val_mae: 0.0234\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0324 - val_loss: 8.6375e-04 - val_mae: 0.0221\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0340 - val_loss: 9.0678e-04 - val_mae: 0.0230\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 9.4430e-04 - val_mae: 0.0237\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0321 - val_loss: 9.5106e-04 - val_mae: 0.0238\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0372 - val_loss: 8.9230e-04 - val_mae: 0.0227\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0365 - val_loss: 8.8015e-04 - val_mae: 0.0224\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0354 - val_loss: 9.4844e-04 - val_mae: 0.0237\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0399 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0383 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0294 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0366 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0286 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0328 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0334 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0286 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0304 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.0502 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0363 - val_loss: 9.8465e-04 - val_mae: 0.0244\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 9.5510e-04 - val_mae: 0.0239\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0389 - val_loss: 9.5406e-04 - val_mae: 0.0239\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0028 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0304 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.9204e-04 - val_mae: 0.0245\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0336 - val_loss: 9.1968e-04 - val_mae: 0.0232\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 9.1600e-04 - val_mae: 0.0232\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0339 - val_loss: 9.0540e-04 - val_mae: 0.0230\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0339 - val_loss: 9.7986e-04 - val_mae: 0.0243\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0273 - val_loss: 9.7652e-04 - val_mae: 0.0243\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0289 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0311 - val_loss: 9.8299e-04 - val_mae: 0.0244\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0356 - val_loss: 9.1516e-04 - val_mae: 0.0232\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0316 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0294 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0306 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0321 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0267 - val_loss: 9.9045e-04 - val_mae: 0.0245\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0352 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0332 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0313 - val_loss: 9.9874e-04 - val_mae: 0.0246\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0310 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0315 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0349 - val_loss: 9.3294e-04 - val_mae: 0.0235\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0269 - val_loss: 8.5692e-04 - val_mae: 0.0220\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 8.2823e-04 - val_mae: 0.0214\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0287 - val_loss: 8.7542e-04 - val_mae: 0.0224\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.3357e-04 - val_mae: 0.0235\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0301 - val_loss: 9.1277e-04 - val_mae: 0.0231\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 9.5860e-04 - val_mae: 0.0239\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0299 - val_loss: 8.1167e-04 - val_mae: 0.0210\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0255 - val_loss: 8.3686e-04 - val_mae: 0.0216\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 8.5061e-04 - val_mae: 0.0219\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 8.5662e-04 - val_mae: 0.0220\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0038 - mae: 0.0241 - val_loss: 8.9675e-04 - val_mae: 0.0228\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0286 - val_loss: 9.3296e-04 - val_mae: 0.0235\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0290 - val_loss: 9.1634e-04 - val_mae: 0.0232\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0325 - val_loss: 8.8735e-04 - val_mae: 0.0226\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0315 - val_loss: 8.9187e-04 - val_mae: 0.0227\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.7300e-04 - val_mae: 0.0223\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0275 - val_loss: 8.8871e-04 - val_mae: 0.0226\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 8.5607e-04 - val_mae: 0.0220\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0270 - val_loss: 8.7210e-04 - val_mae: 0.0223\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0318 - val_loss: 9.3747e-04 - val_mae: 0.0235\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.7338e-04 - val_mae: 0.0242\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.8546e-04 - val_mae: 0.0244\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0283 - val_loss: 9.1887e-04 - val_mae: 0.0232\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0310 - val_loss: 9.4547e-04 - val_mae: 0.0237\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0261 - val_loss: 9.6073e-04 - val_mae: 0.0240\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0333 - val_loss: 9.4570e-04 - val_mae: 0.0237\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.7399e-04 - val_mae: 0.0242\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0050 - mae: 0.0297 - val_loss: 9.7725e-04 - val_mae: 0.0243\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0278 - val_loss: 9.9898e-04 - val_mae: 0.0247\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 9.9928e-04 - val_mae: 0.0247\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 9.2715e-04 - val_mae: 0.0234\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0258 - val_loss: 9.3160e-04 - val_mae: 0.0234\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0264 - val_loss: 8.8122e-04 - val_mae: 0.0225\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 8.7339e-04 - val_mae: 0.0223\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0029 - mae: 0.0272 - val_loss: 9.3573e-04 - val_mae: 0.0235\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0289 - val_loss: 9.5430e-04 - val_mae: 0.0239\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.6111e-04 - val_mae: 0.0240\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.1029e-04 - val_mae: 0.0230\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0261 - val_loss: 9.0691e-04 - val_mae: 0.0230\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.4549e-04 - val_mae: 0.0237\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0233 - val_loss: 9.3081e-04 - val_mae: 0.0234\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.6514e-04 - val_mae: 0.0240\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.0275e-04 - val_mae: 0.0229\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.1053e-04 - val_mae: 0.0230\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 8.8498e-04 - val_mae: 0.0225\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0281 - val_loss: 8.9450e-04 - val_mae: 0.0227\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.2575e-04 - val_mae: 0.0233\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.3199e-04 - val_mae: 0.0234\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 9.5398e-04 - val_mae: 0.0238\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0258 - val_loss: 9.1794e-04 - val_mae: 0.0232\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0285 - val_loss: 9.1942e-04 - val_mae: 0.0232\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 9.7170e-04 - val_mae: 0.0242\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.9859e-04 - val_mae: 0.0246\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0303 - val_loss: 9.9832e-04 - val_mae: 0.0246\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.4207e-04 - val_mae: 0.0236\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.7342e-04 - val_mae: 0.0242\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.5329e-04 - val_mae: 0.0238\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.6662e-04 - val_mae: 0.0241\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.9481e-04 - val_mae: 0.0246\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0296 - val_loss: 8.8128e-04 - val_mae: 0.0225\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.4269e-04 - val_mae: 0.0236\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 9.8030e-04 - val_mae: 0.0243\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0248 - val_loss: 9.9493e-04 - val_mae: 0.0246\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.9902e-04 - val_mae: 0.0246\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.8768e-04 - val_mae: 0.0244\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.8770e-04 - val_mae: 0.0244\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.9923e-04 - val_mae: 0.0246\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.9132e-04 - val_mae: 0.0245\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.7869e-04 - val_mae: 0.0243\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.8266e-04 - val_mae: 0.0244\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.4758e-04 - val_mae: 0.0237\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.9957e-04 - val_mae: 0.0247\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 9.7647e-04 - val_mae: 0.0242\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.3849e-04 - val_mae: 0.0236\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "Model: \"sequential_18\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_216 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_198 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dense_217 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_199 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_218 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_200 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_219 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_201 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_220 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_202 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_221 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_203 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_222 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_204 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_223 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_205 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_224 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_206 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_225 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_207 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_226 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_208 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_227 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 0.7922 - mae: 0.6926 - val_loss: 0.0051 - val_mae: 0.0677\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6195 - mae: 0.5756 - val_loss: 0.0032 - val_mae: 0.0523\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3576 - mae: 0.3832 - val_loss: 0.0050 - val_mae: 0.0671\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1459 - mae: 0.2818 - val_loss: 0.0038 - val_mae: 0.0574\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1382 - mae: 0.2698 - val_loss: 0.0099 - val_mae: 0.0969\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0799 - mae: 0.2053 - val_loss: 0.0105 - val_mae: 0.1004\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0595 - mae: 0.1722 - val_loss: 0.0084 - val_mae: 0.0894\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0515 - mae: 0.1701 - val_loss: 0.0073 - val_mae: 0.0826\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0552 - mae: 0.1718 - val_loss: 0.0056 - val_mae: 0.0718\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0451 - mae: 0.1528 - val_loss: 0.0047 - val_mae: 0.0652\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0351 - mae: 0.1238 - val_loss: 0.0048 - val_mae: 0.0659\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0410 - mae: 0.1344 - val_loss: 0.0051 - val_mae: 0.0676\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0435 - mae: 0.1347 - val_loss: 0.0045 - val_mae: 0.0636\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0327 - mae: 0.1241 - val_loss: 0.0042 - val_mae: 0.0609\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0183 - mae: 0.0909 - val_loss: 0.0037 - val_mae: 0.0563\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0954 - val_loss: 0.0031 - val_mae: 0.0509\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0252 - mae: 0.1094 - val_loss: 0.0025 - val_mae: 0.0449\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0214 - mae: 0.0945 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0139 - mae: 0.0858 - val_loss: 0.0024 - val_mae: 0.0445\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.0895 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0802 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.0910 - val_loss: 0.0022 - val_mae: 0.0420\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0202 - mae: 0.0855 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0687 - val_loss: 0.0021 - val_mae: 0.0400\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0735 - val_loss: 0.0019 - val_mae: 0.0384\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0592 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0722 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0625 - val_loss: 0.0019 - val_mae: 0.0381\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0421 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0663 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0491 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0582 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0527 - val_loss: 0.0022 - val_mae: 0.0412\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0633 - val_loss: 0.0022 - val_mae: 0.0414\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0538 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0483 - val_loss: 0.0020 - val_mae: 0.0397\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0442 - val_loss: 0.0019 - val_mae: 0.0373\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0485 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0612 - val_loss: 0.0017 - val_mae: 0.0346\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0576 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0542 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0417 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0422 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0482 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0375 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0408 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0465 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - mae: 0.0447 - val_loss: 0.0016 - val_mae: 0.0339\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0418 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0389 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0405 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0379 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0419 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - mae: 0.0491 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0350 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0437 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0347 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0370 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0378 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0350 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0417 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0357 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0370 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0465 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0341 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0363 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0343 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0378 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0365 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0384 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0278 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0357 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0367 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0325 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0266 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0374 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0316 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 9.9672e-04 - val_mae: 0.0246\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0293 - val_loss: 9.7794e-04 - val_mae: 0.0243\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0304 - val_loss: 9.6806e-04 - val_mae: 0.0241\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0294 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0288 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0306 - val_loss: 9.8999e-04 - val_mae: 0.0245\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 9.5813e-04 - val_mae: 0.0239\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0300 - val_loss: 9.4292e-04 - val_mae: 0.0236\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0277 - val_loss: 9.1060e-04 - val_mae: 0.0230\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0272 - val_loss: 9.1345e-04 - val_mae: 0.0231\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0304 - val_loss: 9.0160e-04 - val_mae: 0.0229\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.2745e-04 - val_mae: 0.0233\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.0751e-04 - val_mae: 0.0230\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0281 - val_loss: 8.9100e-04 - val_mae: 0.0226\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 8.5285e-04 - val_mae: 0.0219\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0346 - val_loss: 6.3013e-04 - val_mae: 0.0164\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0348 - val_loss: 7.1038e-04 - val_mae: 0.0186\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0267 - val_loss: 7.8914e-04 - val_mae: 0.0205\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0318 - val_loss: 8.4765e-04 - val_mae: 0.0218\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 8.3604e-04 - val_mae: 0.0215\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0279 - val_loss: 8.1580e-04 - val_mae: 0.0211\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0286 - val_loss: 8.5004e-04 - val_mae: 0.0218\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0272 - val_loss: 8.7252e-04 - val_mae: 0.0223\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 8.4038e-04 - val_mae: 0.0216\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 8.5859e-04 - val_mae: 0.0220\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0265 - val_loss: 8.6722e-04 - val_mae: 0.0222\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0266 - val_loss: 8.9061e-04 - val_mae: 0.0226\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0293 - val_loss: 7.4906e-04 - val_mae: 0.0196\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 7.5246e-04 - val_mae: 0.0197\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0284 - val_loss: 7.5221e-04 - val_mae: 0.0197\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 7.7907e-04 - val_mae: 0.0203\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0319 - val_loss: 6.1098e-04 - val_mae: 0.0161\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 6.5232e-04 - val_mae: 0.0170\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0326 - val_loss: 6.7390e-04 - val_mae: 0.0176\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 6.8550e-04 - val_mae: 0.0179\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 7.1596e-04 - val_mae: 0.0188\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0298 - val_loss: 7.2096e-04 - val_mae: 0.0189\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0273 - val_loss: 7.6029e-04 - val_mae: 0.0198\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.1961e-04 - val_mae: 0.0212\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 8.9646e-04 - val_mae: 0.0228\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 8.4272e-04 - val_mae: 0.0217\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0272 - val_loss: 8.0623e-04 - val_mae: 0.0209\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 8.1488e-04 - val_mae: 0.0211\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 7.5932e-04 - val_mae: 0.0198\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 7.8240e-04 - val_mae: 0.0204\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.2807e-04 - val_mae: 0.0214\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 7.9910e-04 - val_mae: 0.0207\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 8.1515e-04 - val_mae: 0.0211\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.7219e-04 - val_mae: 0.0223\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 8.2990e-04 - val_mae: 0.0214\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 8.2755e-04 - val_mae: 0.0214\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 8.3077e-04 - val_mae: 0.0214\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 8.2990e-04 - val_mae: 0.0214\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.7360e-04 - val_mae: 0.0223\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 8.6126e-04 - val_mae: 0.0221\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 8.4960e-04 - val_mae: 0.0218\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.9474e-04 - val_mae: 0.0227\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0254 - val_loss: 8.5112e-04 - val_mae: 0.0218\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 8.7430e-04 - val_mae: 0.0223\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 8.6615e-04 - val_mae: 0.0222\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 8.5371e-04 - val_mae: 0.0219\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0280 - val_loss: 8.9163e-04 - val_mae: 0.0227\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.1030e-04 - val_mae: 0.0230\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0254 - val_loss: 9.2904e-04 - val_mae: 0.0234\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 8.8751e-04 - val_mae: 0.0226\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.4233e-04 - val_mae: 0.0236\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.0337e-04 - val_mae: 0.0229\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.1001e-04 - val_mae: 0.0230\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.2403e-04 - val_mae: 0.0233\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0231 - val_loss: 8.6791e-04 - val_mae: 0.0222\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 8.5130e-04 - val_mae: 0.0219\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.2556e-04 - val_mae: 0.0213\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.6903e-04 - val_mae: 0.0222\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.4280e-04 - val_mae: 0.0236\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.2719e-04 - val_mae: 0.0233\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.0049e-04 - val_mae: 0.0228\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.7222e-04 - val_mae: 0.0223\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0229 - val_loss: 9.2126e-04 - val_mae: 0.0232\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 8.7408e-04 - val_mae: 0.0223\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.2131e-04 - val_mae: 0.0232\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.7435e-04 - val_mae: 0.0223\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 8.2958e-04 - val_mae: 0.0214\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.4680e-04 - val_mae: 0.0218\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.8226e-04 - val_mae: 0.0225\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 8.5684e-04 - val_mae: 0.0220\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 8.6669e-04 - val_mae: 0.0222\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.7644e-04 - val_mae: 0.0224\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.7701e-04 - val_mae: 0.0224\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 8.8015e-04 - val_mae: 0.0224\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 8.8694e-04 - val_mae: 0.0226\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0238 - val_loss: 8.7280e-04 - val_mae: 0.0223\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.5455e-04 - val_mae: 0.0219\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 8.8974e-04 - val_mae: 0.0226\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.2413e-04 - val_mae: 0.0233\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.3071e-04 - val_mae: 0.0234\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.6043e-04 - val_mae: 0.0240\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.2696e-04 - val_mae: 0.0233\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.7596e-04 - val_mae: 0.0224\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.9920e-04 - val_mae: 0.0228\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.1666e-04 - val_mae: 0.0231\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.1496e-04 - val_mae: 0.0231\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.9405e-04 - val_mae: 0.0227\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 8.9687e-04 - val_mae: 0.0228\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.9789e-04 - val_mae: 0.0228\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.6211e-04 - val_mae: 0.0221\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.7118e-04 - val_mae: 0.0223\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0247 - val_loss: 8.5045e-04 - val_mae: 0.0218\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.2162e-04 - val_mae: 0.0232\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 8.9674e-04 - val_mae: 0.0228\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.3424e-04 - val_mae: 0.0235\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.8735e-04 - val_mae: 0.0244\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0222 - val_loss: 9.3432e-04 - val_mae: 0.0235\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.1101e-04 - val_mae: 0.0230\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.3843e-04 - val_mae: 0.0236\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.0482e-04 - val_mae: 0.0229\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2574e-04 - val_mae: 0.0233\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.4589e-04 - val_mae: 0.0237\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 8.7382e-04 - val_mae: 0.0223\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.7805e-04 - val_mae: 0.0224\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 8.9362e-04 - val_mae: 0.0227\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 8.8571e-04 - val_mae: 0.0225\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.4569e-04 - val_mae: 0.0237\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.7932e-04 - val_mae: 0.0224\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.6226e-04 - val_mae: 0.0240\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0222 - val_loss: 8.8992e-04 - val_mae: 0.0226\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.7887e-04 - val_mae: 0.0224\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0535e-04 - val_mae: 0.0229\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.3167e-04 - val_mae: 0.0234\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0232 - val_loss: 8.8809e-04 - val_mae: 0.0226\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0228 - val_loss: 8.9651e-04 - val_mae: 0.0228\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0378e-04 - val_mae: 0.0229\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.1764e-04 - val_mae: 0.0232\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.4570e-04 - val_mae: 0.0237\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.7170e-04 - val_mae: 0.0242\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.9286e-04 - val_mae: 0.0227\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.3498e-04 - val_mae: 0.0235\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.2971e-04 - val_mae: 0.0234\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.3322e-04 - val_mae: 0.0235\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.0864e-04 - val_mae: 0.0230\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 8.8618e-04 - val_mae: 0.0226\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0257 - val_loss: 8.5265e-04 - val_mae: 0.0219\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.5120e-04 - val_mae: 0.0238\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.1594e-04 - val_mae: 0.0231\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 6.1054e-04 - val_mae: 0.0161\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 6.7380e-04 - val_mae: 0.0176\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 7.4739e-04 - val_mae: 0.0195\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 8.2723e-04 - val_mae: 0.0213\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.4433e-04 - val_mae: 0.0237\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.1517e-04 - val_mae: 0.0231\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 8.8203e-04 - val_mae: 0.0225\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.1437e-04 - val_mae: 0.0231\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 8.9876e-04 - val_mae: 0.0228\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.9068e-04 - val_mae: 0.0226\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.8222e-04 - val_mae: 0.0225\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.7005e-04 - val_mae: 0.0241\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0224 - val_loss: 9.7784e-04 - val_mae: 0.0243\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.2909e-04 - val_mae: 0.0234\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.1530e-04 - val_mae: 0.0231\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.7676e-04 - val_mae: 0.0242\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 8.8138e-04 - val_mae: 0.0225\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 7.6067e-04 - val_mae: 0.0199\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 8.2041e-04 - val_mae: 0.0212\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.7713e-04 - val_mae: 0.0224\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.1100e-04 - val_mae: 0.0230\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0225 - val_loss: 8.8989e-04 - val_mae: 0.0226\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.3450e-04 - val_mae: 0.0235\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0048 - mae: 0.0240 - val_loss: 9.0793e-04 - val_mae: 0.0230\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.1074e-04 - val_mae: 0.0230\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0233 - val_loss: 8.6026e-04 - val_mae: 0.0220\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.1139e-04 - val_mae: 0.0230\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.0570e-04 - val_mae: 0.0229\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 8.7711e-04 - val_mae: 0.0224\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.5414e-04 - val_mae: 0.0219\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.1803e-04 - val_mae: 0.0232\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.2824e-04 - val_mae: 0.0234\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0225 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.2536e-04 - val_mae: 0.0233\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.3446e-04 - val_mae: 0.0235\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 8.7369e-04 - val_mae: 0.0223\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.6242e-04 - val_mae: 0.0221\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0224 - val_loss: 9.5178e-04 - val_mae: 0.0238\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.0979e-04 - val_mae: 0.0230\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.5669e-04 - val_mae: 0.0220\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 8.9650e-04 - val_mae: 0.0228\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.0388e-04 - val_mae: 0.0229\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.5293e-04 - val_mae: 0.0238\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.7987e-04 - val_mae: 0.0243\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 8.6365e-04 - val_mae: 0.0221\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.9971e-04 - val_mae: 0.0228\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.9838e-04 - val_mae: 0.0228\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.2351e-04 - val_mae: 0.0233\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 6.3547e-04 - val_mae: 0.0165\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0271 - val_loss: 7.0392e-04 - val_mae: 0.0184\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 7.4435e-04 - val_mae: 0.0195\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 8.6326e-04 - val_mae: 0.0221\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.4273e-04 - val_mae: 0.0217\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.0641e-04 - val_mae: 0.0229\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.0808e-04 - val_mae: 0.0230\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.4094e-04 - val_mae: 0.0236\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.4588e-04 - val_mae: 0.0237\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.0101e-04 - val_mae: 0.0228\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.4801e-04 - val_mae: 0.0237\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.1685e-04 - val_mae: 0.0231\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.6430e-04 - val_mae: 0.0240\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0229 - val_loss: 9.1163e-04 - val_mae: 0.0230\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.6045e-04 - val_mae: 0.0240\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0224 - val_loss: 9.3359e-04 - val_mae: 0.0235\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.8518e-04 - val_mae: 0.0225\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.3449e-04 - val_mae: 0.0235\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.9769e-04 - val_mae: 0.0246\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 8.9877e-04 - val_mae: 0.0228\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0426e-04 - val_mae: 0.0229\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.6013e-04 - val_mae: 0.0239\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 9.8790e-04 - val_mae: 0.0244\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0265 - val_loss: 6.4861e-04 - val_mae: 0.0169\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0273 - val_loss: 6.8443e-04 - val_mae: 0.0179\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 7.6201e-04 - val_mae: 0.0199\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.4191e-04 - val_mae: 0.0217\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.1281e-04 - val_mae: 0.0231\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 9.9230e-04 - val_mae: 0.0245\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.4074e-04 - val_mae: 0.0236\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 9.4389e-04 - val_mae: 0.0237\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 8.8054e-04 - val_mae: 0.0224\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 8.5248e-04 - val_mae: 0.0219\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.7409e-04 - val_mae: 0.0223\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.0877e-04 - val_mae: 0.0230\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.2559e-04 - val_mae: 0.0233\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.6598e-04 - val_mae: 0.0241\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 8.9682e-04 - val_mae: 0.0228\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.2422e-04 - val_mae: 0.0233\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.3219e-04 - val_mae: 0.0234\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 8.7818e-04 - val_mae: 0.0224\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.2476e-04 - val_mae: 0.0233\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 8.7193e-04 - val_mae: 0.0223\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.8813e-04 - val_mae: 0.0226\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.5560e-04 - val_mae: 0.0239\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 6.1917e-04 - val_mae: 0.0162\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 6.9831e-04 - val_mae: 0.0183\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 7.5782e-04 - val_mae: 0.0198\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.0277e-04 - val_mae: 0.0208\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 8.2388e-04 - val_mae: 0.0213\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.7550e-04 - val_mae: 0.0223\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.6712e-04 - val_mae: 0.0222\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 8.6248e-04 - val_mae: 0.0221\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0231 - val_loss: 9.0187e-04 - val_mae: 0.0229\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 8.9943e-04 - val_mae: 0.0228\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 9.1694e-04 - val_mae: 0.0231\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.1167e-04 - val_mae: 0.0230\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.9491e-04 - val_mae: 0.0227\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.7712e-04 - val_mae: 0.0224\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 9.1537e-04 - val_mae: 0.0231\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.6248e-04 - val_mae: 0.0221\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.6139e-04 - val_mae: 0.0221\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.9441e-04 - val_mae: 0.0227\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 8.5302e-04 - val_mae: 0.0219\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0235 - val_loss: 8.4033e-04 - val_mae: 0.0216\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.6356e-04 - val_mae: 0.0221\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 8.6673e-04 - val_mae: 0.0222\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 8.5024e-04 - val_mae: 0.0218\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0273 - val_loss: 5.9553e-04 - val_mae: 0.0158\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0279 - val_loss: 6.6945e-04 - val_mae: 0.0175\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 7.3778e-04 - val_mae: 0.0193\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 8.3780e-04 - val_mae: 0.0216\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_19\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_228 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_209 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_229 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_210 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_230 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_211 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_231 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_212 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_232 (Dense)           (None, 40)                1640      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dropout_213 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_233 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_214 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_234 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_215 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_235 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_216 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_236 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_217 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_237 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_218 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_238 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_219 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_239 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 19ms/step - loss: 0.2950 - mae: 0.4579 - val_loss: 0.0393 - val_mae: 0.1971\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1608 - mae: 0.3198 - val_loss: 0.0027 - val_mae: 0.0477\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1443 - mae: 0.3108 - val_loss: 9.8901e-04 - val_mae: 0.0245\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0945 - mae: 0.2366 - val_loss: 0.0034 - val_mae: 0.0537\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1153 - mae: 0.2675 - val_loss: 0.0093 - val_mae: 0.0939\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1068 - mae: 0.2613 - val_loss: 0.0013 - val_mae: 0.0343\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1003 - mae: 0.2576 - val_loss: 0.0012 - val_mae: 0.0334\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0822 - mae: 0.2236 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0899 - mae: 0.2326 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0684 - mae: 0.2133 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0770 - mae: 0.2287 - val_loss: 0.0063 - val_mae: 0.0762\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0694 - mae: 0.2132 - val_loss: 0.0099 - val_mae: 0.0972\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0593 - mae: 0.1944 - val_loss: 0.0075 - val_mae: 0.0840\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0531 - mae: 0.1836 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0423 - mae: 0.1574 - val_loss: 0.0024 - val_mae: 0.0465\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0454 - mae: 0.1765 - val_loss: 0.0032 - val_mae: 0.0519\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0531 - mae: 0.1786 - val_loss: 0.0061 - val_mae: 0.0749\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0583 - mae: 0.1977 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0299 - mae: 0.1386 - val_loss: 5.0978e-04 - val_mae: 0.0146\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0283 - mae: 0.1304 - val_loss: 0.0037 - val_mae: 0.0567\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0281 - mae: 0.1269 - val_loss: 5.6149e-04 - val_mae: 0.0188\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0255 - mae: 0.1294 - val_loss: 0.0042 - val_mae: 0.0609\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.1299 - val_loss: 6.7519e-04 - val_mae: 0.0177\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0265 - mae: 0.1217 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.1216 - val_loss: 5.0456e-04 - val_mae: 0.0146\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0245 - mae: 0.1161 - val_loss: 0.0030 - val_mae: 0.0506\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1204 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.1109 - val_loss: 0.0030 - val_mae: 0.0502\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0196 - mae: 0.1120 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0266 - mae: 0.1284 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0223 - mae: 0.1125 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0235 - mae: 0.1165 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0872 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0190 - mae: 0.0936 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0966 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - mae: 0.0933 - val_loss: 0.0037 - val_mae: 0.0568\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0977 - val_loss: 6.1489e-04 - val_mae: 0.0162\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0913 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0742 - val_loss: 8.5267e-04 - val_mae: 0.0219\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0771 - val_loss: 4.8848e-04 - val_mae: 0.0146\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0727 - val_loss: 7.0760e-04 - val_mae: 0.0185\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0136 - mae: 0.0863 - val_loss: 7.8926e-04 - val_mae: 0.0205\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0143 - mae: 0.0846 - val_loss: 0.0018 - val_mae: 0.0370\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0833 - val_loss: 5.4283e-04 - val_mae: 0.0151\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0824 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0659 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0698 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0707 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0731 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0694 - val_loss: 0.0029 - val_mae: 0.0497\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0626 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0624 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0658 - val_loss: 0.0020 - val_mae: 0.0394\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0692 - val_loss: 7.0403e-04 - val_mae: 0.0184\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0616 - val_loss: 7.4244e-04 - val_mae: 0.0194\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0637 - val_loss: 0.0016 - val_mae: 0.0340\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.0679 - val_loss: 0.0021 - val_mae: 0.0403\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0608 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0612 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.0642 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0628 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0531 - val_loss: 7.1362e-04 - val_mae: 0.0187\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0560 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0554 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0529 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0552 - val_loss: 9.4212e-04 - val_mae: 0.0236\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0587 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0493 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - mae: 0.0434 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0564 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0470 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0485 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0537 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0482 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0419 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0466 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0503 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0504 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0519 - val_loss: 7.2622e-04 - val_mae: 0.0190\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - mae: 0.0496 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0388 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0446 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0523 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0420 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0465 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0420 - val_loss: 9.5057e-04 - val_mae: 0.0238\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0416 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0400 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0395 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0432 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0402 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0428 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0437 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0423 - val_loss: 8.6408e-04 - val_mae: 0.0221\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0364 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0371 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0368 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0378 - val_loss: 8.3717e-04 - val_mae: 0.0216\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0393 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0408 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0399 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0383 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0389 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0389 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0368 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0401 - val_loss: 9.8773e-04 - val_mae: 0.0244\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0361 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0383 - val_loss: 7.1036e-04 - val_mae: 0.0186\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0374 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0389 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0380 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0369 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0327 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0391 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0351 - val_loss: 8.0942e-04 - val_mae: 0.0210\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0422 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0333 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0354 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0360 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0336 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0349 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0344 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0364 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0363 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0366 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0323 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0336 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0324 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0316 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0324 - val_loss: 8.3251e-04 - val_mae: 0.0215\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0306 - val_loss: 8.9198e-04 - val_mae: 0.0227\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0335 - val_loss: 8.8083e-04 - val_mae: 0.0224\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0329 - val_loss: 9.5750e-04 - val_mae: 0.0239\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0348 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 8.4346e-04 - val_mae: 0.0217\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0385 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0315 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0305 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0325 - val_loss: 8.8833e-04 - val_mae: 0.0226\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0318 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0354 - val_loss: 8.6770e-04 - val_mae: 0.0222\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0328 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0294 - val_loss: 9.7029e-04 - val_mae: 0.0241\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0366 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0376 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0306 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0348 - val_loss: 8.4636e-04 - val_mae: 0.0217\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0328 - val_loss: 9.4231e-04 - val_mae: 0.0236\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0299 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0274 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0344 - val_loss: 9.3342e-04 - val_mae: 0.0235\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0313 - val_loss: 9.6480e-04 - val_mae: 0.0240\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.9290e-04 - val_mae: 0.0245\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 9.8992e-04 - val_mae: 0.0245\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 7.5873e-04 - val_mae: 0.0198\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0296 - val_loss: 8.5699e-04 - val_mae: 0.0220\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0285 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 7.6787e-04 - val_mae: 0.0200\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0291 - val_loss: 9.7641e-04 - val_mae: 0.0242\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0292 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0267 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0300 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0263 - val_loss: 9.6124e-04 - val_mae: 0.0240\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0280 - val_loss: 8.6121e-04 - val_mae: 0.0221\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 9.8754e-04 - val_mae: 0.0244\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0324 - val_loss: 8.0653e-04 - val_mae: 0.0209\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.4394e-04 - val_mae: 0.0237\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0283 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 9.1775e-04 - val_mae: 0.0232\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0263 - val_loss: 9.4731e-04 - val_mae: 0.0237\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.5350e-04 - val_mae: 0.0238\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 8.6534e-04 - val_mae: 0.0221\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0283 - val_loss: 9.1476e-04 - val_mae: 0.0231\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.2868e-04 - val_mae: 0.0234\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 9.4619e-04 - val_mae: 0.0237\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.8143e-04 - val_mae: 0.0225\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0326 - val_loss: 9.2784e-04 - val_mae: 0.0234\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.5437e-04 - val_mae: 0.0238\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.9124e-04 - val_mae: 0.0245\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0270 - val_loss: 9.0275e-04 - val_mae: 0.0229\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 8.8584e-04 - val_mae: 0.0225\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0297 - val_loss: 8.4051e-04 - val_mae: 0.0216\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 8.5539e-04 - val_mae: 0.0219\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0281 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.6907e-04 - val_mae: 0.0241\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 7.7238e-04 - val_mae: 0.0201\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 7.3689e-04 - val_mae: 0.0193\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0347 - val_loss: 4.7584e-04 - val_mae: 0.0146\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0361 - val_loss: 7.3581e-04 - val_mae: 0.0193\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0254 - val_loss: 9.5112e-04 - val_mae: 0.0238\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0289 - val_loss: 8.5396e-04 - val_mae: 0.0219\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0332 - val_loss: 5.9323e-04 - val_mae: 0.0158\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0305 - val_loss: 8.5293e-04 - val_mae: 0.0219\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.7595e-04 - val_mae: 0.0242\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0261 - val_loss: 9.6975e-04 - val_mae: 0.0241\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.1819e-04 - val_mae: 0.0212\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0288 - val_loss: 9.4896e-04 - val_mae: 0.0237\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.2985e-04 - val_mae: 0.0234\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 9.0915e-04 - val_mae: 0.0230\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0221 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.4835e-04 - val_mae: 0.0237\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0289 - val_loss: 9.5876e-04 - val_mae: 0.0239\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0241 - val_loss: 9.7448e-04 - val_mae: 0.0242\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0255 - val_loss: 9.4244e-04 - val_mae: 0.0236\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.9561e-04 - val_mae: 0.0246\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 7.9446e-04 - val_mae: 0.0206\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 8.5096e-04 - val_mae: 0.0218\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.4680e-04 - val_mae: 0.0237\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.9144e-04 - val_mae: 0.0245\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.2159e-04 - val_mae: 0.0232\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 9.1356e-04 - val_mae: 0.0231\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0233 - val_loss: 9.7096e-04 - val_mae: 0.0241\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.5293e-04 - val_mae: 0.0238\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 7.3046e-04 - val_mae: 0.0191\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 9.3218e-04 - val_mae: 0.0234\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0255 - val_loss: 9.7495e-04 - val_mae: 0.0242\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0250 - val_loss: 9.4511e-04 - val_mae: 0.0237\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0253 - val_loss: 9.4790e-04 - val_mae: 0.0237\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.3705e-04 - val_mae: 0.0235\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0228 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 8.6472e-04 - val_mae: 0.0221\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 9.1775e-04 - val_mae: 0.0232\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0244 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 9.0665e-04 - val_mae: 0.0230\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0258 - val_loss: 9.0756e-04 - val_mae: 0.0230\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 9.5513e-04 - val_mae: 0.0239\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.2803e-04 - val_mae: 0.0234\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.1635e-04 - val_mae: 0.0231\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.6567e-04 - val_mae: 0.0241\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.9695e-04 - val_mae: 0.0228\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 8.4000e-04 - val_mae: 0.0216\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.4221e-04 - val_mae: 0.0236\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 9.5876e-04 - val_mae: 0.0239\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0525e-04 - val_mae: 0.0229\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.2941e-04 - val_mae: 0.0234\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 8.5585e-04 - val_mae: 0.0219\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 8.7319e-04 - val_mae: 0.0223\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 7.0288e-04 - val_mae: 0.0184\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 8.0653e-04 - val_mae: 0.0209\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 9.1122e-04 - val_mae: 0.0230\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.7610e-04 - val_mae: 0.0242\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 8.9371e-04 - val_mae: 0.0227\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.3322e-04 - val_mae: 0.0235\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.4729e-04 - val_mae: 0.0237\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0245 - val_loss: 8.8015e-04 - val_mae: 0.0224\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.4810e-04 - val_mae: 0.0237\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0224 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 7.3439e-04 - val_mae: 0.0192\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0242 - val_loss: 9.7852e-04 - val_mae: 0.0243\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 8.6100e-04 - val_mae: 0.0221\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.2918e-04 - val_mae: 0.0234\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.9457e-04 - val_mae: 0.0246\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 8.1724e-04 - val_mae: 0.0211\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.2046e-04 - val_mae: 0.0232\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 9.9304e-04 - val_mae: 0.0245\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0229 - val_loss: 9.2641e-04 - val_mae: 0.0233\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.3403e-04 - val_mae: 0.0215\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0976e-04 - val_mae: 0.0230\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.9127e-04 - val_mae: 0.0245\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.2095e-04 - val_mae: 0.0212\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.5248e-04 - val_mae: 0.0238\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 9.0581e-04 - val_mae: 0.0229\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0241 - val_loss: 9.0240e-04 - val_mae: 0.0229\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.0579e-04 - val_mae: 0.0229\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 9.1719e-04 - val_mae: 0.0232\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.0601e-04 - val_mae: 0.0229\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 8.4715e-04 - val_mae: 0.0218\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0240 - val_loss: 9.8634e-04 - val_mae: 0.0244\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.1946e-04 - val_mae: 0.0232\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 8.2055e-04 - val_mae: 0.0212\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.5831e-04 - val_mae: 0.0239\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0233 - val_loss: 9.3308e-04 - val_mae: 0.0235\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0252 - val_loss: 8.9065e-04 - val_mae: 0.0226\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0245 - val_loss: 9.3302e-04 - val_mae: 0.0235\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 8.7836e-04 - val_mae: 0.0224\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0239 - val_loss: 8.9619e-04 - val_mae: 0.0227\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 8.8983e-04 - val_mae: 0.0226\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0254 - val_loss: 9.0349e-04 - val_mae: 0.0229\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 8.5338e-04 - val_mae: 0.0219\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.9269e-04 - val_mae: 0.0245\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0214 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 8.6935e-04 - val_mae: 0.0222\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0225 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 8.5464e-04 - val_mae: 0.0219\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0250 - val_loss: 8.4914e-04 - val_mae: 0.0218\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.9743e-04 - val_mae: 0.0246\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0309 - val_loss: 5.1672e-04 - val_mae: 0.0147\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0307 - val_loss: 7.0244e-04 - val_mae: 0.0184\n",
            "3/3 [==============================] - 0s 5ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_20\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_240 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_220 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_241 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_221 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_242 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_222 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_243 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_223 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_244 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_224 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_245 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_225 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_246 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_226 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_247 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_227 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_248 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_228 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_249 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_229 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_250 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_230 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_251 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 0.1285 - mae: 0.2831 - val_loss: 4.7834e-04 - val_mae: 0.0149\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1545 - mae: 0.3136 - val_loss: 0.0011 - val_mae: 0.0316\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1185 - mae: 0.2680 - val_loss: 0.0026 - val_mae: 0.0463\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0911 - mae: 0.2436 - val_loss: 8.6271e-04 - val_mae: 0.0271\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0998 - mae: 0.2512 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0528 - mae: 0.1845 - val_loss: 0.0011 - val_mae: 0.0317\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1017 - mae: 0.2524 - val_loss: 0.0082 - val_mae: 0.0878\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0943 - mae: 0.2453 - val_loss: 4.7842e-04 - val_mae: 0.0149\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0509 - mae: 0.1760 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0573 - mae: 0.1839 - val_loss: 9.2289e-04 - val_mae: 0.0233\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0489 - mae: 0.1700 - val_loss: 0.0038 - val_mae: 0.0577\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0352 - mae: 0.1456 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0511 - mae: 0.1866 - val_loss: 4.8099e-04 - val_mae: 0.0150\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0333 - mae: 0.1443 - val_loss: 6.0381e-04 - val_mae: 0.0204\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 0.1633 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0408 - mae: 0.1631 - val_loss: 8.6447e-04 - val_mae: 0.0221\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0369 - mae: 0.1379 - val_loss: 5.2775e-04 - val_mae: 0.0172\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0336 - mae: 0.1538 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0241 - mae: 0.1137 - val_loss: 0.0020 - val_mae: 0.0388\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0254 - mae: 0.1139 - val_loss: 6.1112e-04 - val_mae: 0.0161\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - mae: 0.1171 - val_loss: 4.8841e-04 - val_mae: 0.0146\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0194 - mae: 0.1052 - val_loss: 0.0030 - val_mae: 0.0499\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.1078 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.1185 - val_loss: 4.7358e-04 - val_mae: 0.0146\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0957 - val_loss: 8.0612e-04 - val_mae: 0.0209\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.1022 - val_loss: 9.5285e-04 - val_mae: 0.0238\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0165 - mae: 0.0990 - val_loss: 5.0000e-04 - val_mae: 0.0146\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0818 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.1007 - val_loss: 6.6969e-04 - val_mae: 0.0175\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0812 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0162 - mae: 0.0959 - val_loss: 4.8842e-04 - val_mae: 0.0146\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0839 - val_loss: 4.8166e-04 - val_mae: 0.0151\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0832 - val_loss: 6.1875e-04 - val_mae: 0.0162\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0737 - val_loss: 9.6367e-04 - val_mae: 0.0240\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0873 - val_loss: 7.0721e-04 - val_mae: 0.0185\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.0827 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0754 - val_loss: 7.5177e-04 - val_mae: 0.0196\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0718 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0801 - val_loss: 6.2704e-04 - val_mae: 0.0164\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0713 - val_loss: 7.8946e-04 - val_mae: 0.0205\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0766 - val_loss: 5.5829e-04 - val_mae: 0.0153\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0660 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0668 - val_loss: 5.2751e-04 - val_mae: 0.0149\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0702 - val_loss: 7.2252e-04 - val_mae: 0.0189\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0547 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0524 - val_loss: 7.9885e-04 - val_mae: 0.0207\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0582 - val_loss: 8.1745e-04 - val_mae: 0.0211\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0556 - val_loss: 6.4951e-04 - val_mae: 0.0169\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0677 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0588 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0557 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0573 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0551 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0511 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0583 - val_loss: 6.1655e-04 - val_mae: 0.0162\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0561 - val_loss: 8.8168e-04 - val_mae: 0.0225\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0509 - val_loss: 9.3282e-04 - val_mae: 0.0234\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0567 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0515 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0467 - val_loss: 8.9376e-04 - val_mae: 0.0227\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0487 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0439 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0427 - val_loss: 9.1696e-04 - val_mae: 0.0231\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0479 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0498 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0437 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0389 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0409 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0535 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0404 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0420 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0402 - val_loss: 8.6641e-04 - val_mae: 0.0222\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0406 - val_loss: 9.6632e-04 - val_mae: 0.0241\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0419 - val_loss: 5.8972e-04 - val_mae: 0.0157\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0460 - val_loss: 9.0267e-04 - val_mae: 0.0229\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0366 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0550 - val_loss: 4.7476e-04 - val_mae: 0.0147\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0486 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0422 - val_loss: 9.5039e-04 - val_mae: 0.0238\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - mae: 0.0404 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0400 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0376 - val_loss: 8.7764e-04 - val_mae: 0.0224\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0390 - val_loss: 8.8687e-04 - val_mae: 0.0226\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0381 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0388 - val_loss: 9.3129e-04 - val_mae: 0.0234\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0388 - val_loss: 9.9399e-04 - val_mae: 0.0246\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0050 - mae: 0.0385 - val_loss: 8.4256e-04 - val_mae: 0.0217\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0400 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0377 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0359 - val_loss: 9.1797e-04 - val_mae: 0.0232\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0347 - val_loss: 9.7988e-04 - val_mae: 0.0243\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0329 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0392 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0349 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0356 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0047 - mae: 0.0348 - val_loss: 7.9903e-04 - val_mae: 0.0207\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0433 - val_loss: 4.7570e-04 - val_mae: 0.0146\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0327 - val_loss: 7.9107e-04 - val_mae: 0.0206\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0342 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0314 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0339 - val_loss: 9.2088e-04 - val_mae: 0.0232\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0355 - val_loss: 7.7433e-04 - val_mae: 0.0202\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0353 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0301 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0332 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0354 - val_loss: 8.0402e-04 - val_mae: 0.0208\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0389 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0355 - val_loss: 9.7262e-04 - val_mae: 0.0242\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0344 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0306 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0320 - val_loss: 9.2488e-04 - val_mae: 0.0233\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0302 - val_loss: 9.7476e-04 - val_mae: 0.0242\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0350 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0303 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0307 - val_loss: 8.7207e-04 - val_mae: 0.0223\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0318 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0332 - val_loss: 8.5914e-04 - val_mae: 0.0220\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0322 - val_loss: 9.9667e-04 - val_mae: 0.0246\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0269 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0318 - val_loss: 8.4713e-04 - val_mae: 0.0218\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0337 - val_loss: 8.6790e-04 - val_mae: 0.0222\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0306 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0304 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0269 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0306 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0287 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0298 - val_loss: 8.4671e-04 - val_mae: 0.0218\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0306 - val_loss: 9.5274e-04 - val_mae: 0.0238\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0281 - val_loss: 9.7416e-04 - val_mae: 0.0242\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0281 - val_loss: 8.9757e-04 - val_mae: 0.0228\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 9.3875e-04 - val_mae: 0.0236\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0300 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0323 - val_loss: 8.1037e-04 - val_mae: 0.0210\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0277 - val_loss: 9.9183e-04 - val_mae: 0.0245\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0300 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 9.8162e-04 - val_mae: 0.0243\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0302 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.5687e-04 - val_mae: 0.0239\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 9.8132e-04 - val_mae: 0.0243\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0303 - val_loss: 8.8902e-04 - val_mae: 0.0226\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0268 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0261 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0264 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0269 - val_loss: 9.2464e-04 - val_mae: 0.0233\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0317 - val_loss: 7.2316e-04 - val_mae: 0.0189\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0283 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0291 - val_loss: 9.7638e-04 - val_mae: 0.0242\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0273 - val_loss: 9.9042e-04 - val_mae: 0.0245\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0269 - val_loss: 8.3746e-04 - val_mae: 0.0216\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 8.2177e-04 - val_mae: 0.0212\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0277 - val_loss: 8.6984e-04 - val_mae: 0.0222\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0248 - val_loss: 9.6745e-04 - val_mae: 0.0241\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0261 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0248 - val_loss: 9.6374e-04 - val_mae: 0.0240\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.2449e-04 - val_mae: 0.0233\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.2436e-04 - val_mae: 0.0233\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0268 - val_loss: 9.3974e-04 - val_mae: 0.0236\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0313 - val_loss: 6.3147e-04 - val_mae: 0.0164\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0292 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 9.3764e-04 - val_mae: 0.0235\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0250 - val_loss: 9.8166e-04 - val_mae: 0.0243\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0259 - val_loss: 9.9015e-04 - val_mae: 0.0245\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0255 - val_loss: 7.5098e-04 - val_mae: 0.0196\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0269 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0252 - val_loss: 9.9150e-04 - val_mae: 0.0245\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 8.2177e-04 - val_mae: 0.0212\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.1348e-04 - val_mae: 0.0231\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 8.6157e-04 - val_mae: 0.0221\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0287 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0236 - val_loss: 9.7328e-04 - val_mae: 0.0242\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 9.1576e-04 - val_mae: 0.0231\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.6649e-04 - val_mae: 0.0241\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0230 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.6953e-04 - val_mae: 0.0241\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.7568e-04 - val_mae: 0.0242\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.2932e-04 - val_mae: 0.0234\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 8.5213e-04 - val_mae: 0.0219\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.8609e-04 - val_mae: 0.0244\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0259 - val_loss: 9.2584e-04 - val_mae: 0.0233\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 8.0482e-04 - val_mae: 0.0209\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 9.0528e-04 - val_mae: 0.0229\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.9378e-04 - val_mae: 0.0245\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 8.5424e-04 - val_mae: 0.0219\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0246 - val_loss: 9.8622e-04 - val_mae: 0.0244\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 8.6173e-04 - val_mae: 0.0221\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0237 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0261 - val_loss: 9.6021e-04 - val_mae: 0.0240\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0236 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 8.9372e-04 - val_mae: 0.0227\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.3038e-04 - val_mae: 0.0234\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.1494e-04 - val_mae: 0.0231\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0240 - val_loss: 9.0042e-04 - val_mae: 0.0228\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0260 - val_loss: 9.3130e-04 - val_mae: 0.0234\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 8.8339e-04 - val_mae: 0.0225\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.1403e-04 - val_mae: 0.0231\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 8.8570e-04 - val_mae: 0.0225\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0231 - val_loss: 8.9629e-04 - val_mae: 0.0228\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 8.7776e-04 - val_mae: 0.0224\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.7620e-04 - val_mae: 0.0242\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 9.3292e-04 - val_mae: 0.0234\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0224 - val_loss: 9.6750e-04 - val_mae: 0.0241\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0233 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.1089e-04 - val_mae: 0.0210\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 6.6204e-04 - val_mae: 0.0173\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.3415e-04 - val_mae: 0.0235\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0235 - val_loss: 8.5214e-04 - val_mae: 0.0219\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 9.3648e-04 - val_mae: 0.0235\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0233 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 8.3435e-04 - val_mae: 0.0215\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.7886e-04 - val_mae: 0.0243\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.8803e-04 - val_mae: 0.0244\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0970e-04 - val_mae: 0.0230\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.3136e-04 - val_mae: 0.0234\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.5260e-04 - val_mae: 0.0238\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.2781e-04 - val_mae: 0.0234\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 9.2646e-04 - val_mae: 0.0233\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0223 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0243 - val_loss: 9.5904e-04 - val_mae: 0.0239\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.9171e-04 - val_mae: 0.0245\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.4632e-04 - val_mae: 0.0237\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0254 - val_loss: 8.3550e-04 - val_mae: 0.0215\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0367 - val_loss: 4.7370e-04 - val_mae: 0.0146\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0340 - val_loss: 7.9914e-04 - val_mae: 0.0207\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.9523e-04 - val_mae: 0.0227\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0241 - val_loss: 9.3513e-04 - val_mae: 0.0235\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0212 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0221 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.2315e-04 - val_mae: 0.0233\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.8540e-04 - val_mae: 0.0244\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0226 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 8.0582e-04 - val_mae: 0.0209\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0228 - val_loss: 9.8633e-04 - val_mae: 0.0244\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.6891e-04 - val_mae: 0.0241\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.5359e-04 - val_mae: 0.0238\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.4569e-04 - val_mae: 0.0237\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.0943e-04 - val_mae: 0.0230\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0236 - val_loss: 9.6234e-04 - val_mae: 0.0240\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 7.9056e-04 - val_mae: 0.0205\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.8058e-04 - val_mae: 0.0224\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0234 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0231 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0243 - val_loss: 9.1128e-04 - val_mae: 0.0230\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.9993e-04 - val_mae: 0.0247\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 9.8606e-04 - val_mae: 0.0244\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0227 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 9.2275e-04 - val_mae: 0.0233\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.9389e-04 - val_mae: 0.0246\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.6558e-04 - val_mae: 0.0240\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0239 - val_loss: 8.9442e-04 - val_mae: 0.0227\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0245 - val_loss: 9.6598e-04 - val_mae: 0.0241\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0240 - val_loss: 9.1216e-04 - val_mae: 0.0231\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.7711e-04 - val_mae: 0.0243\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0224 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0217 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.4678e-04 - val_mae: 0.0237\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.7315e-04 - val_mae: 0.0242\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.2101e-04 - val_mae: 0.0232\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.6244e-04 - val_mae: 0.0240\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0231 - val_loss: 9.6233e-04 - val_mae: 0.0240\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0237 - val_loss: 8.6170e-04 - val_mae: 0.0221\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 6.7520e-04 - val_mae: 0.0177\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 8.5956e-04 - val_mae: 0.0220\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.2557e-04 - val_mae: 0.0233\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.8624e-04 - val_mae: 0.0244\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0228 - val_loss: 9.8554e-04 - val_mae: 0.0244\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 9.1264e-04 - val_mae: 0.0231\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0223 - val_loss: 9.9107e-04 - val_mae: 0.0245\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 9.3604e-04 - val_mae: 0.0235\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 8.2568e-04 - val_mae: 0.0213\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.6647e-04 - val_mae: 0.0222\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0239 - val_loss: 8.6840e-04 - val_mae: 0.0222\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0237 - val_loss: 9.1079e-04 - val_mae: 0.0230\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.8964e-04 - val_mae: 0.0245\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 8.9117e-04 - val_mae: 0.0227\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.3128e-04 - val_mae: 0.0234\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0236 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.4043e-04 - val_mae: 0.0236\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Model: \"sequential_21\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_252 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_231 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_253 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_232 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_254 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_233 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_255 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_234 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_256 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_235 (Dropout)       (None, 40)                0         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dense_257 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_236 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_258 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_237 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_259 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_238 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_260 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_239 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_261 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_240 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_262 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_241 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_263 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 0.9567 - mae: 0.8906 - val_loss: 0.1509 - val_mae: 0.3878\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1907 - mae: 0.3399 - val_loss: 0.0069 - val_mae: 0.0803\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3027 - val_loss: 9.3853e-04 - val_mae: 0.0286\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1271 - mae: 0.2706 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1246 - mae: 0.2755 - val_loss: 6.5747e-04 - val_mae: 0.0221\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0910 - mae: 0.2456 - val_loss: 0.0010 - val_mae: 0.0304\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1355 - mae: 0.2876 - val_loss: 5.5601e-04 - val_mae: 0.0152\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0867 - mae: 0.2461 - val_loss: 4.7544e-04 - val_mae: 0.0146\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0820 - mae: 0.2190 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0661 - mae: 0.2041 - val_loss: 5.2161e-04 - val_mae: 0.0148\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0703 - mae: 0.2142 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0996 - mae: 0.2630 - val_loss: 7.4043e-04 - val_mae: 0.0244\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0858 - mae: 0.2322 - val_loss: 0.0022 - val_mae: 0.0412\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0619 - mae: 0.1998 - val_loss: 4.7368e-04 - val_mae: 0.0146\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0937 - mae: 0.2508 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0695 - mae: 0.2153 - val_loss: 0.0020 - val_mae: 0.0426\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0510 - mae: 0.1852 - val_loss: 0.0056 - val_mae: 0.0719\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0547 - mae: 0.1908 - val_loss: 0.0050 - val_mae: 0.0676\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0678 - mae: 0.2127 - val_loss: 8.4458e-04 - val_mae: 0.0217\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0424 - mae: 0.1544 - val_loss: 0.0022 - val_mae: 0.0420\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0380 - mae: 0.1484 - val_loss: 5.5261e-04 - val_mae: 0.0184\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0598 - mae: 0.1877 - val_loss: 4.9133e-04 - val_mae: 0.0146\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0455 - mae: 0.1670 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0478 - mae: 0.1718 - val_loss: 5.6480e-04 - val_mae: 0.0189\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0320 - mae: 0.1411 - val_loss: 5.3655e-04 - val_mae: 0.0150\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0381 - mae: 0.1553 - val_loss: 5.0879e-04 - val_mae: 0.0161\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0317 - mae: 0.1420 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0244 - mae: 0.1205 - val_loss: 8.7395e-04 - val_mae: 0.0223\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0270 - mae: 0.1275 - val_loss: 0.0019 - val_mae: 0.0414\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0295 - mae: 0.1347 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0246 - mae: 0.1208 - val_loss: 6.5210e-04 - val_mae: 0.0170\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0297 - mae: 0.1283 - val_loss: 0.0011 - val_mae: 0.0306\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0271 - mae: 0.1243 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0258 - mae: 0.1307 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0262 - mae: 0.1129 - val_loss: 8.2640e-04 - val_mae: 0.0213\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0245 - mae: 0.1159 - val_loss: 4.7354e-04 - val_mae: 0.0146\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.0950 - val_loss: 5.7343e-04 - val_mae: 0.0193\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0181 - mae: 0.1044 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0254 - mae: 0.1179 - val_loss: 7.3540e-04 - val_mae: 0.0192\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0183 - mae: 0.1037 - val_loss: 6.0731e-04 - val_mae: 0.0206\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0183 - mae: 0.1015 - val_loss: 7.1502e-04 - val_mae: 0.0187\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0733 - val_loss: 0.0015 - val_mae: 0.0328\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0157 - mae: 0.0907 - val_loss: 9.3953e-04 - val_mae: 0.0236\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0144 - mae: 0.0942 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0187 - mae: 0.0980 - val_loss: 6.4554e-04 - val_mae: 0.0168\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0818 - val_loss: 5.9706e-04 - val_mae: 0.0158\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0124 - mae: 0.0839 - val_loss: 8.3866e-04 - val_mae: 0.0216\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0787 - val_loss: 4.9369e-04 - val_mae: 0.0146\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0839 - val_loss: 7.7600e-04 - val_mae: 0.0202\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0751 - val_loss: 9.1629e-04 - val_mae: 0.0231\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0709 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0679 - val_loss: 7.1863e-04 - val_mae: 0.0188\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0728 - val_loss: 5.6873e-04 - val_mae: 0.0154\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0838 - val_loss: 4.7637e-04 - val_mae: 0.0146\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0673 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0813 - val_loss: 4.7492e-04 - val_mae: 0.0147\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0757 - val_loss: 5.7424e-04 - val_mae: 0.0154\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0736 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0750 - val_loss: 7.0282e-04 - val_mae: 0.0184\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0674 - val_loss: 7.2102e-04 - val_mae: 0.0189\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0660 - val_loss: 4.7358e-04 - val_mae: 0.0146\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0685 - val_loss: 7.5495e-04 - val_mae: 0.0197\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0608 - val_loss: 9.5332e-04 - val_mae: 0.0238\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0564 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0661 - val_loss: 8.0955e-04 - val_mae: 0.0210\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0594 - val_loss: 5.0123e-04 - val_mae: 0.0158\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0096 - mae: 0.0652 - val_loss: 5.8726e-04 - val_mae: 0.0157\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0578 - val_loss: 7.6391e-04 - val_mae: 0.0199\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0568 - val_loss: 7.3524e-04 - val_mae: 0.0192\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0603 - val_loss: 5.1090e-04 - val_mae: 0.0146\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0625 - val_loss: 9.6116e-04 - val_mae: 0.0240\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0479 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0537 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0550 - val_loss: 8.9030e-04 - val_mae: 0.0226\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0543 - val_loss: 7.7822e-04 - val_mae: 0.0203\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0511 - val_loss: 6.8013e-04 - val_mae: 0.0178\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0500 - val_loss: 7.2566e-04 - val_mae: 0.0190\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0600 - val_loss: 6.9023e-04 - val_mae: 0.0181\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0492 - val_loss: 8.2331e-04 - val_mae: 0.0213\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0526 - val_loss: 6.5263e-04 - val_mae: 0.0170\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0527 - val_loss: 7.3583e-04 - val_mae: 0.0193\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0535 - val_loss: 5.7825e-04 - val_mae: 0.0155\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0516 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0458 - val_loss: 7.7403e-04 - val_mae: 0.0202\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0529 - val_loss: 6.8448e-04 - val_mae: 0.0179\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0478 - val_loss: 6.4572e-04 - val_mae: 0.0168\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0453 - val_loss: 9.7152e-04 - val_mae: 0.0242\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0531 - val_loss: 9.0739e-04 - val_mae: 0.0230\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0468 - val_loss: 5.0185e-04 - val_mae: 0.0146\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0511 - val_loss: 7.8199e-04 - val_mae: 0.0204\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0437 - val_loss: 9.3341e-04 - val_mae: 0.0235\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0449 - val_loss: 8.3938e-04 - val_mae: 0.0216\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0410 - val_loss: 9.0027e-04 - val_mae: 0.0228\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0500 - val_loss: 5.6568e-04 - val_mae: 0.0153\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0472 - val_loss: 7.8709e-04 - val_mae: 0.0205\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0457 - val_loss: 8.3832e-04 - val_mae: 0.0216\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0422 - val_loss: 8.0661e-04 - val_mae: 0.0209\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0439 - val_loss: 8.1880e-04 - val_mae: 0.0212\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0412 - val_loss: 7.4666e-04 - val_mae: 0.0195\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0440 - val_loss: 5.9571e-04 - val_mae: 0.0201\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0490 - val_loss: 9.0787e-04 - val_mae: 0.0230\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0436 - val_loss: 8.9187e-04 - val_mae: 0.0227\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0436 - val_loss: 8.3364e-04 - val_mae: 0.0215\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0401 - val_loss: 8.2568e-04 - val_mae: 0.0213\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0405 - val_loss: 9.0699e-04 - val_mae: 0.0230\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0436 - val_loss: 5.5421e-04 - val_mae: 0.0152\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0389 - val_loss: 9.1499e-04 - val_mae: 0.0231\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0416 - val_loss: 9.2255e-04 - val_mae: 0.0233\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0445 - val_loss: 7.9333e-04 - val_mae: 0.0206\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0464 - val_loss: 8.1106e-04 - val_mae: 0.0210\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0371 - val_loss: 8.7960e-04 - val_mae: 0.0224\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0375 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0430 - val_loss: 8.5636e-04 - val_mae: 0.0220\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0408 - val_loss: 8.7099e-04 - val_mae: 0.0223\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0344 - val_loss: 8.9018e-04 - val_mae: 0.0226\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0400 - val_loss: 6.3827e-04 - val_mae: 0.0166\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0441 - val_loss: 6.2723e-04 - val_mae: 0.0164\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0366 - val_loss: 8.2295e-04 - val_mae: 0.0213\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0388 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0350 - val_loss: 8.2131e-04 - val_mae: 0.0212\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0379 - val_loss: 6.9984e-04 - val_mae: 0.0183\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 9.3843e-04 - val_mae: 0.0236\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0427 - val_loss: 5.1791e-04 - val_mae: 0.0166\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0435 - val_loss: 5.9951e-04 - val_mae: 0.0159\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0361 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0368 - val_loss: 7.3071e-04 - val_mae: 0.0191\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0368 - val_loss: 8.4543e-04 - val_mae: 0.0217\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0361 - val_loss: 6.9454e-04 - val_mae: 0.0182\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0357 - val_loss: 6.7868e-04 - val_mae: 0.0178\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0491 - val_loss: 5.2217e-04 - val_mae: 0.0169\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0410 - val_loss: 7.7563e-04 - val_mae: 0.0202\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0362 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0345 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0340 - val_loss: 9.2763e-04 - val_mae: 0.0234\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0363 - val_loss: 9.8659e-04 - val_mae: 0.0244\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0352 - val_loss: 9.5869e-04 - val_mae: 0.0239\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0353 - val_loss: 7.8231e-04 - val_mae: 0.0204\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0348 - val_loss: 7.9620e-04 - val_mae: 0.0207\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0341 - val_loss: 8.2404e-04 - val_mae: 0.0213\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0332 - val_loss: 8.8231e-04 - val_mae: 0.0225\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0342 - val_loss: 6.9906e-04 - val_mae: 0.0183\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0334 - val_loss: 8.4522e-04 - val_mae: 0.0217\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0335 - val_loss: 9.1025e-04 - val_mae: 0.0230\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0345 - val_loss: 9.5659e-04 - val_mae: 0.0239\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0354 - val_loss: 8.5439e-04 - val_mae: 0.0219\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0310 - val_loss: 8.9182e-04 - val_mae: 0.0227\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 9.0448e-04 - val_mae: 0.0229\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0324 - val_loss: 7.8831e-04 - val_mae: 0.0205\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 8.7018e-04 - val_mae: 0.0222\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0334 - val_loss: 6.3725e-04 - val_mae: 0.0165\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0365 - val_loss: 6.8696e-04 - val_mae: 0.0180\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0353 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 8.2275e-04 - val_mae: 0.0213\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0335 - val_loss: 7.9856e-04 - val_mae: 0.0207\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0326 - val_loss: 7.2603e-04 - val_mae: 0.0190\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 8.0967e-04 - val_mae: 0.0210\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0316 - val_loss: 7.6375e-04 - val_mae: 0.0199\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0310 - val_loss: 9.1142e-04 - val_mae: 0.0230\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0322 - val_loss: 8.1517e-04 - val_mae: 0.0211\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0300 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0301 - val_loss: 9.5948e-04 - val_mae: 0.0239\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0301 - val_loss: 7.8398e-04 - val_mae: 0.0204\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0311 - val_loss: 8.6574e-04 - val_mae: 0.0221\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0328 - val_loss: 8.0540e-04 - val_mae: 0.0209\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 8.5828e-04 - val_mae: 0.0220\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0303 - val_loss: 7.4898e-04 - val_mae: 0.0196\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0310 - val_loss: 8.8374e-04 - val_mae: 0.0225\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0322 - val_loss: 7.5728e-04 - val_mae: 0.0198\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0307 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0266 - val_loss: 7.8125e-04 - val_mae: 0.0203\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0304 - val_loss: 8.8311e-04 - val_mae: 0.0225\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0283 - val_loss: 8.9346e-04 - val_mae: 0.0227\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0319 - val_loss: 6.9333e-04 - val_mae: 0.0182\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0315 - val_loss: 7.6171e-04 - val_mae: 0.0199\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0340 - val_loss: 7.8758e-04 - val_mae: 0.0205\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0290 - val_loss: 8.1681e-04 - val_mae: 0.0211\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0339 - val_loss: 8.4522e-04 - val_mae: 0.0217\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0312 - val_loss: 6.9930e-04 - val_mae: 0.0183\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0281 - val_loss: 9.2405e-04 - val_mae: 0.0233\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0297 - val_loss: 7.6519e-04 - val_mae: 0.0200\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0279 - val_loss: 8.6182e-04 - val_mae: 0.0221\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 8.9774e-04 - val_mae: 0.0228\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0304 - val_loss: 8.0228e-04 - val_mae: 0.0208\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 8.6274e-04 - val_mae: 0.0221\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0301 - val_loss: 6.9471e-04 - val_mae: 0.0182\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0306 - val_loss: 8.8544e-04 - val_mae: 0.0225\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0295 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0251 - val_loss: 9.8255e-04 - val_mae: 0.0244\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 8.6921e-04 - val_mae: 0.0222\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0280 - val_loss: 8.2290e-04 - val_mae: 0.0213\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 9.8820e-04 - val_mae: 0.0245\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0308 - val_loss: 7.8864e-04 - val_mae: 0.0205\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0270 - val_loss: 9.4398e-04 - val_mae: 0.0237\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0306 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0295 - val_loss: 9.1875e-04 - val_mae: 0.0232\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0284 - val_loss: 7.0774e-04 - val_mae: 0.0185\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0244 - val_loss: 9.2899e-04 - val_mae: 0.0234\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0299 - val_loss: 6.6217e-04 - val_mae: 0.0173\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 7.0377e-04 - val_mae: 0.0184\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0292 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0310 - val_loss: 8.7565e-04 - val_mae: 0.0223\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0295 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0278 - val_loss: 9.1592e-04 - val_mae: 0.0231\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0287 - val_loss: 9.2284e-04 - val_mae: 0.0233\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.4521e-04 - val_mae: 0.0237\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 8.7520e-04 - val_mae: 0.0223\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 8.9566e-04 - val_mae: 0.0227\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0303 - val_loss: 7.6446e-04 - val_mae: 0.0199\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 8.8813e-04 - val_mae: 0.0226\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0292 - val_loss: 8.7437e-04 - val_mae: 0.0223\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 9.2957e-04 - val_mae: 0.0234\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 8.7438e-04 - val_mae: 0.0223\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 8.7592e-04 - val_mae: 0.0224\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0292 - val_loss: 9.3243e-04 - val_mae: 0.0234\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0273 - val_loss: 8.4593e-04 - val_mae: 0.0217\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0252 - val_loss: 9.3890e-04 - val_mae: 0.0236\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.4043e-04 - val_mae: 0.0236\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.3057e-04 - val_mae: 0.0234\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0272 - val_loss: 9.8783e-04 - val_mae: 0.0244\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 7.7507e-04 - val_mae: 0.0202\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0288 - val_loss: 8.3290e-04 - val_mae: 0.0215\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 8.7344e-04 - val_mae: 0.0223\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.7351e-04 - val_mae: 0.0242\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0257 - val_loss: 8.7211e-04 - val_mae: 0.0223\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 8.0833e-04 - val_mae: 0.0209\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0284 - val_loss: 8.0449e-04 - val_mae: 0.0209\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0289 - val_loss: 7.0570e-04 - val_mae: 0.0185\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 8.5554e-04 - val_mae: 0.0219\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 7.9006e-04 - val_mae: 0.0205\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 9.7431e-04 - val_mae: 0.0242\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.6029e-04 - val_mae: 0.0240\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.8333e-04 - val_mae: 0.0225\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 8.9826e-04 - val_mae: 0.0228\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0258 - val_loss: 7.4290e-04 - val_mae: 0.0194\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.9563e-04 - val_mae: 0.0246\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0277 - val_loss: 8.8980e-04 - val_mae: 0.0226\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0284 - val_loss: 8.9269e-04 - val_mae: 0.0227\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0265 - val_loss: 9.3533e-04 - val_mae: 0.0235\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0273 - val_loss: 8.6887e-04 - val_mae: 0.0222\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 8.9468e-04 - val_mae: 0.0227\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0260 - val_loss: 9.2119e-04 - val_mae: 0.0232\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0288 - val_loss: 7.6965e-04 - val_mae: 0.0201\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.9673e-04 - val_mae: 0.0246\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0276 - val_loss: 7.5014e-04 - val_mae: 0.0196\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 9.7630e-04 - val_mae: 0.0242\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0241 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 8.4808e-04 - val_mae: 0.0218\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 8.2578e-04 - val_mae: 0.0213\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0249 - val_loss: 8.8587e-04 - val_mae: 0.0225\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.4263e-04 - val_mae: 0.0236\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 8.9100e-04 - val_mae: 0.0226\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0334 - val_loss: 5.4447e-04 - val_mae: 0.0151\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0283 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0231 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.6639e-04 - val_mae: 0.0222\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 9.4535e-04 - val_mae: 0.0237\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0258 - val_loss: 8.4055e-04 - val_mae: 0.0216\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 7.8457e-04 - val_mae: 0.0204\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 9.6189e-04 - val_mae: 0.0240\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0248 - val_loss: 8.6134e-04 - val_mae: 0.0221\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0268 - val_loss: 8.5099e-04 - val_mae: 0.0218\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 9.1235e-04 - val_mae: 0.0231\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.6672e-04 - val_mae: 0.0222\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0261 - val_loss: 8.3246e-04 - val_mae: 0.0215\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0264 - val_loss: 8.2372e-04 - val_mae: 0.0213\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0248 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0245 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0254 - val_loss: 8.1096e-04 - val_mae: 0.0210\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0265 - val_loss: 8.5384e-04 - val_mae: 0.0219\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0241 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.0377e-04 - val_mae: 0.0208\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.1688e-04 - val_mae: 0.0231\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0263 - val_loss: 7.2198e-04 - val_mae: 0.0189\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0266 - val_loss: 9.4663e-04 - val_mae: 0.0237\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0265 - val_loss: 8.5390e-04 - val_mae: 0.0219\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0233 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.8455e-04 - val_mae: 0.0244\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0263 - val_loss: 8.4280e-04 - val_mae: 0.0217\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 8.1806e-04 - val_mae: 0.0212\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 8.7734e-04 - val_mae: 0.0224\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0248 - val_loss: 9.9222e-04 - val_mae: 0.0245\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.9695e-04 - val_mae: 0.0246\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 8.7898e-04 - val_mae: 0.0224\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.4044e-04 - val_mae: 0.0236\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 8.5232e-04 - val_mae: 0.0219\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0308 - val_loss: 5.7599e-04 - val_mae: 0.0155\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.0535e-04 - val_mae: 0.0229\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0247 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0235 - val_loss: 9.7850e-04 - val_mae: 0.0243\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.3247e-04 - val_mae: 0.0215\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.2009e-04 - val_mae: 0.0232\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0226 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.1623e-04 - val_mae: 0.0231\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 7.3217e-04 - val_mae: 0.0192\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 8.7255e-04 - val_mae: 0.0223\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0248 - val_loss: 9.0545e-04 - val_mae: 0.0229\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 7.4773e-04 - val_mae: 0.0195\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 8.8214e-04 - val_mae: 0.0225\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.8629e-04 - val_mae: 0.0244\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.3525e-04 - val_mae: 0.0235\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.2980e-04 - val_mae: 0.0234\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 8.2145e-04 - val_mae: 0.0212\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 8.6277e-04 - val_mae: 0.0221\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0234 - val_loss: 9.3720e-04 - val_mae: 0.0235\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 8.4835e-04 - val_mae: 0.0218\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0248 - val_loss: 8.3597e-04 - val_mae: 0.0215\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 8.6564e-04 - val_mae: 0.0221\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.8921e-04 - val_mae: 0.0226\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0238 - val_loss: 9.1092e-04 - val_mae: 0.0230\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.6926e-04 - val_mae: 0.0241\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0647e-04 - val_mae: 0.0229\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.5394e-04 - val_mae: 0.0238\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0218 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 9.6055e-04 - val_mae: 0.0240\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.5842e-04 - val_mae: 0.0239\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0342 - val_loss: 4.8784e-04 - val_mae: 0.0146\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 9.2474e-04 - val_mae: 0.0233\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.6056e-04 - val_mae: 0.0240\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.1831e-04 - val_mae: 0.0232\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0268e-04 - val_mae: 0.0229\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 8.9282e-04 - val_mae: 0.0227\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.8048e-04 - val_mae: 0.0224\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0232 - val_loss: 9.5542e-04 - val_mae: 0.0239\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.1288e-04 - val_mae: 0.0231\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 8.4849e-04 - val_mae: 0.0218\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0316e-04 - val_mae: 0.0229\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0227 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0232 - val_loss: 9.6733e-04 - val_mae: 0.0241\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 8.8021e-04 - val_mae: 0.0224\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 8.5390e-04 - val_mae: 0.0219\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_22\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_264 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_242 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_265 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_243 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_266 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_244 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_267 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_245 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_268 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_246 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_269 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_247 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_270 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_248 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_271 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_249 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_272 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_250 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_273 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_251 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_274 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_252 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_275 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 4s 18ms/step - loss: 24.4489 - mae: 3.6181 - val_loss: 0.7550 - val_mae: 0.8686\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 7.1727 - mae: 1.9400 - val_loss: 0.0764 - val_mae: 0.2758\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 5.2957 - mae: 1.6802 - val_loss: 0.0017 - val_mae: 0.0384\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 2.2049 - mae: 0.9933 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 2.3980 - mae: 1.1285 - val_loss: 0.0078 - val_mae: 0.0857\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.1752 - mae: 0.8262 - val_loss: 0.0109 - val_mae: 0.1021\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.4009 - mae: 0.9111 - val_loss: 0.0034 - val_mae: 0.0543\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9667 - mae: 0.7720 - val_loss: 0.0012 - val_mae: 0.0331\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.1699 - mae: 0.7721 - val_loss: 0.0034 - val_mae: 0.0537\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5529 - mae: 0.5519 - val_loss: 0.0044 - val_mae: 0.0623\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5532 - mae: 0.5347 - val_loss: 0.0051 - val_mae: 0.0680\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7294 - mae: 0.6186 - val_loss: 0.0050 - val_mae: 0.0676\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4432 - mae: 0.5091 - val_loss: 0.0063 - val_mae: 0.0763\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4525 - mae: 0.5163 - val_loss: 0.0044 - val_mae: 0.0623\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.4678 - mae: 0.5091 - val_loss: 0.0035 - val_mae: 0.0546\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3682 - mae: 0.4807 - val_loss: 0.0031 - val_mae: 0.0512\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2711 - mae: 0.3654 - val_loss: 0.0029 - val_mae: 0.0491\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4457 - mae: 0.5049 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4627 - mae: 0.4709 - val_loss: 7.4493e-04 - val_mae: 0.0196\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3218 - mae: 0.4034 - val_loss: 6.7419e-04 - val_mae: 0.0177\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3025 - mae: 0.4111 - val_loss: 6.7749e-04 - val_mae: 0.0180\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2910 - mae: 0.4119 - val_loss: 7.2919e-04 - val_mae: 0.0194\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1828 - mae: 0.3110 - val_loss: 7.2311e-04 - val_mae: 0.0192\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1603 - mae: 0.3010 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3417 - mae: 0.4402 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2265 - mae: 0.3312 - val_loss: 0.0022 - val_mae: 0.0415\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3001 - mae: 0.3676 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1585 - mae: 0.3020 - val_loss: 0.0027 - val_mae: 0.0473\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1979 - mae: 0.3198 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1208 - mae: 0.2630 - val_loss: 0.0023 - val_mae: 0.0422\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1471 - mae: 0.2891 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1136 - mae: 0.2504 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1150 - mae: 0.2429 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1717 - mae: 0.2867 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1497 - mae: 0.2943 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1397 - mae: 0.2827 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1429 - mae: 0.2713 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1078 - mae: 0.2388 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1112 - mae: 0.2302 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1259 - mae: 0.2587 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1249 - mae: 0.2358 - val_loss: 0.0031 - val_mae: 0.0518\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0879 - mae: 0.2146 - val_loss: 0.0031 - val_mae: 0.0508\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0902 - mae: 0.2118 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0657 - mae: 0.1947 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0864 - mae: 0.2057 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0817 - mae: 0.2047 - val_loss: 0.0018 - val_mae: 0.0356\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1254 - mae: 0.2421 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0837 - mae: 0.2089 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0860 - mae: 0.2079 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1025 - mae: 0.2287 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0729 - mae: 0.1910 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0999 - mae: 0.2347 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0841 - mae: 0.2070 - val_loss: 0.0020 - val_mae: 0.0386\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0465 - mae: 0.1549 - val_loss: 0.0022 - val_mae: 0.0412\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0949 - mae: 0.2036 - val_loss: 0.0025 - val_mae: 0.0454\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0785 - mae: 0.1996 - val_loss: 0.0025 - val_mae: 0.0445\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0830 - mae: 0.2203 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0622 - mae: 0.1828 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0614 - mae: 0.1840 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0525 - mae: 0.1780 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0528 - mae: 0.1705 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0810 - mae: 0.1856 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0747 - mae: 0.1770 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0564 - mae: 0.1540 - val_loss: 0.0024 - val_mae: 0.0440\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0487 - mae: 0.1642 - val_loss: 0.0025 - val_mae: 0.0452\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0505 - mae: 0.1616 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.1765 - val_loss: 0.0027 - val_mae: 0.0467\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0382 - mae: 0.1476 - val_loss: 0.0029 - val_mae: 0.0488\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0701 - mae: 0.1711 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0535 - mae: 0.1602 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0874 - mae: 0.1751 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0331 - mae: 0.1276 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0351 - mae: 0.1369 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0227 - mae: 0.1141 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0531 - mae: 0.1538 - val_loss: 0.0018 - val_mae: 0.0359\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0316 - mae: 0.1242 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0494 - mae: 0.1544 - val_loss: 0.0019 - val_mae: 0.0371\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0580 - mae: 0.1529 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0377 - mae: 0.1323 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0343 - mae: 0.1301 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0496 - mae: 0.1520 - val_loss: 9.3850e-04 - val_mae: 0.0235\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0308 - mae: 0.1276 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0601 - mae: 0.1554 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0310 - mae: 0.1316 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0468 - mae: 0.1309 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0650 - mae: 0.1439 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0286 - mae: 0.1118 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0501 - mae: 0.1430 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0370 - mae: 0.1314 - val_loss: 0.0016 - val_mae: 0.0335\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0506 - mae: 0.1324 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0281 - mae: 0.1186 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0311 - mae: 0.1270 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0208 - mae: 0.0991 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0289 - mae: 0.1135 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0288 - mae: 0.1151 - val_loss: 0.0021 - val_mae: 0.0407\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0290 - mae: 0.1283 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0263 - mae: 0.1161 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0212 - mae: 0.1097 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0227 - mae: 0.1039 - val_loss: 0.0018 - val_mae: 0.0361\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - mae: 0.1152 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0340 - mae: 0.1281 - val_loss: 0.0017 - val_mae: 0.0350\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0277 - mae: 0.1069 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0351 - mae: 0.1256 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0216 - mae: 0.1024 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0460 - mae: 0.1167 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0168 - mae: 0.0915 - val_loss: 0.0016 - val_mae: 0.0342\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0248 - mae: 0.1052 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0253 - mae: 0.1163 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0150 - mae: 0.0913 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0740 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0240 - mae: 0.1012 - val_loss: 0.0017 - val_mae: 0.0343\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.0950 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0342 - mae: 0.1229 - val_loss: 0.0013 - val_mae: 0.0296\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0164 - mae: 0.0929 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0329 - mae: 0.1165 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0216 - mae: 0.1074 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0225 - mae: 0.1046 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0164 - mae: 0.0873 - val_loss: 0.0018 - val_mae: 0.0365\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0964 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0261 - mae: 0.1108 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0186 - mae: 0.0967 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0168 - mae: 0.0882 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - mae: 0.0875 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0290 - mae: 0.1212 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0174 - mae: 0.0876 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0248 - mae: 0.1010 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0785 - val_loss: 0.0016 - val_mae: 0.0330\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0218 - mae: 0.0991 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0823 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0213 - mae: 0.0951 - val_loss: 0.0017 - val_mae: 0.0352\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0251 - mae: 0.1114 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.0928 - val_loss: 0.0020 - val_mae: 0.0386\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0750 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0194 - mae: 0.0920 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0802 - val_loss: 0.0018 - val_mae: 0.0366\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.1132 - val_loss: 0.0018 - val_mae: 0.0365\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0830 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0743 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0174 - mae: 0.0886 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0138 - mae: 0.0783 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0235 - mae: 0.0928 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0157 - mae: 0.0845 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0701 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0833 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0237 - mae: 0.0874 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0793 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0738 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0797 - val_loss: 0.0015 - val_mae: 0.0327\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - mae: 0.0834 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0766 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0124 - mae: 0.0720 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0761 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0792 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0826 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0713 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0717 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0633 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0677 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0660 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0845 - val_loss: 0.0017 - val_mae: 0.0348\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.0696 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0684 - val_loss: 0.0015 - val_mae: 0.0316\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0679 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0174 - mae: 0.0830 - val_loss: 0.0016 - val_mae: 0.0341\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0763 - val_loss: 0.0019 - val_mae: 0.0383\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0712 - val_loss: 0.0021 - val_mae: 0.0408\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0680 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 0.0801 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0688 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0747 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.0800 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0729 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0651 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0730 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0692 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0591 - val_loss: 0.0019 - val_mae: 0.0377\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0692 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0743 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0676 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0722 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0706 - val_loss: 0.0020 - val_mae: 0.0386\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0617 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.0623 - val_loss: 0.0016 - val_mae: 0.0337\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0666 - val_loss: 0.0023 - val_mae: 0.0432\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0730 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.0727 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0142 - mae: 0.0786 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0651 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0696 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0564 - val_loss: 0.0014 - val_mae: 0.0304\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0523 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - mae: 0.0677 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0695 - val_loss: 0.0014 - val_mae: 0.0300\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0696 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0607 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0534 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0611 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0597 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0136 - mae: 0.0745 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0102 - mae: 0.0614 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0071 - mae: 0.0560 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0577 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - mae: 0.0674 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0613 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0102 - mae: 0.0598 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0085 - mae: 0.0565 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.0714 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0538 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0559 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0094 - mae: 0.0545 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0533 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0135 - mae: 0.0735 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0529 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0528 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0516 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0566 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0672 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0616 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0648 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0549 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0485 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0601 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0613 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0543 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0554 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0485 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0530 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0454 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0493 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0510 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0558 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0478 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0479 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0507 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0510 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0550 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0505 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0492 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0501 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0506 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0466 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0468 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0526 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0501 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0491 - val_loss: 0.0013 - val_mae: 0.0287\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0498 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0302\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0491 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0505 - val_loss: 8.9045e-04 - val_mae: 0.0226\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0497 - val_loss: 8.4797e-04 - val_mae: 0.0218\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0537 - val_loss: 8.0096e-04 - val_mae: 0.0208\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0608 - val_loss: 9.2616e-04 - val_mae: 0.0233\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0508 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0491 - val_loss: 9.4005e-04 - val_mae: 0.0236\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0509 - val_loss: 9.2127e-04 - val_mae: 0.0232\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0476 - val_loss: 9.9403e-04 - val_mae: 0.0246\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0494 - val_loss: 8.9147e-04 - val_mae: 0.0227\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0508 - val_loss: 9.3488e-04 - val_mae: 0.0235\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0471 - val_loss: 8.0510e-04 - val_mae: 0.0209\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0480 - val_loss: 7.9713e-04 - val_mae: 0.0207\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0476 - val_loss: 9.0491e-04 - val_mae: 0.0229\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0433 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0471 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0431 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0460 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0483 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0464 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0472 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0542 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0477 - val_loss: 9.1399e-04 - val_mae: 0.0231\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0522 - val_loss: 9.5406e-04 - val_mae: 0.0238\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0512 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0447 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0493 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0463 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0428 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0431 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0491 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0484 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0451 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0530 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0453 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0458 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0468 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0474 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0439 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0453 - val_loss: 6.8144e-04 - val_mae: 0.0178\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0635 - val_loss: 8.7613e-04 - val_mae: 0.0224\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0489 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0470 - val_loss: 8.5053e-04 - val_mae: 0.0218\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0464 - val_loss: 8.9350e-04 - val_mae: 0.0227\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0467 - val_loss: 8.4982e-04 - val_mae: 0.0218\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0384 - val_loss: 9.6025e-04 - val_mae: 0.0240\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0484 - val_loss: 8.7081e-04 - val_mae: 0.0223\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - mae: 0.0482 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0073 - mae: 0.0441 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0388 - val_loss: 9.8947e-04 - val_mae: 0.0245\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0504 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0387 - val_loss: 8.1349e-04 - val_mae: 0.0211\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0504 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0464 - val_loss: 8.6895e-04 - val_mae: 0.0222\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0440 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0470 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0428 - val_loss: 9.3302e-04 - val_mae: 0.0235\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0350 - val_loss: 8.6514e-04 - val_mae: 0.0221\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0467 - val_loss: 9.1658e-04 - val_mae: 0.0231\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - mae: 0.0464 - val_loss: 9.8936e-04 - val_mae: 0.0245\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0062 - mae: 0.0405 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0400 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0038 - mae: 0.0353 - val_loss: 8.9114e-04 - val_mae: 0.0226\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0440 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0408 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0444 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0420 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0065 - mae: 0.0458 - val_loss: 0.0011 - val_mae: 0.0258\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - mae: 0.0472 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0374 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0419 - val_loss: 9.4732e-04 - val_mae: 0.0237\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0103 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0418 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0379 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0386 - val_loss: 9.6115e-04 - val_mae: 0.0240\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0358 - val_loss: 8.4240e-04 - val_mae: 0.0217\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0406 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0386 - val_loss: 0.0010 - val_mae: 0.0248\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0400 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0415 - val_loss: 8.9533e-04 - val_mae: 0.0227\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0413 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0416 - val_loss: 9.3530e-04 - val_mae: 0.0235\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0424 - val_loss: 8.5546e-04 - val_mae: 0.0219\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0460 - val_loss: 9.2926e-04 - val_mae: 0.0234\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0426 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0384 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0425 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0395 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0387 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0365 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0355 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0408 - val_loss: 8.6287e-04 - val_mae: 0.0221\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0434 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0366 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0364 - val_loss: 9.6820e-04 - val_mae: 0.0241\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0403 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0378 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0373 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0393 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0352 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0389 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0370 - val_loss: 9.7450e-04 - val_mae: 0.0242\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_23\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=================================================================\n",
            " dense_276 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_253 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_277 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_254 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_278 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_255 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_279 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_256 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_280 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_257 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_281 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_258 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_282 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_259 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_283 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_260 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_284 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_261 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_285 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_262 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_286 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_263 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_287 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 41.5545 - mae: 4.8813 - val_loss: 0.6103 - val_mae: 0.7798\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 10.6705 - mae: 2.5103 - val_loss: 0.3419 - val_mae: 0.5836\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 8.9992 - mae: 2.2245 - val_loss: 0.0855 - val_mae: 0.2915\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 6.2233 - mae: 1.7668 - val_loss: 0.0363 - val_mae: 0.1888\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 4.0983 - mae: 1.4354 - val_loss: 0.0100 - val_mae: 0.0971\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.1713 - mae: 1.1746 - val_loss: 0.0121 - val_mae: 0.1079\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.0059 - mae: 1.0479 - val_loss: 0.0079 - val_mae: 0.0862\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 2.3031 - mae: 1.1356 - val_loss: 0.0164 - val_mae: 0.1262\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.4961 - mae: 1.0107 - val_loss: 0.0432 - val_mae: 0.2064\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.2196 - mae: 0.8052 - val_loss: 0.0393 - val_mae: 0.1971\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.4402 - mae: 0.8242 - val_loss: 0.0441 - val_mae: 0.2088\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.2370 - mae: 0.8461 - val_loss: 0.0430 - val_mae: 0.2060\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.1360 - mae: 0.8114 - val_loss: 0.0460 - val_mae: 0.2131\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.2039 - mae: 0.7946 - val_loss: 0.0408 - val_mae: 0.2008\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6578 - mae: 0.6013 - val_loss: 0.0381 - val_mae: 0.1940\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.6333 - mae: 0.8855 - val_loss: 0.0307 - val_mae: 0.1738\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.9722 - mae: 0.7317 - val_loss: 0.0225 - val_mae: 0.1484\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8924 - mae: 0.7148 - val_loss: 0.0169 - val_mae: 0.1283\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6616 - mae: 0.5921 - val_loss: 0.0192 - val_mae: 0.1368\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5826 - mae: 0.5687 - val_loss: 0.0208 - val_mae: 0.1426\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6199 - mae: 0.5594 - val_loss: 0.0224 - val_mae: 0.1482\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6075 - mae: 0.5356 - val_loss: 0.0210 - val_mae: 0.1433\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3706 - mae: 0.4470 - val_loss: 0.0192 - val_mae: 0.1371\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6123 - mae: 0.5653 - val_loss: 0.0191 - val_mae: 0.1362\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.6725 - mae: 0.5164 - val_loss: 0.0140 - val_mae: 0.1161\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4632 - mae: 0.4962 - val_loss: 0.0105 - val_mae: 0.1000\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.3334 - mae: 0.4391 - val_loss: 0.0093 - val_mae: 0.0937\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.6645 - mae: 0.5442 - val_loss: 0.0114 - val_mae: 0.1044\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3608 - mae: 0.4609 - val_loss: 0.0109 - val_mae: 0.1019\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6174 - mae: 0.5228 - val_loss: 0.0105 - val_mae: 0.1003\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2482 - mae: 0.3932 - val_loss: 0.0105 - val_mae: 0.1001\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2558 - mae: 0.3868 - val_loss: 0.0094 - val_mae: 0.0945\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3801 - mae: 0.4136 - val_loss: 0.0088 - val_mae: 0.0911\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3492 - mae: 0.4347 - val_loss: 0.0077 - val_mae: 0.0848\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4567 - mae: 0.4920 - val_loss: 0.0064 - val_mae: 0.0770\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3187 - mae: 0.4333 - val_loss: 0.0066 - val_mae: 0.0784\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2160 - mae: 0.3444 - val_loss: 0.0068 - val_mae: 0.0796\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2216 - mae: 0.3389 - val_loss: 0.0064 - val_mae: 0.0767\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3140 - mae: 0.3826 - val_loss: 0.0070 - val_mae: 0.0805\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2827 - mae: 0.3732 - val_loss: 0.0079 - val_mae: 0.0861\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2613 - mae: 0.3909 - val_loss: 0.0074 - val_mae: 0.0831\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2463 - mae: 0.3931 - val_loss: 0.0075 - val_mae: 0.0839\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1763 - mae: 0.3259 - val_loss: 0.0077 - val_mae: 0.0849\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2679 - mae: 0.3659 - val_loss: 0.0083 - val_mae: 0.0885\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1963 - mae: 0.3198 - val_loss: 0.0088 - val_mae: 0.0910\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1833 - mae: 0.3299 - val_loss: 0.0087 - val_mae: 0.0904\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1160 - mae: 0.2698 - val_loss: 0.0083 - val_mae: 0.0885\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1845 - mae: 0.3167 - val_loss: 0.0086 - val_mae: 0.0900\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2387 - mae: 0.3224 - val_loss: 0.0085 - val_mae: 0.0893\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2661 - mae: 0.3422 - val_loss: 0.0086 - val_mae: 0.0903\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2327 - mae: 0.3472 - val_loss: 0.0096 - val_mae: 0.0952\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2514 - mae: 0.3274 - val_loss: 0.0105 - val_mae: 0.0999\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0994 - mae: 0.2291 - val_loss: 0.0103 - val_mae: 0.0992\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1945 - mae: 0.3026 - val_loss: 0.0102 - val_mae: 0.0987\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1574 - mae: 0.2984 - val_loss: 0.0105 - val_mae: 0.1002\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1160 - mae: 0.2546 - val_loss: 0.0106 - val_mae: 0.1005\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1083 - mae: 0.2517 - val_loss: 0.0100 - val_mae: 0.0974\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1179 - mae: 0.2694 - val_loss: 0.0099 - val_mae: 0.0972\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1303 - mae: 0.2495 - val_loss: 0.0097 - val_mae: 0.0962\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1324 - mae: 0.2658 - val_loss: 0.0103 - val_mae: 0.0991\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1459 - mae: 0.2920 - val_loss: 0.0098 - val_mae: 0.0966\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1284 - mae: 0.2780 - val_loss: 0.0091 - val_mae: 0.0929\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1036 - mae: 0.2577 - val_loss: 0.0086 - val_mae: 0.0901\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1067 - mae: 0.2510 - val_loss: 0.0089 - val_mae: 0.0917\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2480 - mae: 0.2778 - val_loss: 0.0105 - val_mae: 0.1000\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1227 - mae: 0.2243 - val_loss: 0.0116 - val_mae: 0.1055\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1260 - mae: 0.2574 - val_loss: 0.0116 - val_mae: 0.1056\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1072 - mae: 0.2533 - val_loss: 0.0114 - val_mae: 0.1045\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0730 - mae: 0.2078 - val_loss: 0.0104 - val_mae: 0.0998\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0812 - mae: 0.2124 - val_loss: 0.0092 - val_mae: 0.0934\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0766 - mae: 0.2153 - val_loss: 0.0092 - val_mae: 0.0937\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0871 - mae: 0.2274 - val_loss: 0.0097 - val_mae: 0.0960\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0797 - mae: 0.2033 - val_loss: 0.0091 - val_mae: 0.0929\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0463 - mae: 0.1583 - val_loss: 0.0085 - val_mae: 0.0899\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1096 - mae: 0.2431 - val_loss: 0.0091 - val_mae: 0.0928\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0720 - mae: 0.2049 - val_loss: 0.0090 - val_mae: 0.0925\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0542 - mae: 0.1664 - val_loss: 0.0087 - val_mae: 0.0905\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0983 - mae: 0.2306 - val_loss: 0.0082 - val_mae: 0.0878\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1334 - mae: 0.2542 - val_loss: 0.0085 - val_mae: 0.0894\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1818 - mae: 0.2588 - val_loss: 0.0088 - val_mae: 0.0915\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1110 - mae: 0.2264 - val_loss: 0.0086 - val_mae: 0.0904\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0671 - mae: 0.1903 - val_loss: 0.0076 - val_mae: 0.0846\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0883 - mae: 0.2339 - val_loss: 0.0077 - val_mae: 0.0849\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0825 - mae: 0.1951 - val_loss: 0.0084 - val_mae: 0.0891\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0731 - mae: 0.1923 - val_loss: 0.0081 - val_mae: 0.0875\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0430 - mae: 0.1623 - val_loss: 0.0078 - val_mae: 0.0857\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1159 - mae: 0.2262 - val_loss: 0.0075 - val_mae: 0.0836\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0778 - mae: 0.2063 - val_loss: 0.0075 - val_mae: 0.0840\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0772 - mae: 0.1909 - val_loss: 0.0069 - val_mae: 0.0804\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1122 - mae: 0.2312 - val_loss: 0.0066 - val_mae: 0.0782\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0838 - mae: 0.1982 - val_loss: 0.0066 - val_mae: 0.0780\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0691 - mae: 0.2004 - val_loss: 0.0061 - val_mae: 0.0752\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0770 - mae: 0.1962 - val_loss: 0.0066 - val_mae: 0.0780\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0430 - mae: 0.1523 - val_loss: 0.0070 - val_mae: 0.0805\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0534 - mae: 0.1644 - val_loss: 0.0073 - val_mae: 0.0828\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1050 - mae: 0.2025 - val_loss: 0.0084 - val_mae: 0.0891\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0513 - mae: 0.1694 - val_loss: 0.0082 - val_mae: 0.0879\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0730 - mae: 0.1912 - val_loss: 0.0076 - val_mae: 0.0843\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0811 - mae: 0.1691 - val_loss: 0.0080 - val_mae: 0.0867\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0684 - mae: 0.1907 - val_loss: 0.0074 - val_mae: 0.0833\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0657 - mae: 0.1784 - val_loss: 0.0068 - val_mae: 0.0797\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0422 - mae: 0.1584 - val_loss: 0.0071 - val_mae: 0.0813\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0765 - mae: 0.1795 - val_loss: 0.0065 - val_mae: 0.0775\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0346 - mae: 0.1405 - val_loss: 0.0061 - val_mae: 0.0749\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0355 - mae: 0.1368 - val_loss: 0.0060 - val_mae: 0.0740\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0450 - mae: 0.1626 - val_loss: 0.0057 - val_mae: 0.0724\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0341 - mae: 0.1362 - val_loss: 0.0058 - val_mae: 0.0730\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0394 - mae: 0.1507 - val_loss: 0.0053 - val_mae: 0.0692\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0468 - mae: 0.1517 - val_loss: 0.0061 - val_mae: 0.0747\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0462 - mae: 0.1612 - val_loss: 0.0063 - val_mae: 0.0764\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0672 - mae: 0.1793 - val_loss: 0.0058 - val_mae: 0.0730\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0596 - mae: 0.1733 - val_loss: 0.0055 - val_mae: 0.0709\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0389 - mae: 0.1341 - val_loss: 0.0057 - val_mae: 0.0725\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0507 - mae: 0.1615 - val_loss: 0.0054 - val_mae: 0.0701\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0372 - mae: 0.1376 - val_loss: 0.0050 - val_mae: 0.0674\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0513 - mae: 0.1543 - val_loss: 0.0046 - val_mae: 0.0646\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0587 - mae: 0.1544 - val_loss: 0.0044 - val_mae: 0.0626\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0390 - mae: 0.1424 - val_loss: 0.0044 - val_mae: 0.0623\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0405 - mae: 0.1422 - val_loss: 0.0047 - val_mae: 0.0647\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0575 - mae: 0.1738 - val_loss: 0.0042 - val_mae: 0.0612\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0531 - mae: 0.1521 - val_loss: 0.0045 - val_mae: 0.0637\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0539 - mae: 0.1665 - val_loss: 0.0041 - val_mae: 0.0598\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0625 - mae: 0.1790 - val_loss: 0.0039 - val_mae: 0.0588\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0362 - mae: 0.1440 - val_loss: 0.0041 - val_mae: 0.0600\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0373 - mae: 0.1401 - val_loss: 0.0043 - val_mae: 0.0620\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0413 - mae: 0.1548 - val_loss: 0.0047 - val_mae: 0.0647\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0400 - mae: 0.1316 - val_loss: 0.0044 - val_mae: 0.0627\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0230 - mae: 0.1144 - val_loss: 0.0037 - val_mae: 0.0569\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0388 - mae: 0.1268 - val_loss: 0.0037 - val_mae: 0.0566\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0304 - mae: 0.1239 - val_loss: 0.0033 - val_mae: 0.0535\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0368 - mae: 0.1301 - val_loss: 0.0035 - val_mae: 0.0551\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0281 - mae: 0.1138 - val_loss: 0.0036 - val_mae: 0.0561\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0368 - mae: 0.1383 - val_loss: 0.0042 - val_mae: 0.0612\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0401 - mae: 0.1437 - val_loss: 0.0044 - val_mae: 0.0623\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0403 - mae: 0.1571 - val_loss: 0.0047 - val_mae: 0.0646\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0360 - mae: 0.1419 - val_loss: 0.0048 - val_mae: 0.0656\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0278 - mae: 0.1180 - val_loss: 0.0051 - val_mae: 0.0680\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0509 - mae: 0.1451 - val_loss: 0.0049 - val_mae: 0.0663\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0347 - mae: 0.1207 - val_loss: 0.0046 - val_mae: 0.0643\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0220 - mae: 0.1031 - val_loss: 0.0043 - val_mae: 0.0616\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0246 - mae: 0.1102 - val_loss: 0.0041 - val_mae: 0.0606\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0299 - mae: 0.1170 - val_loss: 0.0042 - val_mae: 0.0608\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0288 - mae: 0.1242 - val_loss: 0.0043 - val_mae: 0.0617\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0397 - mae: 0.1403 - val_loss: 0.0048 - val_mae: 0.0660\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0326 - mae: 0.1298 - val_loss: 0.0048 - val_mae: 0.0656\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0208 - mae: 0.1045 - val_loss: 0.0043 - val_mae: 0.0621\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0364 - mae: 0.1211 - val_loss: 0.0040 - val_mae: 0.0595\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 0.1178 - val_loss: 0.0041 - val_mae: 0.0606\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0293 - mae: 0.1131 - val_loss: 0.0042 - val_mae: 0.0608\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0299 - mae: 0.1201 - val_loss: 0.0041 - val_mae: 0.0602\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0932 - val_loss: 0.0038 - val_mae: 0.0576\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0434 - mae: 0.1316 - val_loss: 0.0043 - val_mae: 0.0617\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0441 - mae: 0.1305 - val_loss: 0.0048 - val_mae: 0.0654\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0238 - mae: 0.1080 - val_loss: 0.0043 - val_mae: 0.0621\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0271 - mae: 0.1196 - val_loss: 0.0038 - val_mae: 0.0580\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0541 - mae: 0.1333 - val_loss: 0.0045 - val_mae: 0.0634\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0256 - mae: 0.1096 - val_loss: 0.0048 - val_mae: 0.0657\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0230 - mae: 0.1108 - val_loss: 0.0044 - val_mae: 0.0624\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0300 - mae: 0.1136 - val_loss: 0.0040 - val_mae: 0.0596\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0218 - mae: 0.1066 - val_loss: 0.0034 - val_mae: 0.0543\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0304 - mae: 0.1234 - val_loss: 0.0032 - val_mae: 0.0519\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0259 - mae: 0.1105 - val_loss: 0.0029 - val_mae: 0.0488\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0319 - mae: 0.1106 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1070 - val_loss: 0.0032 - val_mae: 0.0521\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0226 - mae: 0.1090 - val_loss: 0.0034 - val_mae: 0.0537\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0995 - val_loss: 0.0038 - val_mae: 0.0575\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - mae: 0.1040 - val_loss: 0.0039 - val_mae: 0.0588\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1007 - val_loss: 0.0036 - val_mae: 0.0558\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0199 - mae: 0.0951 - val_loss: 0.0035 - val_mae: 0.0545\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0291 - mae: 0.1147 - val_loss: 0.0033 - val_mae: 0.0529\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0236 - mae: 0.1162 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.1064 - val_loss: 0.0032 - val_mae: 0.0517\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.1052 - val_loss: 0.0036 - val_mae: 0.0560\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0780 - val_loss: 0.0036 - val_mae: 0.0563\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.1086 - val_loss: 0.0032 - val_mae: 0.0526\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0210 - mae: 0.1054 - val_loss: 0.0031 - val_mae: 0.0508\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.1059 - val_loss: 0.0027 - val_mae: 0.0471\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0838 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - mae: 0.0991 - val_loss: 0.0028 - val_mae: 0.0477\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0962 - val_loss: 0.0027 - val_mae: 0.0467\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0219 - mae: 0.1050 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - mae: 0.1077 - val_loss: 0.0027 - val_mae: 0.0473\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - mae: 0.1054 - val_loss: 0.0027 - val_mae: 0.0470\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0190 - mae: 0.0954 - val_loss: 0.0027 - val_mae: 0.0467\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - mae: 0.0908 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0726 - val_loss: 0.0025 - val_mae: 0.0447\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.0881 - val_loss: 0.0026 - val_mae: 0.0462\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0951 - val_loss: 0.0025 - val_mae: 0.0444\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0852 - val_loss: 0.0027 - val_mae: 0.0474\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0925 - val_loss: 0.0028 - val_mae: 0.0480\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0188 - mae: 0.0950 - val_loss: 0.0029 - val_mae: 0.0490\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0802 - val_loss: 0.0033 - val_mae: 0.0528\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0187 - mae: 0.0854 - val_loss: 0.0033 - val_mae: 0.0529\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0932 - val_loss: 0.0030 - val_mae: 0.0501\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0750 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0214 - mae: 0.0972 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0787 - val_loss: 0.0028 - val_mae: 0.0478\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0191 - mae: 0.0901 - val_loss: 0.0029 - val_mae: 0.0494\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0210 - mae: 0.0856 - val_loss: 0.0030 - val_mae: 0.0503\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0173 - mae: 0.0816 - val_loss: 0.0038 - val_mae: 0.0577\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0149 - mae: 0.0867 - val_loss: 0.0035 - val_mae: 0.0551\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0797 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0744 - val_loss: 0.0029 - val_mae: 0.0493\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0884 - val_loss: 0.0026 - val_mae: 0.0463\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0729 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0265 - mae: 0.0984 - val_loss: 0.0023 - val_mae: 0.0431\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0857 - val_loss: 0.0023 - val_mae: 0.0428\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0753 - val_loss: 0.0022 - val_mae: 0.0418\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0188 - mae: 0.0847 - val_loss: 0.0022 - val_mae: 0.0412\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0916 - val_loss: 0.0021 - val_mae: 0.0404\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0140 - mae: 0.0790 - val_loss: 0.0020 - val_mae: 0.0396\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0145 - mae: 0.0803 - val_loss: 0.0022 - val_mae: 0.0418\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - mae: 0.0807 - val_loss: 0.0023 - val_mae: 0.0427\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0165 - mae: 0.0842 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0818 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0788 - val_loss: 0.0027 - val_mae: 0.0470\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0806 - val_loss: 0.0029 - val_mae: 0.0490\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0759 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0750 - val_loss: 0.0021 - val_mae: 0.0401\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0128 - mae: 0.0754 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0815 - val_loss: 0.0021 - val_mae: 0.0397\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0673 - val_loss: 0.0022 - val_mae: 0.0410\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.0735 - val_loss: 0.0023 - val_mae: 0.0430\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0687 - val_loss: 0.0024 - val_mae: 0.0441\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0142 - mae: 0.0810 - val_loss: 0.0024 - val_mae: 0.0434\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0236 - mae: 0.0880 - val_loss: 0.0023 - val_mae: 0.0428\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0125 - mae: 0.0686 - val_loss: 0.0031 - val_mae: 0.0509\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0156 - mae: 0.0687 - val_loss: 0.0027 - val_mae: 0.0469\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0126 - mae: 0.0740 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0166 - mae: 0.0816 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0110 - mae: 0.0724 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - mae: 0.0783 - val_loss: 0.0021 - val_mae: 0.0406\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0168 - mae: 0.0791 - val_loss: 0.0022 - val_mae: 0.0411\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - mae: 0.0709 - val_loss: 0.0025 - val_mae: 0.0451\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0241 - mae: 0.0954 - val_loss: 0.0022 - val_mae: 0.0421\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0619 - val_loss: 0.0020 - val_mae: 0.0386\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - mae: 0.0850 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0137 - mae: 0.0732 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0747 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0181 - mae: 0.0781 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - mae: 0.0685 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0732 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - mae: 0.0733 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0657 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0109 - mae: 0.0724 - val_loss: 0.0020 - val_mae: 0.0385\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0123 - mae: 0.0658 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.0669 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0114 - mae: 0.0653 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0714 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0562 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0647 - val_loss: 0.0017 - val_mae: 0.0351\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0748 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0152 - mae: 0.0776 - val_loss: 0.0018 - val_mae: 0.0362\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0689 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0508 - val_loss: 0.0015 - val_mae: 0.0322\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0759 - val_loss: 0.0013 - val_mae: 0.0286\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0536 - val_loss: 0.0014 - val_mae: 0.0311\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.0625 - val_loss: 0.0014 - val_mae: 0.0312\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0137 - mae: 0.0795 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0714 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0729 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.0672 - val_loss: 0.0015 - val_mae: 0.0319\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0634 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0634 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0302 - mae: 0.0846 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0129 - mae: 0.0621 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0671 - val_loss: 0.0015 - val_mae: 0.0325\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0536 - val_loss: 0.0017 - val_mae: 0.0344\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0705 - val_loss: 0.0018 - val_mae: 0.0367\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0629 - val_loss: 0.0019 - val_mae: 0.0376\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0614 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0688 - val_loss: 0.0016 - val_mae: 0.0329\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0634 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0626 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0549 - val_loss: 0.0013 - val_mae: 0.0300\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0588 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0505 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0559 - val_loss: 0.0012 - val_mae: 0.0276\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0635 - val_loss: 8.8859e-04 - val_mae: 0.0226\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0672 - val_loss: 8.3307e-04 - val_mae: 0.0215\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0573 - val_loss: 9.2704e-04 - val_mae: 0.0233\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0656 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0609 - val_loss: 0.0012 - val_mae: 0.0277\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0604 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0564 - val_loss: 0.0014 - val_mae: 0.0308\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0637 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0522 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0671 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0543 - val_loss: 0.0011 - val_mae: 0.0260\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0639 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0563 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0649 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0582 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0600 - val_loss: 0.0013 - val_mae: 0.0288\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0551 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0494 - val_loss: 0.0014 - val_mae: 0.0306\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0523 - val_loss: 0.0015 - val_mae: 0.0323\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0528 - val_loss: 0.0013 - val_mae: 0.0289\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0511 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0612 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0623 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0475 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0553 - val_loss: 0.0011 - val_mae: 0.0261\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0558 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0490 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0521 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0522 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0481 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0148 - mae: 0.0629 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0503 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0546 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0585 - val_loss: 0.0017 - val_mae: 0.0349\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0487 - val_loss: 0.0016 - val_mae: 0.0332\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0578 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0451 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0480 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0452 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0480 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0479 - val_loss: 9.9670e-04 - val_mae: 0.0246\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0526 - val_loss: 9.7728e-04 - val_mae: 0.0243\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0432 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0543 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0496 - val_loss: 0.0013 - val_mae: 0.0299\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0525 - val_loss: 0.0012 - val_mae: 0.0278\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0490 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0528 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - mae: 0.0498 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0552 - val_loss: 6.4918e-04 - val_mae: 0.0169\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0538 - val_loss: 7.2431e-04 - val_mae: 0.0190\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0494 - val_loss: 7.1786e-04 - val_mae: 0.0188\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - mae: 0.0517 - val_loss: 7.8684e-04 - val_mae: 0.0205\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - mae: 0.0538 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0054 - mae: 0.0416 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - mae: 0.0480 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0508 - val_loss: 8.9317e-04 - val_mae: 0.0227\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0425 - val_loss: 9.7783e-04 - val_mae: 0.0243\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0070 - mae: 0.0448 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0512 - val_loss: 9.5342e-04 - val_mae: 0.0238\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0476 - val_loss: 8.7778e-04 - val_mae: 0.0224\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0070 - mae: 0.0459 - val_loss: 8.6800e-04 - val_mae: 0.0222\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0381 - val_loss: 9.0626e-04 - val_mae: 0.0229\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0502 - val_loss: 8.5457e-04 - val_mae: 0.0219\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0502 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0068 - mae: 0.0438 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_24\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_288 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_264 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_289 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_265 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_290 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_266 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_291 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_267 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_292 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_268 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_293 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_269 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_294 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_270 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_295 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_271 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_296 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_272 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_297 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_273 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_298 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_274 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_299 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 29.5599 - mae: 4.1790 - val_loss: 0.5033 - val_mae: 0.7087\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 11.3503 - mae: 2.3204 - val_loss: 0.0301 - val_mae: 0.1720\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 6.3676 - mae: 1.8766 - val_loss: 0.0391 - val_mae: 0.1965\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 5.6728 - mae: 1.4850 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.9365 - mae: 1.1996 - val_loss: 0.0059 - val_mae: 0.0732\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.7049 - mae: 1.0021 - val_loss: 0.0159 - val_mae: 0.1234\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8356 - mae: 1.0025 - val_loss: 0.0138 - val_mae: 0.1154\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.3943 - mae: 0.9041 - val_loss: 0.0128 - val_mae: 0.1114\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0742 - mae: 0.7518 - val_loss: 0.0277 - val_mae: 0.1651\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.2498 - mae: 0.8524 - val_loss: 0.0201 - val_mae: 0.1399\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1890 - mae: 0.7917 - val_loss: 0.0292 - val_mae: 0.1694\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7482 - mae: 0.6669 - val_loss: 0.0239 - val_mae: 0.1531\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8365 - mae: 0.6877 - val_loss: 0.0162 - val_mae: 0.1256\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.9607 - mae: 0.6623 - val_loss: 0.0166 - val_mae: 0.1271\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6185 - mae: 0.5787 - val_loss: 0.0155 - val_mae: 0.1229\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5881 - mae: 0.6029 - val_loss: 0.0071 - val_mae: 0.0817\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6673 - mae: 0.6172 - val_loss: 0.0087 - val_mae: 0.0905\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3745 - mae: 0.4612 - val_loss: 0.0080 - val_mae: 0.0869\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6099 - mae: 0.5418 - val_loss: 0.0099 - val_mae: 0.0974\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4294 - mae: 0.4904 - val_loss: 0.0100 - val_mae: 0.0970\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.5120 - mae: 0.4988 - val_loss: 0.0098 - val_mae: 0.0966\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4139 - mae: 0.4594 - val_loss: 0.0059 - val_mae: 0.0733\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3573 - mae: 0.4111 - val_loss: 0.0060 - val_mae: 0.0741\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2839 - mae: 0.4019 - val_loss: 0.0065 - val_mae: 0.0769\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4158 - mae: 0.4741 - val_loss: 0.0048 - val_mae: 0.0654\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4147 - mae: 0.4300 - val_loss: 0.0030 - val_mae: 0.0510\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2671 - mae: 0.3905 - val_loss: 0.0042 - val_mae: 0.0615\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2362 - mae: 0.3668 - val_loss: 0.0047 - val_mae: 0.0654\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2007 - mae: 0.3452 - val_loss: 0.0057 - val_mae: 0.0727\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2937 - mae: 0.4226 - val_loss: 0.0078 - val_mae: 0.0858\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2884 - mae: 0.3902 - val_loss: 0.0073 - val_mae: 0.0827\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2241 - mae: 0.3496 - val_loss: 0.0061 - val_mae: 0.0753\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3318 - mae: 0.4033 - val_loss: 0.0084 - val_mae: 0.0890\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2182 - mae: 0.3489 - val_loss: 0.0098 - val_mae: 0.0965\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2771 - mae: 0.3931 - val_loss: 0.0113 - val_mae: 0.1041\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1917 - mae: 0.3006 - val_loss: 0.0115 - val_mae: 0.1050\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2196 - mae: 0.3413 - val_loss: 0.0119 - val_mae: 0.1067\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1892 - mae: 0.3195 - val_loss: 0.0139 - val_mae: 0.1156\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1460 - mae: 0.2698 - val_loss: 0.0139 - val_mae: 0.1158\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1276 - mae: 0.2636 - val_loss: 0.0135 - val_mae: 0.1143\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2488 - mae: 0.3373 - val_loss: 0.0156 - val_mae: 0.1230\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1428 - mae: 0.2596 - val_loss: 0.0155 - val_mae: 0.1225\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2520 - mae: 0.3653 - val_loss: 0.0121 - val_mae: 0.1078\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1385 - mae: 0.2741 - val_loss: 0.0094 - val_mae: 0.0946\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1270 - mae: 0.2648 - val_loss: 0.0091 - val_mae: 0.0930\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1478 - mae: 0.2704 - val_loss: 0.0102 - val_mae: 0.0988\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1408 - mae: 0.2492 - val_loss: 0.0106 - val_mae: 0.1008\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1118 - mae: 0.2481 - val_loss: 0.0112 - val_mae: 0.1037\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1089 - mae: 0.2444 - val_loss: 0.0097 - val_mae: 0.0960\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1378 - mae: 0.2613 - val_loss: 0.0092 - val_mae: 0.0935\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1133 - mae: 0.2376 - val_loss: 0.0083 - val_mae: 0.0885\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0890 - mae: 0.2187 - val_loss: 0.0099 - val_mae: 0.0968\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1240 - mae: 0.2553 - val_loss: 0.0112 - val_mae: 0.1034\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1426 - mae: 0.2757 - val_loss: 0.0127 - val_mae: 0.1105\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1006 - mae: 0.2320 - val_loss: 0.0128 - val_mae: 0.1108\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1043 - mae: 0.2460 - val_loss: 0.0120 - val_mae: 0.1072\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0610 - mae: 0.1822 - val_loss: 0.0111 - val_mae: 0.1028\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0781 - mae: 0.2048 - val_loss: 0.0108 - val_mae: 0.1016\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0910 - mae: 0.2361 - val_loss: 0.0100 - val_mae: 0.0976\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0746 - mae: 0.1952 - val_loss: 0.0092 - val_mae: 0.0934\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1032 - mae: 0.2105 - val_loss: 0.0090 - val_mae: 0.0924\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0884 - mae: 0.2142 - val_loss: 0.0081 - val_mae: 0.0873\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0756 - mae: 0.1826 - val_loss: 0.0071 - val_mae: 0.0817\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0690 - mae: 0.2008 - val_loss: 0.0068 - val_mae: 0.0793\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1122 - mae: 0.2442 - val_loss: 0.0069 - val_mae: 0.0804\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0756 - mae: 0.1975 - val_loss: 0.0069 - val_mae: 0.0799\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1430 - mae: 0.2488 - val_loss: 0.0073 - val_mae: 0.0827\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0675 - mae: 0.1919 - val_loss: 0.0076 - val_mae: 0.0847\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1169 - mae: 0.2266 - val_loss: 0.0070 - val_mae: 0.0810\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0473 - mae: 0.1667 - val_loss: 0.0060 - val_mae: 0.0743\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0800 - mae: 0.2046 - val_loss: 0.0057 - val_mae: 0.0725\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0493 - mae: 0.1654 - val_loss: 0.0059 - val_mae: 0.0740\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0771 - mae: 0.1979 - val_loss: 0.0059 - val_mae: 0.0738\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0422 - mae: 0.1636 - val_loss: 0.0064 - val_mae: 0.0768\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0961 - mae: 0.2033 - val_loss: 0.0066 - val_mae: 0.0786\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0719 - mae: 0.1932 - val_loss: 0.0068 - val_mae: 0.0798\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0754 - mae: 0.2011 - val_loss: 0.0063 - val_mae: 0.0765\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0878 - mae: 0.2058 - val_loss: 0.0059 - val_mae: 0.0736\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0687 - mae: 0.1876 - val_loss: 0.0062 - val_mae: 0.0758\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0869 - mae: 0.2135 - val_loss: 0.0062 - val_mae: 0.0755\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0632 - mae: 0.1892 - val_loss: 0.0070 - val_mae: 0.0809\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0571 - mae: 0.1782 - val_loss: 0.0069 - val_mae: 0.0800\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0468 - mae: 0.1648 - val_loss: 0.0062 - val_mae: 0.0759\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0521 - mae: 0.1575 - val_loss: 0.0055 - val_mae: 0.0707\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0396 - mae: 0.1402 - val_loss: 0.0052 - val_mae: 0.0686\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0539 - mae: 0.1673 - val_loss: 0.0054 - val_mae: 0.0700\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0556 - mae: 0.1666 - val_loss: 0.0059 - val_mae: 0.0736\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0597 - mae: 0.1789 - val_loss: 0.0072 - val_mae: 0.0819\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0806 - mae: 0.1851 - val_loss: 0.0079 - val_mae: 0.0863\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0502 - mae: 0.1557 - val_loss: 0.0076 - val_mae: 0.0847\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0523 - mae: 0.1646 - val_loss: 0.0072 - val_mae: 0.0818\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0479 - mae: 0.1561 - val_loss: 0.0069 - val_mae: 0.0801\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0366 - mae: 0.1503 - val_loss: 0.0065 - val_mae: 0.0779\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0477 - mae: 0.1413 - val_loss: 0.0069 - val_mae: 0.0801\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0318 - mae: 0.1283 - val_loss: 0.0064 - val_mae: 0.0770\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0426 - mae: 0.1441 - val_loss: 0.0056 - val_mae: 0.0716\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0413 - mae: 0.1419 - val_loss: 0.0051 - val_mae: 0.0677\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0401 - mae: 0.1308 - val_loss: 0.0041 - val_mae: 0.0606\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0468 - mae: 0.1446 - val_loss: 0.0036 - val_mae: 0.0560\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0367 - mae: 0.1330 - val_loss: 0.0037 - val_mae: 0.0565\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0248 - mae: 0.1221 - val_loss: 0.0048 - val_mae: 0.0658\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0511 - mae: 0.1655 - val_loss: 0.0058 - val_mae: 0.0730\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0490 - mae: 0.1547 - val_loss: 0.0055 - val_mae: 0.0706\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0334 - mae: 0.1355 - val_loss: 0.0056 - val_mae: 0.0714\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0408 - mae: 0.1451 - val_loss: 0.0053 - val_mae: 0.0696\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0322 - mae: 0.1285 - val_loss: 0.0052 - val_mae: 0.0691\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0247 - mae: 0.1224 - val_loss: 0.0056 - val_mae: 0.0715\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0467 - mae: 0.1600 - val_loss: 0.0057 - val_mae: 0.0722\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0269 - mae: 0.1338 - val_loss: 0.0054 - val_mae: 0.0700\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0466 - mae: 0.1545 - val_loss: 0.0051 - val_mae: 0.0680\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0358 - mae: 0.1267 - val_loss: 0.0050 - val_mae: 0.0677\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0273 - mae: 0.1227 - val_loss: 0.0051 - val_mae: 0.0679\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0290 - mae: 0.1270 - val_loss: 0.0055 - val_mae: 0.0710\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0465 - mae: 0.1475 - val_loss: 0.0050 - val_mae: 0.0677\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0423 - mae: 0.1531 - val_loss: 0.0050 - val_mae: 0.0672\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0292 - mae: 0.1254 - val_loss: 0.0047 - val_mae: 0.0652\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0419 - mae: 0.1249 - val_loss: 0.0053 - val_mae: 0.0698\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0296 - mae: 0.1313 - val_loss: 0.0049 - val_mae: 0.0663\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0474 - mae: 0.1428 - val_loss: 0.0052 - val_mae: 0.0687\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0332 - mae: 0.1336 - val_loss: 0.0050 - val_mae: 0.0677\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0599 - mae: 0.1603 - val_loss: 0.0044 - val_mae: 0.0630\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0243 - mae: 0.1169 - val_loss: 0.0050 - val_mae: 0.0675\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0320 - mae: 0.1249 - val_loss: 0.0050 - val_mae: 0.0672\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0301 - mae: 0.1217 - val_loss: 0.0047 - val_mae: 0.0648\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0341 - mae: 0.1295 - val_loss: 0.0050 - val_mae: 0.0671\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0250 - mae: 0.1223 - val_loss: 0.0049 - val_mae: 0.0662\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0303 - mae: 0.1323 - val_loss: 0.0052 - val_mae: 0.0685\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0301 - mae: 0.1203 - val_loss: 0.0051 - val_mae: 0.0684\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0257 - mae: 0.1140 - val_loss: 0.0050 - val_mae: 0.0676\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1128 - val_loss: 0.0051 - val_mae: 0.0679\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0263 - mae: 0.1140 - val_loss: 0.0050 - val_mae: 0.0673\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0246 - mae: 0.1178 - val_loss: 0.0053 - val_mae: 0.0692\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1004 - val_loss: 0.0052 - val_mae: 0.0685\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0243 - mae: 0.1143 - val_loss: 0.0048 - val_mae: 0.0656\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0208 - mae: 0.1056 - val_loss: 0.0047 - val_mae: 0.0654\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0208 - mae: 0.0991 - val_loss: 0.0049 - val_mae: 0.0664\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0216 - mae: 0.1056 - val_loss: 0.0044 - val_mae: 0.0626\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1188 - val_loss: 0.0039 - val_mae: 0.0584\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0242 - mae: 0.0953 - val_loss: 0.0044 - val_mae: 0.0627\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0208 - mae: 0.1037 - val_loss: 0.0049 - val_mae: 0.0667\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0211 - mae: 0.1025 - val_loss: 0.0053 - val_mae: 0.0692\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0176 - mae: 0.0976 - val_loss: 0.0049 - val_mae: 0.0662\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.0951 - val_loss: 0.0045 - val_mae: 0.0633\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0288 - mae: 0.1108 - val_loss: 0.0050 - val_mae: 0.0675\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - mae: 0.0936 - val_loss: 0.0050 - val_mae: 0.0671\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0179 - mae: 0.0923 - val_loss: 0.0040 - val_mae: 0.0596\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0274 - mae: 0.1089 - val_loss: 0.0035 - val_mae: 0.0547\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.1084 - val_loss: 0.0033 - val_mae: 0.0531\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0942 - val_loss: 0.0032 - val_mae: 0.0525\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0282 - mae: 0.1085 - val_loss: 0.0032 - val_mae: 0.0525\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0152 - mae: 0.0865 - val_loss: 0.0036 - val_mae: 0.0561\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0228 - mae: 0.1014 - val_loss: 0.0036 - val_mae: 0.0558\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0824 - val_loss: 0.0035 - val_mae: 0.0548\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0174 - mae: 0.1010 - val_loss: 0.0034 - val_mae: 0.0538\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0313 - mae: 0.1163 - val_loss: 0.0032 - val_mae: 0.0520\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.0996 - val_loss: 0.0033 - val_mae: 0.0532\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.0943 - val_loss: 0.0029 - val_mae: 0.0495\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0240 - mae: 0.1071 - val_loss: 0.0028 - val_mae: 0.0487\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - mae: 0.0867 - val_loss: 0.0029 - val_mae: 0.0495\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1033 - val_loss: 0.0028 - val_mae: 0.0479\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0841 - val_loss: 0.0024 - val_mae: 0.0444\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.0761 - val_loss: 0.0025 - val_mae: 0.0452\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0176 - mae: 0.1008 - val_loss: 0.0026 - val_mae: 0.0457\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0166 - mae: 0.0962 - val_loss: 0.0033 - val_mae: 0.0532\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.0957 - val_loss: 0.0032 - val_mae: 0.0522\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0212 - mae: 0.0992 - val_loss: 0.0031 - val_mae: 0.0511\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0196 - mae: 0.1033 - val_loss: 0.0032 - val_mae: 0.0526\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0198 - mae: 0.0961 - val_loss: 0.0035 - val_mae: 0.0548\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0143 - mae: 0.0817 - val_loss: 0.0036 - val_mae: 0.0560\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - mae: 0.0856 - val_loss: 0.0033 - val_mae: 0.0533\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0887 - val_loss: 0.0032 - val_mae: 0.0527\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.0929 - val_loss: 0.0031 - val_mae: 0.0517\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0729 - val_loss: 0.0038 - val_mae: 0.0579\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.0899 - val_loss: 0.0039 - val_mae: 0.0590\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0320 - mae: 0.0900 - val_loss: 0.0036 - val_mae: 0.0558\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0166 - mae: 0.0849 - val_loss: 0.0036 - val_mae: 0.0562\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0124 - mae: 0.0759 - val_loss: 0.0038 - val_mae: 0.0575\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0228 - mae: 0.0955 - val_loss: 0.0036 - val_mae: 0.0560\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0139 - mae: 0.0853 - val_loss: 0.0033 - val_mae: 0.0536\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0861 - val_loss: 0.0033 - val_mae: 0.0533\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0734 - val_loss: 0.0028 - val_mae: 0.0486\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0729 - val_loss: 0.0027 - val_mae: 0.0468\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - mae: 0.0746 - val_loss: 0.0027 - val_mae: 0.0472\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0271 - mae: 0.1005 - val_loss: 0.0023 - val_mae: 0.0429\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0153 - mae: 0.0832 - val_loss: 0.0020 - val_mae: 0.0390\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0136 - mae: 0.0832 - val_loss: 0.0026 - val_mae: 0.0463\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0183 - mae: 0.0819 - val_loss: 0.0028 - val_mae: 0.0478\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.0931 - val_loss: 0.0028 - val_mae: 0.0482\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - mae: 0.0787 - val_loss: 0.0027 - val_mae: 0.0477\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0207 - mae: 0.0942 - val_loss: 0.0027 - val_mae: 0.0473\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0110 - mae: 0.0744 - val_loss: 0.0023 - val_mae: 0.0426\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - mae: 0.0818 - val_loss: 0.0022 - val_mae: 0.0411\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0640 - val_loss: 0.0024 - val_mae: 0.0440\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0811 - val_loss: 0.0028 - val_mae: 0.0485\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0092 - mae: 0.0725 - val_loss: 0.0033 - val_mae: 0.0532\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0129 - mae: 0.0798 - val_loss: 0.0032 - val_mae: 0.0526\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0141 - mae: 0.0766 - val_loss: 0.0025 - val_mae: 0.0445\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.0749 - val_loss: 0.0021 - val_mae: 0.0408\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0755 - val_loss: 0.0021 - val_mae: 0.0409\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.0695 - val_loss: 0.0021 - val_mae: 0.0405\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0646 - val_loss: 0.0017 - val_mae: 0.0347\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0131 - mae: 0.0728 - val_loss: 0.0019 - val_mae: 0.0381\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0648 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.0851 - val_loss: 0.0021 - val_mae: 0.0398\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0180 - mae: 0.0853 - val_loss: 0.0019 - val_mae: 0.0372\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0689 - val_loss: 0.0021 - val_mae: 0.0401\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0811 - val_loss: 0.0019 - val_mae: 0.0380\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0720 - val_loss: 0.0021 - val_mae: 0.0401\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0691 - val_loss: 0.0024 - val_mae: 0.0439\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0675 - val_loss: 0.0023 - val_mae: 0.0425\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.0870 - val_loss: 0.0022 - val_mae: 0.0413\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0677 - val_loss: 0.0022 - val_mae: 0.0414\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0702 - val_loss: 0.0020 - val_mae: 0.0395\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0610 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0658 - val_loss: 0.0019 - val_mae: 0.0379\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0715 - val_loss: 0.0020 - val_mae: 0.0387\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0705 - val_loss: 0.0022 - val_mae: 0.0412\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0169 - mae: 0.0778 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0605 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0642 - val_loss: 0.0022 - val_mae: 0.0416\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0599 - val_loss: 0.0022 - val_mae: 0.0417\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0558 - val_loss: 0.0019 - val_mae: 0.0375\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0568 - val_loss: 0.0019 - val_mae: 0.0382\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.0729 - val_loss: 0.0017 - val_mae: 0.0355\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0621 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0643 - val_loss: 0.0018 - val_mae: 0.0369\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0135 - mae: 0.0686 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0641 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0626 - val_loss: 0.0023 - val_mae: 0.0426\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0643 - val_loss: 0.0027 - val_mae: 0.0467\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0739 - val_loss: 0.0023 - val_mae: 0.0424\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0635 - val_loss: 0.0021 - val_mae: 0.0399\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0656 - val_loss: 0.0026 - val_mae: 0.0457\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0584 - val_loss: 0.0029 - val_mae: 0.0491\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0592 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0611 - val_loss: 0.0020 - val_mae: 0.0389\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0496 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0611 - val_loss: 0.0023 - val_mae: 0.0423\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0540 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0577 - val_loss: 0.0025 - val_mae: 0.0455\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0666 - val_loss: 0.0024 - val_mae: 0.0433\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0642 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0620 - val_loss: 0.0021 - val_mae: 0.0400\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0582 - val_loss: 0.0020 - val_mae: 0.0393\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0115 - mae: 0.0619 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0553 - val_loss: 0.0018 - val_mae: 0.0360\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0651 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0588 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0564 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0575 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0148 - mae: 0.0609 - val_loss: 0.0015 - val_mae: 0.0321\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0562 - val_loss: 0.0018 - val_mae: 0.0363\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0481 - val_loss: 0.0020 - val_mae: 0.0391\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0568 - val_loss: 0.0022 - val_mae: 0.0419\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0156 - mae: 0.0694 - val_loss: 0.0025 - val_mae: 0.0453\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0687 - val_loss: 0.0024 - val_mae: 0.0442\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0480 - val_loss: 0.0021 - val_mae: 0.0400\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0333\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0553 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0521 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0524 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0592 - val_loss: 0.0019 - val_mae: 0.0374\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0494 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0658 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0479 - val_loss: 0.0015 - val_mae: 0.0317\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0521 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0536 - val_loss: 0.0015 - val_mae: 0.0314\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0592 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0547 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0573 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0463 - val_loss: 0.0013 - val_mae: 0.0293\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0500 - val_loss: 0.0016 - val_mae: 0.0334\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0629 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0544 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0558 - val_loss: 0.0012 - val_mae: 0.0274\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0503 - val_loss: 0.0016 - val_mae: 0.0343\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0537 - val_loss: 0.0019 - val_mae: 0.0378\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0564 - val_loss: 0.0017 - val_mae: 0.0354\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0493 - val_loss: 0.0013 - val_mae: 0.0290\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0104 - mae: 0.0601 - val_loss: 0.0013 - val_mae: 0.0297\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0563 - val_loss: 0.0018 - val_mae: 0.0368\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0490 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0477 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0503 - val_loss: 0.0016 - val_mae: 0.0336\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0633 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0070 - mae: 0.0463 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - mae: 0.0511 - val_loss: 0.0013 - val_mae: 0.0292\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - mae: 0.0529 - val_loss: 0.0012 - val_mae: 0.0271\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0059 - mae: 0.0461 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - mae: 0.0585 - val_loss: 0.0011 - val_mae: 0.0266\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0070 - mae: 0.0446 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0078 - mae: 0.0523 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0472 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0499 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0523 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0062 - mae: 0.0455 - val_loss: 0.0012 - val_mae: 0.0282\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0072 - mae: 0.0502 - val_loss: 0.0014 - val_mae: 0.0305\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0399 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0503 - val_loss: 0.0012 - val_mae: 0.0280\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0422 - val_loss: 0.0013 - val_mae: 0.0295\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - mae: 0.0468 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0510 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0534 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0509 - val_loss: 0.0015 - val_mae: 0.0320\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0492 - val_loss: 0.0015 - val_mae: 0.0326\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0441 - val_loss: 0.0015 - val_mae: 0.0315\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0422 - val_loss: 0.0015 - val_mae: 0.0313\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0092 - mae: 0.0512 - val_loss: 0.0015 - val_mae: 0.0318\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0438 - val_loss: 0.0017 - val_mae: 0.0353\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0470 - val_loss: 0.0015 - val_mae: 0.0324\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0468 - val_loss: 0.0012 - val_mae: 0.0273\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0458 - val_loss: 0.0012 - val_mae: 0.0279\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0493 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0590 - val_loss: 0.0017 - val_mae: 0.0357\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0423 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0433 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0383 - val_loss: 0.0012 - val_mae: 0.0283\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0442 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0430 - val_loss: 0.0011 - val_mae: 0.0255\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0466 - val_loss: 0.0013 - val_mae: 0.0298\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0499 - val_loss: 0.0014 - val_mae: 0.0313\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0420 - val_loss: 0.0014 - val_mae: 0.0309\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0389 - val_loss: 0.0011 - val_mae: 0.0257\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0479 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0460 - val_loss: 0.0013 - val_mae: 0.0294\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0455 - val_loss: 0.0014 - val_mae: 0.0301\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0407 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0529 - val_loss: 0.0014 - val_mae: 0.0303\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0410 - val_loss: 9.1539e-04 - val_mae: 0.0231\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0443 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0405 - val_loss: 0.0014 - val_mae: 0.0307\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0497 - val_loss: 0.0016 - val_mae: 0.0331\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0432 - val_loss: 0.0014 - val_mae: 0.0310\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0419 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0420 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0399 - val_loss: 0.0010 - val_mae: 0.0253\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0256\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0433 - val_loss: 8.3663e-04 - val_mae: 0.0215\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0444 - val_loss: 8.3213e-04 - val_mae: 0.0215\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0469 - val_loss: 0.0012 - val_mae: 0.0275\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0394 - val_loss: 0.0012 - val_mae: 0.0281\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0409 - val_loss: 0.0012 - val_mae: 0.0272\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0416 - val_loss: 0.0013 - val_mae: 0.0291\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0406 - val_loss: 9.8990e-04 - val_mae: 0.0245\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0422 - val_loss: 9.8443e-04 - val_mae: 0.0244\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0371 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0369 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resultados"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2UMWlDoax2IL",
        "outputId": "0d5dc27a-63b4-4586-bd18-e6085c49d275"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[         loss       mae  val_loss   val_mae\n",
              " 0    0.175210  0.345271  0.003942  0.058652\n",
              " 1    0.090000  0.247114  0.004112  0.060430\n",
              " 2    0.100610  0.255825  0.001503  0.037011\n",
              " 3    0.064335  0.195763  0.001121  0.026579\n",
              " 4    0.062428  0.187573  0.002862  0.048840\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004924  0.028834  0.001226  0.028246\n",
              " 346  0.005485  0.042340  0.001159  0.027240\n",
              " 347  0.004606  0.029785  0.002336  0.043162\n",
              " 348  0.003640  0.032923  0.003250  0.052704\n",
              " 349  0.004141  0.034487  0.002295  0.042689\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.188606  0.340928  0.028332  0.166606\n",
              " 1    0.153536  0.291474  0.062951  0.249894\n",
              " 2    0.135927  0.297504  0.002184  0.044256\n",
              " 3    0.081854  0.236055  0.004192  0.061109\n",
              " 4    0.089231  0.235586  0.004145  0.060649\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.003122  0.027778  0.002417  0.044195\n",
              " 346  0.002696  0.025643  0.003343  0.053701\n",
              " 347  0.003946  0.037615  0.002242  0.042240\n",
              " 348  0.003613  0.032531  0.002174  0.041342\n",
              " 349  0.003241  0.027050  0.003644  0.056389\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.254307  0.417031  0.037828  0.193272\n",
              " 1    0.157507  0.307788  0.002334  0.045809\n",
              " 2    0.132106  0.277075  0.004159  0.060705\n",
              " 3    0.085769  0.230403  0.002937  0.049622\n",
              " 4    0.102581  0.251602  0.006758  0.079257\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.003807  0.029409  0.002424  0.044170\n",
              " 346  0.003584  0.028318  0.003026  0.050518\n",
              " 347  0.004242  0.041169  0.001417  0.030881\n",
              " 348  0.004070  0.041321  0.003914  0.058652\n",
              " 349  0.002977  0.031071  0.002183  0.041349\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    12.655471  2.415752  0.009916  0.096229\n",
              " 1     1.155223  0.812121  0.006728  0.078312\n",
              " 2     0.895273  0.681098  0.008489  0.089520\n",
              " 3     0.485747  0.475970  0.005379  0.069253\n",
              " 4     0.456435  0.496078  0.003551  0.055590\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.004305  0.023347  0.000886  0.022550\n",
              " 346   0.004620  0.029169  0.000616  0.016172\n",
              " 347   0.004395  0.028959  0.000704  0.018455\n",
              " 348   0.004353  0.026825  0.000798  0.020719\n",
              " 349   0.004241  0.023623  0.000865  0.022135\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    55.024132  3.957001  0.035554  0.187431\n",
              " 1     5.211384  1.690649  0.017706  0.130878\n",
              " 2     2.710781  1.194180  0.006949  0.080393\n",
              " 3     1.492535  0.949165  0.001050  0.030342\n",
              " 4     1.548099  0.918151  0.001869  0.033682\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.004418  0.025149  0.000948  0.023718\n",
              " 346   0.004441  0.025164  0.001000  0.024651\n",
              " 347   0.004423  0.024140  0.001014  0.024896\n",
              " 348   0.004408  0.023254  0.000976  0.024243\n",
              " 349   0.004353  0.024199  0.000938  0.023553\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.792213  0.692564  0.005061  0.067683\n",
              " 1    0.619486  0.575610  0.003181  0.052312\n",
              " 2    0.357602  0.383158  0.004996  0.067136\n",
              " 3    0.145854  0.281811  0.003829  0.057412\n",
              " 4    0.138207  0.269773  0.009891  0.096914\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004277  0.023554  0.000850  0.021830\n",
              " 346  0.004335  0.027265  0.000596  0.015820\n",
              " 347  0.004345  0.027897  0.000669  0.017493\n",
              " 348  0.004386  0.027607  0.000738  0.019301\n",
              " 349  0.004275  0.024782  0.000838  0.021567\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.294975  0.457898  0.039334  0.197131\n",
              " 1    0.160841  0.319773  0.002750  0.047710\n",
              " 2    0.144250  0.310785  0.000989  0.024466\n",
              " 3    0.094489  0.236580  0.003361  0.053734\n",
              " 4    0.115296  0.267527  0.009286  0.093874\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004311  0.023584  0.000855  0.021920\n",
              " 346  0.004657  0.025023  0.000849  0.021807\n",
              " 347  0.004360  0.023210  0.000997  0.024614\n",
              " 348  0.004582  0.030903  0.000517  0.014739\n",
              " 349  0.004453  0.030727  0.000702  0.018406\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.128500  0.283084  0.000478  0.014933\n",
              " 1    0.154490  0.313605  0.001116  0.031573\n",
              " 2    0.118525  0.268017  0.002616  0.046283\n",
              " 3    0.091107  0.243582  0.000863  0.027082\n",
              " 4    0.099777  0.251200  0.001224  0.028217\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004384  0.024833  0.000891  0.022652\n",
              " 346  0.004346  0.024167  0.001013  0.024877\n",
              " 347  0.004343  0.024033  0.000931  0.023419\n",
              " 348  0.004365  0.023558  0.001036  0.025268\n",
              " 349  0.004294  0.023636  0.000940  0.023589\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "          loss       mae  val_loss   val_mae\n",
              " 0    0.956661  0.890619  0.150882  0.387825\n",
              " 1    0.190686  0.339889  0.006922  0.080305\n",
              " 2    0.142738  0.302682  0.000939  0.028551\n",
              " 3    0.127145  0.270633  0.001491  0.031900\n",
              " 4    0.124587  0.275515  0.000657  0.022150\n",
              " ..        ...       ...       ...       ...\n",
              " 345  0.004384  0.025631  0.000903  0.022885\n",
              " 346  0.004369  0.022665  0.001046  0.025450\n",
              " 347  0.004291  0.023239  0.000967  0.024080\n",
              " 348  0.004383  0.024054  0.000880  0.022436\n",
              " 349  0.004526  0.025743  0.000854  0.021905\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    24.448860  3.618058  0.754951  0.868649\n",
              " 1     7.172698  1.940048  0.076435  0.275777\n",
              " 2     5.295720  1.680245  0.001669  0.038439\n",
              " 3     2.204934  0.993342  0.001372  0.031097\n",
              " 4     2.398015  1.128518  0.007763  0.085684\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.005243  0.037271  0.001204  0.027920\n",
              " 346   0.006478  0.039313  0.001403  0.030697\n",
              " 347   0.005418  0.035203  0.001262  0.028768\n",
              " 348   0.005013  0.038909  0.001222  0.028188\n",
              " 349   0.005193  0.037013  0.000975  0.024209\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    41.554520  4.881284  0.610281  0.779841\n",
              " 1    10.670478  2.510340  0.341855  0.583610\n",
              " 2     8.999222  2.224482  0.085520  0.291467\n",
              " 3     6.223333  1.766808  0.036305  0.188777\n",
              " 4     4.098312  1.435429  0.010021  0.097128\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.006981  0.045875  0.000868  0.022196\n",
              " 346   0.006829  0.038112  0.000906  0.022947\n",
              " 347   0.008619  0.050247  0.000855  0.021922\n",
              " 348   0.006581  0.050245  0.001126  0.026740\n",
              " 349   0.006790  0.043793  0.001167  0.027371\n",
              " \n",
              " [350 rows x 4 columns],\n",
              "           loss       mae  val_loss   val_mae\n",
              " 0    29.559856  4.178976  0.503292  0.708730\n",
              " 1    11.350302  2.320359  0.030118  0.171954\n",
              " 2     6.367592  1.876555  0.039081  0.196514\n",
              " 3     5.672778  1.485041  0.001108  0.026776\n",
              " 4     2.936496  1.199592  0.005895  0.073245\n",
              " ..         ...       ...       ...       ...\n",
              " 345   0.006514  0.041573  0.001289  0.029146\n",
              " 346   0.005907  0.040572  0.000990  0.024484\n",
              " 347   0.007629  0.042157  0.000984  0.024388\n",
              " 348   0.005301  0.037063  0.001073  0.025894\n",
              " 349   0.005064  0.036927  0.001132  0.026837\n",
              " \n",
              " [350 rows x 4 columns]]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(funcoes)):\n",
        "  for j in range(0, len(taxas)):\n",
        "    plt.plot(resultados[j]['loss'])\n",
        "    plt.plot(resultados[j]['val_loss'])\n",
        "  plt.title(funcoes[i])\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.xlabel('Épocas de treinamento')\n",
        "  plt.legend(['0.005 (loss)', '0.01 (loss)', '0.05 (loss)', '0.005 (val_loss)', '0.01 (val_loss)', '0.05 (val_loss)'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "1lycZhUDlIMp",
        "outputId": "e1a2259e-eee5-4a3b-efa5-ef60c70f5f6a"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHJCAYAAABtzYa7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACn3klEQVR4nOzdd3hUVfrA8e/MZFp6TwiQQm8BAkhAVFQiwYKyKCoWkGXR1XXVRVGxAIqKKLAooKi7oq4gRYX1p4gUwUUIIL2EJi2ENEgvM5l2f38MmTCkQCDMILyf55nHzL3n3HvuEJjX9zSVoigKQgghhBBXEbW3GyCEEEII4WkSAAkhhBDiqiMBkBBCCCGuOhIACSGEEOKqIwGQEEIIIa46EgAJIYQQ4qojAZAQQgghrjoSAAkhhBDiqiMBkBBCCCGuOhIACSGuWo888gjx8fHeboYQwgskABJCCCHEVUcCICGEEEJcdSQAEkJcUcrLy73dBCHEH4AEQEKIP6wJEyagUqlIT0/ngQceICQkhOuuuw6AL7/8ku7du2M0GgkNDeX+++/n+PHj9V5vzZo1qFQq1qxZ43b86NGjqFQqPvvss0v0JEIIT/PxdgOEEOJiDRkyhNatW/PWW2+hKApvvvkmr776Kvfeey9/+ctfOHnyJDNmzOCGG25g27ZtBAcHe7vJQggvkwBICPGH16VLF+bNmwfAsWPHaNmyJW+88QYvvfSSq8zgwYNJSkrigw8+cDsuhLg6SReYEOIP769//avr52+//RaHw8G9997LqVOnXK/o6Ghat27N6tWrvdhSIcTlQjJAQog/vISEBNfPBw8eRFEUWrduXWtZrVbrqWYJIS5jEgAJIf7wjEaj62eHw4FKpeLHH39Eo9HUKOvv71/ndVQqVa3H7Xb7xTdSCHFZkQBICHFFadmyJYqikJCQQJs2bRpUNyQkBICioiK348eOHWus5gkhLhMyBkgIcUUZPHgwGo2G1157DUVR3M4pikJ+fn6ddePi4tBoNPzvf/9zO/7BBx9ckrYKIbxHMkBCiCtK1QywsWPHcvToUQYNGkRAQABHjhxh8eLFPProozz33HO11g0KCmLIkCHMmDEDlUpFy5Yt+f7778nLy/PwUwghLjUJgIQQV5wXX3yRNm3a8M9//pPXXnsNgObNm9O/f3/uvPPOeuvOmDEDq9XK7Nmz0ev13Hvvvbz77rt06tTJE00XQniISjk7RyyEEEIIcYWTMUBCCCGEuOpIACSEEEKIq44EQEIIIYS46kgAJIQQQoirjgRAQgghhLjqSAAkhBBCiKuOrANUC4fDQVZWFgEBAXXuDSSEEEKIy4uiKJSWlhITE4NaXX+ORwKgWmRlZdG8eXNvN0MIIYQQF+D48eM0a9as3jISANUiICAAcH6AgYGBXm6NEEIIIc5HSUkJzZs3d32P10cCoFpUdXsFBgZKACSEEEL8wZzP8BUZBC2EEEKIq44EQEIIIYS46kgAJIQQQoirjowBEkIIcVHsdjtWq9XbzRBXAa1Wi0ajaZRrSQAkhBDigiiKQk5ODkVFRd5uiriKBAcHEx0dfdHr9EkAJIQQ4oJUBT+RkZH4+vrKwrHiklIUhYqKCvLy8gBo0qTJRV1PAiAhhBANZrfbXcFPWFiYt5sjrhJGoxGAvLw8IiMjL6o7TAZBCyGEaLCqMT++vr5ebom42lT9zl3suDMJgIQQQlww6fYSntZYv3MSAAkhhBDiqiMBkBBCCHGZW7VqFe3bt8dutwMwYcIEunbt6pF79+rVi2+++cYj9/IkCYCEEEJcdWbNmkV8fDwGg4Hk5GQ2bdp0zjqLFi2iXbt2GAwGEhMTWbp0qdt5RVEYN24cTZo0wWg0kpKSwsGDB93KxMfHo1Kp3F5vv/32Oe/9/PPP88orrzTaGjgN8corr/Diiy/icDg8fu9LSQIgD7KYbJTkmzCVWbzdFCGEuGotWLCA0aNHM378eLZu3UqXLl1ITU11Ta+uzfr16xk6dCgjR45k27ZtDBo0iEGDBrF7925XmXfeeYf333+f2bNns3HjRvz8/EhNTcVsNrtd6/XXXyc7O9v1+vvf/15ve3/99VcOHTrE3XfffXEPfoFuvfVWSktL+fHHH71y/0tFAiAP2rkmk/+8nEba4kPebooQQly1pk2bxqhRoxgxYgQdOnRg9uzZ+Pr68umnn9ZZ57333mPAgAGMGTOG9u3bM3HiRLp168bMmTMBZ/Zn+vTpvPLKK9x111107tyZL774gqysLJYsWeJ2rYCAAKKjo10vPz+/ets7f/58brnlFgwGQ51lHA4Hr7/+Os2aNUOv19O1a1eWLVvmOm+xWHjyySdp0qQJBoOBuLg4Jk2a5Gr7hAkTiI2NRa/XExMTw1NPPeWqq9FouO2225g/f3697fyjkQDIg6oGrisOxbsNEUKIS0BRFCosNo+/FOX8/021WCxs2bKFlJQU1zG1Wk1KSgppaWl11ktLS3OrA5Camuqqc+TIEXJyctzKBAUFkZycXOO6b7/9NmFhYSQlJfHuu+9is9nqbfPatWvp0aNHvWXee+89pk6dypQpU9i5cyepqanceeedri64999/n++++46FCxeyf/9+5s6dS3x8PADffPMN//znP/noo484ePAgS5YsITEx0e36PXv2ZO3atfW24Y/mslgIcdasWbz77rvk5OTQpUsXZsyYQc+ePWst+8knn/DFF1+40o7du3fnrbfeciv/yCOP8Pnnn7vVS01NdYuGvUGldkZAypXVjSqEEACYrHY6jPvJ4/dNfz0VX935fZ2dOnUKu91OVFSU2/GoqCj27dtXZ72cnJxa6+Tk5LjOVx2rqwzAU089Rbdu3QgNDWX9+vWMHTuW7Oxspk2bVue9jx07RkxMTL3PNWXKFF544QXuv/9+ACZPnszq1auZPn06s2bNIiMjg9atW3PdddehUqmIi4tz1c3IyCA6OpqUlBS0Wi2xsbE1voNjYmI4fvw4DocDtfrKyJ14/Ska2he7Zs0ahg4dyurVq0lLS6N58+b079+fEydOuJUbMGCAWx/rV1995YnHqZe6KgBqwP+tCCGEuHKMHj2aG2+8kc6dO/PXv/6VqVOnMmPGDCorK+usYzKZ6u3+KikpISsriz59+rgd79OnD3v37gWciYHt27fTtm1bnnrqKZYvX+4qN2TIEEwmEy1atGDUqFEsXry4RlbKaDTicDjqbecfjdczQGf2xQLMnj2bH374gU8//ZQXX3yxRvm5c+e6vf/Xv/7FN998w6pVqxg2bJjruF6vJzo6+tI2voGqFm+SLjAhxJXIqNWQ/nqqV+57vsLDw9FoNOTm5rodz83Nrfc7Izo6ut46Vf/Nzc1126MqNze33unqycnJ2Gw2jh49Stu2betsc2FhYb3PdS7dunXjyJEj/Pjjj6xcuZJ7772XlJQUvv76a5o3b87+/ftZuXIlK1as4IknnuDdd9/ll19+QavVAlBQUICfn59rK4orgVczQBfaF3umiooKrFYroaGhbsfXrFlDZGQkbdu25fHHHyc/P79R234hVKc/bUkACSGuRCqVCl+dj8dfDVkZWKfT0b17d1atWuU65nA4WLVqFb17966zXu/evd3qAKxYscJVJyEhgejoaLcyJSUlbNy4sd7rbt++HbVaTWRkZJ1lkpKSSE9Pr/N8YGAgMTExrFu3zu34unXr6NChg1u5++67j08++YQFCxbwzTffUFBQADgzPAMHDuT9999nzZo1pKWlsWvXLlfd3bt3k5SUVGcb/oi8mgG60L7YM73wwgvExMS4BVEDBgxg8ODBJCQkcOjQIV566SVuvfVW0tLSal1DobKy0i2tV1JScoFPVD/JAAkhhPeNHj2a4cOH06NHD3r27Mn06dMpLy939UQADBs2jKZNm7pmSj399NP07duXqVOncvvttzN//nw2b97Mxx9/DDj/fX/mmWd44403aN26NQkJCbz66qvExMQwaNAgwDmQeuPGjdx0000EBASQlpbGP/7xDx566CFCQkLqbG9qamqNca1nGzNmDOPHj6dly5Z07dqVOXPmsH37dlevybRp02jSpAlJSUmo1WoWLVpEdHQ0wcHBfPbZZ9jtdpKTk/H19eXLL7/EaDS6jRNau3Yt/fv3v6DP+7KleNGJEycUQFm/fr3b8TFjxig9e/Y8Z/1JkyYpISEhyo4dO+otd+jQIQVQVq5cWev58ePHK0CNV3Fx8fk/zHnY9UumMvOxVcrSD3c26nWFEMLTTCaTkp6erphMJm835YLMmDFDiY2NVXQ6ndKzZ09lw4YNbuf79u2rDB8+3O3YwoULlTZt2ig6nU7p2LGj8sMPP7iddzgcyquvvqpERUUper1e6devn7J//37X+S1btijJyclKUFCQYjAYlPbt2ytvvfWWYjab621rfn6+YjAYlH379rmOjR8/XunSpYvrvd1uVyZMmKA0bdpU0Wq1SpcuXZQff/zRdf7jjz9Wunbtqvj5+SmBgYFKv379lK1btyqKoiiLFy9WkpOTlcDAQMXPz0/p1auX2/dlZmamotVqlePHj9f/oXpIfb97xcXF5/39rVIU73XIWCwWfH19+frrr10RMsDw4cMpKiriv//9b511p0yZwhtvvMHKlSvPOT0QICIigjfeeIPHHnusxrnaMkDNmzenuLiYwMDAhj1UPfasPcGaufuJ7xzO7U90brTrCiGEp5nNZo4cOUJCQkK9A3RF4xgzZgwlJSV89NFHHr/3Cy+8QGFhoSvb5W31/e6VlJQQFBR0Xt/fXh0DdKF9se+88w4TJ05k2bJl5xX8ZGZmkp+f7zYw7Ux6vZ7AwEC316WgkllgQgghLsDLL79MXFycV7ajiIyMZOLEiR6/76Xm9Vlg5+qLPbsfdvLkyYwbN4558+YRHx/vWl/B398ff39/ysrKeO2117j77ruJjo7m0KFDPP/887Rq1YrUVM/PTjhT9RggrzZDCCHEH0xwcDAvvfSSV+797LPPeuW+l5rXA6D77ruPkydPMm7cOHJyclzLd1cNjM7IyHBbdOnDDz/EYrFwzz33uF1n/PjxTJgwAY1Gw86dO/n8888pKioiJiaG/v37M3HiRPR6vUef7WzVs8AkAySEEEJ4k9cDIIAnn3ySJ598stZza9ascXt/9OjReq9lNBr56SfPr0R6PmQWmBBCCHF58PpK0FcTyQAJIYQQlwcJgDxIxgAJIYQQlwcJgDxI9gITQgghLg8SAHmQjAESQgghLg8SAHmQ7AUmhBBCXB4kAPIgyQAJIYQ4m8VioVWrVqxfvx5wznZWqVRs3779kt979uzZDBw48JLf53IkAZAHVa8E7eWGCCHEVW7WrFnEx8djMBhITk5m06ZN56yzaNEi2rVrh8FgIDExkaVLl7qd//bbb+nfvz9hYWENCmBmz55NQkIC11577YU8ykX585//zNatW1m7dq3H7+1tEgB50OkEEA7JAAkhhNcsWLCA0aNHM378eLZu3UqXLl1ITU0lLy+vzjrr169n6NChjBw5km3btjFo0CAGDRrE7t27XWXKy8u57rrrmDx58nm3RVEUZs6cyciRIy/qmS6UTqfjgQce4P333/fK/b1JAiAPcmWAJAASQgivmTZtGqNGjWLEiBF06NCB2bNn4+vry6efflpnnffee48BAwYwZswY2rdvz8SJE+nWrRszZ850lXn44YcZN24cKSkp592WLVu2cOjQIW6//fZ6y/3yyy/07NkTvV5PkyZNePHFF7HZbK7zX3/9NYmJiRiNRsLCwkhJSaG8vBxwLijcs2dP/Pz8CA4Opk+fPhw7dsxVd+DAgXz33XeYTKbzbveVQAIgD5IuMCHEFU1RwFLu+VcD/lG1WCxs2bLFLUhRq9WkpKSQlpZWZ720tLQagU1qamq9dc7H2rVradOmDQEBAXWWOXHiBLfddhvXXHMNO3bs4MMPP+Tf//43b7zxBgDZ2dkMHTqUP//5z+zdu5c1a9YwePBgFEXBZrMxaNAg+vbty86dO0lLS+PRRx91jUkF6NGjBzabjY0bN17Us/zRXBZbYVwtqn7fJAMkhLgiWSvgrRjP3/elLND5nVfRU6dOYbfbXftNVomKimLfvn111svJyam1TtWG3Bfq2LFjxMTU/5l98MEHNG/enJkzZ6JSqWjXrh1ZWVm88MILjBs3juzsbGw2G4MHDyYuLg6AxMREAAoKCiguLuaOO+6gZcuWALRv397t+r6+vgQFBbllha4GkgHyIJUshCiEEOIMJpMJg8FQb5m9e/fSu3dvt6xNnz59KCsrIzMzky5dutCvXz8SExMZMmQIn3zyCYWFhQCEhobyyCOPkJqaysCBA3nvvffIzs6ucQ+j0UhFRUXjPtxlTjJAHiTT4IUQVzStrzMb4437nqfw8HA0Gg25ublux3Nzc4mOjq6zXnR0dIPrnG97du3adVHX0Gg0rFixgvXr17N8+XJmzJjByy+/zMaNG0lISGDOnDk89dRTLFu2jAULFvDKK6+wYsUKevXq5bpGQUEBERERF9WOPxrJAHmQLIQohLiiqVTOrihPv87IjJyLTqeje/furFq1ynXM4XCwatUqevfuXWe93r17u9UBWLFiRb11zkdSUhL79u2rt2egffv2pKWluZVZt24dAQEBNGvWDHD+D3afPn147bXX2LZtGzqdjsWLF7vdZ+zYsaxfv55OnToxb94817lDhw5hNptJSkq6qGf5o5EAyIPUMgtMCCG8bvTo0XzyySd8/vnn7N27l8cff5zy8nJGjBjhKjNs2DDGjh3rev/000+zbNkypk6dyr59+5gwYQKbN2/mySefdJUpKChg+/btpKenA7B//362b99e7zihm266ibKyMvbs2VNnmSeeeILjx4/z97//nX379vHf//6X8ePHM3r0aNRqNRs3buStt95i8+bNZGRk8O2333Ly5Enat2/PkSNHGDt2LGlpaRw7dozly5dz8OBBt3FAa9eupUWLFq4xQlcNRdRQXFysAEpxcXGjXjfvWIky87FVypzn1zbqdYUQwtNMJpOSnp6umEwmbzflgsyYMUOJjY1VdDqd0rNnT2XDhg1u5/v27asMHz7c7djChQuVNm3aKDqdTunYsaPyww8/uJ2fM2eOAtR4jR8/vt623HvvvcqLL77oen/kyBEFULZt2+Y6tmbNGuWaa65RdDqdEh0drbzwwguK1WpVFEVR0tPTldTUVCUiIkLR6/VKmzZtlBkzZiiKoig5OTnKoEGDlCZNmig6nU6Ji4tTxo0bp9jtdte1+/fvr0yaNOl8Pzqvq+93ryHf3ypFkQ6Zs5WUlBAUFERxcTGBgYGNdt1TmaUseOM3fAN1jHjnuka7rhBCeJrZbObIkSMkJCSccxCvqN/OnTu55ZZbOHToEP7+/h699549e7j55ps5cOAAQUFBHr33harvd68h39/SBeZBrkHQEnMKIYQ4rXPnzkyePJkjR454/N7Z2dl88cUXf5jgpzHJLDAPqp4F5uWGCCGEuKw88sgjXrlvQ1atvtJIBsiDqmeBSQZICCGE8CYJgDyoKgMkm6EKIYQQ3iUBkAfJXmBCCCHE5UECIA+SvcCEEEKIy4MEQB4ke4EJIYQQlwcJgDxIZoEJIYQQlwcJgDxIZoEJIYQQlwcJgDyoai8wFAmChBBCOOXn5xMZGcnRo0cBWLNmDSqViqKiokt+7xdffJG///3vl/w+lyMJgDxIdcaOxTIQWgghvGfWrFnEx8djMBhITk5m06ZN56yzaNEi2rVrh8FgIDExkaVLl7qdf+SRR1CpVG6vAQMGnPO6b775JnfddRfx8fEX+jgX7LnnnuPzzz/n8OHDHr+3t0kA5EGqMz5tSQAJIYR3LFiwgNGjRzN+/Hi2bt1Kly5dSE1NJS8vr84669evZ+jQoYwcOZJt27YxaNAgBg0axO7du93KDRgwgOzsbNfrq6++qrctFRUV/Pvf/2bkyJGN8mwNFR4eTmpqKh9++KFX7u9NEgB5kGSAhBDC+6ZNm8aoUaMYMWIEHTp0YPbs2fj6+vLpp5/WWee9995jwIABjBkzhvbt2zNx4kS6devGzJkz3crp9Xqio6Ndr5CQkHrbsnTpUvR6Pb169aq33DfffEPHjh3R6/XEx8czdepUt/MffPABrVu3xmAwEBUVxT333OM69/XXX5OYmIjRaCQsLIyUlBTKy8td5wcOHMj8+fPrvf+VSPYC86CqafAgGSAhxJVHURRMNpPH72v0Mbr9D2Z9LBYLW7ZsYezYsa5jarWalJQU0tLS6qyXlpbG6NGj3Y6lpqayZMkSt2Nr1qwhMjKSkJAQbr75Zt544w3CwsLqvO7atWvp3r17vW3esmUL9957LxMmTOC+++5j/fr1PPHEE4SFhfHII4+wefNmnnrqKf7zn/9w7bXXUlBQwNq1awHnZqdDhw7lnXfe4U9/+hOlpaWsXbvWbRxqz549yczM5OjRo17phvMWCYA8yK0LTDJAQogrjMlmInlessfvu/GBjfhqfc+r7KlTp7Db7URFRbkdj4qKYt++fXXWy8nJqbVOTk6O6/2AAQMYPHgwCQkJHDp0iJdeeolbb72VtLQ0NBpNrdc9duwYMTEx9bZ52rRp9OvXj1dffRWANm3akJ6ezrvvvssjjzxCRkYGfn5+3HHHHQQEBBAXF0dSUhLgDIBsNhuDBw8mLi4OgMTERLfrV93/2LFjV1UAJF1gHuTWBSYpICGEuKLcf//93HnnnSQmJjJo0CC+//57fvvtN9asWVNnHZPJhMFgqPe6e/fupU+fPm7H+vTpw8GDB7Hb7dxyyy3ExcXRokULHn74YebOnUtFRQUAXbp0oV+/fiQmJjJkyBA++eQTCgsL3a5lNBoBXHWuFpIB8iC3LjBZDFEIcYUx+hjZ+MBGr9z3fIWHh6PRaMjNzXU7npubS3R0dJ31oqOjG1ynRYsWhIeH8/vvv9OvX78623N2QNJQAQEBbN26lTVr1rB8+XLGjRvHhAkT+O233wgODmbFihWsX7+e5cuXM2PGDF5++WU2btxIQkICAAUFBQBERERcVDv+aCQD5EFndlHLjvBCiCuNSqXCV+vr8df5jv8B0Ol0dO/enVWrVrmOORwOVq1aRe/eveus17t3b7c6ACtWrKi3TmZmJvn5+TRp0qTOMklJSaSnp9fb5vbt27Nu3Tq3Y+vWraNNmzaurjUfHx9SUlJ455132LlzJ0ePHuXnn38GnH8uffr04bXXXmPbtm3odDoWL17sutbu3bvRarV07Nix3nZcaSQD5EEqlQpUyEKIQgjhRaNHj2b48OH06NGDnj17Mn36dMrLyxkxYoSrzLBhw2jatCmTJk0C4Omnn6Zv375MnTqV22+/nfnz57N582Y+/vhjAMrKynjttde4++67iY6O5tChQzz//PO0atWK1NTUOtuSmprK2LFjKSwsrHPG2LPPPss111zDxIkTue+++0hLS2PmzJl88MEHAHz//fccPnyYG264gZCQEJYuXYrD4aBt27Zs3LiRVatW0b9/fyIjI9m4cSMnT56kffv2ruuvXbuW66+/3tUVdtVQRA3FxcUKoBQXFzf6tWc9/rMy87FVSmmBudGvLYQQnmIymZT09HTFZDJ5uykXZMaMGUpsbKyi0+mUnj17Khs2bHA737dvX2X48OFuxxYuXKi0adNG0el0SseOHZUffvjBda6iokLp37+/EhERoWi1WiUuLk4ZNWqUkpOTc8629OzZU5k9e7br/erVqxVAKSwsdB37+uuvlQ4dOiharVaJjY1V3n33Xde5tWvXKn379lVCQkIUo9GodO7cWVmwYIGiKIqSnp6upKamKhEREYper1fatGmjzJgxw+3+bdu2Vb766qtztvNyUd/vXkO+v1WKIqmIs5WUlBAUFERxcTGBgYGNeu0Pn1yNw6Yw7K1rCQitf+CbEEJcrsxmM0eOHCEhIeGcg3hF/X744QfGjBnD7t27Uas9OzLlxx9/5Nlnn2Xnzp34+PwxOoXq+91ryPf3H+NpryBqlQoHikyDF0IIAcDtt9/OwYMHOXHiBM2bN/fovcvLy5kzZ84fJvhpTFffE3vb6ZlgkncTQghR5ZlnnvHKfc9cMfpqI7PAPMy1IbxkgIQQQgivkQDIw1SuDJAEQEIIIYS3SADkYVXrVchCiEIIIYT3SADkYVX7gUkGSAghhPAeCYA8zJUBkgBICCGE8BoJgDzMNQZIusCEEEIIr5EAyMOqtqyRvcCEEEII75EAyMNkFpgQQoiGWrVqFe3bt8dutzfaNR955BEGDRp0XmVvvPFGj6xVdOrUKSIjI8nMzLzk95IAyMOkC0wIIbxv1qxZxMfHYzAYSE5OZtOmTeess2jRItq1a4fBYCAxMZGlS5e6nVcUhXHjxtGkSROMRiMpKSkcPHjQrUx8fDwqlcrt9fbbb5/z3s8//zyvvPKKa/f3K1V4eDjDhg1j/Pjxl/xeEgB5WFUXmGSAhBDCOxYsWMDo0aMZP348W7dupUuXLqSmppKXl1dnnfXr1zN06FBGjhzJtm3bGDRoEIMGDWL37t2uMu+88w7vv/8+s2fPZuPGjfj5+ZGamorZbHa71uuvv052drbr9fe//73e9v76668cOnSIu+++++Ie/A9ixIgRzJ07l4KCgkt6HwmAPEztygBJACSEEN4wbdo0Ro0axYgRI+jQoQOzZ8/G19eXTz/9tM467733HgMGDGDMmDG0b9+eiRMn0q1bN2bOnAk4/6d2+vTpvPLKK9x111107tyZL774gqysLJYsWeJ2rYCAAKKjo10vPz+/ets7f/58brnlFtfGnwcOHEClUrFv3z63cv/85z9p2bIlAHa7nZEjR5KQkIDRaKRt27a89957Df2o6lRYWMiwYcMICQnB19eXW2+91S3bdezYMQYOHEhISAh+fn507NjRlTErLCzkwQcfJCIiAqPRSOvWrZkzZ46rbseOHYmJiWHx4sWN1t7aSADkaSrZC0wIcWVSFAVHRYXHXw3JqFssFrZs2UJKSorrmFqtJiUlhbS0tDrrpaWludUBSE1NddU5cuQIOTk5bmWCgoJITk6ucd23336bsLAwkpKSePfdd7HZbPW2ee3atfTo0cP1vk2bNvTo0YO5c+e6lZs7dy4PPPAAAA6Hg2bNmrFo0SLS09MZN24cL730EgsXLqz3XufrkUceYfPmzXz33XekpaWhKAq33XYbVqsVgL/97W9UVlbyv//9j127djF58mT8/f0BePXVV0lPT+fHH39k7969fPjhh4SHh7tdv2fPnqxdu7ZR2loX2QzVw9RVCyFKBkgIcYVRTCb2d+vu8fu23boFla/veZU9deoUdrudqKgot+NRUVE1MipnysnJqbVOTk6O63zVsbrKADz11FN069aN0NBQ1q9fz9ixY8nOzmbatGl13vvYsWPExMS4HXvwwQeZOXMmEydOBJxZoS1btvDll18CoNVqee2111zlExISSEtLY+HChdx777113ut8HDx4kO+++45169Zx7bXXAs7gq3nz5ixZsoQhQ4aQkZHB3XffTWJiIgAtWrRw1c/IyCApKckV1MXHx9e4R0xMDNu2bbuodp6LBECeppIuMCGEuFqNHj3a9XPnzp3R6XQ89thjTJo0Cb1eX2sdk8nk6v6qcv/99/Pcc8+xYcMGevXqxdy5c+nWrRvt2rVzlZk1axaffvopGRkZmEwmLBYLXbt2vehn2Lt3Lz4+PiQnJ7uOhYWF0bZtW/bu3Qs4A73HH3+c5cuXk5KSwt13303nzp0BePzxx7n77rvZunUr/fv3Z9CgQa5AqorRaKSiouKi21ofCYA8zDUGSOIfIcQVRmU00nbrFq/c93yFh4ej0WjIzc11O56bm0t0dHSd9aKjo+utU/Xf3NxcmjRp4lamvqAjOTkZm83G0aNHadu2bZ1tLiwsrNGem2++mXnz5tGrVy/mzZvH448/7jo/f/58nnvuOaZOnUrv3r0JCAjg3XffZePGjXW2pTH95S9/ITU1lR9++IHly5czadIkpk6dyt///nduvfVWjh07xtKlS1mxYgX9+vXjb3/7G1OmTHHVLygoICIi4pK2UcYAeZhrFphkgIQQVxiVSoXa19fjr6oths6HTqeje/furFq1ynXM4XCwatUqevfuXWe93r17u9UBWLFihatOQkIC0dHRbmVKSkrYuHFjvdfdvn07arWayMjIOsskJSWRnp5e4/iDDz7IggULSEtL4/Dhw9x///2uc1XdU0888QRJSUm0atWKQ4cO1XmPhmjfvj02m80tmMrPz2f//v106NDBdax58+b89a9/5dtvv+XZZ5/lk08+cZ2LiIhg+PDhfPnll0yfPp2PP/7Y7R67d+8mKSmpUdpbl8siAGrIegyffPIJ119/PSEhIYSEhJCSklKj/PmsxeAtshCiEEJ41+jRo/nkk0/4/PPP2bt3L48//jjl5eWMGDHCVWbYsGGMHTvW9f7pp59m2bJlTJ06lX379jFhwgQ2b97Mk08+CTiDv2eeeYY33niD7777jl27djFs2DBiYmJciw2mpaUxffp0duzYweHDh5k7dy7/+Mc/eOihhwgJCamzvampqfz66681jg8ePJjS0lIef/xxbrrpJrdxQq1bt2bz5s389NNPHDhwgFdffZXffvvtYj8617XvuusuRo0axa+//sqOHTt46KGHaNq0KXfddRcAzzzzDD/99BNHjhxh69atrF69mvbt2wMwbtw4/vvf//L777+zZ88evv/+e9c5gIqKCrZs2UL//v0bpb11Urxs/vz5ik6nUz799FNlz549yqhRo5Tg4GAlNze31vIPPPCAMmvWLGXbtm3K3r17lUceeUQJCgpSMjMzXWXefvttJSgoSFmyZImyY8cO5c4771QSEhIUk8l0Xm0qLi5WAKW4uLhRnvFMX0/erMx8bJVyaGteo19bCCE8xWQyKenp6ef97+rlZsaMGUpsbKyi0+mUnj17Khs2bHA737dvX2X48OFuxxYuXKi0adNG0el0SseOHZUffvjB7bzD4VBeffVVJSoqStHr9Uq/fv2U/fv3u85v2bJFSU5OVoKCghSDwaC0b99eeeuttxSz2VxvW/Pz8xWDwaDs27evxrl7771XAZRPP/3U7bjZbHZ9PwYHByuPP/648uKLLypdunRxlRk+fLhy11131XvvMz+Pp59+2vW+oKBAefjhh5WgoCDFaDQqqampyoEDB1znn3zySaVly5aKXq9XIiIilIcfflg5deqUoiiKMnHiRKV9+/aK0WhUQkNDlbvuuks5fPiwq+68efOUtm3b1tmW+n73GvL9rVIU76YikpOTueaaa1xrKTgcDpo3b87f//53XnzxxXPWt9vthISEMHPmTIYNG4aiKMTExPDss8/y3HPPAVBcXExUVBSfffaZW4qwLiUlJQQFBVFcXExgYODFPeBZvp2yhezfixnwaCdadqs75SmEEJczs9nMkSNHSEhIqDFAVzS+MWPGUFJSwkcffeTtplxyvXr14qmnnnJN6T9bfb97Dfn+9moX2IWux3CmiooKrFYroaGhQMPWYqhSWVlJSUmJ2+tSqeqrls1QhRBCnK+XX36ZuLg4HI4rex+lU6dOMXjwYIYOHXrJ7+XVAKi+9RjOXDehPi+88AIxMTGugOd812I406RJkwgKCnK9mjdv3tBHOW8yBkgIIURDBQcH89JLL6FWN/7XdkZGBv7+/nW+MjIyGv2edQkPD+f5559v0MD2C/WHngb/9ttvM3/+fNasWXNRKdixY8e6rc1QUlJyyYKg6llgl+TyQgghRIPExMSwffv2es9fibwaAF3oegwAU6ZM4e2332blypWuxZXgwtZi0Ov1dS5A1djUkgESQghxGfHx8aFVq1bebobHebUL7ELXY3jnnXeYOHEiy5Ytc9sfBS58LQaPca0E7eV2CCGEEFcxr3eBjR49muHDh9OjRw969uzJ9OnT3dZjGDZsGE2bNmXSpEkATJ48mXHjxjFv3jzi4+Nd43qq+irPXIuhdevWJCQk8Oqrr7qtxeBNrr3AJAMkhBBCeI3XA6D77ruPkydPMm7cOHJycujatSvLli1zDWLOyMhwG/T14YcfYrFYuOeee9yuM378eCZMmADA888/T3l5OY8++ihFRUVcd911LFu27PKYqil7gQkhhBBe5/V1gC5Hl3IdoB9n7+Lw9pP0faAtnW5o2qjXFkIIT5F1gIS3XBHrAF2NVFVdYJIBEkIIIbxGAiAPq1rbQBJvQgghwLkocKtWrVi/fn2jXXPNmjWoVCqKiorOWfazzz4jODi40e5dn/vvv5+pU6d65F7nIgGQh7kWQpRZYEII4TUN2YS7yqJFi2jXrh0Gg4HExESWLl3qdv7bb7+lf//+hIWFoVKp6l1b50yzZ88mISGBa6+99kIe5Q/llVde4c0336S4uNjbTZEAyNNcCyFKBkgIIbxiwYIFjB49mvHjx7N161a6dOlCamoqeXl5ddZZv349Q4cOZeTIkWzbto1BgwYxaNAgdu/e7SpTXl7Oddddx+TJk8+7LYqiMHPmTEaOHHlRz/RH0alTJ1q2bMmXX37p7aZIAORpVRkg2QtMCCG8Y9q0aYwaNYoRI0bQoUMHZs+eja+vL59++mmddd577z0GDBjAmDFjaN++PRMnTqRbt26ujbwBHn74YcaNG+e2F+W5bNmyhUOHDnH77be7jl177bW88MILbuVOnjyJVqvlf//7HwD/+c9/6NGjBwEBAURHR/PAAw/UG8A11IcffkjLli3R6XS0bduW//znP65ziqIwYcIEYmNj0ev1xMTE8NRTT7nOf/DBB7Ru3RqDwUBUVFSNWdsDBw5k/vz5jdbWCyUBkIdVd4FJACSEuLIoioK10u7xV0My6he6CXdaWlqNwCY1NfW8N+6uy9q1a2nTpg0BAQGuYw8++CDz5893e64FCxYQExPD9ddfD4DVamXixIns2LGDJUuWcPToUR555JGLakuVxYsX8/TTT/Pss8+ye/duHnvsMUaMGMHq1asB+Oabb/jnP//JRx99xMGDB1myZAmJiYkAbN68maeeeorXX3+d/fv3s2zZMm644Qa36/fs2ZNNmzZRWVnZKO29UF5fB+hqUmQuotTi3GleesCEEFcam8XBx0//4vH7PvpeX7R6zXmVrW8T7n379tVZLycn56I27q7LsWPHauy1de+99/LMM8/w66+/ugKeefPmMXToUNdEmj//+c+u8i1atOD999/nmmuuoaysDH9//4tq05QpU3jkkUd44oknAOeCxRs2bGDKlCncdNNNZGRkEB0dTUpKClqtltjYWHr27Ak41+7z8/PjjjvuICAggLi4OJKSktyuHxMTg8ViIScnh7i4uItq68WQDJAHLTywkBUZywHJAAkhhACTyVRjLZuIiAj69+/P3LlzAThy5AhpaWk8+OCDrjJbtmxh4MCBxMbGEhAQQN++fQEaZef2vXv30qdPH7djffr0Ye/evQAMGTIEk8lEixYtGDVqFIsXL8ZmswFwyy23EBcXR4sWLXj44YeZO3cuFRUVbtcyGo0ANY57mmSAPEin1qGonIGPZICEEFcaH52aR9/r65X7nq8L3YQ7Ojr6gjbuPp/27Nq1q8bxBx98kKeeeooZM2Ywb948EhMTXd1M5eXlpKamkpqayty5c4mIiCAjI4PU1FQsFstFted8NG/enP3797Ny5UpWrFjBE088wbvvvssvv/xCQEAAW7duZc2aNSxfvpxx48YxYcIEfvvtN9dU+4KCAsAZ6HmTZIA8SKvRouCc/y4ZICHElUalUqHVazz+quoWOh8Xugl379693eoArFix4qI32U5KSmLfvn01xjHdddddmM1mli1bxrx589yyP/v27SM/P5+3336b66+/nnbt2jXqAOj27duzbt06t2Pr1q2jQ4cOrvdGo5GBAwfy/vvvs2bNGtLS0lyBnI+PDykpKbzzzjvs3LmTo0eP8vPPP7vq7t69m2bNmhEeHt5obb4QkgHyIJ3mzAyQBEBCCOEN59qEG2puxP3000/Tt29fpk6dyu233878+fPZvHkzH3/8satOQUEBGRkZZGVlAbB//37AmT2qK1N00003UVZWxp49e+jUqZPruJ+fH4MGDeLVV19l7969DB061HUuNjYWnU7HjBkz+Otf/8ru3buZOHFio30+Y8aM4d577yUpKYmUlBT+7//+j2+//ZaVK1cCzoUT7XY7ycnJ+Pr68uWXX2I0GomLi+P777/n8OHD3HDDDYSEhLB06VIcDgdt27Z1XX/t2rX079+/0dp7wRRRQ3FxsQIoxcXFjXrdJQeXKI9OeFWZ+dgqZf23vzfqtYUQwpNMJpOSnp6umEwmbzflgsyYMUOJjY1VdDqd0rNnT2XDhg1u5/v27asMHz7c7djChQuVNm3aKDqdTunYsaPyww8/uJ2fM2eOAtR4jR8/vt623HvvvcqLL75Y4/jSpUsVQLnhhhtqnJs3b54SHx+v6PV6pXfv3sp3332nAMq2bdsURVGU1atXK4BSWFh4zs9izpw5SlBQkNuxDz74QGnRooWi1WqVNm3aKF988YXr3OLFi5Xk5GQlMDBQ8fPzU3r16qWsXLlSURRFWbt2rdK3b18lJCREMRqNSufOnZUFCxa46ppMJiUoKEhJS0s7Z7vqUt/vXkO+v2Uz1Fpcqs1QfzzyI99+sY6u2TeTdEss197dqtGuLYQQniSboTaenTt3csstt3Do0KGLnsF1ufvwww9ZvHgxy5cvv+BryGaof0A6tQ6kC0wIIcQZOnfuzOTJkzly5Ii3m3LJabVaZsyY4e1mABIAeZRWo8XhGgTt5cYIIYS4bDzyyCOuWV6N7dZbb8Xf37/W11tvvXVJ7lmXv/zlL27jgbxJBkF7kF6jlwyQEEIIj/rXv/6FyWSq9VxoaKiHW3P5kADIg3Qa3RkZIAmAhBBCXHpNmzb1dhMuS9IF5kFnLoQo8Y8QQgjhPRIAeZBWo0VRnc4ASReYEEII4TUSAHmQTq1D4fQYIEkBCSGEEF4jAZAHua8E7eXGCCGEEFcxCYA8SKfRVe8FZpcISAghhPAWCYA8SKuuHgNkd8hCQEIIISA/P5/IyEiOHj3aaNf87LPPXLuvn8uECRPo2rVro927Pr169eKbb77xyL3ORQIgD9Jr9K4uMLvD7uXWCCHE1WvWrFnEx8djMBhITk5m06ZN56yzaNEi2rVrh8FgIDExkaVLl7qdf+SRR1CpVG6vAQMGnPO6b775JnfddRfx8fEX+jh/GK+88govvvgijssgCSABkAftzapwdYHZ7RIACSGENyxYsIDRo0czfvx4tm7dSpcuXUhNTSUvL6/OOuvXr2fo0KGMHDmSbdu2MWjQIAYNGsTu3bvdyg0YMIDs7GzX66uvvqq3LRUVFfz73/9m5MiRjfJsl7tbb72V0tJSfvzxR283RQIgT1p/qICqmFe6wIQQwjumTZvGqFGjGDFiBB06dGD27Nn4+vry6aef1lnnvffeY8CAAYwZM4b27dszceJEunXrxsyZM93K6fV6oqOjXa+QkJB627J06VL0ej29evUCwOFw0KxZMz788EO3ctu2bUOtVnPs2DHXMyQmJuLn50fz5s154oknKCsru5CPowaHw8Hrr79Os2bN0Ov1dO3alWXLlrnOWywWnnzySZo0aYLBYCAuLo5JkyYBziVeJkyYQGxsLHq9npiYGJ566ilXXY1Gw2233cb8+fMbpa0XQwIgD9KoVSioAOkCE0JceRRFwWo2e/zVkHXVLBYLW7ZsISUlxXVMrVaTkpJCWlpanfXS0tLc6gCkpqbWqLNmzRoiIyNp27Ytjz/+OPn5+fW2Z+3atXTv3t2tLUOHDmXevHlu5ebOnUufPn2Ii4tzlXv//ffZs2cPn3/+OT///DPPP/98/Q9/nt577z2mTp3KlClT2LlzJ6mpqdx5550cPHgQgPfff5/vvvuOhQsXsn//fubOnevqvvvmm2/45z//yUcffcTBgwdZsmRJjT3Oevbsydq1axulrRdDtsLwII1KhaI4A6DLof9TCCEak62ykveH3+Px+z71+ddoDYbzKnvq1CnsdjtRUVFux6Oioti3b1+d9XJycmqtk5OT43o/YMAABg8eTEJCAocOHeKll17i1ltvJS0tDY1GU+t1jx07RkxMjNuxBx98kKlTp5KRkUFsbCwOh4P58+fzyiuvuMo888wzrp/j4+N54403+Otf/8oHH3xwzs/gXKZMmcILL7zA/fffD8DkyZNZvXo106dPZ9asWWRkZNC6dWuuu+46VCqVKygDyMjIIDo6mpSUFLRaLbGxsfTs2dPt+jExMRw/fhyHw4Fa7b08jGSAPEh9RgZIAiAhhLiy3H///dx5550kJiYyaNAgvv/+e3777TfWrFlTZx2TyYThrOCta9eutG/f3pUF+uWXX8jLy2PIkCGuMitXrqRfv340bdqUgIAAHn74YfLz86moqLioZygpKSErK4s+ffq4He/Tpw979+4FnIO9t2/fTtu2bXnqqadYvny5q9yQIUMwmUy0aNGCUaNGsXjxYmw2m9u1jEYjDoeDysrKi2rrxZIMkAepVeBwdYFJACSEuLL46PU89fnXXrnv+QoPD0ej0ZCbm+t2PDc3l+jo6DrrRUdHN7hOixYtCA8P5/fff6dfv351tqewsLDG8QcffJB58+bx4osvMm/ePAYMGEBYWBgAR48e5Y477uDxxx/nzTffJDQ0lF9//ZWRI0disVjw9fWts02NoVu3bhw5coQff/yRlStXcu+995KSksLXX39N8+bN2b9/PytXrmTFihU88cQTvPvuu/zyyy9otVoACgoK8PPzw2g0XtJ2notkgDzozDFADrsEQEKIK4tKpUJrMHj8pVKpzruNOp2O7t27s2rVKtcxh8PBqlWr6N27d531evfu7VYHYMWKFfXWyczMJD8/nyZNmtRZJikpifT09BrHH3jgAXbv3s2WLVv4+uuvefDBB13ntmzZgsPhYOrUqfTq1Ys2bdqQlZVV5z0aIjAwkJiYGNatW+d2fN26dXTo0MGt3H333ccnn3zCggUL+OabbygoKACcGZ6BAwfy/vvvs2bNGtLS0ti1a5er7u7du0lKSmqU9l4MyQB5kFp1ZheYrAQthBDeMHr0aIYPH06PHj3o2bMn06dPp7y8nBEjRrjKDBs2jKZNm7pmNz399NP07duXqVOncvvttzN//nw2b97Mxx9/DEBZWRmvvfYad999N9HR0Rw6dIjnn3+eVq1akZqaWmdbUlNTGTt2LIWFhW4zxuLj47n22msZOXIkdrudO++803WuVatWWK1WZsyYwcCBA1m3bh2zZ89utM9nzJgxjB8/npYtW9K1a1fmzJnD9u3bmTt3LuCcgdakSROSkpJQq9UsWrSI6OhogoOD+eyzz7Db7SQnJ+Pr68uXX36J0Wh0Gye0du1a+vfv32jtvVCSAfIgZwbI+ZE7FMkACSGEN9x3331MmTKFcePG0bVrV7Zv386yZcvcBjlnZGSQnZ3ten/ttdcyb948Pv74Y7p06cLXX3/NkiVL6NSpE+Cc3r1z507uvPNO2rRpw8iRI+nevTtr165FX08XXWJiIt26dWPhwoU1zj344IPs2LGDP/3pT27dRV26dGHatGlMnjyZTp06MXfuXFeg1hieeuopRo8ezbPPPktiYiLLli3ju+++o3Xr1gAEBATwzjvv0KNHD6655hqOHj3K0qVLUavVBAcH88knn9CnTx86d+7MypUr+b//+z9X992JEydYv369W7DpLSqlIfMHrxIlJSUEBQVRXFxMYGBgo1134W/H+c/K6Qw4djvG5gp/frn2PmEhhLjcmc1mjhw5QkJCQo1BvKJhfvjhB8aMGcPu3bu9OivKE1544QUKCwtdmbMLUd/vXkO+v6ULzIPU6jOmwUsGSAghBHD77bdz8OBBTpw4QfPmzb3dnEsqMjKS0aNHe7sZgHSBeZRGTXUXmIwBEkIIcdozzzxzyYKfjh074u/vX+uralyPpzz77LM11lPyFskAeZBapcJxOgOkSAAkhBDCA5YuXYrVaq313OUSjHiDBEAe5DYIWgIgIYQQHnDmDCxRTbrAPEhzxjR4GXsuhBBCeI8EQB6kVqtwKM79YKQLTAhxJZBtfYSnNdbvnHSBeZBkgIQQVwqdTodarSYrK4uIiAh0Ol2DVmQWoqEURcFisXDy5EnUajU6ne6iricBkAdp1CocijPpJrPghRB/ZGq1moSEBLKzsxttGwYhzoevry+xsbEXvWaSBEAepD5jELRkgIQQf3Q6nY7Y2FhsNht2u93bzRFXAY1Gg4+PT6NkGyUA8iCNSoUiGSAhxBVEpVKh1WpdO30L8Uchg6A9SK0CB85B0EgCSAghhPAaCYA86MytMKQHTAghhPAeCYA8SKNWSQZICCGEuAxIAORB6jPGAEkAJIQQQniPBEAepDlzIUQJgIQQQgivkQDIgzQqFY7TH7nKLh+9EEII4S3yLexBajVYTq8ErbZrvNwaIYQQ4uolAZAHadQqbKcDII1DK/uBCSGEEF4iAZAHaVQqbGd85DabrIYohBBCeIMEQB6kVquwUt31ZbPI0vFCCCGENzR4K4yioiIWL17M2rVrOXbsGBUVFURERJCUlERqairXXnvtpWjnFcG5FYYWm8qKj6LFZpEMkBBCCOEN550BysrK4i9/+QtNmjThjTfewGQy0bVrV/r160ezZs1YvXo1t9xyCx06dGDBggXn3YBZs2YRHx+PwWAgOTmZTZs21Vl2z5493H333cTHx6NSqZg+fXqNMhMmTEClUrm92rVrd97tuZQ0ahWKQ49NbQEkAySEEEJ4y3lngJKSkhg+fDhbtmyhQ4cOtZYxmUwsWbKE6dOnc/z4cZ577rl6r7lgwQJGjx7N7NmzSU5OZvr06aSmprJ//34iIyNrlK+oqKBFixYMGTKEf/zjH3Vet2PHjqxcudL13sfn8tjzVa1WoTgM2DRWsEOF2UwIft5ulhBCCHHVOe/IID09nbCwsHrLGI1Ghg4dytChQ8nPzz/nNadNm8aoUaMYMWIEALNnz+aHH37g008/5cUXX6xR/pprruGaa64BqPV8FR8fH6Kjo895f0/TqFTg0GFXVwBQWl4O1P+ZCiGEEKLxnXcX2LmCn4aWt1gsbNmyhZSUlOrGqNWkpKSQlpbWoHud7eDBg8TExNCiRQsefPBBMjIy6i1fWVlJSUmJ2+tSUKsB1FhVVgDKTRWX5D5CCCGEqF+DZoE98cQTlJWVud5/9dVXlJeXu94XFRVx2223nde1Tp06hd1uJyoqyu14VFQUOTk5DWmWm+TkZD777DOWLVvGhx9+yJEjR7j++uspLS2ts86kSZMICgpyvZo3b37B96+PRuVcA8imtgFQJgGQEEII4RUNCoA++ugjKiqqv7Qfe+wxcnNzXe8rKyv56aefGq91F+DWW29lyJAhdO7cmdTUVJYuXUpRURELFy6ss87YsWMpLi52vY4fP35J2qZ2BUDOwc8ms/mS3EcIIYQQ9WvQ6GDlrB08z37fEOHh4Wg0GrcACiA3N7dRx+8EBwfTpk0bfv/99zrL6PV69Hp9o92zLmq1MwCyqpzT3ytMEgAJIYQQ3uC1hRB1Oh3du3dn1apVrmMOh4NVq1bRu3fvRrtPWVkZhw4dokmTJo12zQulOR0A2U4HQObKSm82RwghhLhqeXV++OjRoxk+fDg9evSgZ8+eTJ8+nfLyctessGHDhtG0aVMmTZoEOAdOp6enu34+ceIE27dvx9/fn1atWgHw3HPPMXDgQOLi4sjKymL8+PFoNBqGDh3qnYc8Q9UYIKvKmTkzV1q82RwhhBDiqtXgAGjcuHH4+voCziDkzTffJCgoCMBtfND5uO+++zh58iTjxo0jJyeHrl27smzZMtfA6IyMDNTq6iRVVlYWSUlJrvdTpkxhypQp9O3blzVr1gCQmZnpmoYfERHBddddx4YNG4iIiGjooza6qkex4QyALJU2L7ZGCCGEuHqplAYM5LnxxhtRnc5i1Gf16tUX1ShvKykpISgoiOLiYgIDAxvtuja7g1Yv/0g/VQbdCtti75zHU0/c32jXF0IIIa5mDfn+blAGqCrLIi5M1Rgg6+n3VtkKQwghhPCKRhkEbbPZ3NYHErVz7k0G1qrp8LIZqhBCCOEVDQqA/u///o/PPvvM7dibb76Jv78/wcHB9O/fn8LCwsZs3xVHo1JhO/2xO6wSAAkhhBDe0KAAaNq0aW4rP69fv55x48bx6quvsnDhQo4fP87EiRMbvZFXErVahVVxfux26zkKCyGEEOKSaFAAtGfPHq699lrX+6+//ppbbrmFl19+mcGDBzN16lT+7//+r9EbeSXRqFRY0Tjf2M49oFwIIYQQja9BAVBpaanbJqe//vor/fr1c73v2LEjWVlZjde6K5BGXR0AKVYJgIQQQghvaFAA1LRpU/bu3Qs4V1jesWOHW0YoPz/ftUaQqJ1aBVbFOflOZffaQtxCCCHEVa1B38BDhgzhmWee4T//+Q+jRo0iOjqaXr16uc5v3ryZtm3bNnojryQatao6ALJpvNwaIYQQ4urUoHWAxo0bx4kTJ3jqqaeIjo7myy+/RKOp/hL/6quvGDhwYKM38kriDIB0APg4tFjsFnQanZdbJYQQQlxdGhQAGY1GvvjiizrP/9FXgPYElao6A6RxaCmzlhGqCfVyq4QQQoiriwxC8TCNSoVN5fzYfRw6yiyygKQQQgjhaQ3KAN18883nVe7nn3++oMZcDTRqlWszVK1DR2llqZdbJIQQQlx9GrwXWFxcHLfffjtarfZStemKplbDmbPfLRbZEV4IIYTwtAYFQJMnT2bOnDksWrSIBx98kD//+c906tTpUrXtiuTcCqOapVKWgxZCCCE8rUFjgMaMGUN6ejpLliyhtLSUPn360LNnT2bPnk1JScmlauMVRa1WoajArnaGQbIjvBBCCOF5FzQIunfv3nzyySdkZ2fzt7/9jU8//ZSYmBgJgs6D5vRO8FUBkMUiGSAhhBDC0y5qFtjWrVv55Zdf2Lt3L506dZJxQedBo3YGQA7N6QxQpWSAhBBCCE9rcACUlZXFW2+9RZs2bbjnnnsIDQ1l48aNbNiwAaPReCnaeEVRn84AOdQOAGw2CYCEEEIIT2vQIOjbbruN1atX079/f959911uv/12fHwadImrXlUGSFGdDoDsEgAJIYQQntag6GXZsmU0adKEjIwMXnvtNV577bVay23durVRGnclUrsCIOdaQHbJAAkhhBAe16AAaPz48ZeqHVcNzek1gBRXF5jDi60RQgghrk4SAHmYqwtMLRkgIYQQwltkLzAPqxoEXd0FJhkgIYQQwtPOOwAaMGAAGzZsOGe50tJSJk+ezKxZsy6qYVeqGhkguwRAQgghhKeddxfYkCFDuPvuuwkKCmLgwIH06NGDmJgYDAYDhYWFpKen8+uvv7J06VJuv/123n333UvZ7j8syQAJIYQQ3nfeAdDIkSN56KGHWLRoEQsWLODjjz+muLgYAJVKRYcOHUhNTeW3336jffv2l6zBf3TqszJADrvizeYIIYQQV6UGDYLW6/U89NBDPPTQQwAUFxdjMpkICwuTVaDPU/UssKouMBkELYQQQnjaRa1iGBQURFBQUGO15apQNQaIqi4wyQAJIYQQHiezwDzMNQbo9CevSAAkhBBCeJwEQB5WvRWG871kgIQQQgjPkwDIw84eBK3YJAASQgghPE0CIA/TnNUFJrPAhBBCCM+7oADo+PHjZGZmut5v2rSJZ555ho8//rjRGnalqh4E7fyPBEBCCCGE511QAPTAAw+wevVqAHJycrjlllvYtGkTL7/8Mq+//nqjNvBKU2MQtKyDKIQQQnjcBQVAu3fvpmfPngAsXLiQTp06sX79eubOnctnn33WmO274miqAp+qQEgyQEIIIYTHXVAAZLVa0ev1AKxcuZI777wTgHbt2pGdnd14rbsCnd0Fpsg6iEIIIYTHXVAA1LFjR2bPns3atWtZsWIFAwYMACArK4uwsLBGbeCVRrrAhBBCCO+7oABo8uTJfPTRR9x4440MHTqULl26APDdd9+5usZE7c5eB0gyQEIIIYTnXdBWGDfeeCOnTp2ipKSEkJAQ1/FHH30UX1/fRmvclah6N/iqaWAqL7ZGCCGEuDpdUAbIZDJRWVnpCn6OHTvG9OnT2b9/P5GRkY3awCtNdQbo9H+lC0wIIYTwuAsKgO666y6++OILAIqKikhOTmbq1KkMGjSIDz/8sFEbeKWpGgNd1QWGXTJAQgghhKddUAC0detWrr/+egC+/vproqKiOHbsGF988QXvv/9+ozbwSqNWSxeYEEII4W0XFABVVFQQEBAAwPLlyxk8eDBqtZpevXpx7NixRm3glaZ6K4yqAMiLjRFCCCGuUhcUALVq1YolS5Zw/PhxfvrpJ/r37w9AXl4egYGBjdrAK41rDBCSARJCCCG85YICoHHjxvHcc88RHx9Pz5496d27N+DMBiUlJTVqA680VbPAHK4uMNmPVgghhPC0C5oGf88993DdddeRnZ3tWgMIoF+/fvzpT39qtMZdic6eBaaSDJAQQgjhcRcUAAFER0cTHR3t2hW+WbNmsgjieagKgByuAEgyQEIIIYSnXdC3r8Ph4PXXXycoKIi4uDji4uIIDg5m4sSJOBwyqrc+roUQT3/0kgESQgghPO+CMkAvv/wy//73v3n77bfp06cPAL/++isTJkzAbDbz5ptvNmojryRn7wYvGSAhhBDC8y4oAPr888/517/+5doFHqBz5840bdqUJ554QgKgergGQZ+eBaZSJAASQgghPO2Cvn0LCgpo165djePt2rWjoKDgoht1Jas5BkjjzeYIIYQQV6ULCoC6dOnCzJkzaxyfOXOm26wwUZMrADr90aslAySEEEJ43AV1gb3zzjvcfvvtrFy50rUGUFpaGsePH2fp0qWN2sArTXUXWNUgaAmAhBBCCE+7oG/fvn37cuDAAf70pz9RVFREUVERgwcPZv/+/a49wkTtqjJA9tNjgNSKdIEJIYQQnnbB6wDFxMTUGOycmZnJo48+yscff3zRDbtSaVwZIGfgo1F8OJlRSlCEEZ3xgv84hBBCCNEAjdr/kp+fz7///e8G1Zk1axbx8fEYDAaSk5PZtGlTnWX37NnD3XffTXx8PCqViunTp1/0NT2tagcMRVX90S986zcWvb3ZSy0SQgghrj5eHYCyYMECRo8ezfjx49m6dStdunQhNTWVvLy8WstXVFTQokUL3n77baKjoxvlmp7m6gJT3BdALMqt8EZzhBBCiKuSVwOgadOmMWrUKEaMGEGHDh2YPXs2vr6+fPrpp7WWv+aaa3j33Xe5//770ev1jXJNT6sKgNKOFHu5JUIIIcTVy2sBkMViYcuWLaSkpFQ3Rq0mJSWFtLQ0j16zsrKSkpISt9elUjULzC7T34UQQgivadCo28GDB9d7vqio6LyvderUKex2O1FRUW7Ho6Ki2LdvX0OaddHXnDRpEq+99toF3bOhqjJAoMaBHTUyC0wIIYTwtAYFQEFBQec8P2zYsItqkDeMHTuW0aNHu96XlJTQvHnzS3KvqgwQqHGo7DINXgghhPCCBgVAc+bMabQbh4eHo9FoyM3NdTuem5tb5wDnS3VNvV5f55iixuaWAVI7wO6R2wohhBDiDF4biKLT6ejevTurVq1yHXM4HKxatcq1uvTlcM3GpjnjE7erJPoRQgghvMGrK++NHj2a4cOH06NHD3r27Mn06dMpLy9nxIgRAAwbNoymTZsyadIkwDnIOT093fXziRMn2L59O/7+/rRq1eq8rult1V1g4DgrAHI4FNRq1dlVhBBCCNHIvBoA3XfffZw8eZJx48aRk5ND165dWbZsmWsQc0ZGBmp1dcokKyuLpKQk1/spU6YwZcoU+vbty5o1a87rmt6mUdcdANltDtQ6GRMkhBBCXGoqRVEUbzficlNSUkJQUBDFxcUEBgY26rXX/36KB/61EYBHTRUEVYa5zo2cej0GP22j3k8IIYS4WjTk+1sWo/Ew9TkyQEIIIYS49CQA8jD3LjD3gMdulQBICCGE8AQJgDzszEHQZ68BZLPaqbDKnmBCCCHEpSYBkIedmQHycejczv1r+6f0+aoPe/L3eLpZQgghxFVFAiAPc5wx5tzH4T7g+adDy7EpNubsbrwFJ4UQQghRkwRAHlZUYXH97ONwX4VAc/p9hDHCo20SQgghrjYSAHlYbKif62fN2QGQ4nwfbgz3aJuEEEKIq40EQB7WKtKfuX9JZnBSU9Rnffya011iKpWsBi2EEEJcShIAeUGfVuG0axJQ43hVBshit9Q4J4QQQojGIwGQl+g0NT/6qi4xCYCEEEKIS0sCIC/R+dTc86sqALI6rJ5ujhBCCHFVkQDIS3Q+tWWAnGOAJAASQgghLi0JgLxEq1HxY/MVmHzKKNMVAuAjY4CEEEIIj5AAyEv0PmoOh+3g8x4vczx4LyBjgIQQQghPkQDIS3Q+alQ+xaACm9oGQFJYdwAsDgmAhBBCiEtJAiAv0Wk0qLUlANhVzgAoQBMIgM1h81q7hBBCiKuBBEBecuYgaLvaOehZLV1gQgghhEdIAOQlOh81lXmpAFwX2wcAtd35xyEBkBBCCHFpSQDkJTqNGkv+jeizx9O1SRcAVA7n2kAyBkgIIYS4tCQA8hJnF5gKa2UgmtPdYarTGSBZB0gIIYS4tCQA8pKqrTAsNgc+2tN/DHbnJqhWuwRAQgghxKUkAZCXVA2Cttgd1Rkgh4wBEkIIITxBAiAvqQqA7A4FlcaZ+VFszv/KGCAhhBDi0pIAyEvOnAavqJ2Bj6sLTMYACSGEEJeUBEBeUjUGCEA5Hf8odud/pQtMCCGEuLQkAPIS7eluL4DTQ39QTi8ALYOghRBCiEtLAiAvUalUrm4wx+kuMFcGSMYACSGEEJeUBEBepD/dDXZ66A8OqwLIGCAhhBDiUpMAyIu0VTPBTr932J0BkENxyIaoQgghxCUkAZAX6c7KANlPZ4BABkILIYQQl5IEQF7kWgtI5QDAYasOgKQbTAghhLh0JADyoqoAqCrUcTgU1IrsByaEEEJcahIAeVFVF5hVqc78GFS+gHSBCSGEEJeSBEBeVJUBsgGq01PhWxUkARIACSGEEJeSBEBe5AqAFEjs2xSAXvsHE17WTNYCEkIIIS4hCYC8SO/aEd7OdUNa07RtCGrUxJS0ljFAQgghxCUkAZAXaU+PAbLYHKjUKqITAgEIMofLdhhCCCHEJSQBkBfpzgiAAIIijQAEmsNlDJAQQghxCUkA5EVVY4AqqwKgiDMCoNNjgPKzylj+r90U5pR7p5FCCCHEFUgCIC/SucYAOQOgwHDnFPiAyhAsFmcAtHddNgc357F3XbZ3GimEEEJcgSQA8qJQPx0AW44WAuAXpMOusaFGQ3mRcwyQudz538oKGRMkhBBCNBYJgDxMsdk4/rcnOTX7I+6/pjlqFazal8f240Wo1CosfmUAmPKdW6RaTM5NUStN9jqvKYQQQoiGkQDIw0p//pmyVas4OX06LSL8GdytGQCz1xwCwOZfAUBlgbNbrLLCGQBZzbI7vBBCCNFYJADyMEeZ+2DmO7vEAHDklPO4PcAEgMXZK0alKwMkAZAQQgjRWCQA8jSHe1dWsK8WgFKzc4yPPaASAFuRc2sMy+kMkEUCICGEEKLRSADkYcrpGV9VAg3OAKjkdBeXyv90IFR6eoaYuWYAZK20s+n7I+SfKLvk7RVCCCGuRBIAedpZGaBAozMAKqu0YbM7UAc4zytlGhSHUt0FZq6ut/G/h/nt+yPMn7jJQ40WQgghriwSAHnY2RmgAIOP6+eyShuaQMX5xuxDRakFTr+1VdpxnK6beaDQI20VQgghrlQSAHmavborS3E40GrUGLUaAEpMNrQGNRaNGYCCE+4Dpi2ns0C2SpkSL4QQQlwMCYA8THEo1W9szmAo0OjMApWYrWg1Wsp0zgzPqbPG+FSNA7JaJAASQgghLoYEQJ52xhggxe782TUQ2mRFp9FRpncGQGcPcq4aEG2zuHejCSGEEKJhJADysDPHALkCIGPVTDBnAFRaVwB0OgMkXWBCCCHExZEAyNPOGAPk6gI7PRC6xGRDq9ZSrqs9AKraDsNxZjeaEEIIIRpMAiAPU2y1dIGdkQEK0ge5MkDKWT1dFpON9SfWe6ahQgghxBVMAiAPUyyW6p9tNccAhRvCXYOgz2Yx2fjbT0+6HbPbZTyQEEII0VCXRQA0a9Ys4uPjMRgMJCcns2lT/Qv8LVq0iHbt2mEwGEhMTGTp0qVu5x955BFUKpXba8CAAZfyEc7bmQFQVXdY1VpAJWYbYcYwSg0Ftda1mG0YbP5ux+wyIFoIIYRoMK8HQAsWLGD06NGMHz+erVu30qVLF1JTU8nLy6u1/Pr16xk6dCgjR45k27ZtDBo0iEGDBrF79263cgMGDCA7O9v1+uqrrzzxOOekWM/MAFVNg6/uAgszhlGmK6RUVzMIsphsGKx+bsdkSrwQQgjRcF4PgKZNm8aoUaMYMWIEHTp0YPbs2fj6+vLpp5/WWv69995jwIABjBkzhvbt2zNx4kS6devGzJkz3crp9Xqio6Ndr5CQEE88zjk5KitdP9fsArMRog9BrVZzIuigq5xN56xTabJjtLpngGRKvBBCCNFwXg2ALBYLW7ZsISUlxXVMrVaTkpJCWlparXXS0tLcygOkpqbWKL9mzRoiIyNp27Ytjz/+OPn5+XW2o7KykpKSErfXpaJYrNVv7DUXQtSoNYToQzgRdMBVrMJQDJzOANnODoAkAySEEEI0lFcDoFOnTmG324mKinI7HhUVRU5OTq11cnJyzll+wIABfPHFF6xatYrJkyfzyy+/cOutt2K31x4sTJo0iaCgINerefPmF/lkdXMbBF3LQogA4cZwtwDIpHJuiWEx2yQDJIQQQjQCn3MX+eO5//77XT8nJibSuXNnWrZsyZo1a+jXr1+N8mPHjmX06NGu9yUlJZcsCKp1FtjpMUClp1d6DjeGs1+331Uu0/8AUcUJWCokAySEEEI0Bq8GQOHh4Wg0GnJzc92O5+bmEh0dXWud6OjoBpUHaNGiBeHh4fz++++1BkB6vR69Xn8BT9Bwtc0Cq14I0ZkBCjOGAfCfbuMJMoejUtR0P5GK2WTFYJNB0EIIIcTF8moXmE6no3v37qxatcp1zOFwsGrVKnr37l1rnd69e7uVB1ixYkWd5QEyMzPJz8+nSZMmjdPwi6CcOQj6rIUQSytt2B2KKwAq1xeRFfQ7Fh+T832ZqUYAJF1gQgghRMN5fRbY6NGj+eSTT/j888/Zu3cvjz/+OOXl5YwYMQKAYcOGMXbsWFf5p59+mmXLljF16lT27dvHhAkT2Lx5M08+6VwgsKysjDFjxrBhwwaOHj3KqlWruOuuu2jVqhWpqaleecYzOWqZBl+1DhBAUYWFcEO4672P2odKnwoAKsorMdh83a5ns0oGSAghhGgor48Buu+++zh58iTjxo0jJyeHrl27smzZMtdA54yMDNTq6jjt2muvZd68ebzyyiu89NJLtG7dmiVLltCpUycANBoNO3fu5PPPP6eoqIiYmBj69+/PxIkTPdbNVR/3WWDO4EXvo6F5qJHjBSb25ZQSbqwOgJIik9h5fA8APnYdRmsAABaNGZ3dIBkgIYQQ4gJ4PQACePLJJ10ZnLOtWbOmxrEhQ4YwZMiQWssbjUZ++umnxmxeo3IfBF29MWpi0yCOF5jYdaKYpDZhruN/6/o33rfPcL0PMDvPlemKCDVFyyBoIYQQ4gJ4vQvsauM2BsgtAAoG4Mdd2Uz/yTmlX6vW0i2yGx/e8gGVGmc3mI/iHC9UrisCZBaYEEIIcSEuiwzQ1cR9Flh18JLYNAiAHZnFgIagZr148sbeqFQqjD5GLD5m9Pbq8T/lOufiiFbpAhNCCCEaTAIgD6ttHSCoDoCcVBRnDuLPnW53vlOpsGkr4XTyyIGdCq1ztWrJAAkhhBANJ11gHua+EnR1F1iQr7ZG2aKK6rIOfXVZq9aMTeM8J4OghRBCiIaTAMjDHNaas8CqPHpDC7Qalev9/pxS188qfXWg49BZsamrAiDJAAkhhBANJQGQBykOB5wRAJ3ZBQbw4oB2bBvXn5vbRQJwILc6ANIYqsupDWBTO69jqbRRaill4f6FFJoLL2HrhRBCiCuHBEAe5DYAGvcuMAC1WoW/3oc2Uc61fvafEQBpfav/qHx81dg1zgDIbK5kYtpEJm6YyMu/vnypmi6EEEJcUWQQtAedHQBhs9Varl20MwA6kFPmOqY/Y4yQj0GFXud8b6608OPRHwFYe2JtYzZXCCGEuGJJBsiDDm/9jZ3NIjge4gxwzu4Cq1JbBsjXT+f6WeurxmhwrmptqawZRB38LZfPX1pH7pGSRmu7EEIIcSWRAMiDTmUcJTMskEJ/54Ces7vAqsSFOdf7KTZZKTE7u7p8/aoHAel8NRgNzvdWS81rHNp2krKCSo7uOtWo7RdCCCGuFBIAeVDVh+1QnZ7pZa89A+Sn9yH4dJdXVpFzJ/jAgOpd4A2+Wvx9ne/PzAAZfYwAVFY4g6byoupVp4UQQghRTQIgD1KrnB93VQBUVxcYQNNgZzBTFQAFBQa4zhn9dPgbnVmiM6fBm2wmzDYz5nIJgIQQQoj6SADkQWrF+V9XAFRHFxhAzOkA6EShMwAKCQp0nfMN0BPo5w+A1mKk9ckecPra+eZ8Ksud1y2TAEgIIYSolQRAHlS1xqFDffqH88gAZZ7OAIUHhbjOBQT4EuRfHRD1+/1hmpS0BCDflC8ZICGEEOIcJADyILXiTNNUZ4DqDoCahVR1gZkBCAsKQcG5GrS/vy9hIUGsj1vsKh9sjgLgVNkprJXO61ZW2LDKStFCCCFEDRIAeZDa4R4AcV5dYBUAaH18MDU9SXlAPq1iYwnRh7AzZg27o5xr/0TamwJwssh9NejyQskCCSGEEGeThRA9SFWVATrdBaZY6w6AqrrATpzuAgMY8+pQFEVBpVIRYnB2iZXpnQFPgqY1vwCnigqB6u6ysqJKgqN8G/MxhBBCiD88yQB5kNrh7MI6ny6wpqe7wPJKK7HYqjdCVZ2uG2YMA6oDIL3JOSh6ye7v3K4j44CEEEKImiQA8qCzu8DqmwUW5qfDR61CUaDNKz/y9PxtZBdXZ4MifSP5W9e/MbDzAABsJc51g/Q2P7frSAAkhBBC1CQBkAepT2d8XGOA6pkFplKpaBtdvfbPf7dn8fd529zK/LXLXxnS/U/Oa5f7gKLCYHPv7pKp8EIIIURNMgbIg9T2011g6nN3gQFMu7crW44V4qfX8PT87RzMK6tRxi9IhwJoUONrDUB/VgBUmu+cRVaYU87/5h+g+63xNGsbUuM6QgghxNVEAiAPUjvOygDV0wUG0DY6gLbRAZSd3u6i2GSlrNKGv776j02tUWPXq/GpdBBRfh03RV5L5TE45ZtJeEUzju06Reb+Qn77/ghZB4vI3FfI32bffGkeUAghhPiDkC4wD1Kf7vKyn8dWGGfy1/sQZHSO8alaGfpMZucpbt2XSuVvzm6zo6G7+T1qM4oCK+ekU1pgrlGv0mTjl6/2y6apQgghrjoSAHlQ+PDhAChqFQrn7gI7U/W0+Ioa50y1/CmafcpZEzcfVM6B0MrpAdgANqsdU5mFHz/cye5fTrByTnrDHkQIIYT4g5MuMA/yMRhcPztUqnN2gZ2paYiR9OySWjNAxRqFiLOO2bRmbBorWqMaa4UD+xlT6ZdM20bukRLX+8qK82+HEEIIcSWQDJAHaXy0rp8dKlW9CyGerToDVLMra5fBzl6tjWM+1Rklra8GgDxHNgDmMqvr3JnBD4BdZcPWgGBMCCGE+KOTAMiDND7VCTeHWnVBXWBLd2Xz/Nc7KK6oDmhO2Gx872flf4bqY6Wnf6zUlgOgVPeAVZfpdcDZLsWHnw/9Uut9FYfCthUZZB0sOu+2CiGEEJc7CYA8SKVWo9Y4gyCHigZ3gQFkFFSwcHMmM34+CIDF5sBkdQZSORoFMwo2FDIVZ+Bj8imv9XqHQ3cwVzULi9qZUfrxl7X8+vVBLGb3NmWkF7D+m99ZPHVrrQOphRBCiD8iGQPkYRqtFofd5uwCO89ZYFCdAaqyL6cUgBJzddYHFfwr0IwPKqz4oMU5GLo2J/0zADBry9BVGmi+vQc77McJbeKHVqfB4K+leftQMvcVuOqsXXCA2x7vfN5tFkIIIS5XkgHyMI3WOQ7IoWpYF1jMWQHQkVPOwKbYZHU7blJDYutQAnXOxQ7N2pqLJwLk+TkDIIfBmfHR250LKB5PL2D5v/fw3XvbsZhsZP1eXH3PHacoyq05C00IIYT4o5EAyMN8To8DcqhVYKvubsqbOpWc11+vs164v87t/YkiE4u3ZbJ6X16Nsnd0jqFtVCBQXwboOAA2rcrteEZ6dcbn4OZcTmY4M03+IXoAco4UI4QQQvzRSQDkYRqdM5A5MwPkqKwk/5N/UTjvK2wnT9ZaT6VS8d2TffhyZDItI5wbnv5jwQ7e+GFvjbIDOkWT2CwYALO2OgCyqRRMagsnAg9itvtjK21HpeK+LYbFVB2U/frNQRSHQkCogdCOzsxV7mH3GWRCCCHEH5GMAfKwqqnwbgFQWXU3lb2kBJ+Is1f1cep8Oqhp1ySQQyfdMztJscH4633oFhtCqJ+OPycOY2/BLvzLrnOVKdKWsDBhKZqQjVhP3Yzl1C1kV6ppWkdbbWbn2kFNWgcyp2AmfbiXzEP5F/LYQgghxGVFMkAe5hoDpFaBzTl+x1Fa6jpvLz53hqV7bM3NTCMD9PxnZDL/uKUNAOHGcOYMmEObiB6uMhb9SdShG1BUCg5LOACltc2PP4Pa10FILweHDbsBKMoyY7Wc/9glIYQQ4nIkGSAP8zkzA1S1N1hZdTbHXnLuMTb392xOTomZX/afZH+uM3gKNGhrLRsZ7kvVTl+VPtUDmKsCIJO69gBoTYuvsKtt3HB9V35XnaJcX0y5tgg/azAnj5Wwyvo9Rh8j97S5x62eoig4bAoarcTWQgghLl/yLeVhtc0Cc5RVZ4AcJefOAPnqfHjptvYMSqruvKraLPVsMVF+rp/N6urMjcMSRv8OUVSoag+Ajobu5mDEZo5WHGHHyR0AZAceBmDt4v1M2TiF91d9zM/LtjFx/USOlRwDYNeaTGb/fQ3HzxhMLYQQQlxuJAPkYWcGQFWzwNzHAJXWWq82rSL9XT/XFQDFRvqzHQU1KiptTQDw9fFn0v19aBcdwLDd1YOuFZUDlaKmUmPC7ONs09Hio1gcFgA2N/+RhOJETh2uoEflbbTI78LeHYX81mY/O049y9PdnmbPL+WAjgObc2neIfScz2C3OkAFGh+JxYUQQniOfOt4mOaMafBVGSB76ZkB0PlPMz8zAPI31B7LRocYMJ+e6R7o24xpN07jX/0/5o7OMbSKDODN+7u4yhb6OjdaLTachNN1DhUf4nipc8p8kTGPzW3/D4CuJ24m2BwJQFxhR/YX7mfsLy9RmeusmHu4mM0/HmXDfw/hsFdvxHomh0Nh0eTNzB2/QcYVCSGE8CgJgDys9i6w6gDIcR6DoKs0D6leHLHMXPu2GnofDRbnvqhEhBm5Je4WEiMSXeev7xTl+nnX6Tglz/9YjesE+jiDnW0Bv1DuW4IajetcbFF7UFToigLxUZzPV5hTwcb/HmbLj8dY/q892GsJgnIOFZOfWUZpvpm8ozK9XgghhOdIAORhZ06Dr+4CO2MW2HmMAario6n+42sWaqyznM3gLNe0SUDNa+g0tL8hht99HWzSqfmx/X/ZEPcdAIpSff28zGQcNn9QwdbolW7X8LUGEl7elMjSuFrvf2jbSXasPM5vOb9xqOiQ6/jh7dXdb2fvUC+EEEJcSjIGyMPOnAbv6gI7cwxQacMCgcVPXEva4XwGdo6ps0zve1qRlpbFw7e2rPX8zQ+0g24hWLacILnz9by79WcAVIoPqJzjf6xFPfAJ2I3ap4z94etpn9MTi8aMxcdMfGEnbjw0FOX0gGoFBdXpPrQWXSM4vP0km5YeZk7Gy6iMGm72e5/XBnZ2C4B2pWXw/drVtO4WxdDBtzboMxBCCCEaSjJAHuZTaxdY9TT4hnSBASTFhvDEja3cskFn69+rOeP/kUygb+0DpQFubhfFrAe7MbjtAGIDYukT04eXej0HgPVUCm0jwzHYWwFg01j5usu7fNfkGHsCMnHgILyiGRHlzQHICjsAgDFAS/+/dCQyLgB7pULXEymEnorm6IZd/PDzUUrzq3eXL8uxEnYqloLlen5ddMA5OBrYfaKYk6WVOOwOTmWWUXLKhHKOtYuEEEKIc5EMkIe5dYFZa1kIsQFdYJeCv86f7//0PSqVCrvDTs8mPVFbowgP0LPqQASvblvhKvvnxOH8a+1hPkv4iXYOMy3yu2JTW/k5/ktebDKdTr1i+XzDMZZVltIXaJXfnbYnk9HbjWR+exQVKn4P20qr/G5ubdixKpOM9ELaDo7n1c+2Ed7Mn8eaR7F9pXMwduKNzbjh/jY12l5yysSetSdI6h+Hwa/uYE8IIYSQAMjDahsEbS933wrD21QqZ/eVRq2hZXB1t9mgzu35/FAnfi/ZjU5t5B+3tOEft7Rh1m+FzE5/i50xawjWhVFhKUFzYx77Kpry+tfpaHxO0UsThq+1egySChUmn1L+F/M/WuZ3RYWafN8sNjdbRkrGQxRmw4ZZe7gdHcUHzRzIyXXV3bP2BN1S41wbtAK8seEN7D81ITw7AbtV4bp7W3vgkxJCCPFHJV1gHua2FYbDgeJw4Cg9cxbY5b3b+icDZnBbwm3M6DfddezmFl0BcFhCKCpwdoO9vP5FXvz5HQC6dtrP0dBdrvJFhjwKtKV8b4D8449S2CeD4wGH+W9IBkfCdvB1l3cJbFId3AQ51FQUW7BrrOia2HHYFT5f8B0DFw/k4PEjLJqyiaPLK/DPc85US/vlOP9cvv8SfxJCCCH+yCQD5GFuXWAAdrv7NPiKChSbDZXP5flHE24MZ/INk92OtQ9rT9+QJ1m6VQFFi55yfPwPogpZQ5eA7hyxLsMc1oa2J5NxoDDPoKf8jF+9fZUdWKfJh/IofM2rKTTk8HHCS0T4taB1Xm9iS5xjjzIDDpAeuI5bsx/FutMfWgfw46970ZQbSCLFdT1fOyxccZh7ejSneagv4FxwccWcdE4dL2XwmO74BuoAOPhbLrv/d4K+Q9sSGuPHmRRFYfm/9lB80sTAp7pwMqOUiOYBGAN0l+SzFUII4TmX57fsFcxtJWhAsduxl7mv/mwvLcUnpOaGp5ezv3a/n+/X/wqAKvdR7OqZaHyPcVj7DjigWftgOkTG4B9hZOqq3W511/1etcO8GsupfhibzaVIKaAoogCLxuQKgIoj8zgWks6JwIM0LWnNgP1/qbM9bSwOxvz0AZ3DFYL3tMKSp0Zb4OyCS/81ix63xbNiaxYH/3MAxeLghw93MuTFHmiMUGYuw6j4k3u0mN+35AHw1esbMZVYiU8M4/a/danzvpeCoigc2X6KqIRA/IL1564ghBDinCQA8jBXBkh9OgCy2d1mgcHpbrA/WADUMSaQuDBfMgtN/GdkMnN35bIifwoAQfogXuz1AglBCQA03XKIE0WmGte4uV0kP+/riN3cBI0hG3POQI7o8qjwKUNvN5KW0x2bYQfL23zKoN3PEGKOIiM4nWPB6Vx/1Lkp65GQnSQUdqZzpZ7VJ/bAhgEolUGcOSR6+6oMyiptrP5lJ00twQCUnDTxzis/kR20k5b5HTFa3ddMMpU4B6wf3ZVPWaEZi8leI2N0JnO5lZzDxTRtG8y8g3Np6t+UlLgULCYbG747TJOWQcR1CiNzXyEo0KxdCDpj7X8d96zN4pd5+2nWLoS7nklyHc86WIhvoJ7gKN/6/3CEEELUIAGQh1VNg7dXdYHZrK4uMJVWi2K1XtRA6IriIixmM8FR0Rfd1oZQqVR8NaoXRRVWOsQE0qX5gzyz+jcqbBW8du1rNA9o7irbKtKfE0UmercII+2wM/vzWN8W9GoRxs/78jBl/AWVTzGOyhj6tI3gv8GFWMxWdIF+lJ/qh0/cv/g2cSr9DX9nue3f2BUHidk34l8ZSlr8Eiw+JtqeTKbf7w8DYPM3YU3M5qeKJdy2+wkoN7DnpwyaEgzA/oRsWp+IIszkS5ipl9tz2VU29kam0fZkMlqHs+vr87HrAeh5dwJrft5Ltj6TI+33MufOiQQb/bFW2vl2ylYKs8tR+zvIUlnZr/4ddbdobGUqDv6Wy67VmSh+FlTlzmuGtdXT5tZgKnbrKC+sJK5vED+WfMOhwkO0/elW1BjI3F/Ad3t+4M6Ot3Myo5TF07Zh9Nfy0MTe6E5vhWJ3OAfWa9QahBBC1E0CIA87uwvMVlpKdoCRQFMlwU2aYD2W0aANUc+kKAqfj3kSc1kZj34wB79gz2aRYoKNxAQ7V6T2Ufsws9/MWstd2zKMXw6c5K6uMdzcLpKTZZWM6d+WErMNg1aNQwmgV1w8/ztwkls7RdPyplacKDJxR+cYKiw38upq+GFHPvOLwlFpxuITsIsFQcX8o3cnynNsrE34mkBzBCFlsZzSqLnuT4m0a9OXZqfC+DkvjS7ZN1GsL+D38N845XeCw0EH2RIUwE2H7sdu9+Nkm3QOKBvonHUTWUEHORKxh/Xxi+l+/Da6Z1WPNdr0zRF8MdCSVpSojzJp4gLa9wrHtCcER3bVKt9qomkBwN7VeW6fg6pch81gRms1kL+/kv8dzEDrcHZxrdu/iWVtF9Il+ybUZQZnBUXFZz8uok2TluSuU4ECplIrX838H7+rdtO5aScWO76gyJDHRykfsfr4aq5reh0tgltwYFMOKz/bS7O2wXTpF0tsh1BUp7OQACePl5J7pIQO18WgPuP4xVIUBbvNgY/WGZCVF1ViMdsIifYj35RPqCHUNeuwMZlsJnxUPmg1shyCEKJ2KkVWlauhpKSEoKAgiouLCQwMbNRr71v3Cz+8/y6hZSZ6HcqCN19j6cIvCCk30y8khorffiN46P1Ev/xygwdC5x09zH9eeAqAO597mdbX9G7UtjcWm93B7yfLaBsVUOPL7/e8Mnx1GmKCjZSarQQYan6B2ewO+k//H4dPlqNRq4gM0HPfNc15JqUNC/cvZOKGibQKboXfqef59WDBGTUV/JrPobkdcv2PYkOHTm3AojoFgLW0A+bMh+jXPpSy0FmkF+xCceioOPI3DE2+Icrh4J5dYwCo1JjQ2+vefsSBg6XtP8LHrkONBq1dR2J2X8IrmrK9ySoMBKC16FibsIheJwbSLtuZeTrpd5xgUyRahx6r2uLKOpVri/CzBmP2KWdd/Df0+31Yrfe1qM1sb7qSSq2J/eGbCLNH0z/uYXx+CkFfXv1ZRsYFcOuTHdm0fwdto1vxw7Q9WCsc9BoSz1LDfArXBONXHkFiuxYU7ioiqFUg7VNb0T4qwK2rrqLEQt7REpq1D0HjoyZzXyE5h4tJ7NsMnVHDdzO3kXuklFsfTUSr9+G797djt9nJHbCRbwvm0bdZX/550z/xUflwKrOMkChf1FoVJQUVFGSYiO0Uis3iQKUCva8Wi9nmynad2Qa1RoXBT0tOeQ5vbniTX7N+JcYvhhk3z6BFcAtX2b35e1mTuYZ729xLmDGszj+/KnnHSlAUiIp3/juQc7gYndGH0CZ1d38KIbynId/fEgDV4lIGQAc3ree7qW8RXFHJtQczOfrQENJ3bUXtUHj4zvs5+eZbAIQ99hgFyd3IO3SQrs1aENCnDypd/bOPNi5eyK/zvwDgpkcepdutdzZq2y8nxwsq2HysgL5tIgn1q/5cFEVhZcZKOoV1ws8nnFk//85XmzJQFCittKH2KaVz+/2o1FbubjeAuJAARn7zL+wV8djL2wBqAvQ+JLcy8Gvhv/BztOWBDkMI89OyPOM7/PYXg8rK/shN9Dp6D31uuoHS9YUU55nICDpITEkChb7ZbIj7jqP44rCEYitrh2/cR2hQCDJHcEqlxnR8JHr/Y2hj/oPREsC9O17Agg8LordyTUkiSSXO37uTagcHg+z4xmbSdUeC22dQpiukTF9IZGkch8J2ElAZTHRZdRmTTxlGm7/rvVVdyd7IjbTLuxadwweTtgyj1Z+z5fofJaosvsZxOwoqlcLuJgdpXhSMnzUIrV2PyqEiPyCLCpWV5iXO/eAqDCUQacI34/RmuxoFtUqNw+b85ybPL4NC32yKDCexxqsZYn6I7N8KsPtYKdEXEFQejhoN/uEGKoorsSt2zOEFGHPCORG7F0vySbTmcCq3W2l5vAuoILK1Hz8HfIPvkSYcCd3BwYgtYDfyyjWTqVAd5Xj+CVbt/4VCXS7R/tG8dd1b/JL5C9tytvF4s3/QNrwNlf6lrMv9lbyKPFoVdeXwQgsK0OYeP/7v0P/RduvNKCqFrJa76NSlO765WrQmA3ofHf4hejpcF0NguBFFUbCY7VjNdtZtz8DXoKNru0jws+Gv9efY7nysdgfqcD1KXiVhLQ34+xs5nn+CZb+sI3h/CxI6RpB8ZwvUp1d5X//7KXz1PnRpFkR5kQXfQK3rXJX8E2X46DQERTiD85J8E5u+O0JpWTnGfsXc3PYGdJq6/x2xmG3sXZ9NRGwAMa2CMZdZKS0wExrjh8bHM6ummMutOOyKa6YmgMXmoMhkITLAcNHXzy+rZO7GDG7tFE3rqJr7IzaG8evHszpjNSGGEG5sfiMPd3iYcGP4JbnX2Sx2CxXWCoINwR6537koisLSXTnM/y2D+65pzh31bNvUGCQAukiXMgA6vO03Fr/9GoFmK332Z5B2XRJFp/f/Gj5lFuqf15A76W0Ot01g3+lNTLsfzqbTXx4j/LFH6732V+OeJ2t/OgBd+99Ov5GPN7h95vIy5r3yHEGRUdw99rUG17+cFVdYUVAI9nX/AvhpTw5//2obf+3bks/XH6XY5BzwrFbB//39OjrGBAGwP6eUATN+QB/1Pf4BucxI+Se9m3eissJKpclGQKiBvSfy+b/Mz0HtoJ3+flbvPYXeR4PFbzUFbCM5uhdHjySxcJMz62SM+h6f0F/Rl3fkjiavcKSwgpdS2nDwu2OUa2F2UT5HCk2gwJ0VOiJUZaCpINTUhNVBJ0iP2ERUgI6bY+8h0/YT15zsQ3mOFUuODV+Le3CzN3wzv7T+D+FlzRi0+xl8lOqMkF1lw+xTjp/V+axWlY0j4bsJrgjlRNABErNvwEep/YvTrrKhUZxZGQcOTNpS13UACozZhJqaAJAV8DuRZXFn3duORqk5ZsmqrnR1CZ6tKiNWnzxjDlZtKQ6VDRVqmpS0RKP4YFVbKPDNosA3C63dQLPithhszoyO2aecIyG7MNh8iS3q4HouBQUFB2rqH1vlUNk5FZyFvzkEX1PtwaVWrSW0pKnb8QptKXYfKwGmULfjWQHHORiyj8T83viYjOSrwVdvJqrcD4vGjMlQicMnmGKjhmAfDUGZZhwqhSPxeYQ6Ygk5bkHl3FWGIkMex1vso42ShKVAhVKux2DRYgj2ITPsCJmaXDof7Iqh0vnMVn0l2krn51/qV4Ip1oQDGHTb9eh9/dmYlkle9klUvhAS2YTQY2Z8VGDxhYrsUvRqHXnaEsrsFkItAZTG7qepEku0sTlF/qXk5hfQMSkSR6aawgyFSn81Rwq3ELQ3DpVdDbG+lPmqadLMn+8OrMVkOUmCXzcSHSGoDOWUWUuxlUBly1O07BZB27B48ndbOLXdQY/+LdCp1Kxdnc7x3BwqEvJo2T6aa2N6M+6/uzlQuhObOpLB3eJQ+RRxV8dWOI7r8PfzR6fzITsjn8yiEqLaNCWgBMoyy0lKjSMg1IDNbuNkiYXDx0qwVhbx67KN2NUWmt0Uht6nG2b7YWbtH0N4eTNiSlqyL3IjISHBTL/uU9pERKCoVJSXVnDoeAbYNPip/fhh/yqidNH0iOmMX5CeAms+hfts+BoNNEnyZU/2XsILYwkI9CUsNoCjmdn8+OvPdOnZgjt698NksXHyZAXGYCuP/DSc3IocJvScSsaJpqDNpW/rJrQMjWPtvjxCCmzExAQQ0SKQ4wUVZBWZadckgHD/6r9rJWYrBh/n7/qvR45gUh/EV2ukVXBrmgU4/y5XZe+tdgfbjhYQGmAg0OhDgF6LUeesa3co/GPBdr7bkQWAjwLjbmvPsL4tOJBbSkK4H9p6tnG6EBIAXaRLFgBtn8ex5Z/z9ZbT//grCpzRBTTgiX8Q27IN++64g/+1rR403DK3kKSENsTNmVPnpU1lpXz4lwdRFOe/dhFlJm67637CRv2lQWMsNi5ZxK9ffQ7An6d/REiTpueo0XCKomAvKMAn7NxdEJ5isTnQ+aj55H+HmbpiP2argz/3SWDcwA5u5ZZsO0Glzc493ZujucCxMqVmK7e9v5YSk415j17Dgj0rGNLxOhKb1Pw/o0qbnR92ZvPTnhxuaBPB5+uPciC3mKf6tiGzxExcmB9/u6lljb3gzOVW1q06xg9HTxF7uBQfs5ovA4txtFxFqxgLPr/HE5XRgfzmvuRUrKVc7UBnjiS1sAWaGBV/uv96msb6sSP7GPN2/MqGzDno7Ea6nUqlZVYXTvqXsS5yGybdCRy2AJKzr0UVlM+BiH0czo8kqbQZ4UolOboyjiSsILzUSJm+kFPoaPf7X+hdEcRBrZ0YtYUIs3MW26aYnzni40BTHk95UDqEbKJL9k3k+WegMTUhuqgDZp2K7vnVfzeKjAVsiP2WQmMu/Q+MIKwihhO6CmIsvtT2p2PHgaaW9V/NGudMTIPdvWvrUOh2LD4m2uc5u5MzgtPZG76ZTtn9iKqIICN4PzmBh1ArKpoWt6V5cTu3+goOSvT5oIIgc0R1O1Q2bGoLersvFo0Znb06s1GhLeFw6A7anuxZZwDYEFmBBwkwhxFgCT13YZzBmMHqh/r052RTWdyCX6vaQrnaSrDt4rsBFRyoGmE93gptCXaVzfWMdQXVZyrXFmHxMaNxaFEpqlo/H4vajM7h/LOxqa1U6syU+OTjbwkm4PQM0jOfpUJjwc/unqUy+ZRTbMwltDwGFWp+98+mdWmM2/8EXCibysqhyBMEFwcQZQ7jYPBu9jdZQ4fc62le1A4FOB68l2Ohu4ko6UBCYWv8rQE4UPhfYD6qMoUBBfkUGO3s6GbCZA0iLCuWUt/tRFhCCakM5ZT/72QFHSDIFIGPQ8vhsL2EZMXQvvIG/HR6Cu0lNC+JIZsKDmjLCdVrSFAbsUapKCnzozjfgk0NkaE6orMtqCt/p1I5jrnIQtvRj3Hv9TW3NboYEgBdpEsWAK2fQeaSd1hwrO51ZFQoRNsg26f6n+/QMhPX5pVy7C8PUZp/ioH/eBGd0fmlcfL99ylZvpzcP91B2vLvXXV8K63cuC+D8PtvIWTwTZSE9yQ0pv5gxma18q8n/0x5USEANz3yGN1uHXjOx1IUhfK1a9HFxqKLj4cja2HtVIhJgj5PgzHYrXz+nM/ImzyZwNtvJ/q119D4X17jKUwWOwfzSukUE9SoA4LPVFZpw25XCKpng9ramK12juVX0Db6/FP35jIruTllbCoqI6V9FCGnuwwdDgUFeG/VQUpMVvp3jOLaljXT9IqiMG/fPCx2Cw91eIiKfBuBYQa3QdRnt9FksfPeqoNEBuoZ3COAaRu/4MffjLQLSWLm0O6E+uk4WVpJVKCBvQd+Z9XOPeyqiGTYta0prLCQWWiiZysfpqxeQ+/Ytozs1YNTZRbiw3zJ/r0Im8VBRFwAOl8NC/Z+h8MaSLi6HZZiG327x+AosVCYU0FuUSlL926jbUhLzEYDPmF6eoQF8MtvWRTnFmDUa9FEBPBT6QbU/rtItvegk6oHDrWKqFYBzM1Yx46i1aitFVzDw1zTM4AdmTZOnNLxTP9m5BTCdwd+oUw5SoBBS9a+GJrYTCh6C4cNRZRRwgOJqXSMVbN9fx6/bwkipyibvPC9+DU5hGIpB6OKxPy7OG7azZGQbXQNfYDDlctoam3FNUdSUJ/UsitmPYcDttAyPwn/ymDyO+QRoerEwcIVGMqNhJc3R2/z5XD4DmKVDoTkRmJSl7I3agMF4RWEViTTNKMVUZVmSvQlnArIwWTIIV+bSWRZHD0z7kDn0LMvaiPFXXKx5bekuOx38gJ20j3wNnz3BKCzavE1GwmrcM4wtaksZAYfIMgcQYgpilO+mZwIOoifJYgTgYewaUw0LW6HzqGnWH+ShPxulOhPYvUxEWKKxqGC8IporGoLByI24V8ZgqJycCxkDwW+2cQXJBJoDifI7Pyd9NFpcVQ6OB68D7XDgI89GIdWoXVuK3Snx8rZVFYKfLOJLI8FYE/Ur5hVRjqcaovGoQWcX3caRVsjQDL5lKKoFFSKmlz/YwRWhhFqcj5rse4kgWYDKnX13ztFseJQqzgadBB9ZRjNTJFu17PioFwNwQ71GRs423BYDqLyaYLJoMGqNqNxWCnX2bFpKlErKvysQeitvuQEHsbXEkhkeRxWdSW5AUfxtQQRZArFx26iVF+Mvy221r+DzvvZUKlq/vviwIRKUeOwZaNCg8onBpVKU7O+YnJ+XipfHNb9OGwnQKUHhwm7ZRdqn+boAobUev8a7XGUYrfsQ61NwFIyD7Bh0HSmiXkvg79dfF7XOF9/uABo1qxZvPvuu+Tk5NClSxdmzJhBz5496yy/aNEiXn31VY4ePUrr1q2ZPHkyt912m+u8oiiMHz+eTz75hKKiIvr06cOHH35I69bntz/UJQuATv1O9uYVzJvzg9thX42FCnvN7oW4SgfH9GrUDgc9D2WzobUzgGmT3IfQZrG0bNuBwoeGY7dZWdMxgUqNmjbZ+RxoEoZKUUjdeRjFANs6R5FX6c+fHriVFgOGgT4AU1kpR7dsoKUxF12rPuQWO/h5zkeuLjSAhK7dGTz2NRRF4Yf336U0/yR3/uXv+MVW/6VTFIW8KVMo+PenqI1aYq4zUZFhJqRVOboAO0pwHGXtJlGw4Gt8k7oR8tCDHBv6AJZjxwAwdO5M3BefozbU3bdv2r4dy/FMAlL6oTZWDzx22O2cPHaE8Nh4NBexcrbNYuHQlk0079AJ36DgC76OqJ/N7qiRqbraOBwKWzMKaRXpX6Mr1uawYbKZCNC5B7eKQ0GlVlFmKWNd1joqrBXc1eou1Co1VruVnIocTDYTR4uP0jmiM9F+0VjsFtLz04kPjCfQrqXy0CE0oaHomjVzu3aFtQKNWoOjQoWpzHrOwd0Wu4UF6//L8vRVNIuLYOzNY6i0VfLjzlUYg3yJC4qjZUgzAkvsZO/aQHD7LmgiwzmQl47hmBrCQwhuEkC4RU3J90s5FtEJon3Z9OkoWmw/SVZqEm2ua0uBqZQupm5Ytu8kN7SEyNT+tOowiJLKEip37MRPHwB2B9bM4xiSe5NXqKG80kZAE198j+xi7eKNFFUeRBWXx/1RBnz2fYdNH8vBO9+nIMiPngWZHF0wHVuJDkfbh8jBzDXH36bSP4SKkyrUh/I5TBPyInphjo4g13wIdU4ezQsdRJjDUDusBBfuIa97As1bR1NwvJAdNisl9kq6HCrBR+9DbL8eBHXrzMqv/0de+SlUNhs+Dg2VPs4sfVx8c1odTEefnoejVRyqu4ewdd8PFJUVoraFk5CTRURJOcUxTTkSE4Lf7nT8HDZaZlhRK+BQqUlveR15IX44ItSEHDxOnr8vapUBncGKqTwH30oFvbYVNr8wbJYjOJQSYnLyOB4eik3tXDLDx6HDRzFS6WNDwUGgLYIK9UlsKmfXe4ASRqk6v9bfB5tfILoKCyq7GaMSjVoTjs2ehVVVik4dS7A1EpvtMHmGkygqByoFFNf/N/ngG38nj0/+83n+7Tk/f6gAaMGCBQwbNozZs2eTnJzM9OnTWbRoEfv37ycyMrJG+fXr13PDDTcwadIk7rjjDubNm8fkyZPZunUrnTp1AmDy5MlMmjSJzz//nISEBF599VV27dpFeno6hnq+aKtcyjFAJadO8snfRgDQ+2AmRe0CaNskkyWZHWuUvW7/cTa2jMHqo8HfbKHM4P4PptHm4Pq9R8kMCSC9WQR6q40b9x5jZccE7Bo1N57IY0dwAIV+zqAhTF/OsL4Gyvt9wNfT3qAgN5cIyojRWdhlj8Bht+Oj09PzrntYv2guPlodT/x7Hif27uGbSeMBaJOdT5/+3Qh9aQao1eR/Ooe8d95xtckBlBl0VPrpiI0sQ8m1YC6oY9Cljw/YbATckkLYQ0Mo+fI9zJaTFEWGosQlEt/3Txxev4EdX38LDoUeBRVE3X03qDUc2LGFXeYSKnAQ1iyWXjelEqnW4te2LfqWLWu9XUFWJvvW/Y/cndtotn0vzbr3QOl/DcvnziX/VAmBgf7c1b8vepuOkj2HKQgJJrh3b5r1TEbjo8VcVobOYCDt2wUc3ZLGTd1D8e88gLXL11FeWMCtw4YSEJ/o1q1pzc1FMZtRGY1o9ArqzDQUYyjbFqzElH2KNolJVFKEriQfc5EVe0AUsY8+iiY4GIDKinLKiwox+PmDtRKVqQCtRo9PkwS3+1T/AThApUIBSrKzKN2zh5zdv1GReZwYxUj04Hvwv64PprJSsvanY7NYaNquI/4hoTgslVTmHuDgvuOYysvRaDRofdSENG9BeGwcvoHOcT2KolBRXIS5rBSNj5bAiEgsZhN6oy8qtfp0M+zkHTmMubyMgLBwwppWd1tVHN5C8aHtRHS/HU1IFCpFAUspdnwoyM3DNygYrcFA6amThMY0c24XYzajNhhQad3/j1ZRFCrLy1AXH0dLJarQBDAGU7FlC9asLHQtWqBv0QK10YjdZqXo8GEqjxwkvPP/t3fn4VFU+cLHv1W9dyedpLMnBAgQwg6CgBkdcQyPhOv4gLigw3sFR0UQF64wjs4iOM/1ZcY7OiOOIjNzBxgfR2bgVbgXkVU2BYJEdjGQEAiQDRKS9L7Vef+IaW2TQFwghJzP8/QDXXXq9Dm/Oun+ddXpqhHokpJo2LmL8JkzxI/Nx5Caiq+khJrPP6NRC5PmSMJqMoPFgNvrQxwvJYAgtnsSsd0T8VecwrthI2pCCrbxk1Gz++E6UYYxHMZ/+CCa201swb8RKC0FvR7VZMK9axcNG9YTe/MYEu65B09REb7PjqJPScHSvw8E6nAW7kEJm1AT00ATiGCQ+LsmoU9J4cI/3sFfWkrC/fdh7J7OmXUbOff+GtTSE6h9c4gdNhxLKAx1dVhHjaLu/Dmq//u/CbucBPQ6TGNupu9PH8Fui8EvNPAHqNu2FZsjkbjrh6K6ytH0dhRHdxpOnKB+9w4MxccIna0hlJzMhR7dqKuvQx8K4ms8j+J0ke70EzNyBKesNjSnk9TjJwgdK8FjNKAz6DD16UHtyTMYAiFMwRDulHgaAaPHjzUQwqwFEWEFp8VIdZwNHQKrL0isN0DmBSeaolDnMCO6ZRLnV6g6V0NlvA23yYA+LOh1/gI5CXWYkxzUlQhOKnpKUhNQhCDZ5SHV7MRWGSYQ1hHU6xAWA41mlUqrDU0oWAMhTOEQQVWHORjCHAxRbbfhNbU8eqIIwSjTGapEPGf8NsKqiqIJRCtHQ82BEJZAkAsx0b8W1WthQooKikKS04OqCTwmA3EeP06zgUZr259RMV4/iS4vASu4VAtOy7c/RWoKhtBUhaCufdcMy6xz4jYZaLCasASCeEyXviWQIgSilfep5phlZRi59w/vfuO2X0ynSoBGjx7NyJEj+dOfmq4Zo2kaWVlZPPHEEzz77LMtyk+ePBm3282aNV+e7rnhhhsYNmwYb775JkIIMjIymDNnDnPnzgWgoaGB1NRUli5dyn333XfJNl3OBAjg1L49qH95AGttI45cN2EUXj+WR0joiNX7cIbMmEJhbj1ykr3ZaZyzf/mtrHeClfJaF2iCoF5HWr2Lc7FWwjqVARXn6XmugR19u+G0mDCLED5Fjz4cRtUJAuiJ93tx6k2EW/kmnub1MzojDY4WsyHJgVevJ1GvEvb7qf/ieir6cJjBp2tI769Htdmp2VOL16DnfIYZZ9CM16CP1G0MhsmtrMWohdEPzSFYeoagN0BQp8PUI4PkG0ZwauX7+HUqmqpQZ7PgaeVNp5nNF0AooA8LGq0t//BVTWD1B8BmITHGhO1CA16XHx0qXr2OCqsp8seoaoJYn5+Gr73Z6ENh7L4ADZYvY6QTGpZQCJfBiCEcjrxhKKLpFFJzImILBegbr+IURtSgE4ergZp6CxXxMQR1OizBICmKG6fByDm1aYKsIRQmqNdFzQdzeH2k6jWqTBYuaC3fPHRhjQS/j8SgH2s4jN+gx2UyolND6EJB3IqZWr2FwNf2sSIE5kAIkxqmUW9EU5rWq0JgVgSeS8zFMAsNcziMS1UJtXKhRZMWxiJCeFU9IaEQVr+sL8HrxRgM4zUYaDQbQVGw+gOkeLyoZo1Go5E61RLVJk1RiA0GSGrwEFJUnGYjHrOeuKCfWG8Al87I+RgL2hevow+Hiff70RkEQb+KoOmK6yFVRa8IXAZDpE3mQJCgXhd5bgiFiff5cRv0X76xC4E1EMKv17X4e1E1DU1VMQWbPtTDqorXaEBTFYzBMKZQiKBOhS9mIgkFTKEwVn+QGrsVVQgMYa3pDENTCQCCuqYPaWMojM0XwBDWCKsKYZ1KWKcQpqlfOiEI6lT8hpZHPlVNI8YXIKDX4TO2/iGuD2tN4655mSYwB0ME9TpMwRABvS6yXtEE5lAIr0HfetJ9GelFmBDqFX9dAJtBhyngxB/QYwmEwCA4b44+QqYPa4R0KgqC9JCTesWMWR/CqZkIfnFaSadpDCmvQVOBEQmMSqni0A4duxMyW+2XQdNIqXfRkBCDS1FRhCDB7aPeZv7yHpJfUBWI8/nQ+8MYLSF6xtRTXR5LWFHJrG9EDNA4oTkIhXQkh3wotWFK0h3EWKzc7KkktccxSgOJXPjchsUTQh0QpsiVSa90E6PzRrBq1S7OBYwkBTz8KFgPih732UboFWKtrmm+W79gDb0cdRwMpyGEQjddAwaXRokllSqvBRCMspzBbvexqToHBRjTozdHG8r40YxnybzuB9/rfus0CVAgEMBqtbJy5UomTpwYWT516lTq6+tZvXp1i226d+/O008/zezZsyPL5s2bx6pVqzhw4AAnTpygd+/e7Nu3j2HDhkXKjBkzhmHDhvHqq6+2qNPv9+P3+yPPGxsbycrKumwJEADlu2HTC3B2L4x8mOotfyckFBrMvfmgOJYhtkpyT9RxXElm/xdHwhJcXvJKm2bT1yWb2J3x5eFsh8vLWH8pBrPGVrUnZy1ftnvEiUrcZgOfZ3w5v8PmC5BTXcexjCSsmp+saidpF9yRiaPnYizs65FK6Is3QVUTWIJB3O3I+k1WGzpNw+NrebuLSxKCOI8foSg0Wk3YfAEyG52cSrPj16LfzHNqa8mqcnIiJZ6quBh8xkufBktu9DT1z26NvF7mBSc9zzewv0dqVP8soSBhoRIwtPywt3v9NH7x7SvR6cFrNFw0efs6VdNQFUFI0UV9S2rtG1Pzm+w3pWgCvaYRowVQVajVR38TtfkCqEK0+BYZ6/Vj9zbtg5DalHi0+Db8xQd4WFUiCcjX6cNhzIEQbrOxRZ90Ya3VJFwfDhP6aoL5PX/wqVrT6Ye22txcxuYPRsWluS2q0CJJ2tVA1TSsBPGreowiTEDoCH4lOdVpGhaC6E0axlCYoEsXOSIcqaOtPgmBXmhRya4j6CFJ86DpFEwGFacphkq/jpCmkOxxo6qCWosFVJU4m46A04fQIDHRRshowO3yYxIa6TY9QbuV+lonXs0EllhizZA9cAiKYqe+8gQnjh2m3tV0msZh1WH0NnBOWEm3esnNtpHVN4ez3gR2f3QEj8tNmKY5lEkpDkbe+1PiU9M5/tYyKo59xgWzEYvDQYwhhFJfQZy/mszsIcSP+CHu2hM0BFOx5Qyg4UIdPrcLe1IyA28Zi9FbTfjgGsIX6vENncCqNxaj0+vo1bc7vXJ7Y/WaaYxLxJKejqN8NexeBDGphIZMYe8ZKyf2FvLD//MgSUENxWjEPKDpRxUiHOKz//cvzhwvJmXYUGLP7eZomRsRm86PHpxBjCMRRVEI+nwEzp7Fu2EDpvx8yitPU3vmFAR9pOQMoseQYZhVQejIZgwWDdE9j1OPzsV37BiZ/3c+seYjIDTo+UNw9ILCN9H63YHS7XoUBJzaCRfKIL47IqEXSjgA9nQwNiV6nroaDq/5BwNvm4gtrWfTIKg8ANteYp+rH2QMYVhsKcq2l0ALQvYYuPVXkNIfoTNRtemvqCUbSHXuRfjd7ImZjH30PfS/cQxCiMtyEdROkwBVVFSQmZnJzp07ycv78qJ9zzzzDNu2baOwsLDFNkajkWXLlnH//fdHlr3xxhu88MILVFdXs3PnTm688UYqKipIT0+PlLn33ntRFIV//vOfLeqcP38+L7zQ8ifflzUB+iohYPXjEPTALc9S8/fHcFCDvucNcPvvaThZwom5s7G6fVisCkaLm6TrDRQ3xnC0IZGgYuKGhjK65Q/CkOygsrSUHYc9NPpUsnVWep9vQBV1nIvLQeueTHq2wKEacDu7Ez/5fgxHFqMd34a7zI27PIA5pxe6lAxqj5/iswsBGowx9B40jF7jJvHJh+upOVCEx9kAAowmE7bURLLjXaQPGIZt1E9wZGQSCgXZtfIdzn76EaGGKmxGjZBiQrvgQe/xYUpVcQZ12I1B4u0mREJ/MsfeT0buQBr/+t84t25BOBxYM7uRMPZ6Gr3lHNm1myxKCQTCxCc7SEwezLn3j2CyuYkdGIc/IY7qo6dxHnFTY44lFG8nJtFC2FOHSRU4NCvJehsx3QJUGU14gwkYT4cxVl0gdnwB9jvvpOrMKRpqqklOtJLsOoDrwElqzgXxJaeTnJRMpcuNsbaUTO0C5/v9G/rCjzBUnSZgsVJmtHK+rASbTiWomKkPhXHkZNN3aAbJ8UYqTjg5XVyDeuIkvYYOJ/Whuzl79DDZN08kLASqt47gsR0c/GA7dQ0ebC43PZz1WE0CY//+mG+4Dd3AG2isP0/51nVUVZzB7/NiUAQJBh0hv4JmNGOhngzzBdIHD8U0KA8lczjEpOE8UUTtwYM4S05jViEt1UTodCnnXR4ay+qxnPNg7NMXR04c5qwUgsFY/GfOY9BfIOh1csHjw28wkJAzBEd2P7STxQTra9HSshDlxzjv0fCHBLawD0taIvE9cgicqcN5rpZzjlgUi4WYODvxxhiUOjcVwRrqKisJ13uI1ZlI75NDcu80XCeP4a2owmQ0c9Ifwq1XMcaYccTasOjs1JyrxRMMYIix0qtPDjGhEJpipd4foLb0GN69n2Ab1JvY/lmoOhWdORFPyefYbSZSrxuByBrEmU+2YNZZSerTB6HTOF92msq927DFGek9qA8GRzfcmpV6LxhjHCQlxhNsrMAYn443aMBZdgKzyYzLYsLvdqF4XdgazxPfpxs1tS6CigmTSY8oP4zOYkAxmqm94OVCnZPsIUMwmW34zleghp2IcAhhTUSzpWCMTcSemkZj5WnqjhYS9LrRW2wo1afRCRVLj57o45MIBBWUoCAlxYDZHtv04XZsHSI2gzq/mQsVpzHqFNL79sdg++I9TFHQglB7dDdBv4vkjDQUzwX0wkO9V8VlSMeS0Q9nQz0WJUBCajKGxCyc9Q04Tx8j1m7FnpgEvnqwJkJseuQIhgiHUTznIBwESwKYvrgEgPcCBDwQ981/TRoOhag8/jn25BTsSSlN75N+J5hiWz1yIjQNgUC91G1ghABXNcSkdsiRpctNBINofj+6mJaXYbhswiFQdVdFPGUC9A0ToA45AiRJkiRJ0vfqmyRAHXosNykpCZ1OR3V1ddTy6upq0tJav5lnWlraRcs3//tN6jSZTNjt9qiHJEmSJEnXrg5NgIxGIyNGjGDz5s2RZZqmsXnz5qgjQl+Vl5cXVR5g48aNkfLZ2dmkpaVFlWlsbKSwsLDNOiVJkiRJ6lo6/G7wTz/9NFOnTuX6669n1KhR/PGPf8TtdvPgg00/FX/ggQfIzMxkwYIFADz11FOMGTOGl19+mdtvv53ly5ezd+9e/vznPwNNl+eePXs2//mf/0lOTk7kZ/AZGRlRE60lSZIkSeq6OjwBmjx5MufOneP555+nqqqKYcOGsW7dOlJTm26iWF5ejvqVX2z84Ac/4B//+Ae/+tWv+MUvfkFOTg6rVq2KXAMImuYQud1upk+fTn19PTfddBPr1q1r1zWAJEmSJEm69nX4dYCuRpf7OkCSJEmSJH3/Os0kaEmSJEmSpI4gEyBJkiRJkrocmQBJkiRJktTlyARIkiRJkqQuRyZAkiRJkiR1OTIBkiRJkiSpy5EJkCRJkiRJXY5MgCRJkiRJ6nJkAiRJkiRJUpfT4bfCuBo1Xxy7sbGxg1siSZIkSVJ7NX9ut+cmFzIBaoXT6QQgKyurg1siSZIkSdI35XQ6iYuLu2gZeS+wVmiaRkVFBbGxsSiK8r3W3djYSFZWFqdPn+6S9xnr6v0HGYOu3n+QMQAZg67ef7g8MRBC4HQ6ycjIiLqRemvkEaBWqKpKt27dLutr2O32LjvoQfYfZAy6ev9BxgBkDLp6/+H7j8Gljvw0k5OgJUmSJEnqcmQCJEmSJElSlyMToCvMZDIxb948TCZTRzelQ3T1/oOMQVfvP8gYgIxBV+8/dHwM5CRoSZIkSZK6HHkESJIkSZKkLkcmQJIkSZIkdTkyAZIkSZIkqcuRCZAkSZIkSV2OTICuoNdff52ePXtiNpsZPXo0e/bs6egmXRbz589HUZSoR79+/SLrfT4fs2bNIjExkZiYGO666y6qq6s7sMXf3fbt27njjjvIyMhAURRWrVoVtV4IwfPPP096ejoWi4WxY8dy/PjxqDJ1dXVMmTIFu91OfHw8Dz30EC6X6wr24ru5VAymTZvWYlwUFBRElenMMViwYAEjR44kNjaWlJQUJk6cSHFxcVSZ9oz98vJybr/9dqxWKykpKfzsZz8jFApdya58K+3p/y233NJiDMyYMSOqTGftP8CiRYsYMmRI5MJ+eXl5fPDBB5H11/L+b3apGFxNY0AmQFfIP//5T55++mnmzZvHp59+ytChQxk3bhw1NTUd3bTLYuDAgVRWVkYeH330UWTdf/zHf/C///u/rFixgm3btlFRUcGkSZM6sLXfndvtZujQobz++uutrn/ppZdYuHAhb775JoWFhdhsNsaNG4fP54uUmTJlCkeOHGHjxo2sWbOG7du3M3369CvVhe/sUjEAKCgoiBoX77zzTtT6zhyDbdu2MWvWLHbv3s3GjRsJBoPcdtttuN3uSJlLjf1wOMztt99OIBBg586dLFu2jKVLl/L88893RJe+kfb0H+CRRx6JGgMvvfRSZF1n7j9At27d+O1vf0tRURF79+7l1ltvZcKECRw5cgS4tvd/s0vFAK6iMSCkK2LUqFFi1qxZkefhcFhkZGSIBQsWdGCrLo958+aJoUOHtrquvr5eGAwGsWLFisiyo0ePCkDs2rXrCrXw8gLEe++9F3muaZpIS0sT//Vf/xVZVl9fL0wmk3jnnXeEEEJ89tlnAhCffPJJpMwHH3wgFEURZ8+evWJt/758PQZCCDF16lQxYcKENre51mJQU1MjALFt2zYhRPvG/tq1a4WqqqKqqipSZtGiRcJutwu/339lO/Adfb3/QggxZswY8dRTT7W5zbXU/2YJCQnir3/9a5fb/1/VHAMhrq4xII8AXQGBQICioiLGjh0bWaaqKmPHjmXXrl0d2LLL5/jx42RkZNCrVy+mTJlCeXk5AEVFRQSDwahY9OvXj+7du1+zsSgrK6Oqqiqqz3FxcYwePTrS5127dhEfH8/1118fKTN27FhUVaWwsPCKt/ly2bp1KykpKeTm5jJz5kxqa2sj6661GDQ0NADgcDiA9o39Xbt2MXjwYFJTUyNlxo0bR2NjY9Q36M7g6/1v9vbbb5OUlMSgQYN47rnn8Hg8kXXXUv/D4TDLly/H7XaTl5fX5fY/tIxBs6tlDMiboV4B58+fJxwOR+1QgNTUVD7//PMOatXlM3r0aJYuXUpubi6VlZW88MIL/PCHP+Tw4cNUVVVhNBqJj4+P2iY1NZWqqqqOafBl1tyv1vZ/87qqqipSUlKi1uv1ehwOxzUTl4KCAiZNmkR2djalpaX84he/YPz48ezatQudTndNxUDTNGbPns2NN97IoEGDANo19quqqlodJ83rOovW+g/wk5/8hB49epCRkcHBgwf5+c9/TnFxMe+++y5wbfT/0KFD5OXl4fP5iImJ4b333mPAgAHs37+/y+z/tmIAV9cYkAmQ9L0bP3585P9Dhgxh9OjR9OjRg3/9619YLJYObJnUke67777I/wcPHsyQIUPo3bs3W7duJT8/vwNb9v2bNWsWhw8fjpr71pW01f+vzucaPHgw6enp5OfnU1paSu/eva90My+L3Nxc9u/fT0NDAytXrmTq1Kls27ato5t1RbUVgwEDBlxVY0CeArsCkpKS0Ol0LWb7V1dXk5aW1kGtunLi4+Pp27cvJSUlpKWlEQgEqK+vjypzLceiuV8X2/9paWktJsSHQiHq6uqu2bj06tWLpKQkSkpKgGsnBo8//jhr1qxhy5YtdOvWLbK8PWM/LS2t1XHSvK4zaKv/rRk9ejRA1Bjo7P03Go306dOHESNGsGDBAoYOHcqrr77aZfY/tB2D1nTkGJAJ0BVgNBoZMWIEmzdvjizTNI3NmzdHnRe9VrlcLkpLS0lPT2fEiBEYDIaoWBQXF1NeXn7NxiI7O5u0tLSoPjc2NlJYWBjpc15eHvX19RQVFUXKfPjhh2iaFnmDuNacOXOG2tpa0tPTgc4fAyEEjz/+OO+99x4ffvgh2dnZUevbM/bz8vI4dOhQVCK4ceNG7HZ75BTC1epS/W/N/v37AaLGQGftf1s0TcPv91/z+/9immPQmg4dA9/rlGqpTcuXLxcmk0ksXbpUfPbZZ2L69OkiPj4+aqb7tWLOnDli69atoqysTHz88cdi7NixIikpSdTU1AghhJgxY4bo3r27+PDDD8XevXtFXl6eyMvL6+BWfzdOp1Ps27dP7Nu3TwDilVdeEfv27ROnTp0SQgjx29/+VsTHx4vVq1eLgwcPigkTJojs7Gzh9XojdRQUFIjrrrtOFBYWio8++kjk5OSI+++/v6O69I1dLAZOp1PMnTtX7Nq1S5SVlYlNmzaJ4cOHi5ycHOHz+SJ1dOYYzJw5U8TFxYmtW7eKysrKyMPj8UTKXGrsh0IhMWjQIHHbbbeJ/fv3i3Xr1onk5GTx3HPPdUSXvpFL9b+kpET85je/EXv37hVlZWVi9erVolevXuLmm2+O1NGZ+y+EEM8++6zYtm2bKCsrEwcPHhTPPvusUBRFbNiwQQhxbe//ZheLwdU2BmQCdAW99tpronv37sJoNIpRo0aJ3bt3d3STLovJkyeL9PR0YTQaRWZmppg8ebIoKSmJrPd6veKxxx4TCQkJwmq1ijvvvFNUVlZ2YIu/uy1btgigxWPq1KlCiKafwv/6178WqampwmQyifz8fFFcXBxVR21trbj//vtFTEyMsNvt4sEHHxROp7MDevPtXCwGHo9H3HbbbSI5OVkYDAbRo0cP8cgjj7T4AtCZY9Ba3wGxZMmSSJn2jP2TJ0+K8ePHC4vFIpKSksScOXNEMBi8wr355i7V//LycnHzzTcLh8MhTCaT6NOnj/jZz34mGhoaourprP0XQoif/vSnokePHsJoNIrk5GSRn58fSX6EuLb3f7OLxeBqGwOKEEJ8v8eUJEmSJEmSrm5yDpAkSZIkSV2OTIAkSZIkSepyZAIkSZIkSVKXIxMgSZIkSZK6HJkASZIkSZLU5cgESJIkSZKkLkcmQJIkSZIkdTkyAZKkTu6pp55i+vTpaJrW0U2RJEnqNGQCJEmd2OnTp8nNzWXx4sWoqvxzliRJai95JWhJkq5qPXv2ZPbs2cyePbujmwLAtGnTqK+vZ9WqVR3dFEmSvgP5lVGSOqFp06ahKEqLR0FBQUc37apz8uRJFEWJ3HX6u3r11VdZunTp91LX1WDatGlMnDixo5shSVecvqMbIEnSt1NQUMCSJUuilplMpg5qTecXCAQwGo2XLBcXF3cFWiNJ0uUmjwBJUidlMplIS0uLeiQkJETWK4rCokWLGD9+PBaLhV69erFy5cqoOg4dOsStt96KxWIhMTGR6dOn43K5osr87W9/Y+DAgZhMJtLT03n88ccj61555RUGDx6MzWYjKyuLxx57LGr7U6dOcccdd5CQkIDNZmPgwIGsXbu2zT7V1NRwxx13YLFYyM7O5u23325Rpr6+nocffpjk5GTsdju33norBw4caLPO7OxsAK677joUReGWW24Bvjzy8eKLL5KRkUFubi7QNK/q3nvvJT4+HofDwYQJEzh58mSkvq8fMbnlllt48skneeaZZ3A4HKSlpTF//vyoNlwqTkuXLiU+Pp41a9aQm5uL1Wrl7rvvxuPxsGzZMnr27ElCQgJPPvkk4XA4sp3f72fu3LlkZmZis9kYPXo0W7dubVHv+vXr6d+/PzExMRQUFFBZWQnA/PnzWbZsGatXr44cRWzevj1jQ5I6M5kASdI17Ne//jV33XUXBw4cYMqUKdx3330cPXoUALfbzbhx40hISOCTTz5hxYoVbNq0KSrBWbRoEbNmzWL69OkcOnSI//mf/6FPnz6R9aqqsnDhQo4cOcKyZcv48MMPeeaZZyLrZ82ahd/vZ/v27Rw6dIjf/e53xMTEtNneadOmcfr0abZs2cLKlSt54403qKmpiSpzzz33UFNTwwcffEBRURHDhw8nPz+furq6Vuvcs2cPAJs2baKyspJ33303sm7z5s0UFxezceNG1qxZQzAYZNy4ccTGxrJjxw4+/vjjSNIQCATabPeyZcuw2WwUFhby0ksv8Zvf/IaNGze2O04AHo+HhQsXsnz5ctatW8fWrVu58847Wbt2LWvXruWtt95i8eLFUUns448/zq5du1i+fDkHDx7knnvuoaCggOPHj0fV+/vf/5633nqL7du3U15ezty5cwGYO3cu9957byQpqqys5Ac/+EG7xoYkdXpCkqROZ+rUqUKn0wmbzRb1ePHFFyNlADFjxoyo7UaPHi1mzpwphBDiz3/+s0hISBAulyuy/v333xeqqoqqqiohhBAZGRnil7/8ZbvbtWLFCpGYmBh5PnjwYDF//vx2bVtcXCwAsWfPnsiyo0ePCkD84Q9/EEIIsWPHDmG324XP54vatnfv3mLx4sWt1ltWViYAsW/fvqjlU6dOFampqcLv90eWvfXWWyI3N1domhZZ5vf7hcViEevXr49sN2HChMj6MWPGiJtuuimq7pEjR4qf//znbfb163FasmSJAERJSUlk2aOPPiqsVqtwOp2RZePGjROPPvqoEEKIU6dOCZ1OJ86ePRtVd35+vnjuuefarPf1118XqampUXH4an+EaN/YkKTOTs4BkqRO6kc/+hGLFi2KWuZwOKKe5+XltXjePBn46NGjDB06FJvNFll/4403omkaxcXFKIpCRUUF+fn5bbZh06ZNLFiwgM8//5zGxkZCoRA+nw+Px4PVauXJJ59k5syZbNiwgbFjx3LXXXcxZMiQVus6evQoer2eESNGRJb169eP+Pj4yPMDBw7gcrlITEyM2tbr9VJaWtpmO9syePDgqHk/Bw4coKSkhNjY2KhyPp/vovV/vU/p6elRR64uFScAq9VK7969I9ukpqbSs2fPqCNmqampkXoPHTpEOBymb9++Ua/t9/uj4vP1er/ettZcamykpqZedHtJ6gxkAiRJnZTNZos6HfV9s1gsF11/8uRJfvzjHzNz5kxefPFFHA4HH330EQ899BCBQACr1crDDz/MuHHjeP/999mwYQMLFizg5Zdf5oknnvhWbXK5XKSnp0fNc2n21USpvb76Ad9c/4gRI1qde5ScnNxmPQaDIeq5oiiRC1O2J05t1XGxel0uFzqdjqKiInQ6XVS5ryZNrdUh5NVPJEnOAZKka9nu3btbPO/fvz8A/fv358CBA7jd7sj6jz/+GFVVyc3NJTY2lp49e7J58+ZW6y4qKkLTNF5++WVuuOEG+vbtS0VFRYtyWVlZzJgxg3fffZc5c+bwl7/8pdX6+vXrRygUoqioKLKsuLiY+vr6yPPhw4dTVVWFXq+nT58+UY+kpKRW620+wvPVycNtGT58OMePHyclJaVF/d/211/tjdM3dd111xEOh6mpqWnR1rS0tHbXYzQaW8TmUmNDkq4FMgGSpE7K7/dTVVUV9Th//nxUmRUrVvC3v/2NY8eOMW/ePPbs2ROZyDplyhTMZjNTp07l8OHDbNmyhSeeeIJ///d/j5zimD9/Pi+//DILFy7k+PHjfPrpp7z22msA9OnTh2AwyGuvvcaJEyd46623ePPNN6Nef/bs2axfv56ysjI+/fRTtmzZEknAvi43N5eCggIeffRRCgsLKSoq4uGHH446EjV27Fjy8vKYOHEiGzZs4OTJk+zcuZNf/vKX7N27t9V6U1JSsFgsrFu3jurqahoaGtqM6ZQpU0hKSmLChAns2LGDsrIytm7dypNPPsmZM2cusUda1544fRt9+/ZlypQpPPDAA7z77ruUlZWxZ88eFixYwPvvv9/uenr27MnBgwcpLi7m/PnzBIPBdo0NSersZAIkSZ3UunXrSE9Pj3rcdNNNUWVeeOEFli9fzpAhQ/j73//OO++8w4ABA4CmuSHr16+nrq6OkSNHcvfdd5Ofn8+f/vSnyPZTp07lj3/8I2+88QYDBw7kxz/+ceQXRkOHDuWVV17hd7/7HYMGDeLtt99mwYIFUa8fDoeZNWsW/fv3p6CggL59+/LGG2+02aclS5aQkZHBmDFjmDRpEtOnTyclJSWyXlEU1q5dy80338yDDz5I3759ue+++zh16lSbH8x6vZ6FCxeyePFiMjIymDBhQpuvb7Va2b59O927d2fSpEn079+fhx56CJ/Ph91ub3O7i2lPnL6tJUuW8MADDzBnzhxyc3OZOHEin3zyCd27d293HY888gi5ublcf/31JCcn8/HHH7drbEhSZydvhSFJ1yhFUXjvvffkVX4lSZJaIY8ASZIkSZLU5cgESJIkSZKkLkf+DF6SrlHy7LYkSVLb5BEgSZIkSZK6HJkASZIkSZLU5cgESJIkSZKkLkcmQJIkSZIkdTkyAZIkSZIkqcuRCZAkSZIkSV2OTIAkSZIkSepyZAIkSZIkSVKXIxMgSZIkSZK6nP8PWA90WGJmiZsAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_treino, x_teste, y_treino, y_teste, = train_test_split(x , y, test_size = 10, random_state = None)"
      ],
      "metadata": {
        "id": "Zp2TVOQYS35i"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resultados_a = list()\n",
        "erros_relativos_a = list()\n",
        "for i in funcoes:\n",
        "  #modelo = modelo_RNA(x_treino, i, 40, 11)\n",
        "  for j in taxas:\n",
        "      otimizador = tf.keras.optimizers.Adam(learning_rate=j)\n",
        "      modelo = modelo_RNA(x_treino, i, 40, 11)\n",
        "      resultado, modelo = treino_modelo(modelo, 'adam', 'mse', ['mae'], x_treino, y_treino, x_teste, y_teste, 350)\n",
        "      resultado = pd.DataFrame(resultado.history)\n",
        "      resultados_a.append(resultado)\n",
        "      y_pred = modelo.predict(x_treino)\n",
        "      y_pred = pd.DataFrame(y_pred)\n",
        "      erro = erro_relativo(y_pred, y_treino)\n",
        "      erros_relativos.append(erro)\n",
        "      '''\n",
        "      plt.plot(resultado.history['loss'])\n",
        "      plt.plot(resultado.history['val_loss'])\n",
        "      plt.title('Histórico de Treinamento')\n",
        "      plt.ylabel('Loss (MSE)')\n",
        "      plt.xlabel('Épocas de treinamento')\n",
        "      plt.legend(['Erro treino', 'Erro teste'])\n",
        "      plt.show()\n",
        "      '''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7rtx6-wMTGG5",
        "outputId": "9fdae02a-4cc7-439f-d8d5-a8a4318340ed"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_25\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_300 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_275 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_301 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_276 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_302 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_277 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_303 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_278 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_304 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_279 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_305 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_280 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_306 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_281 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_307 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_282 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_308 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_283 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_309 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_284 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_310 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_285 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_311 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 0.3188 - mae: 0.4544 - val_loss: 0.0109 - val_mae: 0.0954\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2273 - mae: 0.3743 - val_loss: 0.0092 - val_mae: 0.0908\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1620 - mae: 0.3375 - val_loss: 0.0049 - val_mae: 0.0673\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1334 - mae: 0.2902 - val_loss: 0.0073 - val_mae: 0.0791\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.1130 - mae: 0.2693 - val_loss: 0.0015 - val_mae: 0.0288\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0830 - mae: 0.2236 - val_loss: 0.0022 - val_mae: 0.0436\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0843 - mae: 0.2321 - val_loss: 0.0014 - val_mae: 0.0322\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0793 - mae: 0.2248 - val_loss: 9.9660e-04 - val_mae: 0.0212\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0604 - mae: 0.1812 - val_loss: 0.0113 - val_mae: 0.1020\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0891 - mae: 0.2430 - val_loss: 0.0022 - val_mae: 0.0434\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0681 - mae: 0.2009 - val_loss: 0.0012 - val_mae: 0.0285\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0493 - mae: 0.1861 - val_loss: 0.0035 - val_mae: 0.0555\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0799 - mae: 0.2222 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0610 - mae: 0.1790 - val_loss: 0.0012 - val_mae: 0.0290\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0547 - mae: 0.1793 - val_loss: 0.0026 - val_mae: 0.0416\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0605 - mae: 0.1963 - val_loss: 9.1058e-04 - val_mae: 0.0205\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0507 - mae: 0.1697 - val_loss: 0.0043 - val_mae: 0.0618\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0513 - mae: 0.1643 - val_loss: 0.0084 - val_mae: 0.0865\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0517 - mae: 0.1824 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0416 - mae: 0.1619 - val_loss: 0.0026 - val_mae: 0.0418\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0262 - mae: 0.1290 - val_loss: 0.0023 - val_mae: 0.0380\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0420 - mae: 0.1522 - val_loss: 9.9859e-04 - val_mae: 0.0212\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0417 - mae: 0.1627 - val_loss: 0.0032 - val_mae: 0.0535\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0278 - mae: 0.1256 - val_loss: 0.0011 - val_mae: 0.0283\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0289 - mae: 0.1375 - val_loss: 0.0021 - val_mae: 0.0428\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0350 - mae: 0.1430 - val_loss: 9.8879e-04 - val_mae: 0.0211\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0280 - mae: 0.1273 - val_loss: 0.0011 - val_mae: 0.0282\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0409 - mae: 0.1435 - val_loss: 9.1269e-04 - val_mae: 0.0210\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0272 - mae: 0.1276 - val_loss: 0.0036 - val_mae: 0.0524\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0229 - mae: 0.1189 - val_loss: 9.2741e-04 - val_mae: 0.0203\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0374 - mae: 0.1447 - val_loss: 0.0015 - val_mae: 0.0352\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0248 - mae: 0.1259 - val_loss: 0.0011 - val_mae: 0.0278\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 0.1224 - val_loss: 0.0012 - val_mae: 0.0298\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0184 - mae: 0.1073 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0195 - mae: 0.1055 - val_loss: 9.0051e-04 - val_mae: 0.0197\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1048 - val_loss: 9.0051e-04 - val_mae: 0.0198\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0217 - mae: 0.1151 - val_loss: 0.0015 - val_mae: 0.0340\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0298 - mae: 0.1329 - val_loss: 0.0011 - val_mae: 0.0272\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0246 - mae: 0.1203 - val_loss: 9.3282e-04 - val_mae: 0.0204\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0203 - mae: 0.1118 - val_loss: 0.0011 - val_mae: 0.0277\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0219 - mae: 0.1114 - val_loss: 0.0011 - val_mae: 0.0277\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.1076 - val_loss: 0.0013 - val_mae: 0.0307\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0232 - mae: 0.1095 - val_loss: 9.2803e-04 - val_mae: 0.0221\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0182 - mae: 0.1056 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0233 - mae: 0.1118 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.1062 - val_loss: 9.1354e-04 - val_mae: 0.0212\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0188 - mae: 0.1017 - val_loss: 0.0012 - val_mae: 0.0293\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0214 - mae: 0.1151 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.0987 - val_loss: 9.0744e-04 - val_mae: 0.0207\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0149 - mae: 0.0958 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0166 - mae: 0.0956 - val_loss: 9.0777e-04 - val_mae: 0.0206\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0184 - mae: 0.1010 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0133 - mae: 0.0791 - val_loss: 9.7583e-04 - val_mae: 0.0210\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0889 - val_loss: 0.0011 - val_mae: 0.0272\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0965 - val_loss: 0.0011 - val_mae: 0.0277\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0159 - mae: 0.0938 - val_loss: 9.6382e-04 - val_mae: 0.0236\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0900 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0120 - mae: 0.0875 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0965 - val_loss: 9.0337e-04 - val_mae: 0.0197\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0865 - val_loss: 9.1342e-04 - val_mae: 0.0200\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0157 - mae: 0.0904 - val_loss: 9.6904e-04 - val_mae: 0.0209\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0661 - val_loss: 9.3208e-04 - val_mae: 0.0204\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0126 - mae: 0.0768 - val_loss: 8.9990e-04 - val_mae: 0.0199\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0137 - mae: 0.0866 - val_loss: 9.2615e-04 - val_mae: 0.0219\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0141 - mae: 0.0870 - val_loss: 8.9897e-04 - val_mae: 0.0197\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0132 - mae: 0.0848 - val_loss: 9.4229e-04 - val_mae: 0.0228\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0711 - val_loss: 9.0396e-04 - val_mae: 0.0197\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0136 - mae: 0.0857 - val_loss: 9.5151e-04 - val_mae: 0.0207\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0805 - val_loss: 9.4539e-04 - val_mae: 0.0206\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0634 - val_loss: 9.3409e-04 - val_mae: 0.0224\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0116 - mae: 0.0744 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0751 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0103 - mae: 0.0765 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0766 - val_loss: 0.0012 - val_mae: 0.0298\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0099 - mae: 0.0793 - val_loss: 0.0011 - val_mae: 0.0278\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0810 - val_loss: 8.9874e-04 - val_mae: 0.0198\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0708 - val_loss: 9.3182e-04 - val_mae: 0.0223\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0117 - mae: 0.0833 - val_loss: 9.1817e-04 - val_mae: 0.0215\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0092 - mae: 0.0694 - val_loss: 9.1089e-04 - val_mae: 0.0209\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0749 - val_loss: 8.9869e-04 - val_mae: 0.0197\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0091 - mae: 0.0662 - val_loss: 9.0172e-04 - val_mae: 0.0201\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0659 - val_loss: 8.9766e-04 - val_mae: 0.0197\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0762 - val_loss: 9.0754e-04 - val_mae: 0.0206\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0633 - val_loss: 8.9787e-04 - val_mae: 0.0197\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0611 - val_loss: 9.8171e-04 - val_mae: 0.0211\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0707 - val_loss: 9.4798e-04 - val_mae: 0.0206\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0668 - val_loss: 9.1065e-04 - val_mae: 0.0199\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0747 - val_loss: 9.2912e-04 - val_mae: 0.0203\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0633 - val_loss: 8.9998e-04 - val_mae: 0.0197\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0600 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0603 - val_loss: 9.0489e-04 - val_mae: 0.0203\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0085 - mae: 0.0633 - val_loss: 9.9138e-04 - val_mae: 0.0246\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0073 - mae: 0.0563 - val_loss: 0.0011 - val_mae: 0.0277\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0084 - mae: 0.0653 - val_loss: 9.9507e-04 - val_mae: 0.0212\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0089 - mae: 0.0641 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0097 - mae: 0.0681 - val_loss: 9.6892e-04 - val_mae: 0.0209\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0683 - val_loss: 9.7649e-04 - val_mae: 0.0241\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0591 - val_loss: 8.9937e-04 - val_mae: 0.0197\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0607 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0576 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0071 - mae: 0.0535 - val_loss: 9.3938e-04 - val_mae: 0.0205\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0572 - val_loss: 8.9883e-04 - val_mae: 0.0197\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0656 - val_loss: 8.9915e-04 - val_mae: 0.0197\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0594 - val_loss: 9.1908e-04 - val_mae: 0.0201\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0502 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0576 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0574 - val_loss: 8.9946e-04 - val_mae: 0.0197\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0574 - val_loss: 8.9944e-04 - val_mae: 0.0197\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0519 - val_loss: 9.2606e-04 - val_mae: 0.0203\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0544 - val_loss: 9.1042e-04 - val_mae: 0.0199\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0461 - val_loss: 9.3208e-04 - val_mae: 0.0204\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0541 - val_loss: 9.2198e-04 - val_mae: 0.0202\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0524 - val_loss: 9.9268e-04 - val_mae: 0.0212\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0452 - val_loss: 9.6984e-04 - val_mae: 0.0209\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0071 - mae: 0.0550 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0543 - val_loss: 9.5217e-04 - val_mae: 0.0207\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0493 - val_loss: 9.2043e-04 - val_mae: 0.0215\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0496 - val_loss: 9.2776e-04 - val_mae: 0.0220\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0547 - val_loss: 9.3708e-04 - val_mae: 0.0205\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0066 - mae: 0.0481 - val_loss: 9.3049e-04 - val_mae: 0.0204\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0516 - val_loss: 9.0359e-04 - val_mae: 0.0201\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0479 - val_loss: 9.0157e-04 - val_mae: 0.0197\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0496 - val_loss: 9.0606e-04 - val_mae: 0.0203\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0473 - val_loss: 9.0066e-04 - val_mae: 0.0197\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0493 - val_loss: 9.1423e-04 - val_mae: 0.0200\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0489 - val_loss: 9.0593e-04 - val_mae: 0.0198\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0443 - val_loss: 9.0270e-04 - val_mae: 0.0197\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0529 - val_loss: 9.0073e-04 - val_mae: 0.0199\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0519 - val_loss: 9.1782e-04 - val_mae: 0.0201\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0480 - val_loss: 9.0380e-04 - val_mae: 0.0202\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0470 - val_loss: 9.0012e-04 - val_mae: 0.0198\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0480 - val_loss: 9.0102e-04 - val_mae: 0.0199\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0471 - val_loss: 9.0050e-04 - val_mae: 0.0197\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0456 - val_loss: 9.0023e-04 - val_mae: 0.0197\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0431 - val_loss: 9.5247e-04 - val_mae: 0.0207\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0414 - val_loss: 9.0028e-04 - val_mae: 0.0197\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0405 - val_loss: 9.0456e-04 - val_mae: 0.0197\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0445 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0430 - val_loss: 9.2219e-04 - val_mae: 0.0202\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0437 - val_loss: 9.1281e-04 - val_mae: 0.0210\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0452 - val_loss: 9.0230e-04 - val_mae: 0.0199\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0408 - val_loss: 9.0922e-04 - val_mae: 0.0206\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0080 - mae: 0.0517 - val_loss: 9.0205e-04 - val_mae: 0.0199\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0538 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0453 - val_loss: 9.0922e-04 - val_mae: 0.0206\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0463 - val_loss: 9.0854e-04 - val_mae: 0.0198\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0396 - val_loss: 8.9972e-04 - val_mae: 0.0197\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0437 - val_loss: 9.0317e-04 - val_mae: 0.0201\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0430 - val_loss: 8.9971e-04 - val_mae: 0.0197\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0445 - val_loss: 9.1066e-04 - val_mae: 0.0208\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0417 - val_loss: 0.0010 - val_mae: 0.0260\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0446 - val_loss: 8.9991e-04 - val_mae: 0.0197\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0055 - mae: 0.0402 - val_loss: 9.0335e-04 - val_mae: 0.0197\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0395 - val_loss: 9.0077e-04 - val_mae: 0.0197\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0358 - val_loss: 9.0026e-04 - val_mae: 0.0197\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0426 - val_loss: 9.3927e-04 - val_mae: 0.0226\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0364 - val_loss: 9.1172e-04 - val_mae: 0.0209\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0054 - mae: 0.0388 - val_loss: 9.5037e-04 - val_mae: 0.0231\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0410 - val_loss: 8.9897e-04 - val_mae: 0.0197\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0418 - val_loss: 9.0346e-04 - val_mae: 0.0197\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0390 - val_loss: 9.0586e-04 - val_mae: 0.0198\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0386 - val_loss: 9.1562e-04 - val_mae: 0.0201\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0370 - val_loss: 9.1845e-04 - val_mae: 0.0201\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0389 - val_loss: 8.9904e-04 - val_mae: 0.0197\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0396 - val_loss: 9.0086e-04 - val_mae: 0.0197\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0379 - val_loss: 9.0718e-04 - val_mae: 0.0198\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0385 - val_loss: 9.0225e-04 - val_mae: 0.0197\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0384 - val_loss: 9.0612e-04 - val_mae: 0.0204\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0389 - val_loss: 9.0787e-04 - val_mae: 0.0206\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0396 - val_loss: 9.0287e-04 - val_mae: 0.0197\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0363 - val_loss: 9.2808e-04 - val_mae: 0.0203\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0374 - val_loss: 9.2569e-04 - val_mae: 0.0203\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0365 - val_loss: 9.0398e-04 - val_mae: 0.0197\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0057 - mae: 0.0364 - val_loss: 9.0316e-04 - val_mae: 0.0201\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0392 - val_loss: 8.9915e-04 - val_mae: 0.0197\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0361 - val_loss: 9.0399e-04 - val_mae: 0.0202\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0360 - val_loss: 9.0367e-04 - val_mae: 0.0197\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0342 - val_loss: 9.2119e-04 - val_mae: 0.0202\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0368 - val_loss: 9.1494e-04 - val_mae: 0.0212\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 9.2595e-04 - val_mae: 0.0219\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0378 - val_loss: 9.0868e-04 - val_mae: 0.0206\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0052 - mae: 0.0393 - val_loss: 9.2536e-04 - val_mae: 0.0203\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0379 - val_loss: 9.0173e-04 - val_mae: 0.0200\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0416 - val_loss: 9.2182e-04 - val_mae: 0.0216\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0362 - val_loss: 9.1321e-04 - val_mae: 0.0210\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0403 - val_loss: 9.7385e-04 - val_mae: 0.0240\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0375 - val_loss: 9.2527e-04 - val_mae: 0.0219\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0375 - val_loss: 9.1862e-04 - val_mae: 0.0201\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0367 - val_loss: 9.0291e-04 - val_mae: 0.0201\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0369 - val_loss: 9.2331e-04 - val_mae: 0.0202\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0362 - val_loss: 9.1647e-04 - val_mae: 0.0201\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0347 - val_loss: 9.0906e-04 - val_mae: 0.0206\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0374 - val_loss: 9.0362e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0417 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0435 - val_loss: 9.2496e-04 - val_mae: 0.0202\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0404 - val_loss: 9.0848e-04 - val_mae: 0.0198\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0068 - mae: 0.0434 - val_loss: 9.2431e-04 - val_mae: 0.0202\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 9.0609e-04 - val_mae: 0.0198\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0360 - val_loss: 9.2835e-04 - val_mae: 0.0220\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0379 - val_loss: 8.9957e-04 - val_mae: 0.0197\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0334 - val_loss: 9.0399e-04 - val_mae: 0.0197\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0351 - val_loss: 9.0174e-04 - val_mae: 0.0200\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0364 - val_loss: 9.2363e-04 - val_mae: 0.0202\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0360 - val_loss: 9.8775e-04 - val_mae: 0.0211\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0329 - val_loss: 9.1768e-04 - val_mae: 0.0201\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0328 - val_loss: 9.1045e-04 - val_mae: 0.0199\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0053 - mae: 0.0334 - val_loss: 9.0320e-04 - val_mae: 0.0201\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0370 - val_loss: 9.0354e-04 - val_mae: 0.0197\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0401 - val_loss: 0.0011 - val_mae: 0.0274\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0389 - val_loss: 9.1214e-04 - val_mae: 0.0200\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0359 - val_loss: 9.8503e-04 - val_mae: 0.0211\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0332 - val_loss: 9.6109e-04 - val_mae: 0.0208\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0365 - val_loss: 9.0730e-04 - val_mae: 0.0206\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0362 - val_loss: 9.0565e-04 - val_mae: 0.0204\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0347 - val_loss: 9.2286e-04 - val_mae: 0.0202\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0334 - val_loss: 9.1812e-04 - val_mae: 0.0201\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0312 - val_loss: 9.0053e-04 - val_mae: 0.0199\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0338 - val_loss: 8.9994e-04 - val_mae: 0.0198\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0366 - val_loss: 9.0110e-04 - val_mae: 0.0197\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0370 - val_loss: 9.6404e-04 - val_mae: 0.0236\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 9.0186e-04 - val_mae: 0.0197\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0331 - val_loss: 9.1791e-04 - val_mae: 0.0201\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0321 - val_loss: 8.9983e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0338 - val_loss: 9.0721e-04 - val_mae: 0.0198\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0308 - val_loss: 9.1477e-04 - val_mae: 0.0200\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0311 - val_loss: 9.1934e-04 - val_mae: 0.0201\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0302 - val_loss: 9.0798e-04 - val_mae: 0.0198\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 8.9906e-04 - val_mae: 0.0197\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0326 - val_loss: 8.9867e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0330 - val_loss: 9.0855e-04 - val_mae: 0.0199\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0321 - val_loss: 9.3292e-04 - val_mae: 0.0204\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0276 - val_loss: 9.3558e-04 - val_mae: 0.0205\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0293 - val_loss: 9.0942e-04 - val_mae: 0.0199\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0320 - val_loss: 8.9900e-04 - val_mae: 0.0197\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0277 - val_loss: 8.9965e-04 - val_mae: 0.0197\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0340 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0310 - val_loss: 8.9985e-04 - val_mae: 0.0197\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 9.0041e-04 - val_mae: 0.0197\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0312 - val_loss: 9.0035e-04 - val_mae: 0.0197\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0041 - mae: 0.0306 - val_loss: 9.0174e-04 - val_mae: 0.0197\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0302 - val_loss: 9.0376e-04 - val_mae: 0.0197\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0328 - val_loss: 9.0677e-04 - val_mae: 0.0198\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 9.1870e-04 - val_mae: 0.0201\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0291 - val_loss: 8.9939e-04 - val_mae: 0.0197\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 9.0036e-04 - val_mae: 0.0197\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0289 - val_loss: 9.1850e-04 - val_mae: 0.0201\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0302 - val_loss: 9.0462e-04 - val_mae: 0.0197\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.1430e-04 - val_mae: 0.0200\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0291 - val_loss: 8.9978e-04 - val_mae: 0.0197\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0319 - val_loss: 9.1059e-04 - val_mae: 0.0199\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 9.2653e-04 - val_mae: 0.0203\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 8.9953e-04 - val_mae: 0.0197\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0302 - val_loss: 9.1180e-04 - val_mae: 0.0199\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0286 - val_loss: 9.0141e-04 - val_mae: 0.0197\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0288 - val_loss: 9.0030e-04 - val_mae: 0.0197\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0302 - val_loss: 9.0855e-04 - val_mae: 0.0198\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 9.0976e-04 - val_mae: 0.0199\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 8.9984e-04 - val_mae: 0.0197\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0344 - val_loss: 0.0011 - val_mae: 0.0269\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0365 - val_loss: 9.0288e-04 - val_mae: 0.0197\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0285 - val_loss: 8.9937e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 9.1442e-04 - val_mae: 0.0200\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0296 - val_loss: 8.9948e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0296 - val_loss: 9.0240e-04 - val_mae: 0.0197\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0307 - val_loss: 9.5369e-04 - val_mae: 0.0207\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0285 - val_loss: 9.0910e-04 - val_mae: 0.0199\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.0188e-04 - val_mae: 0.0199\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0295 - val_loss: 9.4302e-04 - val_mae: 0.0228\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 9.2838e-04 - val_mae: 0.0220\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0302 - val_loss: 9.1013e-04 - val_mae: 0.0208\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0289 - val_loss: 9.0668e-04 - val_mae: 0.0198\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 9.0053e-04 - val_mae: 0.0197\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 9.0397e-04 - val_mae: 0.0197\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.0532e-04 - val_mae: 0.0203\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0295 - val_loss: 9.0482e-04 - val_mae: 0.0197\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0940e-04 - val_mae: 0.0199\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 8.9954e-04 - val_mae: 0.0197\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0260 - val_loss: 9.0777e-04 - val_mae: 0.0205\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0305 - val_loss: 9.0287e-04 - val_mae: 0.0197\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 9.0157e-04 - val_mae: 0.0199\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0261 - val_loss: 9.0380e-04 - val_mae: 0.0197\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0291 - val_loss: 9.0006e-04 - val_mae: 0.0197\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 9.0337e-04 - val_mae: 0.0197\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0287 - val_loss: 9.0458e-04 - val_mae: 0.0197\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0282 - val_loss: 9.0482e-04 - val_mae: 0.0197\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0285e-04 - val_mae: 0.0197\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 8.9993e-04 - val_mae: 0.0197\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0290 - val_loss: 9.1258e-04 - val_mae: 0.0200\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 9.0589e-04 - val_mae: 0.0198\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0265 - val_loss: 9.0707e-04 - val_mae: 0.0198\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0272 - val_loss: 8.9935e-04 - val_mae: 0.0197\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0279 - val_loss: 9.1925e-04 - val_mae: 0.0201\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.0711e-04 - val_mae: 0.0198\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0272 - val_loss: 9.0119e-04 - val_mae: 0.0197\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 8.9976e-04 - val_mae: 0.0197\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 9.1298e-04 - val_mae: 0.0200\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.0288e-04 - val_mae: 0.0197\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 9.0918e-04 - val_mae: 0.0199\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 8.9941e-04 - val_mae: 0.0197\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 8.9943e-04 - val_mae: 0.0197\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.9953e-04 - val_mae: 0.0197\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0292 - val_loss: 8.9998e-04 - val_mae: 0.0197\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 9.0936e-04 - val_mae: 0.0199\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0255 - val_loss: 8.9965e-04 - val_mae: 0.0197\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0256 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.0216e-04 - val_mae: 0.0197\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 9.0327e-04 - val_mae: 0.0197\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 9.0412e-04 - val_mae: 0.0197\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0263 - val_loss: 9.0054e-04 - val_mae: 0.0197\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 8.9950e-04 - val_mae: 0.0197\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 9.1120e-04 - val_mae: 0.0199\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.9941e-04 - val_mae: 0.0197\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0146e-04 - val_mae: 0.0199\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.0103e-04 - val_mae: 0.0198\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0265e-04 - val_mae: 0.0197\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.0811e-04 - val_mae: 0.0198\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.2406e-04 - val_mae: 0.0202\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.0463e-04 - val_mae: 0.0197\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.9980e-04 - val_mae: 0.0197\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0276 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.0085e-04 - val_mae: 0.0197\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.9905e-04 - val_mae: 0.0197\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 8.9980e-04 - val_mae: 0.0197\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 9.1005e-04 - val_mae: 0.0199\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0243 - val_loss: 9.0450e-04 - val_mae: 0.0202\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 9.0352e-04 - val_mae: 0.0201\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0255 - val_loss: 9.0137e-04 - val_mae: 0.0199\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 9.1157e-04 - val_mae: 0.0199\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 9.4469e-04 - val_mae: 0.0206\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 9.0206e-04 - val_mae: 0.0197\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.0784e-04 - val_mae: 0.0206\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 9.0055e-04 - val_mae: 0.0198\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0071e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0246 - val_loss: 9.0248e-04 - val_mae: 0.0197\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0341e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0375e-04 - val_mae: 0.0197\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.1493e-04 - val_mae: 0.0212\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.0158e-04 - val_mae: 0.0199\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 8.9921e-04 - val_mae: 0.0197\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0246 - val_loss: 9.0008e-04 - val_mae: 0.0197\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.0773e-04 - val_mae: 0.0198\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0248 - val_loss: 8.9897e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0280 - val_loss: 9.0153e-04 - val_mae: 0.0197\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0252 - val_loss: 9.0120e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.0557e-04 - val_mae: 0.0198\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 9.0117e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0140e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.1309e-04 - val_mae: 0.0200\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_26\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_312 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_286 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_313 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_287 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_314 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_288 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_315 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_289 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_316 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_290 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_317 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_291 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_318 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_292 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_319 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_293 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_320 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_294 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_321 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_295 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_322 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_296 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_323 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 0.2278 - mae: 0.3656 - val_loss: 0.0271 - val_mae: 0.1620\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1076 - mae: 0.2601 - val_loss: 0.0111 - val_mae: 0.1023\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0546 - mae: 0.1946 - val_loss: 0.0108 - val_mae: 0.0934\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0739 - mae: 0.2117 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0509 - mae: 0.1893 - val_loss: 0.0031 - val_mae: 0.0522\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0585 - mae: 0.1918 - val_loss: 0.0021 - val_mae: 0.0428\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0540 - mae: 0.1766 - val_loss: 9.3137e-04 - val_mae: 0.0204\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0553 - mae: 0.1815 - val_loss: 9.3183e-04 - val_mae: 0.0204\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0513 - mae: 0.1787 - val_loss: 0.0030 - val_mae: 0.0515\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0462 - mae: 0.1545 - val_loss: 9.9385e-04 - val_mae: 0.0212\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0501 - mae: 0.1631 - val_loss: 0.0022 - val_mae: 0.0438\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0515 - mae: 0.1730 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0459 - mae: 0.1643 - val_loss: 0.0016 - val_mae: 0.0355\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0322 - mae: 0.1433 - val_loss: 9.2610e-04 - val_mae: 0.0202\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0421 - mae: 0.1588 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0276 - mae: 0.1326 - val_loss: 0.0015 - val_mae: 0.0345\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0287 - mae: 0.1309 - val_loss: 0.0011 - val_mae: 0.0280\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1445 - val_loss: 9.1787e-04 - val_mae: 0.0204\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0284 - mae: 0.1272 - val_loss: 0.0029 - val_mae: 0.0452\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0315 - mae: 0.1255 - val_loss: 8.9284e-04 - val_mae: 0.0200\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0222 - mae: 0.1140 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0253 - mae: 0.1238 - val_loss: 9.2863e-04 - val_mae: 0.0214\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0238 - mae: 0.1146 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0224 - mae: 0.1082 - val_loss: 0.0010 - val_mae: 0.0209\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0231 - mae: 0.1191 - val_loss: 0.0025 - val_mae: 0.0468\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0182 - mae: 0.1037 - val_loss: 9.7625e-04 - val_mae: 0.0208\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0196 - mae: 0.1021 - val_loss: 9.8958e-04 - val_mae: 0.0209\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.1020 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0201 - mae: 0.1101 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0177 - mae: 0.0951 - val_loss: 0.0010 - val_mae: 0.0207\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0180 - mae: 0.1018 - val_loss: 0.0016 - val_mae: 0.0300\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0968 - val_loss: 0.0015 - val_mae: 0.0292\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0862 - val_loss: 0.0011 - val_mae: 0.0277\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0178 - mae: 0.0974 - val_loss: 0.0029 - val_mae: 0.0505\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.0887 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0809 - val_loss: 0.0013 - val_mae: 0.0264\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0162 - mae: 0.0924 - val_loss: 0.0011 - val_mae: 0.0217\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0164 - mae: 0.1035 - val_loss: 0.0010 - val_mae: 0.0247\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0831 - val_loss: 0.0011 - val_mae: 0.0274\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0178 - mae: 0.1022 - val_loss: 9.2718e-04 - val_mae: 0.0205\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0140 - mae: 0.0861 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0119 - mae: 0.0813 - val_loss: 0.0011 - val_mae: 0.0217\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0759 - val_loss: 9.8903e-04 - val_mae: 0.0211\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0806 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0185 - mae: 0.0929 - val_loss: 9.5609e-04 - val_mae: 0.0228\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0714 - val_loss: 0.0011 - val_mae: 0.0274\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0755 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0762 - val_loss: 9.5682e-04 - val_mae: 0.0207\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0779 - val_loss: 9.3537e-04 - val_mae: 0.0204\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0744 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0728 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0731 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0696 - val_loss: 9.9554e-04 - val_mae: 0.0249\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0101 - mae: 0.0732 - val_loss: 9.0549e-04 - val_mae: 0.0201\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0646 - val_loss: 9.7322e-04 - val_mae: 0.0212\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0695 - val_loss: 8.8994e-04 - val_mae: 0.0200\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0694 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0624 - val_loss: 8.7380e-04 - val_mae: 0.0195\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0624 - val_loss: 9.9396e-04 - val_mae: 0.0212\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0653 - val_loss: 9.7284e-04 - val_mae: 0.0208\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0602 - val_loss: 9.1121e-04 - val_mae: 0.0198\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0086 - mae: 0.0580 - val_loss: 9.8255e-04 - val_mae: 0.0210\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0667 - val_loss: 9.1622e-04 - val_mae: 0.0211\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0115 - mae: 0.0674 - val_loss: 9.4722e-04 - val_mae: 0.0229\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0628 - val_loss: 9.0019e-04 - val_mae: 0.0198\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0123 - mae: 0.0808 - val_loss: 9.0338e-04 - val_mae: 0.0197\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0615 - val_loss: 9.0442e-04 - val_mae: 0.0203\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0622 - val_loss: 9.0425e-04 - val_mae: 0.0203\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0094 - mae: 0.0610 - val_loss: 9.6738e-04 - val_mae: 0.0238\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0617 - val_loss: 9.0600e-04 - val_mae: 0.0198\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - mae: 0.0576 - val_loss: 9.1244e-04 - val_mae: 0.0210\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0577 - val_loss: 9.8289e-04 - val_mae: 0.0211\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0564 - val_loss: 9.2611e-04 - val_mae: 0.0203\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0511 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0497 - val_loss: 9.1270e-04 - val_mae: 0.0209\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0113 - mae: 0.0559 - val_loss: 9.1426e-04 - val_mae: 0.0200\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0080 - mae: 0.0558 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0088 - mae: 0.0608 - val_loss: 9.0404e-04 - val_mae: 0.0197\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0089 - mae: 0.0565 - val_loss: 9.1282e-04 - val_mae: 0.0209\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0572 - val_loss: 9.4865e-04 - val_mae: 0.0206\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0590 - val_loss: 9.0956e-04 - val_mae: 0.0199\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0582 - val_loss: 9.0026e-04 - val_mae: 0.0197\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0510 - val_loss: 9.1453e-04 - val_mae: 0.0200\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0560 - val_loss: 9.5382e-04 - val_mae: 0.0207\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0525 - val_loss: 9.4346e-04 - val_mae: 0.0206\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0512 - val_loss: 9.0005e-04 - val_mae: 0.0197\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0444 - val_loss: 8.9891e-04 - val_mae: 0.0197\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0599 - val_loss: 9.2810e-04 - val_mae: 0.0220\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0474 - val_loss: 9.0176e-04 - val_mae: 0.0197\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0058 - mae: 0.0465 - val_loss: 9.2169e-04 - val_mae: 0.0202\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0479 - val_loss: 9.3936e-04 - val_mae: 0.0226\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0475 - val_loss: 9.1661e-04 - val_mae: 0.0213\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0462 - val_loss: 9.0161e-04 - val_mae: 0.0197\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0475 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0504 - val_loss: 9.0636e-04 - val_mae: 0.0204\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0460 - val_loss: 9.0228e-04 - val_mae: 0.0200\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0457 - val_loss: 9.2118e-04 - val_mae: 0.0216\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0523 - val_loss: 9.4969e-04 - val_mae: 0.0231\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0510 - val_loss: 9.0765e-04 - val_mae: 0.0198\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0485 - val_loss: 9.2934e-04 - val_mae: 0.0203\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0482 - val_loss: 9.2043e-04 - val_mae: 0.0202\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0442 - val_loss: 9.0089e-04 - val_mae: 0.0198\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0516 - val_loss: 9.0224e-04 - val_mae: 0.0197\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0467 - val_loss: 9.0028e-04 - val_mae: 0.0197\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0484 - val_loss: 9.0006e-04 - val_mae: 0.0198\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0448 - val_loss: 9.5358e-04 - val_mae: 0.0207\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0403 - val_loss: 8.9964e-04 - val_mae: 0.0197\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0431 - val_loss: 9.5127e-04 - val_mae: 0.0231\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0422 - val_loss: 8.9952e-04 - val_mae: 0.0197\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0405 - val_loss: 9.6300e-04 - val_mae: 0.0208\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0441 - val_loss: 9.4543e-04 - val_mae: 0.0206\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0441 - val_loss: 9.0386e-04 - val_mae: 0.0197\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0479 - val_loss: 9.0051e-04 - val_mae: 0.0197\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0491 - val_loss: 9.6333e-04 - val_mae: 0.0236\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0440 - val_loss: 9.1327e-04 - val_mae: 0.0211\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0423 - val_loss: 9.0283e-04 - val_mae: 0.0201\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0478 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0403 - val_loss: 9.8839e-04 - val_mae: 0.0211\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0395 - val_loss: 9.0022e-04 - val_mae: 0.0197\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0429 - val_loss: 9.0812e-04 - val_mae: 0.0198\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0427 - val_loss: 9.0556e-04 - val_mae: 0.0198\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0378 - val_loss: 9.4254e-04 - val_mae: 0.0206\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0441 - val_loss: 9.4023e-04 - val_mae: 0.0205\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0393 - val_loss: 9.0669e-04 - val_mae: 0.0205\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0441 - val_loss: 9.2160e-04 - val_mae: 0.0217\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0397 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0416 - val_loss: 9.1160e-04 - val_mae: 0.0209\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0412 - val_loss: 9.0887e-04 - val_mae: 0.0207\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0417 - val_loss: 9.0017e-04 - val_mae: 0.0197\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0363 - val_loss: 9.0241e-04 - val_mae: 0.0197\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0355 - val_loss: 9.1760e-04 - val_mae: 0.0201\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0405 - val_loss: 9.2259e-04 - val_mae: 0.0217\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0384 - val_loss: 9.1563e-04 - val_mae: 0.0213\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0372 - val_loss: 9.0172e-04 - val_mae: 0.0200\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0391 - val_loss: 9.2775e-04 - val_mae: 0.0203\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0360 - val_loss: 9.2724e-04 - val_mae: 0.0203\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0396 - val_loss: 8.9978e-04 - val_mae: 0.0197\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0376 - val_loss: 9.1353e-04 - val_mae: 0.0200\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0361 - val_loss: 9.0013e-04 - val_mae: 0.0197\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0402 - val_loss: 9.1919e-04 - val_mae: 0.0201\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0441 - val_loss: 0.0012 - val_mae: 0.0300\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0441 - val_loss: 9.3972e-04 - val_mae: 0.0205\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0407 - val_loss: 8.9944e-04 - val_mae: 0.0197\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0445 - val_loss: 9.0879e-04 - val_mae: 0.0198\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0420 - val_loss: 9.0175e-04 - val_mae: 0.0197\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0357 - val_loss: 9.0134e-04 - val_mae: 0.0199\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0367 - val_loss: 9.0042e-04 - val_mae: 0.0198\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0360 - val_loss: 9.0015e-04 - val_mae: 0.0198\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0405 - val_loss: 8.9849e-04 - val_mae: 0.0197\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0326 - val_loss: 9.2265e-04 - val_mae: 0.0202\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0348 - val_loss: 9.0181e-04 - val_mae: 0.0197\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0371 - val_loss: 8.9959e-04 - val_mae: 0.0197\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0380 - val_loss: 9.0608e-04 - val_mae: 0.0198\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0372 - val_loss: 9.0195e-04 - val_mae: 0.0200\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0332 - val_loss: 9.2310e-04 - val_mae: 0.0202\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0349 - val_loss: 9.1551e-04 - val_mae: 0.0212\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0343 - val_loss: 9.0882e-04 - val_mae: 0.0198\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0336 - val_loss: 9.0919e-04 - val_mae: 0.0199\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0311 - val_loss: 9.0255e-04 - val_mae: 0.0197\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0339 - val_loss: 9.1323e-04 - val_mae: 0.0200\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0319 - val_loss: 9.6143e-04 - val_mae: 0.0208\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0335 - val_loss: 9.2574e-04 - val_mae: 0.0203\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0320 - val_loss: 9.1718e-04 - val_mae: 0.0201\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0046 - mae: 0.0318 - val_loss: 9.1321e-04 - val_mae: 0.0211\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0356 - val_loss: 8.9882e-04 - val_mae: 0.0196\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0319 - val_loss: 9.4792e-04 - val_mae: 0.0206\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0049 - mae: 0.0358 - val_loss: 8.9829e-04 - val_mae: 0.0196\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0319 - val_loss: 9.0872e-04 - val_mae: 0.0207\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0335 - val_loss: 9.0507e-04 - val_mae: 0.0197\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0343 - val_loss: 8.9891e-04 - val_mae: 0.0197\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0322 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0337 - val_loss: 9.0241e-04 - val_mae: 0.0201\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0342 - val_loss: 9.0713e-04 - val_mae: 0.0205\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0355 - val_loss: 9.2261e-04 - val_mae: 0.0202\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0327 - val_loss: 9.7441e-04 - val_mae: 0.0210\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0326 - val_loss: 8.9869e-04 - val_mae: 0.0197\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0321 - val_loss: 9.5144e-04 - val_mae: 0.0207\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0357 - val_loss: 9.1386e-04 - val_mae: 0.0200\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0323 - val_loss: 8.9933e-04 - val_mae: 0.0197\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0366 - val_loss: 9.1402e-04 - val_mae: 0.0200\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0315 - val_loss: 9.6478e-04 - val_mae: 0.0209\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0315 - val_loss: 9.0040e-04 - val_mae: 0.0197\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0364 - val_loss: 9.0029e-04 - val_mae: 0.0197\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0312 - val_loss: 9.1446e-04 - val_mae: 0.0200\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0327 - val_loss: 9.0277e-04 - val_mae: 0.0197\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0299 - val_loss: 8.9964e-04 - val_mae: 0.0197\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0325 - val_loss: 9.2186e-04 - val_mae: 0.0202\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 9.0079e-04 - val_mae: 0.0197\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0310 - val_loss: 9.1365e-04 - val_mae: 0.0200\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0331 - val_loss: 9.0157e-04 - val_mae: 0.0197\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 9.3721e-04 - val_mae: 0.0205\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0299 - val_loss: 9.3878e-04 - val_mae: 0.0205\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0279 - val_loss: 8.9972e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0301 - val_loss: 9.0042e-04 - val_mae: 0.0199\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0324 - val_loss: 9.0477e-04 - val_mae: 0.0197\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 9.7961e-04 - val_mae: 0.0210\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.0010e-04 - val_mae: 0.0197\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0300 - val_loss: 9.0222e-04 - val_mae: 0.0201\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0304 - val_loss: 9.0026e-04 - val_mae: 0.0198\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0323 - val_loss: 9.0968e-04 - val_mae: 0.0199\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0301 - val_loss: 9.3479e-04 - val_mae: 0.0204\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0328 - val_loss: 8.9922e-04 - val_mae: 0.0197\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0325 - val_loss: 9.1630e-04 - val_mae: 0.0201\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0303 - val_loss: 9.2532e-04 - val_mae: 0.0203\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0301 - val_loss: 9.4193e-04 - val_mae: 0.0205\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0305 - val_loss: 9.0588e-04 - val_mae: 0.0198\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0305 - val_loss: 8.9965e-04 - val_mae: 0.0197\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0315 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0315 - val_loss: 9.0137e-04 - val_mae: 0.0197\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0305 - val_loss: 9.1676e-04 - val_mae: 0.0201\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0314 - val_loss: 9.0158e-04 - val_mae: 0.0197\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0324 - val_loss: 9.3824e-04 - val_mae: 0.0205\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0305 - val_loss: 9.0114e-04 - val_mae: 0.0199\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0299 - val_loss: 9.0243e-04 - val_mae: 0.0197\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0324 - val_loss: 9.4935e-04 - val_mae: 0.0207\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0325 - val_loss: 9.0176e-04 - val_mae: 0.0197\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0302 - val_loss: 9.7797e-04 - val_mae: 0.0210\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0315 - val_loss: 9.0647e-04 - val_mae: 0.0205\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0298 - val_loss: 8.9863e-04 - val_mae: 0.0197\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0305 - val_loss: 9.1841e-04 - val_mae: 0.0201\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 9.0386e-04 - val_mae: 0.0197\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0291 - val_loss: 8.9936e-04 - val_mae: 0.0197\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0330 - val_loss: 8.9914e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.0030e-04 - val_mae: 0.0197\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0296 - val_loss: 9.0271e-04 - val_mae: 0.0197\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0336 - val_loss: 9.0065e-04 - val_mae: 0.0199\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 8.9994e-04 - val_mae: 0.0198\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0324 - val_loss: 8.9868e-04 - val_mae: 0.0197\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 8.9955e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 9.0815e-04 - val_mae: 0.0198\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0294 - val_loss: 9.1548e-04 - val_mae: 0.0201\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0276 - val_loss: 9.1965e-04 - val_mae: 0.0201\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.5061e-04 - val_mae: 0.0207\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.0327e-04 - val_mae: 0.0197\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0271 - val_loss: 9.5468e-04 - val_mae: 0.0207\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0276 - val_loss: 9.1963e-04 - val_mae: 0.0201\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 9.1624e-04 - val_mae: 0.0201\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 9.4781e-04 - val_mae: 0.0206\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 9.9236e-04 - val_mae: 0.0212\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0304 - val_loss: 8.9916e-04 - val_mae: 0.0197\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 9.2639e-04 - val_mae: 0.0203\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 9.2557e-04 - val_mae: 0.0203\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0300 - val_loss: 8.9846e-04 - val_mae: 0.0196\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 8.9980e-04 - val_mae: 0.0197\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0290 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0265 - val_loss: 9.0837e-04 - val_mae: 0.0199\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0302 - val_loss: 8.9868e-04 - val_mae: 0.0196\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0307 - val_loss: 8.9841e-04 - val_mae: 0.0196\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0309 - val_loss: 9.0380e-04 - val_mae: 0.0197\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0314 - val_loss: 9.1359e-04 - val_mae: 0.0200\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0303 - val_loss: 9.3357e-04 - val_mae: 0.0204\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0293 - val_loss: 9.6619e-04 - val_mae: 0.0209\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0306 - val_loss: 9.8098e-04 - val_mae: 0.0210\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.4818e-04 - val_mae: 0.0206\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.4625e-04 - val_mae: 0.0206\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0309 - val_loss: 8.9781e-04 - val_mae: 0.0197\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 9.1387e-04 - val_mae: 0.0200\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 9.8104e-04 - val_mae: 0.0210\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.7641e-04 - val_mae: 0.0210\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0284 - val_loss: 9.1680e-04 - val_mae: 0.0201\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 9.4969e-04 - val_mae: 0.0207\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0261 - val_loss: 9.9879e-04 - val_mae: 0.0212\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0270 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0301 - val_loss: 9.8791e-04 - val_mae: 0.0245\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0333 - val_loss: 8.9952e-04 - val_mae: 0.0198\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 9.8996e-04 - val_mae: 0.0211\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 9.5959e-04 - val_mae: 0.0208\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0288 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0315 - val_loss: 9.9279e-04 - val_mae: 0.0212\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0300 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0267 - val_loss: 9.9969e-04 - val_mae: 0.0212\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 9.4463e-04 - val_mae: 0.0206\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.6346e-04 - val_mae: 0.0208\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0239 - val_loss: 9.9125e-04 - val_mae: 0.0211\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0275 - val_loss: 9.3709e-04 - val_mae: 0.0205\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0293 - val_loss: 9.8334e-04 - val_mae: 0.0211\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0252 - val_loss: 9.6323e-04 - val_mae: 0.0208\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0302 - val_loss: 9.3222e-04 - val_mae: 0.0204\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0299 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0296 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0304 - val_loss: 9.0783e-04 - val_mae: 0.0199\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0288 - val_loss: 9.2473e-04 - val_mae: 0.0202\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0269 - val_loss: 9.7964e-04 - val_mae: 0.0210\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0270 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0259 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0290 - val_loss: 9.9972e-04 - val_mae: 0.0212\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0297 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 9.8949e-04 - val_mae: 0.0211\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0286 - val_loss: 9.2272e-04 - val_mae: 0.0202\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 9.8147e-04 - val_mae: 0.0211\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0274 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0335 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0037 - mae: 0.0293 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0280 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0286 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0320 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0278 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0268 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0297 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0317 - val_loss: 9.6279e-04 - val_mae: 0.0209\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0303 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0254 - val_loss: 0.0013 - val_mae: 0.0271\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0284 - val_loss: 0.0015 - val_mae: 0.0295\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0285 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0324 - val_loss: 0.0014 - val_mae: 0.0288\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0278 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0287 - val_loss: 9.9226e-04 - val_mae: 0.0212\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0337 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0285 - val_loss: 0.0013 - val_mae: 0.0262\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0281 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0313 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0265 - val_loss: 0.0015 - val_mae: 0.0295\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0275 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0298 - val_loss: 8.7937e-04 - val_mae: 0.0204\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0314 - val_loss: 0.0010 - val_mae: 0.0236\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0319 - val_loss: 9.0940e-04 - val_mae: 0.0206\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0261 - val_loss: 8.6366e-04 - val_mae: 0.0196\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0262 - val_loss: 8.8797e-04 - val_mae: 0.0203\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0255 - val_loss: 0.0011 - val_mae: 0.0259\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0283 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0034 - mae: 0.0281 - val_loss: 0.0014 - val_mae: 0.0297\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0310 - val_loss: 9.8870e-04 - val_mae: 0.0225\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0298 - val_loss: 9.7196e-04 - val_mae: 0.0205\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0277 - val_loss: 0.0010 - val_mae: 0.0221\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0276 - val_loss: 9.6073e-04 - val_mae: 0.0201\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0259 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0256 - val_loss: 0.0010 - val_mae: 0.0221\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.4256e-04 - val_mae: 0.0205\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0257 - val_loss: 9.5733e-04 - val_mae: 0.0212\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0260 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 0.0011 - val_mae: 0.0253\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_27\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_324 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_297 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_325 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_298 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_326 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_299 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_327 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_300 (Dropout)       (None, 40)                0         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dense_328 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_301 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_329 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_302 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_330 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_303 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_331 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_304 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_332 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_305 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_333 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_306 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_334 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_307 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_335 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 0.1207 - mae: 0.2736 - val_loss: 0.0041 - val_mae: 0.0601\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1048 - mae: 0.2557 - val_loss: 0.0083 - val_mae: 0.0863\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0465 - mae: 0.1702 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0587 - mae: 0.1937 - val_loss: 0.0040 - val_mae: 0.0555\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0571 - mae: 0.1901 - val_loss: 0.0077 - val_mae: 0.0825\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0437 - mae: 0.1622 - val_loss: 0.0052 - val_mae: 0.0659\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0474 - mae: 0.1794 - val_loss: 0.0015 - val_mae: 0.0348\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0392 - mae: 0.1646 - val_loss: 9.4445e-04 - val_mae: 0.0228\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0447 - mae: 0.1698 - val_loss: 0.0074 - val_mae: 0.0805\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0659 - mae: 0.1871 - val_loss: 0.0014 - val_mae: 0.0333\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0291 - mae: 0.1406 - val_loss: 0.0023 - val_mae: 0.0386\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0408 - mae: 0.1566 - val_loss: 0.0026 - val_mae: 0.0482\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0268 - mae: 0.1302 - val_loss: 9.2854e-04 - val_mae: 0.0203\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0260 - mae: 0.1291 - val_loss: 9.4123e-04 - val_mae: 0.0205\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 0.1086 - val_loss: 0.0018 - val_mae: 0.0384\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0267 - mae: 0.1273 - val_loss: 0.0017 - val_mae: 0.0322\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0259 - mae: 0.1231 - val_loss: 9.1969e-04 - val_mae: 0.0215\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0279 - mae: 0.1247 - val_loss: 0.0025 - val_mae: 0.0472\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0279 - mae: 0.1197 - val_loss: 9.6659e-04 - val_mae: 0.0209\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0176 - mae: 0.1044 - val_loss: 8.9964e-04 - val_mae: 0.0197\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0159 - mae: 0.0947 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0913 - val_loss: 9.1639e-04 - val_mae: 0.0201\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0202 - mae: 0.1065 - val_loss: 9.0676e-04 - val_mae: 0.0198\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0181 - mae: 0.1010 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0220 - mae: 0.1174 - val_loss: 0.0012 - val_mae: 0.0298\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.1136 - val_loss: 0.0013 - val_mae: 0.0312\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.1101 - val_loss: 9.2151e-04 - val_mae: 0.0202\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0175 - mae: 0.0948 - val_loss: 9.0309e-04 - val_mae: 0.0197\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - mae: 0.0882 - val_loss: 0.0010 - val_mae: 0.0260\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0859 - val_loss: 9.1665e-04 - val_mae: 0.0213\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0159 - mae: 0.0907 - val_loss: 9.3173e-04 - val_mae: 0.0222\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0173 - mae: 0.1007 - val_loss: 9.0112e-04 - val_mae: 0.0197\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0146 - mae: 0.0885 - val_loss: 8.9935e-04 - val_mae: 0.0197\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.0826 - val_loss: 0.0013 - val_mae: 0.0271\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0827 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0117 - mae: 0.0769 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - mae: 0.0802 - val_loss: 0.0019 - val_mae: 0.0334\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0705 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0731 - val_loss: 8.9919e-04 - val_mae: 0.0197\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0868 - val_loss: 9.0163e-04 - val_mae: 0.0197\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0126 - mae: 0.0779 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0112 - mae: 0.0727 - val_loss: 9.0541e-04 - val_mae: 0.0203\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0751 - val_loss: 9.6427e-04 - val_mae: 0.0209\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0105 - mae: 0.0682 - val_loss: 9.1459e-04 - val_mae: 0.0200\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0730 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0121 - mae: 0.0773 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0739 - val_loss: 9.3669e-04 - val_mae: 0.0205\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0654 - val_loss: 9.2242e-04 - val_mae: 0.0217\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0622 - val_loss: 9.3277e-04 - val_mae: 0.0223\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0680 - val_loss: 8.9906e-04 - val_mae: 0.0196\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0721 - val_loss: 9.0217e-04 - val_mae: 0.0196\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0101 - mae: 0.0649 - val_loss: 9.0464e-04 - val_mae: 0.0203\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0095 - mae: 0.0642 - val_loss: 9.0946e-04 - val_mae: 0.0208\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0721 - val_loss: 8.9921e-04 - val_mae: 0.0196\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0601 - val_loss: 9.1632e-04 - val_mae: 0.0213\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0644 - val_loss: 9.2451e-04 - val_mae: 0.0219\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0607 - val_loss: 9.2519e-04 - val_mae: 0.0202\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0639 - val_loss: 9.0221e-04 - val_mae: 0.0196\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0560 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0613 - val_loss: 9.1576e-04 - val_mae: 0.0201\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0720 - val_loss: 9.0115e-04 - val_mae: 0.0196\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0610 - val_loss: 9.0603e-04 - val_mae: 0.0197\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0592 - val_loss: 9.1310e-04 - val_mae: 0.0200\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0114 - mae: 0.0623 - val_loss: 9.2163e-04 - val_mae: 0.0216\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0607 - val_loss: 8.9950e-04 - val_mae: 0.0197\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0484 - val_loss: 9.0632e-04 - val_mae: 0.0198\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0587 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0540 - val_loss: 9.8826e-04 - val_mae: 0.0211\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0594 - val_loss: 9.3992e-04 - val_mae: 0.0205\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0482 - val_loss: 9.0171e-04 - val_mae: 0.0196\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0509 - val_loss: 9.7656e-04 - val_mae: 0.0210\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0540 - val_loss: 8.9931e-04 - val_mae: 0.0196\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0500 - val_loss: 0.0010 - val_mae: 0.0255\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0528 - val_loss: 9.1099e-04 - val_mae: 0.0209\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0065 - mae: 0.0509 - val_loss: 9.3737e-04 - val_mae: 0.0205\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0487 - val_loss: 9.5668e-04 - val_mae: 0.0207\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0469 - val_loss: 9.0512e-04 - val_mae: 0.0203\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0555 - val_loss: 9.3508e-04 - val_mae: 0.0204\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0466 - val_loss: 9.7232e-04 - val_mae: 0.0203\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0513 - val_loss: 9.1224e-04 - val_mae: 0.0190\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0540 - val_loss: 9.0804e-04 - val_mae: 0.0192\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0574 - val_loss: 9.1397e-04 - val_mae: 0.0215\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0498 - val_loss: 9.5819e-04 - val_mae: 0.0201\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0481 - val_loss: 9.0133e-04 - val_mae: 0.0193\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0519 - val_loss: 9.1075e-04 - val_mae: 0.0197\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0502 - val_loss: 9.6386e-04 - val_mae: 0.0206\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0484 - val_loss: 9.0079e-04 - val_mae: 0.0194\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0449 - val_loss: 9.0213e-04 - val_mae: 0.0193\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0501 - val_loss: 9.5295e-04 - val_mae: 0.0234\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0504 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0525 - val_loss: 8.9874e-04 - val_mae: 0.0194\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0514 - val_loss: 8.9892e-04 - val_mae: 0.0194\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0429 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0376 - val_loss: 9.6310e-04 - val_mae: 0.0208\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0445 - val_loss: 9.1434e-04 - val_mae: 0.0199\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0516 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0059 - mae: 0.0451 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0481 - val_loss: 9.1331e-04 - val_mae: 0.0200\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0446 - val_loss: 9.1103e-04 - val_mae: 0.0209\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0428 - val_loss: 9.0334e-04 - val_mae: 0.0196\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0468 - val_loss: 9.0102e-04 - val_mae: 0.0196\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0416 - val_loss: 9.4509e-04 - val_mae: 0.0205\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0378 - val_loss: 9.5000e-04 - val_mae: 0.0206\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0443 - val_loss: 9.8466e-04 - val_mae: 0.0244\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0463 - val_loss: 9.1019e-04 - val_mae: 0.0208\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0505 - val_loss: 9.2884e-04 - val_mae: 0.0221\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0484 - val_loss: 9.9241e-04 - val_mae: 0.0246\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0060 - mae: 0.0484 - val_loss: 9.0785e-04 - val_mae: 0.0198\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0410 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0443 - val_loss: 9.2595e-04 - val_mae: 0.0201\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0399 - val_loss: 9.3258e-04 - val_mae: 0.0203\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0400 - val_loss: 9.0484e-04 - val_mae: 0.0196\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0419 - val_loss: 9.5023e-04 - val_mae: 0.0206\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0056 - mae: 0.0415 - val_loss: 8.9932e-04 - val_mae: 0.0196\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0329 - val_loss: 9.2013e-04 - val_mae: 0.0201\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0386 - val_loss: 9.1145e-04 - val_mae: 0.0199\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0400 - val_loss: 9.1618e-04 - val_mae: 0.0201\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0367 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0384 - val_loss: 8.9973e-04 - val_mae: 0.0197\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0064 - mae: 0.0424 - val_loss: 9.2519e-04 - val_mae: 0.0202\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0386 - val_loss: 8.9904e-04 - val_mae: 0.0196\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0404 - val_loss: 8.9920e-04 - val_mae: 0.0196\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0374 - val_loss: 9.3686e-04 - val_mae: 0.0205\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0388 - val_loss: 8.9920e-04 - val_mae: 0.0197\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0379 - val_loss: 9.3507e-04 - val_mae: 0.0204\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0362 - val_loss: 9.1284e-04 - val_mae: 0.0200\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0385 - val_loss: 9.0421e-04 - val_mae: 0.0197\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0430 - val_loss: 9.0985e-04 - val_mae: 0.0199\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0384 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0398 - val_loss: 9.1755e-04 - val_mae: 0.0201\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0395 - val_loss: 8.9930e-04 - val_mae: 0.0197\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0329 - val_loss: 9.0080e-04 - val_mae: 0.0197\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0384 - val_loss: 9.0805e-04 - val_mae: 0.0198\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0380 - val_loss: 9.2492e-04 - val_mae: 0.0202\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0369 - val_loss: 9.6028e-04 - val_mae: 0.0208\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0333 - val_loss: 9.1032e-04 - val_mae: 0.0199\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0406 - val_loss: 9.1989e-04 - val_mae: 0.0201\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0350 - val_loss: 9.4990e-04 - val_mae: 0.0207\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0335 - val_loss: 9.0807e-04 - val_mae: 0.0198\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0337 - val_loss: 8.9993e-04 - val_mae: 0.0197\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0340 - val_loss: 9.0283e-04 - val_mae: 0.0197\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0383 - val_loss: 9.6487e-04 - val_mae: 0.0209\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0400 - val_loss: 9.4944e-04 - val_mae: 0.0206\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0357 - val_loss: 9.9213e-04 - val_mae: 0.0212\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0336 - val_loss: 9.1723e-04 - val_mae: 0.0201\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0330 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0053 - mae: 0.0321 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0320 - val_loss: 8.9950e-04 - val_mae: 0.0197\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0325 - val_loss: 9.1732e-04 - val_mae: 0.0201\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0359 - val_loss: 9.1413e-04 - val_mae: 0.0200\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0331 - val_loss: 9.2750e-04 - val_mae: 0.0203\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0338 - val_loss: 9.0027e-04 - val_mae: 0.0197\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 9.2573e-04 - val_mae: 0.0203\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0294 - val_loss: 9.0333e-04 - val_mae: 0.0201\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0337 - val_loss: 9.1999e-04 - val_mae: 0.0201\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0359 - val_loss: 9.0615e-04 - val_mae: 0.0198\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0299 - val_loss: 9.0792e-04 - val_mae: 0.0206\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.0373e-04 - val_mae: 0.0202\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0360 - val_loss: 8.9948e-04 - val_mae: 0.0197\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0302 - val_loss: 9.0061e-04 - val_mae: 0.0197\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0321 - val_loss: 9.0595e-04 - val_mae: 0.0198\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0320 - val_loss: 9.0033e-04 - val_mae: 0.0197\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0311 - val_loss: 9.0391e-04 - val_mae: 0.0202\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0341 - val_loss: 9.0793e-04 - val_mae: 0.0198\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0324 - val_loss: 9.0213e-04 - val_mae: 0.0197\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0322 - val_loss: 9.0045e-04 - val_mae: 0.0197\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0319 - val_loss: 9.3941e-04 - val_mae: 0.0205\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0334 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0320 - val_loss: 9.4495e-04 - val_mae: 0.0206\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0325 - val_loss: 9.0101e-04 - val_mae: 0.0197\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0345 - val_loss: 9.0443e-04 - val_mae: 0.0197\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0345 - val_loss: 9.2481e-04 - val_mae: 0.0202\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0341 - val_loss: 9.1538e-04 - val_mae: 0.0212\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0351 - val_loss: 8.9976e-04 - val_mae: 0.0197\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 9.7418e-04 - val_mae: 0.0210\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0303 - val_loss: 9.0890e-04 - val_mae: 0.0199\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 8.9936e-04 - val_mae: 0.0197\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0303 - val_loss: 9.0053e-04 - val_mae: 0.0198\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0314 - val_loss: 9.0487e-04 - val_mae: 0.0203\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0298 - val_loss: 8.9942e-04 - val_mae: 0.0197\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0306 - val_loss: 8.9972e-04 - val_mae: 0.0197\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0325 - val_loss: 9.0205e-04 - val_mae: 0.0197\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0314 - val_loss: 9.1974e-04 - val_mae: 0.0215\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0339 - val_loss: 9.0161e-04 - val_mae: 0.0197\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0297 - val_loss: 9.5122e-04 - val_mae: 0.0207\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0333 - val_loss: 9.7194e-04 - val_mae: 0.0209\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0313 - val_loss: 9.2471e-04 - val_mae: 0.0202\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 9.2464e-04 - val_mae: 0.0202\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0304 - val_loss: 9.9031e-04 - val_mae: 0.0211\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 9.4161e-04 - val_mae: 0.0205\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0296 - val_loss: 9.0305e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0322 - val_loss: 9.3121e-04 - val_mae: 0.0204\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0289 - val_loss: 9.4551e-04 - val_mae: 0.0206\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0288 - val_loss: 9.0068e-04 - val_mae: 0.0197\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0284 - val_loss: 9.4448e-04 - val_mae: 0.0206\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0312 - val_loss: 9.4691e-04 - val_mae: 0.0206\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0308 - val_loss: 9.0714e-04 - val_mae: 0.0198\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0327 - val_loss: 9.2353e-04 - val_mae: 0.0202\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0336 - val_loss: 9.0186e-04 - val_mae: 0.0196\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0315 - val_loss: 9.4246e-04 - val_mae: 0.0205\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 9.3034e-04 - val_mae: 0.0203\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 9.9545e-04 - val_mae: 0.0212\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0314 - val_loss: 9.7850e-04 - val_mae: 0.0210\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0304 - val_loss: 9.1887e-04 - val_mae: 0.0201\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0282 - val_loss: 9.2560e-04 - val_mae: 0.0203\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 9.2742e-04 - val_mae: 0.0203\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0286 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0319 - val_loss: 9.2429e-04 - val_mae: 0.0202\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 9.5172e-04 - val_mae: 0.0207\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0329 - val_loss: 9.7988e-04 - val_mae: 0.0210\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 9.3027e-04 - val_mae: 0.0203\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0276 - val_loss: 9.5280e-04 - val_mae: 0.0207\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0330 - val_loss: 9.0364e-04 - val_mae: 0.0197\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0307 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0276 - val_loss: 9.9908e-04 - val_mae: 0.0212\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0274 - val_loss: 9.2881e-04 - val_mae: 0.0203\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0295 - val_loss: 9.2006e-04 - val_mae: 0.0201\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0309 - val_loss: 9.8010e-04 - val_mae: 0.0210\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0381 - val_loss: 9.0779e-04 - val_mae: 0.0198\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0347 - val_loss: 0.0016 - val_mae: 0.0303\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0363 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0309 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0325 - val_loss: 9.1416e-04 - val_mae: 0.0200\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0331 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0324 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0324 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0279 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0289 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0312 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0272 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0320 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 9.4056e-04 - val_mae: 0.0205\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 9.5048e-04 - val_mae: 0.0207\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0277 - val_loss: 9.8227e-04 - val_mae: 0.0211\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0306 - val_loss: 9.0466e-04 - val_mae: 0.0197\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0292 - val_loss: 9.5803e-04 - val_mae: 0.0208\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0300 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0289 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0290 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0318 - val_loss: 9.3238e-04 - val_mae: 0.0204\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 9.3140e-04 - val_mae: 0.0204\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0288 - val_loss: 9.5557e-04 - val_mae: 0.0207\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0342 - val_loss: 9.4956e-04 - val_mae: 0.0231\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0297 - val_loss: 9.6368e-04 - val_mae: 0.0208\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 9.6463e-04 - val_mae: 0.0209\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0332 - val_loss: 9.4470e-04 - val_mae: 0.0206\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0292 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0308 - val_loss: 9.2134e-04 - val_mae: 0.0202\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0298 - val_loss: 9.4396e-04 - val_mae: 0.0206\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0312 - val_loss: 9.0022e-04 - val_mae: 0.0197\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0298 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0291 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0280 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0312 - val_loss: 9.7889e-04 - val_mae: 0.0210\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0277 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0293 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 0.0014 - val_mae: 0.0276\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0043 - mae: 0.0304 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0282 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0037 - mae: 0.0299 - val_loss: 0.0017 - val_mae: 0.0320\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0344 - val_loss: 0.0016 - val_mae: 0.0302\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0279 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0308 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0299 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0282 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0287 - val_loss: 0.0013 - val_mae: 0.0267\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0258 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0299 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0300 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0269 - val_loss: 0.0015 - val_mae: 0.0290\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0377 - val_loss: 9.2547e-04 - val_mae: 0.0219\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0332 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0289 - val_loss: 0.0013 - val_mae: 0.0267\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0285 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0362 - val_loss: 0.0012 - val_mae: 0.0237\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0330 - val_loss: 0.0013 - val_mae: 0.0264\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0255 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0314 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0306 - val_loss: 9.7890e-04 - val_mae: 0.0210\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0036 - mae: 0.0276 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0294 - val_loss: 0.0015 - val_mae: 0.0297\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0305 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0273 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0271 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0254 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0285 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0266 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0280 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0294 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0267 - val_loss: 0.0017 - val_mae: 0.0316\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 9.9948e-04 - val_mae: 0.0212\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0298 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0302 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0286 - val_loss: 0.0016 - val_mae: 0.0307\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0289 - val_loss: 0.0013 - val_mae: 0.0265\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0278 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0280 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0268 - val_loss: 0.0017 - val_mae: 0.0318\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0284 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0254 - val_loss: 0.0016 - val_mae: 0.0306\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0297 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0259 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0271 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0259 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0286 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0275 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0285 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0275 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0035 - mae: 0.0268 - val_loss: 0.0015 - val_mae: 0.0299\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0034 - mae: 0.0272 - val_loss: 0.0021 - val_mae: 0.0355\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0291 - val_loss: 0.0016 - val_mae: 0.0301\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0273 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0312 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0273 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0263 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0308 - val_loss: 0.0018 - val_mae: 0.0328\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0290 - val_loss: 0.0018 - val_mae: 0.0326\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0276 - val_loss: 0.0015 - val_mae: 0.0297\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0313 - val_loss: 0.0014 - val_mae: 0.0276\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0290 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0284 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0266 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0297 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0255 - val_loss: 0.0018 - val_mae: 0.0328\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0263 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0294 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0265 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 9.8317e-04 - val_mae: 0.0211\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0038 - mae: 0.0292 - val_loss: 0.0016 - val_mae: 0.0303\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0039 - mae: 0.0287 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0287 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0294 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0033 - mae: 0.0275 - val_loss: 0.0018 - val_mae: 0.0326\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0033 - mae: 0.0276 - val_loss: 0.0019 - val_mae: 0.0342\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Model: \"sequential_28\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_336 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_308 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_337 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_309 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_338 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dropout_310 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_339 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_311 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_340 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_312 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_341 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_313 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_342 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_314 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_343 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_315 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_344 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_316 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_345 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_317 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_346 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_318 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_347 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 4.1167 - mae: 1.4885 - val_loss: 0.0122 - val_mae: 0.1034\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8875 - mae: 0.6651 - val_loss: 0.0032 - val_mae: 0.0506\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5901 - mae: 0.5846 - val_loss: 7.4115e-04 - val_mae: 0.0242\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3577 - mae: 0.4651 - val_loss: 0.0028 - val_mae: 0.0460\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4100 - mae: 0.4302 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2209 - mae: 0.3072 - val_loss: 0.0013 - val_mae: 0.0271\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1092 - mae: 0.2441 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0981 - mae: 0.2397 - val_loss: 0.0011 - val_mae: 0.0251\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0855 - mae: 0.2199 - val_loss: 0.0012 - val_mae: 0.0230\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0754 - mae: 0.2057 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1004 - mae: 0.2347 - val_loss: 0.0011 - val_mae: 0.0247\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1046 - mae: 0.2230 - val_loss: 9.7610e-04 - val_mae: 0.0210\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0576 - mae: 0.1686 - val_loss: 0.0011 - val_mae: 0.0220\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0760 - mae: 0.1903 - val_loss: 0.0012 - val_mae: 0.0237\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0740 - mae: 0.1845 - val_loss: 0.0013 - val_mae: 0.0254\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.1753 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0399 - mae: 0.1478 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0421 - mae: 0.1499 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0418 - mae: 0.1353 - val_loss: 0.0012 - val_mae: 0.0229\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0670 - mae: 0.1492 - val_loss: 0.0014 - val_mae: 0.0268\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1345 - val_loss: 0.0015 - val_mae: 0.0277\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0670 - mae: 0.1548 - val_loss: 0.0013 - val_mae: 0.0236\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0232 - mae: 0.1080 - val_loss: 0.0012 - val_mae: 0.0231\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0319 - mae: 0.1095 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0392 - mae: 0.1191 - val_loss: 0.0011 - val_mae: 0.0215\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.1021 - val_loss: 0.0011 - val_mae: 0.0212\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0305 - mae: 0.1159 - val_loss: 0.0012 - val_mae: 0.0224\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0170 - mae: 0.0843 - val_loss: 0.0013 - val_mae: 0.0243\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0361 - mae: 0.1177 - val_loss: 0.0012 - val_mae: 0.0229\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0253 - mae: 0.1011 - val_loss: 0.0012 - val_mae: 0.0215\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0183 - mae: 0.0856 - val_loss: 0.0012 - val_mae: 0.0232\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0153 - mae: 0.0809 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0246 - mae: 0.1033 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0722 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0137 - mae: 0.0803 - val_loss: 0.0012 - val_mae: 0.0240\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0202 - mae: 0.0927 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0694 - val_loss: 0.0014 - val_mae: 0.0276\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0165 - mae: 0.0693 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0261 - mae: 0.1005 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0690 - val_loss: 0.0014 - val_mae: 0.0279\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0142 - mae: 0.0737 - val_loss: 0.0014 - val_mae: 0.0288\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0154 - mae: 0.0801 - val_loss: 0.0015 - val_mae: 0.0295\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0641 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.0887 - val_loss: 0.0013 - val_mae: 0.0262\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0638 - val_loss: 0.0014 - val_mae: 0.0275\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0172 - mae: 0.0729 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0200 - mae: 0.0672 - val_loss: 0.0015 - val_mae: 0.0292\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0755 - val_loss: 0.0015 - val_mae: 0.0292\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0483 - val_loss: 0.0015 - val_mae: 0.0297\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0542 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0615 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0083 - mae: 0.0567 - val_loss: 0.0015 - val_mae: 0.0297\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0581 - val_loss: 0.0015 - val_mae: 0.0287\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0081 - mae: 0.0521 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0584 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0589 - val_loss: 0.0013 - val_mae: 0.0275\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0112 - mae: 0.0619 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0107 - mae: 0.0516 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0391 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0088 - mae: 0.0503 - val_loss: 0.0013 - val_mae: 0.0272\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0397 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0496 - val_loss: 0.0012 - val_mae: 0.0265\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0469 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0180 - mae: 0.0605 - val_loss: 0.0012 - val_mae: 0.0262\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0599 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0516 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0454 - val_loss: 0.0012 - val_mae: 0.0253\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0413 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0414 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0468 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0476 - val_loss: 0.0010 - val_mae: 0.0230\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0402 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0411 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0447 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0483 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0450 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0400 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0392 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0385 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0334 - val_loss: 9.9720e-04 - val_mae: 0.0216\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0384 - val_loss: 9.5540e-04 - val_mae: 0.0210\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0368 - val_loss: 9.6114e-04 - val_mae: 0.0210\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0398 - val_loss: 9.7193e-04 - val_mae: 0.0211\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0431 - val_loss: 9.6328e-04 - val_mae: 0.0211\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0370 - val_loss: 9.9534e-04 - val_mae: 0.0214\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0435 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0385 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0301 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0392 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0051 - mae: 0.0309 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0409 - val_loss: 9.6594e-04 - val_mae: 0.0209\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0391 - val_loss: 9.9234e-04 - val_mae: 0.0212\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0334 - val_loss: 9.7355e-04 - val_mae: 0.0209\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.0468 - val_loss: 9.8529e-04 - val_mae: 0.0211\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0319 - val_loss: 9.5279e-04 - val_mae: 0.0207\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0367 - val_loss: 9.5359e-04 - val_mae: 0.0207\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0432 - val_loss: 9.2332e-04 - val_mae: 0.0203\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0326 - val_loss: 9.2487e-04 - val_mae: 0.0204\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0403 - val_loss: 9.3713e-04 - val_mae: 0.0205\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0294 - val_loss: 9.3720e-04 - val_mae: 0.0206\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0399 - val_loss: 9.7113e-04 - val_mae: 0.0210\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0346 - val_loss: 9.7817e-04 - val_mae: 0.0212\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0358 - val_loss: 9.9101e-04 - val_mae: 0.0213\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0398 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0398 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0300 - val_loss: 8.8458e-04 - val_mae: 0.0199\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0329 - val_loss: 8.8050e-04 - val_mae: 0.0197\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0360 - val_loss: 8.9153e-04 - val_mae: 0.0199\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0385 - val_loss: 9.0350e-04 - val_mae: 0.0202\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0347 - val_loss: 9.0793e-04 - val_mae: 0.0203\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0290 - val_loss: 9.0769e-04 - val_mae: 0.0203\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0321 - val_loss: 9.1368e-04 - val_mae: 0.0203\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0338 - val_loss: 9.0108e-04 - val_mae: 0.0201\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0376 - val_loss: 8.9904e-04 - val_mae: 0.0200\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0357 - val_loss: 9.0914e-04 - val_mae: 0.0202\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0301 - val_loss: 9.1296e-04 - val_mae: 0.0203\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0334 - val_loss: 9.1907e-04 - val_mae: 0.0203\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0307 - val_loss: 9.0744e-04 - val_mae: 0.0201\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0398 - val_loss: 9.0302e-04 - val_mae: 0.0200\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0322 - val_loss: 8.9819e-04 - val_mae: 0.0199\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0351 - val_loss: 9.0775e-04 - val_mae: 0.0200\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0285 - val_loss: 9.0237e-04 - val_mae: 0.0199\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0325 - val_loss: 9.0477e-04 - val_mae: 0.0200\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0328 - val_loss: 8.9072e-04 - val_mae: 0.0197\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0335 - val_loss: 8.8979e-04 - val_mae: 0.0196\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0300 - val_loss: 8.8823e-04 - val_mae: 0.0196\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0301 - val_loss: 8.9361e-04 - val_mae: 0.0197\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0328 - val_loss: 8.9632e-04 - val_mae: 0.0198\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0300 - val_loss: 9.0609e-04 - val_mae: 0.0200\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0338 - val_loss: 9.3024e-04 - val_mae: 0.0204\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0343 - val_loss: 9.2889e-04 - val_mae: 0.0203\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0303 - val_loss: 9.2810e-04 - val_mae: 0.0203\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 9.1620e-04 - val_mae: 0.0201\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0292 - val_loss: 9.1637e-04 - val_mae: 0.0201\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0325 - val_loss: 9.0827e-04 - val_mae: 0.0200\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 9.1047e-04 - val_mae: 0.0200\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0324 - val_loss: 9.0990e-04 - val_mae: 0.0200\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 9.0642e-04 - val_mae: 0.0199\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 9.1211e-04 - val_mae: 0.0201\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0322 - val_loss: 9.0043e-04 - val_mae: 0.0198\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0319 - val_loss: 9.1057e-04 - val_mae: 0.0200\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0293 - val_loss: 9.1449e-04 - val_mae: 0.0201\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0304 - val_loss: 9.2513e-04 - val_mae: 0.0204\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0352 - val_loss: 9.2571e-04 - val_mae: 0.0204\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0294 - val_loss: 9.2706e-04 - val_mae: 0.0203\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0289 - val_loss: 9.3163e-04 - val_mae: 0.0204\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0311 - val_loss: 9.2953e-04 - val_mae: 0.0204\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0306 - val_loss: 9.3883e-04 - val_mae: 0.0205\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0307 - val_loss: 9.2653e-04 - val_mae: 0.0203\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 9.2865e-04 - val_mae: 0.0203\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 9.3186e-04 - val_mae: 0.0204\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 9.4062e-04 - val_mae: 0.0206\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.2681e-04 - val_mae: 0.0203\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 9.2675e-04 - val_mae: 0.0203\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0290 - val_loss: 9.1769e-04 - val_mae: 0.0201\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0271 - val_loss: 9.3180e-04 - val_mae: 0.0204\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0260 - val_loss: 9.3046e-04 - val_mae: 0.0204\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0338 - val_loss: 8.9862e-04 - val_mae: 0.0196\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0304 - val_loss: 9.0020e-04 - val_mae: 0.0196\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0308 - val_loss: 9.0633e-04 - val_mae: 0.0198\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0310 - val_loss: 9.1652e-04 - val_mae: 0.0201\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0318 - val_loss: 9.2548e-04 - val_mae: 0.0203\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.3954e-04 - val_mae: 0.0205\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0286 - val_loss: 9.3066e-04 - val_mae: 0.0204\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 9.3204e-04 - val_mae: 0.0204\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 9.4039e-04 - val_mae: 0.0205\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 9.3064e-04 - val_mae: 0.0203\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0288 - val_loss: 9.2011e-04 - val_mae: 0.0202\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 9.2557e-04 - val_mae: 0.0203\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 9.3242e-04 - val_mae: 0.0204\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0299 - val_loss: 9.2738e-04 - val_mae: 0.0203\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 9.4070e-04 - val_mae: 0.0206\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0311 - val_loss: 9.4303e-04 - val_mae: 0.0206\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 9.4843e-04 - val_mae: 0.0207\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0288 - val_loss: 9.4311e-04 - val_mae: 0.0206\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.1698e-04 - val_mae: 0.0201\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0323 - val_loss: 9.2055e-04 - val_mae: 0.0202\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 9.1226e-04 - val_mae: 0.0200\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0298 - val_loss: 9.1271e-04 - val_mae: 0.0200\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0273 - val_loss: 9.0294e-04 - val_mae: 0.0197\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.0265e-04 - val_mae: 0.0197\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0317 - val_loss: 9.0555e-04 - val_mae: 0.0197\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 9.0855e-04 - val_mae: 0.0199\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.1200e-04 - val_mae: 0.0200\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.0463e-04 - val_mae: 0.0197\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.0969e-04 - val_mae: 0.0199\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.1220e-04 - val_mae: 0.0200\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 9.1063e-04 - val_mae: 0.0199\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.1089e-04 - val_mae: 0.0199\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0037 - mae: 0.0262 - val_loss: 9.0045e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0300 - val_loss: 9.0355e-04 - val_mae: 0.0197\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.1000e-04 - val_mae: 0.0199\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0306 - val_loss: 9.0899e-04 - val_mae: 0.0199\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0544e-04 - val_mae: 0.0197\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0566e-04 - val_mae: 0.0197\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0296 - val_loss: 9.0214e-04 - val_mae: 0.0197\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.0149e-04 - val_mae: 0.0197\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 8.9960e-04 - val_mae: 0.0197\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 8.9971e-04 - val_mae: 0.0197\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 8.9997e-04 - val_mae: 0.0197\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 8.9915e-04 - val_mae: 0.0197\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 8.9803e-04 - val_mae: 0.0197\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 8.9805e-04 - val_mae: 0.0196\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 8.9787e-04 - val_mae: 0.0196\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0289 - val_loss: 8.9820e-04 - val_mae: 0.0196\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 9.0570e-04 - val_mae: 0.0198\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 8.9834e-04 - val_mae: 0.0196\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.0169e-04 - val_mae: 0.0196\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9863e-04 - val_mae: 0.0196\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 9.0072e-04 - val_mae: 0.0196\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.0058e-04 - val_mae: 0.0197\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.0062e-04 - val_mae: 0.0196\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0255e-04 - val_mae: 0.0196\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0846e-04 - val_mae: 0.0199\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.1163e-04 - val_mae: 0.0200\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0122e-04 - val_mae: 0.0196\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 9.0216e-04 - val_mae: 0.0196\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0258 - val_loss: 9.0925e-04 - val_mae: 0.0199\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.1427e-04 - val_mae: 0.0200\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.0414e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0272 - val_loss: 9.1290e-04 - val_mae: 0.0200\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0242 - val_loss: 9.1088e-04 - val_mae: 0.0199\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.0167e-04 - val_mae: 0.0196\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0179e-04 - val_mae: 0.0196\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 8.9906e-04 - val_mae: 0.0196\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 8.9635e-04 - val_mae: 0.0196\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 8.9697e-04 - val_mae: 0.0196\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 8.9753e-04 - val_mae: 0.0196\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.9765e-04 - val_mae: 0.0196\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 8.9732e-04 - val_mae: 0.0196\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9905e-04 - val_mae: 0.0196\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0283 - val_loss: 8.9708e-04 - val_mae: 0.0196\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0261 - val_loss: 8.9904e-04 - val_mae: 0.0196\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 8.9826e-04 - val_mae: 0.0196\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 8.9887e-04 - val_mae: 0.0196\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0368e-04 - val_mae: 0.0197\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 9.0204e-04 - val_mae: 0.0196\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0263 - val_loss: 9.0026e-04 - val_mae: 0.0196\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.0095e-04 - val_mae: 0.0196\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0241 - val_loss: 9.0636e-04 - val_mae: 0.0198\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.9913e-04 - val_mae: 0.0196\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 8.9797e-04 - val_mae: 0.0196\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0131e-04 - val_mae: 0.0196\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0028 - mae: 0.0268 - val_loss: 9.2512e-04 - val_mae: 0.0219\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0317 - val_loss: 9.1078e-04 - val_mae: 0.0210\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.9727e-04 - val_mae: 0.0196\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 8.9784e-04 - val_mae: 0.0196\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0470e-04 - val_mae: 0.0197\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0277 - val_loss: 9.3262e-04 - val_mae: 0.0224\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0299 - val_loss: 9.2848e-04 - val_mae: 0.0221\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 8.9881e-04 - val_mae: 0.0199\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0264 - val_loss: 8.9692e-04 - val_mae: 0.0196\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 8.9771e-04 - val_mae: 0.0196\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0384e-04 - val_mae: 0.0197\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0274 - val_loss: 9.0596e-04 - val_mae: 0.0198\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0244 - val_loss: 9.0272e-04 - val_mae: 0.0197\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0283 - val_loss: 8.9830e-04 - val_mae: 0.0196\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0276 - val_loss: 8.9815e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0076e-04 - val_mae: 0.0197\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 9.0201e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0226e-04 - val_mae: 0.0197\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.0357e-04 - val_mae: 0.0197\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0362e-04 - val_mae: 0.0197\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 9.0110e-04 - val_mae: 0.0197\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.0336e-04 - val_mae: 0.0197\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.0719e-04 - val_mae: 0.0198\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0253 - val_loss: 9.1700e-04 - val_mae: 0.0201\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.0483e-04 - val_mae: 0.0197\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 9.1173e-04 - val_mae: 0.0200\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 9.1581e-04 - val_mae: 0.0201\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 9.0516e-04 - val_mae: 0.0197\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.1208e-04 - val_mae: 0.0200\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0377e-04 - val_mae: 0.0197\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.1348e-04 - val_mae: 0.0200\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 9.1842e-04 - val_mae: 0.0201\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.0492e-04 - val_mae: 0.0197\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0085e-04 - val_mae: 0.0197\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 9.0119e-04 - val_mae: 0.0197\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1230e-04 - val_mae: 0.0200\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0265 - val_loss: 9.1013e-04 - val_mae: 0.0199\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0534e-04 - val_mae: 0.0198\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.1164e-04 - val_mae: 0.0200\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.1923e-04 - val_mae: 0.0215\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0308 - val_loss: 9.0824e-04 - val_mae: 0.0205\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0222e-04 - val_mae: 0.0197\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0568e-04 - val_mae: 0.0197\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0242 - val_loss: 9.0300e-04 - val_mae: 0.0197\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.0859e-04 - val_mae: 0.0198\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.1100e-04 - val_mae: 0.0199\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.1236e-04 - val_mae: 0.0199\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0238 - val_loss: 9.3188e-04 - val_mae: 0.0204\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0245 - val_loss: 9.1010e-04 - val_mae: 0.0199\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0718e-04 - val_mae: 0.0198\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.1639e-04 - val_mae: 0.0200\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.1052e-04 - val_mae: 0.0199\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.2460e-04 - val_mae: 0.0202\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0261 - val_loss: 9.1042e-04 - val_mae: 0.0199\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0240 - val_loss: 9.0844e-04 - val_mae: 0.0198\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 9.0244e-04 - val_mae: 0.0197\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0383e-04 - val_mae: 0.0197\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0222e-04 - val_mae: 0.0197\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0465e-04 - val_mae: 0.0197\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0380e-04 - val_mae: 0.0197\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.0139e-04 - val_mae: 0.0197\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0909e-04 - val_mae: 0.0199\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0807e-04 - val_mae: 0.0198\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0438e-04 - val_mae: 0.0197\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0265e-04 - val_mae: 0.0197\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0234 - val_loss: 9.0795e-04 - val_mae: 0.0198\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.0438e-04 - val_mae: 0.0197\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.0028e-04 - val_mae: 0.0197\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0002e-04 - val_mae: 0.0197\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0496e-04 - val_mae: 0.0197\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.0456e-04 - val_mae: 0.0197\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.9937e-04 - val_mae: 0.0197\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0241 - val_loss: 9.0145e-04 - val_mae: 0.0197\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 8.9920e-04 - val_mae: 0.0197\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 8.9944e-04 - val_mae: 0.0197\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 9.1226e-04 - val_mae: 0.0210\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.0230e-04 - val_mae: 0.0200\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.9945e-04 - val_mae: 0.0197\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0276 - val_loss: 9.6476e-04 - val_mae: 0.0236\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 9.3418e-04 - val_mae: 0.0223\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.0733e-04 - val_mae: 0.0205\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.0065e-04 - val_mae: 0.0198\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0564e-04 - val_mae: 0.0197\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0178e-04 - val_mae: 0.0197\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.1433e-04 - val_mae: 0.0200\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.0213e-04 - val_mae: 0.0197\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 8.9953e-04 - val_mae: 0.0197\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0575e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0237 - val_loss: 9.1163e-04 - val_mae: 0.0200\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0237 - val_loss: 9.0388e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0503e-04 - val_mae: 0.0197\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.0266e-04 - val_mae: 0.0197\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0047e-04 - val_mae: 0.0197\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 9.0162e-04 - val_mae: 0.0197\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0235 - val_loss: 9.1320e-04 - val_mae: 0.0200\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0450e-04 - val_mae: 0.0197\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.1063e-04 - val_mae: 0.0199\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0943e-04 - val_mae: 0.0199\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0368e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0424e-04 - val_mae: 0.0197\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.0285e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0252 - val_loss: 9.0589e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0993e-04 - val_mae: 0.0199\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Model: \"sequential_29\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_348 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_319 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_349 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_320 (Dropout)       (None, 40)                0         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dense_350 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_321 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_351 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_322 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_352 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_323 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_353 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_324 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_354 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_325 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_355 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_326 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_356 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_327 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_357 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_328 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_358 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_329 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_359 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 27ms/step - loss: 6.6383 - mae: 1.7845 - val_loss: 0.1565 - val_mae: 0.3936\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.2657 - mae: 0.7386 - val_loss: 0.0088 - val_mae: 0.0916\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.8452 - mae: 0.6601 - val_loss: 0.0144 - val_mae: 0.1128\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5108 - mae: 0.5331 - val_loss: 0.0128 - val_mae: 0.1062\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2448 - mae: 0.4100 - val_loss: 0.0083 - val_mae: 0.0813\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.3698 - mae: 0.4106 - val_loss: 0.0023 - val_mae: 0.0403\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1617 - mae: 0.2787 - val_loss: 0.0011 - val_mae: 0.0274\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1679 - mae: 0.2899 - val_loss: 0.0017 - val_mae: 0.0356\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1616 - mae: 0.3194 - val_loss: 0.0020 - val_mae: 0.0399\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1776 - mae: 0.2860 - val_loss: 0.0017 - val_mae: 0.0345\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1307 - mae: 0.2776 - val_loss: 0.0015 - val_mae: 0.0332\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1613 - mae: 0.2551 - val_loss: 0.0016 - val_mae: 0.0338\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0882 - mae: 0.2224 - val_loss: 5.1080e-04 - val_mae: 0.0193\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0601 - mae: 0.1837 - val_loss: 4.5240e-04 - val_mae: 0.0178\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0925 - mae: 0.2178 - val_loss: 4.0776e-04 - val_mae: 0.0176\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0410 - mae: 0.1535 - val_loss: 4.1407e-04 - val_mae: 0.0181\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.1067 - mae: 0.2125 - val_loss: 6.7309e-04 - val_mae: 0.0230\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0980 - mae: 0.2221 - val_loss: 9.0313e-04 - val_mae: 0.0251\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0802 - mae: 0.2009 - val_loss: 9.0918e-04 - val_mae: 0.0258\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0897 - mae: 0.1750 - val_loss: 7.7401e-04 - val_mae: 0.0234\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0531 - mae: 0.1577 - val_loss: 6.8855e-04 - val_mae: 0.0204\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0441 - mae: 0.1494 - val_loss: 7.2602e-04 - val_mae: 0.0205\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0305 - mae: 0.1184 - val_loss: 7.4486e-04 - val_mae: 0.0205\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0292 - mae: 0.1242 - val_loss: 7.5449e-04 - val_mae: 0.0208\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0336 - mae: 0.1325 - val_loss: 8.0603e-04 - val_mae: 0.0216\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0388 - mae: 0.1433 - val_loss: 7.8574e-04 - val_mae: 0.0217\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0353 - mae: 0.1311 - val_loss: 9.1400e-04 - val_mae: 0.0233\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0355 - mae: 0.1358 - val_loss: 8.1715e-04 - val_mae: 0.0227\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0270 - mae: 0.1193 - val_loss: 7.7936e-04 - val_mae: 0.0221\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.1002 - val_loss: 7.8681e-04 - val_mae: 0.0213\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0240 - mae: 0.1069 - val_loss: 8.1807e-04 - val_mae: 0.0218\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0447 - mae: 0.1269 - val_loss: 7.9934e-04 - val_mae: 0.0207\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.0967 - val_loss: 7.9050e-04 - val_mae: 0.0201\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0408 - mae: 0.1288 - val_loss: 7.4410e-04 - val_mae: 0.0194\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0257 - mae: 0.0922 - val_loss: 7.8387e-04 - val_mae: 0.0211\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0241 - mae: 0.1071 - val_loss: 7.7556e-04 - val_mae: 0.0209\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0342 - mae: 0.1177 - val_loss: 8.3058e-04 - val_mae: 0.0212\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0275 - mae: 0.0996 - val_loss: 8.3603e-04 - val_mae: 0.0213\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0266 - mae: 0.1153 - val_loss: 8.6990e-04 - val_mae: 0.0214\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0189 - mae: 0.0963 - val_loss: 8.9919e-04 - val_mae: 0.0219\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0153 - mae: 0.0783 - val_loss: 8.9360e-04 - val_mae: 0.0214\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0282 - mae: 0.1041 - val_loss: 8.4142e-04 - val_mae: 0.0207\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0169 - mae: 0.0875 - val_loss: 8.1794e-04 - val_mae: 0.0201\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0189 - mae: 0.0911 - val_loss: 8.4382e-04 - val_mae: 0.0203\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.0948 - val_loss: 8.4514e-04 - val_mae: 0.0201\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0190 - mae: 0.0924 - val_loss: 8.6717e-04 - val_mae: 0.0202\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.1022 - val_loss: 9.0441e-04 - val_mae: 0.0204\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0146 - mae: 0.0755 - val_loss: 9.3181e-04 - val_mae: 0.0206\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0723 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0607 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0671 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0781 - val_loss: 0.0010 - val_mae: 0.0227\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0234 - mae: 0.0959 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0141 - mae: 0.0677 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.0833 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.0817 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0771 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0549 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0668 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0126 - mae: 0.0674 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0641 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0157 - mae: 0.0805 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0573 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0586 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0557 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0521 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0597 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0150 - mae: 0.0716 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0433 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.0598 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0605 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0644 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0612 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0510 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0549 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0463 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0467 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0422 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0472 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0472 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0109 - mae: 0.0565 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0542 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0586 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0546 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0510 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0411 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0526 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0473 - val_loss: 0.0011 - val_mae: 0.0221\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0221\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0220\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0445 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0462 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0466 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0387 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0106 - mae: 0.0540 - val_loss: 0.0011 - val_mae: 0.0220\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0371 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0394 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0493 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0477 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0444 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0536 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0124 - mae: 0.0536 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0411 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0077 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0399 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0431 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0439 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0426 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0355 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0381 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0371 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0320 - val_loss: 9.9510e-04 - val_mae: 0.0212\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0384 - val_loss: 9.8512e-04 - val_mae: 0.0210\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - mae: 0.0428 - val_loss: 9.9477e-04 - val_mae: 0.0212\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0455 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0417 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0501 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0390 - val_loss: 9.9394e-04 - val_mae: 0.0212\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0414 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0340 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0456 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0352 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0333 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0315 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0355 - val_loss: 9.8552e-04 - val_mae: 0.0210\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0058 - mae: 0.0360 - val_loss: 9.8538e-04 - val_mae: 0.0210\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0359 - val_loss: 9.7853e-04 - val_mae: 0.0209\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0355 - val_loss: 9.6125e-04 - val_mae: 0.0207\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0367 - val_loss: 9.1978e-04 - val_mae: 0.0199\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0336 - val_loss: 9.1746e-04 - val_mae: 0.0198\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0400 - val_loss: 9.1638e-04 - val_mae: 0.0198\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0332 - val_loss: 9.1629e-04 - val_mae: 0.0198\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.1613e-04 - val_mae: 0.0199\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0321 - val_loss: 9.1614e-04 - val_mae: 0.0199\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0306 - val_loss: 9.2231e-04 - val_mae: 0.0201\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0448 - val_loss: 9.1235e-04 - val_mae: 0.0199\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0361 - val_loss: 9.1289e-04 - val_mae: 0.0198\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0413 - val_loss: 9.1857e-04 - val_mae: 0.0198\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0391 - val_loss: 9.3009e-04 - val_mae: 0.0202\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0325 - val_loss: 9.3633e-04 - val_mae: 0.0203\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0351 - val_loss: 9.0391e-04 - val_mae: 0.0198\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0372 - val_loss: 9.0925e-04 - val_mae: 0.0199\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0314 - val_loss: 9.1864e-04 - val_mae: 0.0201\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0309 - val_loss: 9.1788e-04 - val_mae: 0.0201\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0312 - val_loss: 9.2121e-04 - val_mae: 0.0202\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0341 - val_loss: 9.3799e-04 - val_mae: 0.0205\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0324 - val_loss: 9.3804e-04 - val_mae: 0.0205\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0307 - val_loss: 9.2877e-04 - val_mae: 0.0203\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0329 - val_loss: 9.2736e-04 - val_mae: 0.0203\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0353 - val_loss: 9.2605e-04 - val_mae: 0.0202\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0298 - val_loss: 9.3180e-04 - val_mae: 0.0203\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0300 - val_loss: 9.3322e-04 - val_mae: 0.0204\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0339 - val_loss: 9.2995e-04 - val_mae: 0.0203\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0349 - val_loss: 9.4357e-04 - val_mae: 0.0205\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0283 - val_loss: 9.2022e-04 - val_mae: 0.0202\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0381 - val_loss: 9.1850e-04 - val_mae: 0.0201\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0338 - val_loss: 9.1944e-04 - val_mae: 0.0201\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0318 - val_loss: 9.3794e-04 - val_mae: 0.0205\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0338 - val_loss: 9.3665e-04 - val_mae: 0.0205\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0327 - val_loss: 9.2336e-04 - val_mae: 0.0202\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 9.1730e-04 - val_mae: 0.0201\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0319 - val_loss: 9.1469e-04 - val_mae: 0.0200\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0311 - val_loss: 9.1912e-04 - val_mae: 0.0201\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0317 - val_loss: 9.2739e-04 - val_mae: 0.0203\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0287 - val_loss: 9.2288e-04 - val_mae: 0.0202\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0298 - val_loss: 9.2000e-04 - val_mae: 0.0202\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.2589e-04 - val_mae: 0.0203\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0035 - mae: 0.0271 - val_loss: 9.2304e-04 - val_mae: 0.0202\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0305 - val_loss: 9.3400e-04 - val_mae: 0.0204\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 9.3061e-04 - val_mae: 0.0203\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0333 - val_loss: 9.1598e-04 - val_mae: 0.0200\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0312 - val_loss: 9.0646e-04 - val_mae: 0.0197\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 9.0578e-04 - val_mae: 0.0197\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0292 - val_loss: 9.0539e-04 - val_mae: 0.0197\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0300 - val_loss: 9.1760e-04 - val_mae: 0.0201\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0310 - val_loss: 9.2446e-04 - val_mae: 0.0202\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0308 - val_loss: 9.2544e-04 - val_mae: 0.0203\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0286 - val_loss: 9.3932e-04 - val_mae: 0.0205\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 9.3435e-04 - val_mae: 0.0204\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0291 - val_loss: 9.2313e-04 - val_mae: 0.0202\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0315 - val_loss: 9.2420e-04 - val_mae: 0.0203\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0271 - val_loss: 9.2191e-04 - val_mae: 0.0202\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0312 - val_loss: 9.1686e-04 - val_mae: 0.0201\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.1122e-04 - val_mae: 0.0199\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0299 - val_loss: 9.1282e-04 - val_mae: 0.0199\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0304 - val_loss: 9.0644e-04 - val_mae: 0.0197\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0350 - val_loss: 9.0399e-04 - val_mae: 0.0197\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0296 - val_loss: 9.0250e-04 - val_mae: 0.0197\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0298 - val_loss: 9.0379e-04 - val_mae: 0.0197\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0295 - val_loss: 9.0845e-04 - val_mae: 0.0198\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 9.0553e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0295 - val_loss: 9.0495e-04 - val_mae: 0.0197\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0291 - val_loss: 9.0631e-04 - val_mae: 0.0197\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 9.1047e-04 - val_mae: 0.0198\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 9.1238e-04 - val_mae: 0.0199\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0324 - val_loss: 9.0603e-04 - val_mae: 0.0197\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0271 - val_loss: 9.0313e-04 - val_mae: 0.0197\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 9.0350e-04 - val_mae: 0.0197\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0291 - val_loss: 9.0659e-04 - val_mae: 0.0198\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0275 - val_loss: 9.1252e-04 - val_mae: 0.0199\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 9.1493e-04 - val_mae: 0.0200\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0245 - val_loss: 9.1008e-04 - val_mae: 0.0198\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0279 - val_loss: 9.0400e-04 - val_mae: 0.0197\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0303 - val_loss: 9.0385e-04 - val_mae: 0.0197\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0281 - val_loss: 9.0557e-04 - val_mae: 0.0197\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0294 - val_loss: 9.0816e-04 - val_mae: 0.0198\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0286 - val_loss: 9.1127e-04 - val_mae: 0.0198\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0283 - val_loss: 9.0989e-04 - val_mae: 0.0198\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0758e-04 - val_mae: 0.0197\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0292 - val_loss: 9.1382e-04 - val_mae: 0.0199\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 9.0946e-04 - val_mae: 0.0198\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0271 - val_loss: 9.1476e-04 - val_mae: 0.0199\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 9.1618e-04 - val_mae: 0.0200\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.1626e-04 - val_mae: 0.0200\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 9.1033e-04 - val_mae: 0.0197\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 9.0628e-04 - val_mae: 0.0197\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0277 - val_loss: 9.1306e-04 - val_mae: 0.0198\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0283 - val_loss: 9.0416e-04 - val_mae: 0.0197\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 9.0286e-04 - val_mae: 0.0197\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0283 - val_loss: 9.0269e-04 - val_mae: 0.0197\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 9.0321e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0296 - val_loss: 9.0217e-04 - val_mae: 0.0197\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.0435e-04 - val_mae: 0.0197\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 9.0625e-04 - val_mae: 0.0197\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 9.1043e-04 - val_mae: 0.0199\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0037 - mae: 0.0257 - val_loss: 9.1200e-04 - val_mae: 0.0199\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0287 - val_loss: 9.0548e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.1113e-04 - val_mae: 0.0199\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.0371e-04 - val_mae: 0.0197\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0331e-04 - val_mae: 0.0197\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0041e-04 - val_mae: 0.0197\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.0079e-04 - val_mae: 0.0197\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.0242e-04 - val_mae: 0.0197\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.0247e-04 - val_mae: 0.0197\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0349e-04 - val_mae: 0.0197\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.0016e-04 - val_mae: 0.0197\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 9.0008e-04 - val_mae: 0.0197\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 9.0006e-04 - val_mae: 0.0197\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0284 - val_loss: 9.1026e-04 - val_mae: 0.0199\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0251 - val_loss: 9.0184e-04 - val_mae: 0.0197\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0344e-04 - val_mae: 0.0197\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 9.0427e-04 - val_mae: 0.0197\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0246 - val_loss: 9.0706e-04 - val_mae: 0.0198\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 9.0407e-04 - val_mae: 0.0197\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.0764e-04 - val_mae: 0.0198\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.0247e-04 - val_mae: 0.0197\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.0652e-04 - val_mae: 0.0198\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0633e-04 - val_mae: 0.0198\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0214e-04 - val_mae: 0.0197\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.0210e-04 - val_mae: 0.0197\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 9.0341e-04 - val_mae: 0.0197\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.0061e-04 - val_mae: 0.0197\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 9.0113e-04 - val_mae: 0.0197\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 8.9983e-04 - val_mae: 0.0197\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.0252e-04 - val_mae: 0.0197\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0403e-04 - val_mae: 0.0197\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0309e-04 - val_mae: 0.0197\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0270 - val_loss: 9.0255e-04 - val_mae: 0.0197\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0270 - val_loss: 9.0133e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0256 - val_loss: 9.0535e-04 - val_mae: 0.0197\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 9.0490e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.0233e-04 - val_mae: 0.0197\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 9.0475e-04 - val_mae: 0.0197\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.0283e-04 - val_mae: 0.0197\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 9.0444e-04 - val_mae: 0.0197\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0271 - val_loss: 9.1250e-04 - val_mae: 0.0200\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0243 - val_loss: 9.0898e-04 - val_mae: 0.0199\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0240 - val_loss: 9.0289e-04 - val_mae: 0.0197\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0275 - val_loss: 8.9957e-04 - val_mae: 0.0197\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 8.9994e-04 - val_mae: 0.0197\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 8.9971e-04 - val_mae: 0.0197\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.0079e-04 - val_mae: 0.0197\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.0257e-04 - val_mae: 0.0197\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.4372e-04 - val_mae: 0.0228\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0286 - val_loss: 9.1886e-04 - val_mae: 0.0214\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0291 - val_loss: 9.0972e-04 - val_mae: 0.0207\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 9.0132e-04 - val_mae: 0.0198\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0329 - val_loss: 9.0179e-04 - val_mae: 0.0197\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0232 - val_loss: 8.9912e-04 - val_mae: 0.0197\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.9892e-04 - val_mae: 0.0197\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0250 - val_loss: 8.9837e-04 - val_mae: 0.0197\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.0071e-04 - val_mae: 0.0197\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 8.9838e-04 - val_mae: 0.0196\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0265 - val_loss: 8.9868e-04 - val_mae: 0.0197\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0260 - val_loss: 8.9911e-04 - val_mae: 0.0197\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0270 - val_loss: 8.9912e-04 - val_mae: 0.0197\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0000e-04 - val_mae: 0.0197\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.0577e-04 - val_mae: 0.0198\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 8.9982e-04 - val_mae: 0.0197\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 9.0209e-04 - val_mae: 0.0197\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0494e-04 - val_mae: 0.0197\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0270 - val_loss: 9.0521e-04 - val_mae: 0.0197\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0668e-04 - val_mae: 0.0198\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.0189e-04 - val_mae: 0.0197\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 8.9987e-04 - val_mae: 0.0197\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0142e-04 - val_mae: 0.0197\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0269 - val_loss: 9.0467e-04 - val_mae: 0.0197\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0734e-04 - val_mae: 0.0198\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.0641e-04 - val_mae: 0.0198\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0249 - val_loss: 9.0209e-04 - val_mae: 0.0197\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0213e-04 - val_mae: 0.0197\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0251 - val_loss: 9.0551e-04 - val_mae: 0.0197\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0572e-04 - val_mae: 0.0197\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.2342e-04 - val_mae: 0.0202\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 9.0748e-04 - val_mae: 0.0198\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0901e-04 - val_mae: 0.0199\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0390e-04 - val_mae: 0.0197\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 9.0172e-04 - val_mae: 0.0197\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.0008e-04 - val_mae: 0.0197\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 8.9963e-04 - val_mae: 0.0197\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0361e-04 - val_mae: 0.0197\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0043e-04 - val_mae: 0.0197\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0372e-04 - val_mae: 0.0197\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 8.9961e-04 - val_mae: 0.0197\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0089e-04 - val_mae: 0.0197\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 8.9966e-04 - val_mae: 0.0197\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0261 - val_loss: 9.0047e-04 - val_mae: 0.0197\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 9.0050e-04 - val_mae: 0.0197\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 8.9962e-04 - val_mae: 0.0197\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.0270e-04 - val_mae: 0.0200\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0005e-04 - val_mae: 0.0197\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0084e-04 - val_mae: 0.0197\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 9.1701e-04 - val_mae: 0.0201\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.2403e-04 - val_mae: 0.0202\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.1429e-04 - val_mae: 0.0200\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0174e-04 - val_mae: 0.0197\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.0004e-04 - val_mae: 0.0197\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0250 - val_loss: 9.0854e-04 - val_mae: 0.0198\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.0610e-04 - val_mae: 0.0197\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.9999e-04 - val_mae: 0.0197\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0094e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.0200e-04 - val_mae: 0.0197\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0273e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.0002e-04 - val_mae: 0.0197\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.1181e-04 - val_mae: 0.0199\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.0283e-04 - val_mae: 0.0197\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0378e-04 - val_mae: 0.0197\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0043 - mae: 0.0235 - val_loss: 9.0634e-04 - val_mae: 0.0198\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.0070e-04 - val_mae: 0.0197\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0124e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0245e-04 - val_mae: 0.0197\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0041 - mae: 0.0228 - val_loss: 9.0191e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0054e-04 - val_mae: 0.0197\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0253 - val_loss: 9.0084e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0072e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0244 - val_loss: 9.0038e-04 - val_mae: 0.0197\n",
            "3/3 [==============================] - 0s 4ms/step\n",
            "Model: \"sequential_30\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_360 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_330 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_361 (Dense)           (None, 40)                1640      \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dropout_331 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_362 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_332 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_363 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_333 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_364 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_334 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_365 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_335 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_366 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_336 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_367 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_337 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_368 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_338 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_369 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_339 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_370 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_340 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_371 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 16ms/step - loss: 6.1293 - mae: 1.8866 - val_loss: 0.1101 - val_mae: 0.3300\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 1.6277 - mae: 0.9197 - val_loss: 0.0202 - val_mae: 0.1400\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7786 - mae: 0.6439 - val_loss: 0.0026 - val_mae: 0.0477\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4781 - mae: 0.5121 - val_loss: 0.0054 - val_mae: 0.0691\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3312 - mae: 0.4306 - val_loss: 0.0066 - val_mae: 0.0754\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3473 - mae: 0.4031 - val_loss: 0.0045 - val_mae: 0.0626\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.3383 - mae: 0.3974 - val_loss: 0.0019 - val_mae: 0.0408\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1354 - mae: 0.2542 - val_loss: 0.0011 - val_mae: 0.0291\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1949 - mae: 0.3203 - val_loss: 0.0013 - val_mae: 0.0327\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1566 - mae: 0.2774 - val_loss: 0.0015 - val_mae: 0.0362\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1024 - mae: 0.2341 - val_loss: 0.0011 - val_mae: 0.0300\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1689 - mae: 0.2861 - val_loss: 7.1882e-04 - val_mae: 0.0184\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1001 - mae: 0.2106 - val_loss: 7.0469e-04 - val_mae: 0.0181\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0718 - mae: 0.1912 - val_loss: 7.6304e-04 - val_mae: 0.0205\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0915 - mae: 0.2030 - val_loss: 7.9324e-04 - val_mae: 0.0205\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0702 - mae: 0.1836 - val_loss: 8.2198e-04 - val_mae: 0.0199\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1469 - val_loss: 8.5481e-04 - val_mae: 0.0198\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0498 - mae: 0.1677 - val_loss: 9.2514e-04 - val_mae: 0.0209\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0414 - mae: 0.1399 - val_loss: 0.0010 - val_mae: 0.0222\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0678 - mae: 0.1744 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0421 - mae: 0.1417 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0420 - mae: 0.1540 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0539 - mae: 0.1617 - val_loss: 0.0012 - val_mae: 0.0240\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0574 - mae: 0.1532 - val_loss: 0.0011 - val_mae: 0.0217\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0494 - mae: 0.1431 - val_loss: 9.3414e-04 - val_mae: 0.0197\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0201 - mae: 0.1080 - val_loss: 9.3078e-04 - val_mae: 0.0203\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0328 - mae: 0.1353 - val_loss: 9.1186e-04 - val_mae: 0.0197\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0405 - mae: 0.1369 - val_loss: 9.0319e-04 - val_mae: 0.0207\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0487 - mae: 0.1632 - val_loss: 9.1316e-04 - val_mae: 0.0207\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0504 - mae: 0.1458 - val_loss: 9.3078e-04 - val_mae: 0.0210\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0409 - mae: 0.1236 - val_loss: 9.9263e-04 - val_mae: 0.0250\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0275 - mae: 0.1090 - val_loss: 0.0010 - val_mae: 0.0254\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0220 - mae: 0.1015 - val_loss: 9.3820e-04 - val_mae: 0.0238\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0243 - mae: 0.1069 - val_loss: 8.4034e-04 - val_mae: 0.0207\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0247 - mae: 0.0978 - val_loss: 8.0167e-04 - val_mae: 0.0190\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0240 - mae: 0.0948 - val_loss: 7.9506e-04 - val_mae: 0.0186\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0226 - mae: 0.0895 - val_loss: 8.0458e-04 - val_mae: 0.0190\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0232 - mae: 0.0958 - val_loss: 8.1052e-04 - val_mae: 0.0192\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0192 - mae: 0.0974 - val_loss: 8.0283e-04 - val_mae: 0.0188\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0129 - mae: 0.0793 - val_loss: 8.0720e-04 - val_mae: 0.0188\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0207 - mae: 0.0923 - val_loss: 8.1253e-04 - val_mae: 0.0188\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0261 - mae: 0.1004 - val_loss: 8.7070e-04 - val_mae: 0.0199\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - mae: 0.0721 - val_loss: 9.1055e-04 - val_mae: 0.0208\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - mae: 0.0792 - val_loss: 8.8137e-04 - val_mae: 0.0204\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0241 - mae: 0.0918 - val_loss: 8.6806e-04 - val_mae: 0.0201\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - mae: 0.0829 - val_loss: 8.5000e-04 - val_mae: 0.0198\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0252 - mae: 0.0979 - val_loss: 8.7615e-04 - val_mae: 0.0201\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0113 - mae: 0.0684 - val_loss: 8.8820e-04 - val_mae: 0.0203\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0161 - mae: 0.0772 - val_loss: 9.1700e-04 - val_mae: 0.0204\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.0919 - val_loss: 9.8265e-04 - val_mae: 0.0216\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0702 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0596 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0146 - mae: 0.0731 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0536 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0601 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0606 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0115 - mae: 0.0661 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0560 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0701 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0623 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0604 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0599 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0127 - mae: 0.0696 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0578 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0139 - mae: 0.0746 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0110 - mae: 0.0649 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0079 - mae: 0.0535 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0118 - mae: 0.0664 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0087 - mae: 0.0600 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0625 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0596 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0105 - mae: 0.0625 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0583 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0487 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0094 - mae: 0.0529 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0566 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0533 - val_loss: 0.0011 - val_mae: 0.0243\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0103 - mae: 0.0462 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0406 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0426 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0441 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0443 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0545 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0466 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0442 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0402 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0488 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0429 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0507 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0531 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0084 - mae: 0.0469 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0472 - val_loss: 9.8607e-04 - val_mae: 0.0211\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0390 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0067 - mae: 0.0445 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0401 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0414 - val_loss: 9.9092e-04 - val_mae: 0.0212\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0070 - mae: 0.0420 - val_loss: 9.8138e-04 - val_mae: 0.0212\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0428 - val_loss: 9.9974e-04 - val_mae: 0.0213\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0468 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0406 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0389 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0417 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0443 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0435 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0390 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0429 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0412 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0448 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0347 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0440 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0395 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0326 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0374 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0398 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0370 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0436 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0397 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0368 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0380 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0411 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0387 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0435 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0395 - val_loss: 9.9988e-04 - val_mae: 0.0212\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0358 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0370 - val_loss: 0.0010 - val_mae: 0.0222\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0356 - val_loss: 0.0010 - val_mae: 0.0222\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0382 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0470 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0345 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0359 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0356 - val_loss: 9.9360e-04 - val_mae: 0.0211\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0376 - val_loss: 9.7729e-04 - val_mae: 0.0210\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0369 - val_loss: 9.3466e-04 - val_mae: 0.0204\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0379 - val_loss: 9.6627e-04 - val_mae: 0.0208\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0360 - val_loss: 9.5789e-04 - val_mae: 0.0207\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0038 - mae: 0.0300 - val_loss: 9.8162e-04 - val_mae: 0.0210\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0349 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0312 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0053 - mae: 0.0326 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0333 - val_loss: 9.8234e-04 - val_mae: 0.0210\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0307 - val_loss: 9.4887e-04 - val_mae: 0.0206\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0404 - val_loss: 9.5435e-04 - val_mae: 0.0207\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0332 - val_loss: 9.6926e-04 - val_mae: 0.0209\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0340 - val_loss: 9.7716e-04 - val_mae: 0.0210\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0315 - val_loss: 9.6801e-04 - val_mae: 0.0209\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0309 - val_loss: 9.6883e-04 - val_mae: 0.0209\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0340 - val_loss: 9.5282e-04 - val_mae: 0.0207\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0407 - val_loss: 9.3987e-04 - val_mae: 0.0205\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0303 - val_loss: 9.3001e-04 - val_mae: 0.0203\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 9.3099e-04 - val_mae: 0.0204\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0375 - val_loss: 9.1991e-04 - val_mae: 0.0202\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0340 - val_loss: 9.3803e-04 - val_mae: 0.0205\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0318 - val_loss: 9.3533e-04 - val_mae: 0.0205\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0316 - val_loss: 9.5208e-04 - val_mae: 0.0207\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0269 - val_loss: 9.5925e-04 - val_mae: 0.0208\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0316 - val_loss: 9.5716e-04 - val_mae: 0.0208\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0341 - val_loss: 9.7078e-04 - val_mae: 0.0209\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0319 - val_loss: 9.6472e-04 - val_mae: 0.0209\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0288 - val_loss: 9.6808e-04 - val_mae: 0.0209\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0312 - val_loss: 9.7923e-04 - val_mae: 0.0210\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0314 - val_loss: 9.5760e-04 - val_mae: 0.0208\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0340 - val_loss: 9.6711e-04 - val_mae: 0.0209\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0238 - val_loss: 9.6479e-04 - val_mae: 0.0209\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0342 - val_loss: 9.6050e-04 - val_mae: 0.0208\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0307 - val_loss: 9.5314e-04 - val_mae: 0.0207\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0286 - val_loss: 9.5639e-04 - val_mae: 0.0208\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0335 - val_loss: 9.4821e-04 - val_mae: 0.0207\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 9.4903e-04 - val_mae: 0.0207\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0278 - val_loss: 9.4720e-04 - val_mae: 0.0206\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0287 - val_loss: 9.2891e-04 - val_mae: 0.0204\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0311 - val_loss: 9.2862e-04 - val_mae: 0.0203\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0287 - val_loss: 9.1733e-04 - val_mae: 0.0201\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0292 - val_loss: 9.1343e-04 - val_mae: 0.0200\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0292 - val_loss: 9.2681e-04 - val_mae: 0.0203\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 9.3605e-04 - val_mae: 0.0205\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0317 - val_loss: 9.4034e-04 - val_mae: 0.0205\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0296 - val_loss: 9.5897e-04 - val_mae: 0.0208\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0283 - val_loss: 9.8184e-04 - val_mae: 0.0211\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0284 - val_loss: 9.6403e-04 - val_mae: 0.0209\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 9.4576e-04 - val_mae: 0.0206\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.2294e-04 - val_mae: 0.0202\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.3000e-04 - val_mae: 0.0204\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0301 - val_loss: 9.4487e-04 - val_mae: 0.0206\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0321 - val_loss: 9.5596e-04 - val_mae: 0.0208\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0277 - val_loss: 9.4543e-04 - val_mae: 0.0206\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0314 - val_loss: 9.3280e-04 - val_mae: 0.0204\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0310 - val_loss: 9.2214e-04 - val_mae: 0.0202\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0305 - val_loss: 9.1661e-04 - val_mae: 0.0201\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.1327e-04 - val_mae: 0.0200\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0315 - val_loss: 9.1970e-04 - val_mae: 0.0202\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0303 - val_loss: 9.1187e-04 - val_mae: 0.0200\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0291 - val_loss: 9.1170e-04 - val_mae: 0.0200\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.1712e-04 - val_mae: 0.0201\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0290 - val_loss: 9.1652e-04 - val_mae: 0.0201\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.1503e-04 - val_mae: 0.0200\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0308 - val_loss: 9.0192e-04 - val_mae: 0.0197\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0324 - val_loss: 9.0794e-04 - val_mae: 0.0198\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0328 - val_loss: 9.0787e-04 - val_mae: 0.0198\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0272 - val_loss: 9.1712e-04 - val_mae: 0.0201\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.0744e-04 - val_mae: 0.0198\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 9.0579e-04 - val_mae: 0.0197\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0313 - val_loss: 9.0762e-04 - val_mae: 0.0198\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0283 - val_loss: 9.1071e-04 - val_mae: 0.0199\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0299 - val_loss: 9.1868e-04 - val_mae: 0.0201\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0250 - val_loss: 9.2195e-04 - val_mae: 0.0202\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0874e-04 - val_mae: 0.0198\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 9.1077e-04 - val_mae: 0.0199\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0271 - val_loss: 9.1393e-04 - val_mae: 0.0200\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0283 - val_loss: 9.1376e-04 - val_mae: 0.0200\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 9.1880e-04 - val_mae: 0.0201\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.1484e-04 - val_mae: 0.0200\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 9.1433e-04 - val_mae: 0.0200\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 9.0720e-04 - val_mae: 0.0198\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.1086e-04 - val_mae: 0.0200\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 9.1262e-04 - val_mae: 0.0200\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.0137e-04 - val_mae: 0.0197\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 9.0001e-04 - val_mae: 0.0197\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 9.0110e-04 - val_mae: 0.0197\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 9.0618e-04 - val_mae: 0.0198\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0294 - val_loss: 9.0426e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.0095e-04 - val_mae: 0.0197\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.0992e-04 - val_mae: 0.0199\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0318e-04 - val_mae: 0.0197\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0036 - mae: 0.0268 - val_loss: 9.0447e-04 - val_mae: 0.0197\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0309 - val_loss: 9.2152e-04 - val_mae: 0.0202\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 9.1347e-04 - val_mae: 0.0200\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0418e-04 - val_mae: 0.0197\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 9.0190e-04 - val_mae: 0.0197\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 9.0149e-04 - val_mae: 0.0197\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0281 - val_loss: 8.9942e-04 - val_mae: 0.0197\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0222e-04 - val_mae: 0.0197\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0244 - val_loss: 8.9966e-04 - val_mae: 0.0197\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0291 - val_loss: 8.9939e-04 - val_mae: 0.0197\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 9.0244e-04 - val_mae: 0.0197\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0297 - val_loss: 9.0833e-04 - val_mae: 0.0198\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 9.0933e-04 - val_mae: 0.0199\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0300 - val_loss: 8.9910e-04 - val_mae: 0.0197\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0006e-04 - val_mae: 0.0197\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 8.9969e-04 - val_mae: 0.0197\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0288 - val_loss: 9.0701e-04 - val_mae: 0.0198\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.0339e-04 - val_mae: 0.0197\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0281 - val_loss: 9.0106e-04 - val_mae: 0.0197\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.9995e-04 - val_mae: 0.0197\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0035e-04 - val_mae: 0.0197\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0036 - mae: 0.0247 - val_loss: 9.0302e-04 - val_mae: 0.0197\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0459e-04 - val_mae: 0.0197\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0404e-04 - val_mae: 0.0197\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.0599e-04 - val_mae: 0.0198\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.0523e-04 - val_mae: 0.0198\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0748e-04 - val_mae: 0.0198\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0264 - val_loss: 9.0184e-04 - val_mae: 0.0197\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0034e-04 - val_mae: 0.0197\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0279 - val_loss: 8.9906e-04 - val_mae: 0.0197\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 9.3762e-04 - val_mae: 0.0225\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0301 - val_loss: 9.3714e-04 - val_mae: 0.0225\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 9.1079e-04 - val_mae: 0.0209\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0279 - val_loss: 8.9844e-04 - val_mae: 0.0197\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 8.9849e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0291e-04 - val_mae: 0.0197\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 8.9908e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.0044e-04 - val_mae: 0.0197\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 9.0000e-04 - val_mae: 0.0197\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 8.9898e-04 - val_mae: 0.0197\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.9914e-04 - val_mae: 0.0197\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 8.9890e-04 - val_mae: 0.0197\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.9884e-04 - val_mae: 0.0197\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0272 - val_loss: 8.9975e-04 - val_mae: 0.0197\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 8.9943e-04 - val_mae: 0.0197\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 8.9935e-04 - val_mae: 0.0197\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0275e-04 - val_mae: 0.0197\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 9.1162e-04 - val_mae: 0.0200\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0629e-04 - val_mae: 0.0198\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.0565e-04 - val_mae: 0.0198\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 9.0037e-04 - val_mae: 0.0197\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0421e-04 - val_mae: 0.0197\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.0188e-04 - val_mae: 0.0197\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0164e-04 - val_mae: 0.0197\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.0365e-04 - val_mae: 0.0197\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.1389e-04 - val_mae: 0.0200\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.0635e-04 - val_mae: 0.0198\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0384e-04 - val_mae: 0.0197\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.1623e-04 - val_mae: 0.0201\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0248 - val_loss: 9.1085e-04 - val_mae: 0.0199\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.9919e-04 - val_mae: 0.0197\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 8.9905e-04 - val_mae: 0.0197\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0021e-04 - val_mae: 0.0197\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0212e-04 - val_mae: 0.0197\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0210e-04 - val_mae: 0.0197\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0277 - val_loss: 8.9935e-04 - val_mae: 0.0197\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.0225e-04 - val_mae: 0.0197\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0624e-04 - val_mae: 0.0198\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0091e-04 - val_mae: 0.0197\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0248 - val_loss: 8.9989e-04 - val_mae: 0.0197\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.9993e-04 - val_mae: 0.0197\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.0173e-04 - val_mae: 0.0197\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.0367e-04 - val_mae: 0.0197\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0247 - val_loss: 9.0163e-04 - val_mae: 0.0197\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 8.9971e-04 - val_mae: 0.0197\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0264 - val_loss: 8.9993e-04 - val_mae: 0.0197\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0243 - val_loss: 9.0055e-04 - val_mae: 0.0197\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0169e-04 - val_mae: 0.0197\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 9.0617e-04 - val_mae: 0.0198\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0130e-04 - val_mae: 0.0197\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0260 - val_loss: 9.0244e-04 - val_mae: 0.0197\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 8.9971e-04 - val_mae: 0.0197\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0246 - val_loss: 9.0020e-04 - val_mae: 0.0197\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0132e-04 - val_mae: 0.0197\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 8.9948e-04 - val_mae: 0.0197\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.9957e-04 - val_mae: 0.0197\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0184e-04 - val_mae: 0.0197\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0238 - val_loss: 9.0990e-04 - val_mae: 0.0199\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.0422e-04 - val_mae: 0.0197\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 8.9942e-04 - val_mae: 0.0197\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.0024e-04 - val_mae: 0.0197\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0277 - val_loss: 9.0027e-04 - val_mae: 0.0197\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0075e-04 - val_mae: 0.0197\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0237 - val_loss: 9.0451e-04 - val_mae: 0.0197\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0003e-04 - val_mae: 0.0197\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.0177e-04 - val_mae: 0.0197\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0039 - mae: 0.0244 - val_loss: 9.0096e-04 - val_mae: 0.0197\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0823e-04 - val_mae: 0.0198\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 8.9961e-04 - val_mae: 0.0197\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9942e-04 - val_mae: 0.0197\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.0232e-04 - val_mae: 0.0197\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0242 - val_loss: 9.0023e-04 - val_mae: 0.0197\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9952e-04 - val_mae: 0.0197\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0078e-04 - val_mae: 0.0197\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0263 - val_loss: 9.0338e-04 - val_mae: 0.0197\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0332e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0252e-04 - val_mae: 0.0197\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0065e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0121e-04 - val_mae: 0.0197\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.0143e-04 - val_mae: 0.0197\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0200e-04 - val_mae: 0.0197\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0241 - val_loss: 9.0107e-04 - val_mae: 0.0197\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0400e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0244 - val_loss: 9.0230e-04 - val_mae: 0.0197\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0280e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 8.9915e-04 - val_mae: 0.0197\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0404e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 8.9933e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0267 - val_loss: 9.0794e-04 - val_mae: 0.0198\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "Model: \"sequential_31\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_372 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_341 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_373 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_342 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_374 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_343 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_375 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_344 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_376 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_345 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_377 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_346 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_378 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dropout_347 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_379 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_348 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_380 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_349 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_381 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_350 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_382 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_351 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_383 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 0.4415 - mae: 0.5335 - val_loss: 0.0029 - val_mae: 0.0447\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1439 - mae: 0.3199 - val_loss: 0.0425 - val_mae: 0.2040\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1520 - mae: 0.3329 - val_loss: 0.0069 - val_mae: 0.0776\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1355 - mae: 0.2751 - val_loss: 0.0031 - val_mae: 0.0528\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1019 - mae: 0.2550 - val_loss: 0.0088 - val_mae: 0.0889\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1177 - mae: 0.2786 - val_loss: 0.0044 - val_mae: 0.0622\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1112 - mae: 0.2759 - val_loss: 9.5885e-04 - val_mae: 0.0234\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1067 - mae: 0.2484 - val_loss: 9.1630e-04 - val_mae: 0.0213\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0955 - mae: 0.2564 - val_loss: 9.7062e-04 - val_mae: 0.0209\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0783 - mae: 0.2294 - val_loss: 9.8747e-04 - val_mae: 0.0244\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0861 - mae: 0.2228 - val_loss: 0.0020 - val_mae: 0.0414\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0716 - mae: 0.2124 - val_loss: 0.0011 - val_mae: 0.0273\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0742 - mae: 0.2142 - val_loss: 9.0280e-04 - val_mae: 0.0197\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0604 - mae: 0.1985 - val_loss: 0.0063 - val_mae: 0.0736\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0412 - mae: 0.1620 - val_loss: 0.0078 - val_mae: 0.0832\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0645 - mae: 0.2022 - val_loss: 0.0037 - val_mae: 0.0575\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0558 - mae: 0.1823 - val_loss: 0.0013 - val_mae: 0.0313\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0541 - mae: 0.1842 - val_loss: 0.0050 - val_mae: 0.0637\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0434 - mae: 0.1669 - val_loss: 0.0020 - val_mae: 0.0419\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0424 - mae: 0.1625 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0448 - mae: 0.1726 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.0343 - mae: 0.1375 - val_loss: 9.2109e-04 - val_mae: 0.0202\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1410 - val_loss: 9.1650e-04 - val_mae: 0.0213\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0400 - mae: 0.1607 - val_loss: 9.0901e-04 - val_mae: 0.0199\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0340 - mae: 0.1408 - val_loss: 0.0031 - val_mae: 0.0527\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0354 - mae: 0.1434 - val_loss: 9.8640e-04 - val_mae: 0.0211\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0264 - mae: 0.1291 - val_loss: 9.6418e-04 - val_mae: 0.0208\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0295 - mae: 0.1388 - val_loss: 0.0017 - val_mae: 0.0374\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0315 - mae: 0.1318 - val_loss: 0.0017 - val_mae: 0.0374\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0291 - mae: 0.1358 - val_loss: 9.9216e-04 - val_mae: 0.0246\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0248 - mae: 0.1159 - val_loss: 9.9947e-04 - val_mae: 0.0212\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0271 - mae: 0.1268 - val_loss: 0.0011 - val_mae: 0.0264\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0216 - mae: 0.1098 - val_loss: 0.0017 - val_mae: 0.0321\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0198 - mae: 0.1093 - val_loss: 9.0594e-04 - val_mae: 0.0198\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0213 - mae: 0.1139 - val_loss: 9.8960e-04 - val_mae: 0.0211\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0249 - mae: 0.1260 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0204 - mae: 0.1069 - val_loss: 0.0012 - val_mae: 0.0297\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1081 - val_loss: 9.2079e-04 - val_mae: 0.0216\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0993 - val_loss: 0.0012 - val_mae: 0.0288\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0205 - mae: 0.1103 - val_loss: 0.0011 - val_mae: 0.0274\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0851 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0143 - mae: 0.0832 - val_loss: 9.3012e-04 - val_mae: 0.0221\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0147 - mae: 0.0871 - val_loss: 8.9949e-04 - val_mae: 0.0197\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0135 - mae: 0.0817 - val_loss: 0.0013 - val_mae: 0.0307\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0141 - mae: 0.0868 - val_loss: 9.0265e-04 - val_mae: 0.0200\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.0912 - val_loss: 9.4981e-04 - val_mae: 0.0207\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0136 - mae: 0.0843 - val_loss: 0.0010 - val_mae: 0.0259\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - mae: 0.0865 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0910 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0159 - mae: 0.0946 - val_loss: 9.4262e-04 - val_mae: 0.0227\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0116 - mae: 0.0753 - val_loss: 0.0013 - val_mae: 0.0309\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0778 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0683 - val_loss: 9.0088e-04 - val_mae: 0.0198\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0109 - mae: 0.0773 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.0864 - val_loss: 9.0942e-04 - val_mae: 0.0199\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0120 - mae: 0.0776 - val_loss: 9.4184e-04 - val_mae: 0.0205\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0711 - val_loss: 0.0013 - val_mae: 0.0316\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0088 - mae: 0.0682 - val_loss: 8.9956e-04 - val_mae: 0.0197\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0667 - val_loss: 9.1405e-04 - val_mae: 0.0211\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0600 - val_loss: 0.0010 - val_mae: 0.0261\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - mae: 0.0639 - val_loss: 9.0101e-04 - val_mae: 0.0197\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0087 - mae: 0.0647 - val_loss: 9.0843e-04 - val_mae: 0.0206\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0099 - mae: 0.0674 - val_loss: 9.2752e-04 - val_mae: 0.0203\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0727 - val_loss: 0.0012 - val_mae: 0.0287\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0626 - val_loss: 9.7691e-04 - val_mae: 0.0241\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0683 - val_loss: 9.2746e-04 - val_mae: 0.0220\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0582 - val_loss: 9.3786e-04 - val_mae: 0.0225\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0082 - mae: 0.0606 - val_loss: 9.2268e-04 - val_mae: 0.0217\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0602 - val_loss: 9.7605e-04 - val_mae: 0.0241\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0068 - mae: 0.0554 - val_loss: 9.0196e-04 - val_mae: 0.0200\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0515 - val_loss: 9.7664e-04 - val_mae: 0.0241\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0572 - val_loss: 0.0011 - val_mae: 0.0267\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0623 - val_loss: 9.0155e-04 - val_mae: 0.0197\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0078 - mae: 0.0590 - val_loss: 0.0014 - val_mae: 0.0333\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0566 - val_loss: 8.9936e-04 - val_mae: 0.0197\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0080 - mae: 0.0478 - val_loss: 9.3812e-04 - val_mae: 0.0205\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0504 - val_loss: 9.5562e-04 - val_mae: 0.0233\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0545 - val_loss: 9.1238e-04 - val_mae: 0.0200\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0556 - val_loss: 9.3847e-04 - val_mae: 0.0226\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0511 - val_loss: 9.0530e-04 - val_mae: 0.0203\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0494 - val_loss: 9.9028e-04 - val_mae: 0.0245\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0548 - val_loss: 9.8921e-04 - val_mae: 0.0245\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0071 - mae: 0.0502 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0514 - val_loss: 9.3781e-04 - val_mae: 0.0225\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0440 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0538 - val_loss: 9.0057e-04 - val_mae: 0.0197\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0489 - val_loss: 9.2577e-04 - val_mae: 0.0219\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0468 - val_loss: 9.6535e-04 - val_mae: 0.0237\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0423 - val_loss: 9.0804e-04 - val_mae: 0.0198\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0474 - val_loss: 9.0971e-04 - val_mae: 0.0207\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0540 - val_loss: 0.0020 - val_mae: 0.0416\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0503 - val_loss: 9.2014e-04 - val_mae: 0.0215\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0447 - val_loss: 9.1322e-04 - val_mae: 0.0200\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0404 - val_loss: 8.9964e-04 - val_mae: 0.0197\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0432 - val_loss: 9.4198e-04 - val_mae: 0.0227\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0475 - val_loss: 9.0140e-04 - val_mae: 0.0199\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0457 - val_loss: 9.0418e-04 - val_mae: 0.0197\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0440 - val_loss: 9.2557e-04 - val_mae: 0.0203\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0444 - val_loss: 9.0916e-04 - val_mae: 0.0207\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0419 - val_loss: 9.2682e-04 - val_mae: 0.0219\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0454 - val_loss: 8.9956e-04 - val_mae: 0.0197\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0378 - val_loss: 9.0531e-04 - val_mae: 0.0203\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0394 - val_loss: 9.0686e-04 - val_mae: 0.0205\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0423 - val_loss: 9.3464e-04 - val_mae: 0.0224\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0398 - val_loss: 9.0388e-04 - val_mae: 0.0202\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0413 - val_loss: 9.0506e-04 - val_mae: 0.0203\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0411 - val_loss: 9.3621e-04 - val_mae: 0.0224\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0432 - val_loss: 9.2644e-04 - val_mae: 0.0219\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0441 - val_loss: 9.5224e-04 - val_mae: 0.0232\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0395 - val_loss: 9.0156e-04 - val_mae: 0.0197\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0435 - val_loss: 0.0011 - val_mae: 0.0282\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0398 - val_loss: 8.9930e-04 - val_mae: 0.0197\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0374 - val_loss: 9.3017e-04 - val_mae: 0.0203\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0373 - val_loss: 9.0229e-04 - val_mae: 0.0200\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0375 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0362 - val_loss: 9.2970e-04 - val_mae: 0.0221\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0391 - val_loss: 9.1169e-04 - val_mae: 0.0209\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0363 - val_loss: 9.1111e-04 - val_mae: 0.0199\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0404 - val_loss: 9.0642e-04 - val_mae: 0.0204\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0058 - mae: 0.0413 - val_loss: 8.9979e-04 - val_mae: 0.0197\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0369 - val_loss: 9.0147e-04 - val_mae: 0.0199\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0370 - val_loss: 8.9981e-04 - val_mae: 0.0197\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0351 - val_loss: 9.2386e-04 - val_mae: 0.0218\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0370 - val_loss: 9.0854e-04 - val_mae: 0.0198\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0378 - val_loss: 9.1547e-04 - val_mae: 0.0200\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0385 - val_loss: 9.2847e-04 - val_mae: 0.0203\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0351 - val_loss: 0.0010 - val_mae: 0.0249\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0401 - val_loss: 9.0052e-04 - val_mae: 0.0197\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0342 - val_loss: 9.0443e-04 - val_mae: 0.0197\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0394 - val_loss: 9.1117e-04 - val_mae: 0.0199\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0329 - val_loss: 9.1247e-04 - val_mae: 0.0200\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0360 - val_loss: 9.0179e-04 - val_mae: 0.0197\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0328 - val_loss: 9.0819e-04 - val_mae: 0.0198\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0312 - val_loss: 8.9930e-04 - val_mae: 0.0197\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0341 - val_loss: 8.9997e-04 - val_mae: 0.0197\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0339 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0332 - val_loss: 9.0068e-04 - val_mae: 0.0198\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0339 - val_loss: 9.0392e-04 - val_mae: 0.0202\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0323 - val_loss: 9.0012e-04 - val_mae: 0.0197\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0349 - val_loss: 9.0551e-04 - val_mae: 0.0203\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0372 - val_loss: 9.0553e-04 - val_mae: 0.0203\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0318 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0341 - val_loss: 9.2993e-04 - val_mae: 0.0203\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0365 - val_loss: 9.1074e-04 - val_mae: 0.0199\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0340 - val_loss: 9.1691e-04 - val_mae: 0.0213\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0345 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0320 - val_loss: 9.0570e-04 - val_mae: 0.0203\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0343 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0352 - val_loss: 8.9985e-04 - val_mae: 0.0197\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0371 - val_loss: 9.0208e-04 - val_mae: 0.0197\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0292 - val_loss: 9.0233e-04 - val_mae: 0.0197\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0327 - val_loss: 8.9972e-04 - val_mae: 0.0197\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0321 - val_loss: 9.0354e-04 - val_mae: 0.0197\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0348 - val_loss: 9.0920e-04 - val_mae: 0.0199\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0331 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0300 - val_loss: 9.0396e-04 - val_mae: 0.0202\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0342 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0328 - val_loss: 9.0385e-04 - val_mae: 0.0197\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0316 - val_loss: 9.0282e-04 - val_mae: 0.0201\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0314 - val_loss: 9.0959e-04 - val_mae: 0.0207\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0335 - val_loss: 9.1044e-04 - val_mae: 0.0199\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0299 - val_loss: 9.0048e-04 - val_mae: 0.0198\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0330 - val_loss: 9.0052e-04 - val_mae: 0.0197\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0051 - mae: 0.0271 - val_loss: 9.0830e-04 - val_mae: 0.0198\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0343 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0049 - mae: 0.0316 - val_loss: 9.0137e-04 - val_mae: 0.0199\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0415 - val_loss: 0.0014 - val_mae: 0.0325\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0383 - val_loss: 9.3214e-04 - val_mae: 0.0222\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0308 - val_loss: 9.0184e-04 - val_mae: 0.0197\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0311 - val_loss: 9.0031e-04 - val_mae: 0.0197\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0301 - val_loss: 9.0972e-04 - val_mae: 0.0199\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0275 - val_loss: 9.1185e-04 - val_mae: 0.0209\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0318 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 8.9984e-04 - val_mae: 0.0197\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0294 - val_loss: 9.0925e-04 - val_mae: 0.0207\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0316 - val_loss: 8.9961e-04 - val_mae: 0.0197\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0292 - val_loss: 9.0020e-04 - val_mae: 0.0197\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0338 - val_loss: 9.0543e-04 - val_mae: 0.0203\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0038 - mae: 0.0273 - val_loss: 9.0152e-04 - val_mae: 0.0199\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0296 - val_loss: 9.0203e-04 - val_mae: 0.0200\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0288 - val_loss: 9.1948e-04 - val_mae: 0.0201\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0294 - val_loss: 9.0199e-04 - val_mae: 0.0197\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0305 - val_loss: 8.9976e-04 - val_mae: 0.0197\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0299 - val_loss: 8.9955e-04 - val_mae: 0.0197\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 8.9950e-04 - val_mae: 0.0197\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0292 - val_loss: 9.0056e-04 - val_mae: 0.0197\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0309 - val_loss: 9.0325e-04 - val_mae: 0.0197\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0304 - val_loss: 9.2170e-04 - val_mae: 0.0202\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 9.0092e-04 - val_mae: 0.0197\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0316 - val_loss: 9.0470e-04 - val_mae: 0.0197\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 9.0028e-04 - val_mae: 0.0197\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 8.9990e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0269 - val_loss: 9.0181e-04 - val_mae: 0.0200\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0291 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 9.0621e-04 - val_mae: 0.0198\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0289 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0287 - val_loss: 9.0171e-04 - val_mae: 0.0197\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 9.0060e-04 - val_mae: 0.0198\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0283 - val_loss: 8.9954e-04 - val_mae: 0.0197\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0041 - mae: 0.0285 - val_loss: 9.0688e-04 - val_mae: 0.0198\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 9.0553e-04 - val_mae: 0.0203\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0317 - val_loss: 9.1319e-04 - val_mae: 0.0210\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0295 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0308 - val_loss: 9.0057e-04 - val_mae: 0.0197\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0311 - val_loss: 9.0762e-04 - val_mae: 0.0198\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0380 - val_loss: 0.0013 - val_mae: 0.0318\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0332 - val_loss: 9.0463e-04 - val_mae: 0.0197\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0290 - val_loss: 9.1264e-04 - val_mae: 0.0200\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0284 - val_loss: 9.0368e-04 - val_mae: 0.0197\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0278 - val_loss: 8.9942e-04 - val_mae: 0.0197\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0285 - val_loss: 9.2090e-04 - val_mae: 0.0216\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0315 - val_loss: 9.2508e-04 - val_mae: 0.0218\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0286 - val_loss: 9.0260e-04 - val_mae: 0.0197\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0277 - val_loss: 9.0545e-04 - val_mae: 0.0197\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 9.0105e-04 - val_mae: 0.0197\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0270 - val_loss: 9.0846e-04 - val_mae: 0.0198\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.0163e-04 - val_mae: 0.0197\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0294 - val_loss: 8.9992e-04 - val_mae: 0.0197\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0286 - val_loss: 9.0095e-04 - val_mae: 0.0198\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0278 - val_loss: 9.0292e-04 - val_mae: 0.0197\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0278 - val_loss: 9.0008e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0284 - val_loss: 9.1588e-04 - val_mae: 0.0212\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0275 - val_loss: 9.0199e-04 - val_mae: 0.0200\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0266 - val_loss: 9.1829e-04 - val_mae: 0.0201\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0022e-04 - val_mae: 0.0198\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0298 - val_loss: 9.0353e-04 - val_mae: 0.0201\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 8.9986e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0277 - val_loss: 9.0769e-04 - val_mae: 0.0198\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0281 - val_loss: 9.0077e-04 - val_mae: 0.0197\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0298 - val_loss: 9.0417e-04 - val_mae: 0.0202\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 9.1428e-04 - val_mae: 0.0200\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0256 - val_loss: 9.0227e-04 - val_mae: 0.0197\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0281 - val_loss: 9.0614e-04 - val_mae: 0.0204\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 8.9964e-04 - val_mae: 0.0197\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0286 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 9.0859e-04 - val_mae: 0.0198\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.9994e-04 - val_mae: 0.0197\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0291 - val_loss: 9.0090e-04 - val_mae: 0.0198\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0282 - val_loss: 8.9950e-04 - val_mae: 0.0197\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0280 - val_loss: 8.9940e-04 - val_mae: 0.0197\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 9.0052e-04 - val_mae: 0.0197\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0378e-04 - val_mae: 0.0202\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 9.0139e-04 - val_mae: 0.0199\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0285 - val_loss: 9.0049e-04 - val_mae: 0.0198\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0297 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0285 - val_loss: 9.0041e-04 - val_mae: 0.0197\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.3926e-04 - val_mae: 0.0205\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0040 - mae: 0.0241 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0283 - val_loss: 9.0175e-04 - val_mae: 0.0199\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 9.0398e-04 - val_mae: 0.0197\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0284 - val_loss: 8.9937e-04 - val_mae: 0.0197\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 9.1513e-04 - val_mae: 0.0200\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 9.3530e-04 - val_mae: 0.0204\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0256 - val_loss: 9.2034e-04 - val_mae: 0.0202\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0255 - val_loss: 9.0325e-04 - val_mae: 0.0201\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 8.9981e-04 - val_mae: 0.0197\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.1267e-04 - val_mae: 0.0200\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.0092e-04 - val_mae: 0.0198\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0284 - val_loss: 9.1142e-04 - val_mae: 0.0209\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.0587e-04 - val_mae: 0.0198\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.0009e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0274 - val_loss: 9.0334e-04 - val_mae: 0.0197\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0248 - val_loss: 9.0205e-04 - val_mae: 0.0200\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0293 - val_loss: 9.0318e-04 - val_mae: 0.0201\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0294 - val_loss: 9.5383e-04 - val_mae: 0.0232\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0292 - val_loss: 9.0019e-04 - val_mae: 0.0198\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 8.9936e-04 - val_mae: 0.0197\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0166e-04 - val_mae: 0.0199\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 8.9936e-04 - val_mae: 0.0197\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 9.0884e-04 - val_mae: 0.0199\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 9.0011e-04 - val_mae: 0.0197\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.0771e-04 - val_mae: 0.0198\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0274 - val_loss: 8.9951e-04 - val_mae: 0.0197\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.0880e-04 - val_mae: 0.0199\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 9.0715e-04 - val_mae: 0.0198\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1423e-04 - val_mae: 0.0200\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 8.9992e-04 - val_mae: 0.0197\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0290 - val_loss: 9.0153e-04 - val_mae: 0.0199\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 8.9990e-04 - val_mae: 0.0197\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0241 - val_loss: 9.1817e-04 - val_mae: 0.0201\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 9.0524e-04 - val_mae: 0.0197\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 9.0445e-04 - val_mae: 0.0202\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0259 - val_loss: 9.0080e-04 - val_mae: 0.0197\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 9.1277e-04 - val_mae: 0.0200\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0007e-04 - val_mae: 0.0197\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 9.0682e-04 - val_mae: 0.0204\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.0117e-04 - val_mae: 0.0197\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.1429e-04 - val_mae: 0.0200\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0249 - val_loss: 8.9956e-04 - val_mae: 0.0197\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.1310e-04 - val_mae: 0.0200\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.9930e-04 - val_mae: 0.0197\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 9.0151e-04 - val_mae: 0.0199\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 9.1809e-04 - val_mae: 0.0201\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0244 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 9.0288e-04 - val_mae: 0.0201\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0245 - val_loss: 8.9993e-04 - val_mae: 0.0197\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0267 - val_loss: 9.0431e-04 - val_mae: 0.0197\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0261 - val_loss: 9.0473e-04 - val_mae: 0.0197\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 9.0375e-04 - val_mae: 0.0202\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0278 - val_loss: 9.0598e-04 - val_mae: 0.0204\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 9.0578e-04 - val_mae: 0.0197\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0239 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0239 - val_loss: 8.9945e-04 - val_mae: 0.0197\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0267 - val_loss: 8.9939e-04 - val_mae: 0.0197\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.0449e-04 - val_mae: 0.0197\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 8.9933e-04 - val_mae: 0.0197\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 9.1212e-04 - val_mae: 0.0200\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.0629e-04 - val_mae: 0.0198\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.1600e-04 - val_mae: 0.0201\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 9.0531e-04 - val_mae: 0.0203\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0267 - val_loss: 9.0304e-04 - val_mae: 0.0197\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0243 - val_loss: 9.0722e-04 - val_mae: 0.0198\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0265 - val_loss: 8.9946e-04 - val_mae: 0.0197\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.0756e-04 - val_mae: 0.0198\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0252 - val_loss: 9.0611e-04 - val_mae: 0.0198\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0256 - val_loss: 9.0390e-04 - val_mae: 0.0197\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0251 - val_loss: 9.0434e-04 - val_mae: 0.0197\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0245 - val_loss: 9.0897e-04 - val_mae: 0.0199\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 8.9966e-04 - val_mae: 0.0197\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 9.0069e-04 - val_mae: 0.0197\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 9.0153e-04 - val_mae: 0.0197\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.2154e-04 - val_mae: 0.0202\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0040 - mae: 0.0239 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0368 - val_loss: 0.0012 - val_mae: 0.0287\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0317 - val_loss: 8.9993e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 9.1407e-04 - val_mae: 0.0200\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 8.9943e-04 - val_mae: 0.0197\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 8.9984e-04 - val_mae: 0.0197\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0175e-04 - val_mae: 0.0197\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 9.0001e-04 - val_mae: 0.0197\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.9945e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0692e-04 - val_mae: 0.0198\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0245 - val_loss: 8.9982e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.9981e-04 - val_mae: 0.0197\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0518e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "3/3 [==============================] - 0s 5ms/step\n",
            "Model: \"sequential_32\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_384 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_352 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_385 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_353 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_386 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dropout_354 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_387 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_355 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_388 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_356 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_389 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_357 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_390 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_358 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_391 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_359 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_392 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_360 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_393 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_361 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_394 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_362 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_395 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 0.1181 - mae: 0.2730 - val_loss: 0.0073 - val_mae: 0.0801\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1471 - mae: 0.3158 - val_loss: 0.0176 - val_mae: 0.1291\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1330 - mae: 0.2947 - val_loss: 0.0013 - val_mae: 0.0312\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0912 - mae: 0.2348 - val_loss: 9.1825e-04 - val_mae: 0.0214\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0869 - mae: 0.2355 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.2081 - val_loss: 0.0014 - val_mae: 0.0321\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0742 - mae: 0.2223 - val_loss: 9.0003e-04 - val_mae: 0.0197\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0570 - mae: 0.1839 - val_loss: 0.0010 - val_mae: 0.0259\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0582 - mae: 0.1951 - val_loss: 9.4028e-04 - val_mae: 0.0226\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0720 - mae: 0.2074 - val_loss: 0.0013 - val_mae: 0.0272\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0562 - mae: 0.1926 - val_loss: 0.0028 - val_mae: 0.0499\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0659 - mae: 0.2099 - val_loss: 0.0147 - val_mae: 0.1173\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0558 - mae: 0.1862 - val_loss: 0.0029 - val_mae: 0.0512\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0445 - mae: 0.1686 - val_loss: 0.0016 - val_mae: 0.0306\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0348 - mae: 0.1378 - val_loss: 0.0012 - val_mae: 0.0284\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0375 - mae: 0.1539 - val_loss: 8.9956e-04 - val_mae: 0.0197\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0378 - mae: 0.1437 - val_loss: 0.0017 - val_mae: 0.0373\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0274 - mae: 0.1318 - val_loss: 0.0016 - val_mae: 0.0368\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0272 - mae: 0.1205 - val_loss: 0.0014 - val_mae: 0.0286\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0327 - mae: 0.1423 - val_loss: 8.9939e-04 - val_mae: 0.0197\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0205 - mae: 0.1128 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0220 - mae: 0.1120 - val_loss: 9.6096e-04 - val_mae: 0.0235\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0257 - mae: 0.1250 - val_loss: 0.0017 - val_mae: 0.0380\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1186 - val_loss: 9.1603e-04 - val_mae: 0.0213\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0213 - mae: 0.1136 - val_loss: 9.0644e-04 - val_mae: 0.0204\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0189 - mae: 0.1108 - val_loss: 9.3600e-04 - val_mae: 0.0204\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0167 - mae: 0.1004 - val_loss: 9.0149e-04 - val_mae: 0.0199\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0229 - mae: 0.1091 - val_loss: 0.0013 - val_mae: 0.0312\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0197 - mae: 0.1001 - val_loss: 9.0625e-04 - val_mae: 0.0198\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0856 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0200 - mae: 0.1080 - val_loss: 8.9960e-04 - val_mae: 0.0197\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0163 - mae: 0.1020 - val_loss: 9.3500e-04 - val_mae: 0.0224\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0112 - mae: 0.0775 - val_loss: 9.2675e-04 - val_mae: 0.0219\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0178 - mae: 0.0956 - val_loss: 0.0013 - val_mae: 0.0272\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0746 - val_loss: 9.5607e-04 - val_mae: 0.0233\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - mae: 0.0912 - val_loss: 9.6086e-04 - val_mae: 0.0235\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0124 - mae: 0.0834 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0107 - mae: 0.0728 - val_loss: 0.0014 - val_mae: 0.0287\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0838 - val_loss: 9.2539e-04 - val_mae: 0.0219\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0689 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0109 - mae: 0.0654 - val_loss: 0.0013 - val_mae: 0.0311\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0102 - mae: 0.0715 - val_loss: 9.0229e-04 - val_mae: 0.0200\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0717 - val_loss: 9.1560e-04 - val_mae: 0.0212\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0693 - val_loss: 9.0026e-04 - val_mae: 0.0197\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0722 - val_loss: 9.5931e-04 - val_mae: 0.0208\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0094 - mae: 0.0680 - val_loss: 9.0875e-04 - val_mae: 0.0199\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0687 - val_loss: 0.0013 - val_mae: 0.0260\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0104 - mae: 0.0668 - val_loss: 9.0876e-04 - val_mae: 0.0199\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0076 - mae: 0.0602 - val_loss: 9.9414e-04 - val_mae: 0.0246\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0097 - mae: 0.0715 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0715 - val_loss: 9.0125e-04 - val_mae: 0.0197\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0098 - mae: 0.0615 - val_loss: 9.1796e-04 - val_mae: 0.0214\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0566 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0616 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0583 - val_loss: 9.6314e-04 - val_mae: 0.0208\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0566 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0263\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0541 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0460 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0530 - val_loss: 8.9945e-04 - val_mae: 0.0197\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 9.2823e-04 - val_mae: 0.0220\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0521 - val_loss: 9.3094e-04 - val_mae: 0.0222\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0507 - val_loss: 9.4500e-04 - val_mae: 0.0206\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0501 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0536 - val_loss: 9.1509e-04 - val_mae: 0.0212\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0514 - val_loss: 9.5083e-04 - val_mae: 0.0231\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0482 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0450 - val_loss: 8.9979e-04 - val_mae: 0.0197\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0068 - mae: 0.0477 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0467 - val_loss: 9.1945e-04 - val_mae: 0.0201\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0491 - val_loss: 9.4383e-04 - val_mae: 0.0206\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0403 - val_loss: 9.1721e-04 - val_mae: 0.0213\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0491 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - mae: 0.0446 - val_loss: 9.2947e-04 - val_mae: 0.0203\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0469 - val_loss: 0.0010 - val_mae: 0.0257\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0483 - val_loss: 9.6489e-04 - val_mae: 0.0209\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0442 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0467 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0476 - val_loss: 8.9955e-04 - val_mae: 0.0197\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0438 - val_loss: 9.0332e-04 - val_mae: 0.0201\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0375 - val_loss: 9.3539e-04 - val_mae: 0.0204\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0416 - val_loss: 8.9970e-04 - val_mae: 0.0197\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0404 - val_loss: 9.0991e-04 - val_mae: 0.0208\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0440 - val_loss: 9.2531e-04 - val_mae: 0.0203\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0424 - val_loss: 8.9965e-04 - val_mae: 0.0197\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0376 - val_loss: 9.2402e-04 - val_mae: 0.0218\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0432 - val_loss: 9.5702e-04 - val_mae: 0.0208\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0409 - val_loss: 9.0224e-04 - val_mae: 0.0200\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0400 - val_loss: 9.0079e-04 - val_mae: 0.0197\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0431 - val_loss: 9.0070e-04 - val_mae: 0.0197\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0440 - val_loss: 9.0375e-04 - val_mae: 0.0197\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0407 - val_loss: 9.3025e-04 - val_mae: 0.0203\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0377 - val_loss: 9.1593e-04 - val_mae: 0.0201\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0389 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0390 - val_loss: 9.1533e-04 - val_mae: 0.0200\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0375 - val_loss: 9.0241e-04 - val_mae: 0.0197\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0386 - val_loss: 8.9959e-04 - val_mae: 0.0197\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0382 - val_loss: 9.3732e-04 - val_mae: 0.0225\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0413 - val_loss: 9.3047e-04 - val_mae: 0.0204\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0392 - val_loss: 9.1670e-04 - val_mae: 0.0213\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0351 - val_loss: 8.9948e-04 - val_mae: 0.0197\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0368 - val_loss: 9.1066e-04 - val_mae: 0.0208\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0414 - val_loss: 9.2717e-04 - val_mae: 0.0220\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0379 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0307 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0383 - val_loss: 9.0317e-04 - val_mae: 0.0197\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0329 - val_loss: 9.0926e-04 - val_mae: 0.0199\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0352 - val_loss: 9.4335e-04 - val_mae: 0.0206\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0333 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0362 - val_loss: 9.0298e-04 - val_mae: 0.0201\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0346 - val_loss: 8.9934e-04 - val_mae: 0.0197\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0344 - val_loss: 9.6586e-04 - val_mae: 0.0209\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0057 - mae: 0.0340 - val_loss: 9.3584e-04 - val_mae: 0.0204\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0295 - val_loss: 9.3071e-04 - val_mae: 0.0204\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0346 - val_loss: 9.1956e-04 - val_mae: 0.0201\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0340 - val_loss: 9.1385e-04 - val_mae: 0.0200\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0339 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 9.0320e-04 - val_mae: 0.0197\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0343 - val_loss: 9.0280e-04 - val_mae: 0.0197\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0374 - val_loss: 9.0668e-04 - val_mae: 0.0204\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0356 - val_loss: 9.8999e-04 - val_mae: 0.0211\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0315 - val_loss: 9.3845e-04 - val_mae: 0.0205\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0352 - val_loss: 9.0076e-04 - val_mae: 0.0197\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0325 - val_loss: 9.0022e-04 - val_mae: 0.0198\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0317 - val_loss: 9.0074e-04 - val_mae: 0.0197\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0341 - val_loss: 9.4653e-04 - val_mae: 0.0206\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0272\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0358 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 9.1359e-04 - val_mae: 0.0200\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0329 - val_loss: 9.0543e-04 - val_mae: 0.0203\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0345 - val_loss: 9.0300e-04 - val_mae: 0.0197\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0302 - val_loss: 9.9783e-04 - val_mae: 0.0212\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0286 - val_loss: 9.0604e-04 - val_mae: 0.0198\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0328 - val_loss: 9.0053e-04 - val_mae: 0.0198\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0332 - val_loss: 9.0673e-04 - val_mae: 0.0198\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0407 - val_loss: 0.0011 - val_mae: 0.0276\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0382 - val_loss: 9.2324e-04 - val_mae: 0.0217\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0329 - val_loss: 9.1499e-04 - val_mae: 0.0200\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0303 - val_loss: 9.0541e-04 - val_mae: 0.0197\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0417 - val_loss: 0.0012 - val_mae: 0.0289\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0337 - val_loss: 9.0556e-04 - val_mae: 0.0203\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0310 - val_loss: 9.0146e-04 - val_mae: 0.0197\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0299 - val_loss: 9.0215e-04 - val_mae: 0.0197\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0307 - val_loss: 9.1381e-04 - val_mae: 0.0200\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0322 - val_loss: 8.9977e-04 - val_mae: 0.0197\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.1347e-04 - val_mae: 0.0200\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0314 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.0042e-04 - val_mae: 0.0197\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0292 - val_loss: 9.1863e-04 - val_mae: 0.0201\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0282 - val_loss: 9.0727e-04 - val_mae: 0.0198\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0297 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0299 - val_loss: 9.4409e-04 - val_mae: 0.0206\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0299 - val_loss: 9.1113e-04 - val_mae: 0.0199\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0312 - val_loss: 8.9990e-04 - val_mae: 0.0197\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0294 - val_loss: 9.2975e-04 - val_mae: 0.0203\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0300 - val_loss: 9.0425e-04 - val_mae: 0.0197\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0313 - val_loss: 9.0004e-04 - val_mae: 0.0197\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0317 - val_loss: 9.0045e-04 - val_mae: 0.0197\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 9.2695e-04 - val_mae: 0.0203\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0275 - val_loss: 9.0382e-04 - val_mae: 0.0197\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0297 - val_loss: 9.1288e-04 - val_mae: 0.0200\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0285 - val_loss: 9.8463e-04 - val_mae: 0.0211\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0277 - val_loss: 9.0350e-04 - val_mae: 0.0201\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0283 - val_loss: 9.1411e-04 - val_mae: 0.0200\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0286 - val_loss: 9.3116e-04 - val_mae: 0.0222\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0323 - val_loss: 9.0207e-04 - val_mae: 0.0200\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0304 - val_loss: 9.1678e-04 - val_mae: 0.0201\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0260 - val_loss: 9.0589e-04 - val_mae: 0.0198\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 9.0061e-04 - val_mae: 0.0197\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0288 - val_loss: 9.1066e-04 - val_mae: 0.0208\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0303 - val_loss: 9.0101e-04 - val_mae: 0.0198\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0040 - mae: 0.0275 - val_loss: 9.3240e-04 - val_mae: 0.0204\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 9.0180e-04 - val_mae: 0.0197\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0316 - val_loss: 9.0423e-04 - val_mae: 0.0197\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0279 - val_loss: 9.3561e-04 - val_mae: 0.0204\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0047 - mae: 0.0285 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0299 - val_loss: 9.0242e-04 - val_mae: 0.0200\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 9.2529e-04 - val_mae: 0.0203\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 9.0064e-04 - val_mae: 0.0198\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0287 - val_loss: 9.0070e-04 - val_mae: 0.0198\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0281 - val_loss: 9.0213e-04 - val_mae: 0.0197\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0184e-04 - val_mae: 0.0197\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0327 - val_loss: 0.0011 - val_mae: 0.0275\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0339 - val_loss: 9.0012e-04 - val_mae: 0.0197\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0270 - val_loss: 9.0238e-04 - val_mae: 0.0197\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0273 - val_loss: 9.1236e-04 - val_mae: 0.0200\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0285 - val_loss: 9.0077e-04 - val_mae: 0.0197\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 8.9964e-04 - val_mae: 0.0197\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0273 - val_loss: 8.9955e-04 - val_mae: 0.0197\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0259 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0269 - val_loss: 9.0007e-04 - val_mae: 0.0197\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0268 - val_loss: 8.9944e-04 - val_mae: 0.0197\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0288 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0295 - val_loss: 9.1885e-04 - val_mae: 0.0215\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0287 - val_loss: 9.2923e-04 - val_mae: 0.0203\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.0010e-04 - val_mae: 0.0197\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0289 - val_loss: 9.2760e-04 - val_mae: 0.0203\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0276 - val_loss: 9.1622e-04 - val_mae: 0.0201\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0283 - val_loss: 9.0225e-04 - val_mae: 0.0200\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 9.0180e-04 - val_mae: 0.0199\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0282 - val_loss: 9.0846e-04 - val_mae: 0.0198\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0283 - val_loss: 9.0250e-04 - val_mae: 0.0197\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 9.1095e-04 - val_mae: 0.0199\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0273 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0246 - val_loss: 9.0112e-04 - val_mae: 0.0197\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0265 - val_loss: 8.9942e-04 - val_mae: 0.0197\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 8.9974e-04 - val_mae: 0.0197\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0270 - val_loss: 9.2171e-04 - val_mae: 0.0202\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0276 - val_loss: 9.0587e-04 - val_mae: 0.0198\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.2220e-04 - val_mae: 0.0202\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 9.0277e-04 - val_mae: 0.0197\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 9.0345e-04 - val_mae: 0.0197\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 9.0047e-04 - val_mae: 0.0197\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0297 - val_loss: 9.1991e-04 - val_mae: 0.0215\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 9.0795e-04 - val_mae: 0.0198\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0288 - val_loss: 9.0298e-04 - val_mae: 0.0197\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0841e-04 - val_mae: 0.0198\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0294 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0274 - val_loss: 9.2169e-04 - val_mae: 0.0202\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.2671e-04 - val_mae: 0.0203\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0274 - val_loss: 9.0001e-04 - val_mae: 0.0197\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0283 - val_loss: 9.0547e-04 - val_mae: 0.0197\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0274 - val_loss: 9.0034e-04 - val_mae: 0.0198\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.0104e-04 - val_mae: 0.0198\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0276 - val_loss: 9.1201e-04 - val_mae: 0.0200\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.0203e-04 - val_mae: 0.0197\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.0839e-04 - val_mae: 0.0206\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0255 - val_loss: 9.0391e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 8.9946e-04 - val_mae: 0.0197\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0274 - val_loss: 8.9954e-04 - val_mae: 0.0197\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0289 - val_loss: 9.0031e-04 - val_mae: 0.0197\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0248 - val_loss: 9.1168e-04 - val_mae: 0.0199\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 9.1136e-04 - val_mae: 0.0199\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0242 - val_loss: 9.0090e-04 - val_mae: 0.0197\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0281 - val_loss: 8.9974e-04 - val_mae: 0.0197\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0278 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0255 - val_loss: 9.0880e-04 - val_mae: 0.0199\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0236 - val_loss: 9.0055e-04 - val_mae: 0.0197\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0254 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 8.9982e-04 - val_mae: 0.0197\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0251 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0259 - val_loss: 9.0318e-04 - val_mae: 0.0197\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 9.3829e-04 - val_mae: 0.0205\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0263 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 9.0103e-04 - val_mae: 0.0197\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0277 - val_loss: 9.0231e-04 - val_mae: 0.0200\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 9.1127e-04 - val_mae: 0.0199\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 8.9943e-04 - val_mae: 0.0197\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0501e-04 - val_mae: 0.0197\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0277 - val_loss: 9.0262e-04 - val_mae: 0.0200\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 8.9973e-04 - val_mae: 0.0197\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 9.0017e-04 - val_mae: 0.0197\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 9.1907e-04 - val_mae: 0.0201\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0237 - val_loss: 9.0494e-04 - val_mae: 0.0197\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 9.1293e-04 - val_mae: 0.0210\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 9.0229e-04 - val_mae: 0.0197\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.0082e-04 - val_mae: 0.0197\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 9.1153e-04 - val_mae: 0.0199\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0237 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0265 - val_loss: 9.0301e-04 - val_mae: 0.0201\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0192e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.1203e-04 - val_mae: 0.0200\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0234 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.0691e-04 - val_mae: 0.0198\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0259 - val_loss: 9.0192e-04 - val_mae: 0.0200\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0261 - val_loss: 9.0295e-04 - val_mae: 0.0197\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0253 - val_loss: 9.0534e-04 - val_mae: 0.0197\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.0936e-04 - val_mae: 0.0199\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1862e-04 - val_mae: 0.0201\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.1261e-04 - val_mae: 0.0200\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 9.0653e-04 - val_mae: 0.0204\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.1509e-04 - val_mae: 0.0200\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0267 - val_loss: 9.0085e-04 - val_mae: 0.0197\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.0437e-04 - val_mae: 0.0197\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0259 - val_loss: 9.0079e-04 - val_mae: 0.0197\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0423e-04 - val_mae: 0.0197\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0239 - val_loss: 9.1240e-04 - val_mae: 0.0200\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0053e-04 - val_mae: 0.0197\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.0410e-04 - val_mae: 0.0197\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.0989e-04 - val_mae: 0.0199\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 9.0149e-04 - val_mae: 0.0199\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0042 - mae: 0.0260 - val_loss: 8.9973e-04 - val_mae: 0.0197\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0444e-04 - val_mae: 0.0197\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0241 - val_loss: 9.1212e-04 - val_mae: 0.0200\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0282 - val_loss: 9.7975e-04 - val_mae: 0.0242\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0341 - val_loss: 9.8575e-04 - val_mae: 0.0244\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 8.9939e-04 - val_mae: 0.0197\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0530e-04 - val_mae: 0.0197\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0041 - mae: 0.0248 - val_loss: 9.0011e-04 - val_mae: 0.0197\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.0323e-04 - val_mae: 0.0197\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 9.0583e-04 - val_mae: 0.0197\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.0239e-04 - val_mae: 0.0200\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0287 - val_loss: 9.4510e-04 - val_mae: 0.0229\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0287 - val_loss: 9.0932e-04 - val_mae: 0.0207\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.0461e-04 - val_mae: 0.0197\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.1234e-04 - val_mae: 0.0200\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0245 - val_loss: 9.0167e-04 - val_mae: 0.0199\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0254 - val_loss: 9.0103e-04 - val_mae: 0.0197\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 8.9957e-04 - val_mae: 0.0197\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 8.9954e-04 - val_mae: 0.0197\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0047 - mae: 0.0329 - val_loss: 0.0011 - val_mae: 0.0278\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0339 - val_loss: 9.0935e-04 - val_mae: 0.0207\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0254 - val_loss: 9.0061e-04 - val_mae: 0.0197\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0248 - val_loss: 9.1878e-04 - val_mae: 0.0201\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0256 - val_loss: 9.0174e-04 - val_mae: 0.0197\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0230 - val_loss: 9.0170e-04 - val_mae: 0.0197\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0256 - val_loss: 9.0780e-04 - val_mae: 0.0198\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0236 - val_loss: 9.0029e-04 - val_mae: 0.0197\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0670e-04 - val_mae: 0.0198\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0237 - val_loss: 9.0646e-04 - val_mae: 0.0198\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1257e-04 - val_mae: 0.0200\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.9978e-04 - val_mae: 0.0197\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0233 - val_loss: 8.9962e-04 - val_mae: 0.0197\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0275 - val_loss: 9.0070e-04 - val_mae: 0.0198\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 9.1199e-04 - val_mae: 0.0199\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 8.9951e-04 - val_mae: 0.0197\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0266 - val_loss: 9.0231e-04 - val_mae: 0.0197\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0224 - val_loss: 9.2982e-04 - val_mae: 0.0203\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0208e-04 - val_mae: 0.0200\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0246 - val_loss: 9.0187e-04 - val_mae: 0.0197\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0242 - val_loss: 8.9939e-04 - val_mae: 0.0197\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0264 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0236 - val_loss: 9.0723e-04 - val_mae: 0.0198\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.0881e-04 - val_mae: 0.0199\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0909e-04 - val_mae: 0.0199\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0253 - val_loss: 9.0090e-04 - val_mae: 0.0198\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 9.0505e-04 - val_mae: 0.0197\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0257 - val_loss: 9.0073e-04 - val_mae: 0.0198\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 8.9930e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 8.9954e-04 - val_mae: 0.0197\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0230 - val_loss: 9.1968e-04 - val_mae: 0.0201\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0243 - val_loss: 9.0133e-04 - val_mae: 0.0197\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0269 - val_loss: 9.0293e-04 - val_mae: 0.0201\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0260 - val_loss: 9.1102e-04 - val_mae: 0.0199\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0243 - val_loss: 9.0069e-04 - val_mae: 0.0198\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0271 - val_loss: 9.0806e-04 - val_mae: 0.0206\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0260 - val_loss: 9.0676e-04 - val_mae: 0.0198\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 9.0188e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0237 - val_loss: 8.9929e-04 - val_mae: 0.0197\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0257 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0237 - val_loss: 9.1655e-04 - val_mae: 0.0201\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0257 - val_loss: 8.9955e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 8.9979e-04 - val_mae: 0.0197\n",
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_33\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_396 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_363 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_397 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_364 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_398 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_365 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_399 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_366 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_400 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_367 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_401 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_368 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_402 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_369 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_403 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_370 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_404 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_371 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_405 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_372 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_406 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_373 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_407 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 17ms/step - loss: 0.4419 - mae: 0.5378 - val_loss: 0.0032 - val_mae: 0.0536\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2009 - mae: 0.3758 - val_loss: 0.0109 - val_mae: 0.0999\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1546 - mae: 0.3154 - val_loss: 0.0101 - val_mae: 0.0957\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1399 - mae: 0.2974 - val_loss: 9.5017e-04 - val_mae: 0.0231\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1701 - mae: 0.3230 - val_loss: 0.0011 - val_mae: 0.0271\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1427 - mae: 0.3015 - val_loss: 0.0016 - val_mae: 0.0360\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1255 - mae: 0.2730 - val_loss: 0.0016 - val_mae: 0.0363\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1049 - mae: 0.2582 - val_loss: 0.0018 - val_mae: 0.0330\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0939 - mae: 0.2522 - val_loss: 8.9973e-04 - val_mae: 0.0197\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1095 - mae: 0.2599 - val_loss: 8.9934e-04 - val_mae: 0.0197\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 4ms/step - loss: 0.1258 - mae: 0.2822 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0777 - mae: 0.2244 - val_loss: 0.0013 - val_mae: 0.0313\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0670 - mae: 0.2057 - val_loss: 0.0011 - val_mae: 0.0268\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0820 - mae: 0.2235 - val_loss: 9.4375e-04 - val_mae: 0.0206\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0960 - mae: 0.2470 - val_loss: 9.0441e-04 - val_mae: 0.0202\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0590 - mae: 0.1976 - val_loss: 9.2402e-04 - val_mae: 0.0202\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0452 - mae: 0.1721 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0508 - mae: 0.1842 - val_loss: 0.0011 - val_mae: 0.0262\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0764 - mae: 0.2126 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0529 - mae: 0.1746 - val_loss: 8.9950e-04 - val_mae: 0.0197\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0407 - mae: 0.1504 - val_loss: 0.0011 - val_mae: 0.0265\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0554 - mae: 0.1873 - val_loss: 0.0012 - val_mae: 0.0289\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0412 - mae: 0.1642 - val_loss: 0.0013 - val_mae: 0.0301\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0442 - mae: 0.1586 - val_loss: 0.0011 - val_mae: 0.0281\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0373 - mae: 0.1559 - val_loss: 0.0029 - val_mae: 0.0447\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0295 - mae: 0.1310 - val_loss: 0.0012 - val_mae: 0.0289\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0303 - mae: 0.1425 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0300 - mae: 0.1415 - val_loss: 9.1539e-04 - val_mae: 0.0212\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0262 - mae: 0.1265 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0317 - mae: 0.1270 - val_loss: 0.0010 - val_mae: 0.0252\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0260 - mae: 0.1255 - val_loss: 0.0011 - val_mae: 0.0270\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0274 - mae: 0.1209 - val_loss: 8.9941e-04 - val_mae: 0.0197\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0996 - val_loss: 0.0014 - val_mae: 0.0324\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0211 - mae: 0.1105 - val_loss: 0.0023 - val_mae: 0.0382\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0227 - mae: 0.1184 - val_loss: 0.0023 - val_mae: 0.0452\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0265 - mae: 0.1219 - val_loss: 9.9696e-04 - val_mae: 0.0247\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0166 - mae: 0.1012 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0195 - mae: 0.1054 - val_loss: 0.0012 - val_mae: 0.0292\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0184 - mae: 0.1022 - val_loss: 9.2858e-04 - val_mae: 0.0220\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0181 - mae: 0.1052 - val_loss: 0.0016 - val_mae: 0.0369\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0199 - mae: 0.1081 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0208 - mae: 0.1088 - val_loss: 9.7556e-04 - val_mae: 0.0240\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0177 - mae: 0.0980 - val_loss: 0.0015 - val_mae: 0.0352\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0122 - mae: 0.0840 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0158 - mae: 0.0902 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0837 - val_loss: 9.0004e-04 - val_mae: 0.0197\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0130 - mae: 0.0830 - val_loss: 0.0010 - val_mae: 0.0260\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0154 - mae: 0.0878 - val_loss: 0.0011 - val_mae: 0.0272\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0125 - mae: 0.0861 - val_loss: 0.0013 - val_mae: 0.0301\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0800 - val_loss: 9.0456e-04 - val_mae: 0.0197\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0138 - mae: 0.0789 - val_loss: 9.5349e-04 - val_mae: 0.0232\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0712 - val_loss: 0.0012 - val_mae: 0.0295\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - mae: 0.0830 - val_loss: 9.3939e-04 - val_mae: 0.0205\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0753 - val_loss: 9.0827e-04 - val_mae: 0.0198\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0108 - mae: 0.0727 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0758 - val_loss: 9.2752e-04 - val_mae: 0.0203\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0681 - val_loss: 0.0010 - val_mae: 0.0259\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0099 - mae: 0.0679 - val_loss: 8.9936e-04 - val_mae: 0.0197\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0773 - val_loss: 9.7351e-04 - val_mae: 0.0240\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0611 - val_loss: 9.0358e-04 - val_mae: 0.0197\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0693 - val_loss: 9.2322e-04 - val_mae: 0.0217\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0715 - val_loss: 0.0013 - val_mae: 0.0311\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0664 - val_loss: 9.3158e-04 - val_mae: 0.0222\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0651 - val_loss: 9.0153e-04 - val_mae: 0.0199\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0554 - val_loss: 9.0070e-04 - val_mae: 0.0198\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0092 - mae: 0.0660 - val_loss: 9.5557e-04 - val_mae: 0.0233\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0596 - val_loss: 9.0361e-04 - val_mae: 0.0197\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0523 - val_loss: 9.3658e-04 - val_mae: 0.0205\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0608 - val_loss: 9.4118e-04 - val_mae: 0.0227\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0083 - mae: 0.0601 - val_loss: 0.0010 - val_mae: 0.0257\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0559 - val_loss: 9.1597e-04 - val_mae: 0.0213\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0069 - mae: 0.0560 - val_loss: 9.0116e-04 - val_mae: 0.0197\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0580 - val_loss: 8.9973e-04 - val_mae: 0.0197\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0487 - val_loss: 9.7841e-04 - val_mae: 0.0241\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0074 - mae: 0.0590 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0545 - val_loss: 9.8916e-04 - val_mae: 0.0211\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0527 - val_loss: 0.0011 - val_mae: 0.0279\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0602 - val_loss: 9.3203e-04 - val_mae: 0.0222\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0601 - val_loss: 0.0014 - val_mae: 0.0326\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0088 - mae: 0.0559 - val_loss: 9.0744e-04 - val_mae: 0.0205\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0477 - val_loss: 9.0218e-04 - val_mae: 0.0197\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0554 - val_loss: 9.2028e-04 - val_mae: 0.0215\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0568 - val_loss: 9.7699e-04 - val_mae: 0.0241\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0085 - mae: 0.0556 - val_loss: 9.0762e-04 - val_mae: 0.0205\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0490 - val_loss: 9.0073e-04 - val_mae: 0.0198\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0527 - val_loss: 9.0362e-04 - val_mae: 0.0201\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0063 - mae: 0.0534 - val_loss: 9.2461e-04 - val_mae: 0.0218\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0436 - val_loss: 9.0626e-04 - val_mae: 0.0204\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0460 - val_loss: 9.0158e-04 - val_mae: 0.0197\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0483 - val_loss: 8.9971e-04 - val_mae: 0.0197\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0067 - mae: 0.0502 - val_loss: 9.2225e-04 - val_mae: 0.0217\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0069 - mae: 0.0531 - val_loss: 9.0385e-04 - val_mae: 0.0202\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0504 - val_loss: 9.0663e-04 - val_mae: 0.0198\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0406 - val_loss: 8.9958e-04 - val_mae: 0.0197\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0424 - val_loss: 9.1895e-04 - val_mae: 0.0215\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0542 - val_loss: 9.0670e-04 - val_mae: 0.0204\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0417 - val_loss: 9.2121e-04 - val_mae: 0.0202\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0457 - val_loss: 8.9945e-04 - val_mae: 0.0197\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0400 - val_loss: 9.7608e-04 - val_mae: 0.0241\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0477 - val_loss: 9.0125e-04 - val_mae: 0.0197\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0369 - val_loss: 9.2067e-04 - val_mae: 0.0202\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0449 - val_loss: 9.0096e-04 - val_mae: 0.0198\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0055 - mae: 0.0429 - val_loss: 9.0047e-04 - val_mae: 0.0198\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0439 - val_loss: 9.0075e-04 - val_mae: 0.0197\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0409 - val_loss: 9.4211e-04 - val_mae: 0.0205\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0423 - val_loss: 9.0147e-04 - val_mae: 0.0199\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0433 - val_loss: 8.9975e-04 - val_mae: 0.0197\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0059 - mae: 0.0413 - val_loss: 9.7180e-04 - val_mae: 0.0239\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0404 - val_loss: 9.1805e-04 - val_mae: 0.0214\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0400 - val_loss: 9.4866e-04 - val_mae: 0.0206\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0396 - val_loss: 9.3378e-04 - val_mae: 0.0204\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0345 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0054 - mae: 0.0382 - val_loss: 9.0119e-04 - val_mae: 0.0197\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0402 - val_loss: 9.9191e-04 - val_mae: 0.0246\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0391 - val_loss: 9.0069e-04 - val_mae: 0.0197\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0397 - val_loss: 9.7135e-04 - val_mae: 0.0209\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0406 - val_loss: 9.0072e-04 - val_mae: 0.0198\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0440 - val_loss: 9.1128e-04 - val_mae: 0.0209\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0401 - val_loss: 9.2069e-04 - val_mae: 0.0216\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0393 - val_loss: 9.1437e-04 - val_mae: 0.0200\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0386 - val_loss: 9.0439e-04 - val_mae: 0.0202\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0402 - val_loss: 9.0630e-04 - val_mae: 0.0204\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0387 - val_loss: 9.0606e-04 - val_mae: 0.0198\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0362 - val_loss: 9.0191e-04 - val_mae: 0.0200\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0364 - val_loss: 9.0250e-04 - val_mae: 0.0200\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0404 - val_loss: 9.0372e-04 - val_mae: 0.0202\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0386 - val_loss: 9.3463e-04 - val_mae: 0.0224\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0398 - val_loss: 9.0123e-04 - val_mae: 0.0199\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0393 - val_loss: 9.0500e-04 - val_mae: 0.0203\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0412 - val_loss: 9.2311e-04 - val_mae: 0.0217\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0375 - val_loss: 9.1460e-04 - val_mae: 0.0211\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0350 - val_loss: 8.9970e-04 - val_mae: 0.0197\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0362 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0328 - val_loss: 9.1056e-04 - val_mae: 0.0208\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0037 - mae: 0.0332 - val_loss: 9.0023e-04 - val_mae: 0.0198\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0363 - val_loss: 8.9959e-04 - val_mae: 0.0197\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0056 - mae: 0.0380 - val_loss: 9.0551e-04 - val_mae: 0.0203\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0339 - val_loss: 9.6634e-04 - val_mae: 0.0237\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0040 - mae: 0.0327 - val_loss: 9.0573e-04 - val_mae: 0.0197\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0382 - val_loss: 0.0010 - val_mae: 0.0251\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0367 - val_loss: 8.9977e-04 - val_mae: 0.0197\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0327 - val_loss: 9.0140e-04 - val_mae: 0.0197\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0357 - val_loss: 9.1243e-04 - val_mae: 0.0210\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0330 - val_loss: 9.0085e-04 - val_mae: 0.0198\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0345 - val_loss: 9.0357e-04 - val_mae: 0.0197\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0368 - val_loss: 9.1011e-04 - val_mae: 0.0208\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0321 - val_loss: 9.0466e-04 - val_mae: 0.0202\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0312 - val_loss: 9.0031e-04 - val_mae: 0.0197\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0298 - val_loss: 9.1418e-04 - val_mae: 0.0211\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0389 - val_loss: 9.1640e-04 - val_mae: 0.0213\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0352 - val_loss: 9.0011e-04 - val_mae: 0.0197\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0331 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0340 - val_loss: 9.0698e-04 - val_mae: 0.0205\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0362 - val_loss: 9.1326e-04 - val_mae: 0.0200\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0319 - val_loss: 9.0013e-04 - val_mae: 0.0197\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0318 - val_loss: 9.1609e-04 - val_mae: 0.0213\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0331 - val_loss: 9.0119e-04 - val_mae: 0.0199\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0334 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0352 - val_loss: 9.2453e-04 - val_mae: 0.0218\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0461 - val_loss: 0.0013 - val_mae: 0.0316\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0361 - val_loss: 9.1316e-04 - val_mae: 0.0200\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0334 - val_loss: 9.2392e-04 - val_mae: 0.0202\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0352 - val_loss: 9.0045e-04 - val_mae: 0.0197\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0325 - val_loss: 9.0865e-04 - val_mae: 0.0198\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0052 - mae: 0.0351 - val_loss: 0.0010 - val_mae: 0.0257\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0351 - val_loss: 8.9997e-04 - val_mae: 0.0197\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0319 - val_loss: 9.0891e-04 - val_mae: 0.0199\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0322 - val_loss: 8.9949e-04 - val_mae: 0.0197\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0324 - val_loss: 9.9124e-04 - val_mae: 0.0246\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0050 - mae: 0.0331 - val_loss: 9.0665e-04 - val_mae: 0.0204\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0324 - val_loss: 9.0022e-04 - val_mae: 0.0198\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0309 - val_loss: 8.9992e-04 - val_mae: 0.0197\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0336 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0341 - val_loss: 9.3388e-04 - val_mae: 0.0223\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0048 - mae: 0.0324 - val_loss: 9.0236e-04 - val_mae: 0.0197\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0043 - mae: 0.0305 - val_loss: 9.3155e-04 - val_mae: 0.0204\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0051 - mae: 0.0316 - val_loss: 9.0232e-04 - val_mae: 0.0200\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0296 - val_loss: 9.0147e-04 - val_mae: 0.0197\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0323 - val_loss: 8.9966e-04 - val_mae: 0.0197\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0322 - val_loss: 9.0009e-04 - val_mae: 0.0197\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0309 - val_loss: 9.0375e-04 - val_mae: 0.0202\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0316 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0300 - val_loss: 9.1612e-04 - val_mae: 0.0213\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0308 - val_loss: 8.9962e-04 - val_mae: 0.0197\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0270 - val_loss: 9.0084e-04 - val_mae: 0.0197\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0312 - val_loss: 9.0626e-04 - val_mae: 0.0198\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0039 - mae: 0.0249 - val_loss: 9.0012e-04 - val_mae: 0.0197\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.0026e-04 - val_mae: 0.0197\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0293 - val_loss: 9.0724e-04 - val_mae: 0.0198\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0301 - val_loss: 9.0372e-04 - val_mae: 0.0202\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0301 - val_loss: 8.9982e-04 - val_mae: 0.0197\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0301 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0048 - mae: 0.0279 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0335 - val_loss: 9.3034e-04 - val_mae: 0.0221\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0048 - mae: 0.0305 - val_loss: 9.0568e-04 - val_mae: 0.0203\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0303 - val_loss: 9.0148e-04 - val_mae: 0.0199\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0267 - val_loss: 8.9975e-04 - val_mae: 0.0197\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0305 - val_loss: 9.0122e-04 - val_mae: 0.0199\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0327 - val_loss: 8.9953e-04 - val_mae: 0.0197\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 9.0644e-04 - val_mae: 0.0198\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0318 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 9.1688e-04 - val_mae: 0.0201\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0286 - val_loss: 9.0029e-04 - val_mae: 0.0197\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0271 - val_loss: 9.1173e-04 - val_mae: 0.0199\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0290 - val_loss: 9.1081e-04 - val_mae: 0.0208\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 9.0110e-04 - val_mae: 0.0199\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0331 - val_loss: 8.9948e-04 - val_mae: 0.0197\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0280 - val_loss: 9.0132e-04 - val_mae: 0.0197\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0301 - val_loss: 9.0871e-04 - val_mae: 0.0206\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0295 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0282 - val_loss: 8.9946e-04 - val_mae: 0.0197\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 9.1296e-04 - val_mae: 0.0200\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0299 - val_loss: 9.0084e-04 - val_mae: 0.0197\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.0253e-04 - val_mae: 0.0200\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0278 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0278 - val_loss: 9.3365e-04 - val_mae: 0.0204\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0256 - val_loss: 9.1949e-04 - val_mae: 0.0201\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0049 - mae: 0.0270 - val_loss: 9.0110e-04 - val_mae: 0.0199\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0402 - val_loss: 0.0015 - val_mae: 0.0352\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0353 - val_loss: 9.2359e-04 - val_mae: 0.0218\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0279 - val_loss: 9.2090e-04 - val_mae: 0.0202\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0251 - val_loss: 9.0031e-04 - val_mae: 0.0198\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0307 - val_loss: 9.0050e-04 - val_mae: 0.0198\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.1807e-04 - val_mae: 0.0214\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0314 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.0812e-04 - val_mae: 0.0198\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0282 - val_loss: 9.0308e-04 - val_mae: 0.0201\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 9.0025e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0246 - val_loss: 9.1663e-04 - val_mae: 0.0201\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 8.9989e-04 - val_mae: 0.0197\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0275 - val_loss: 9.0013e-04 - val_mae: 0.0197\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0342 - val_loss: 0.0012 - val_mae: 0.0286\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0313 - val_loss: 9.1135e-04 - val_mae: 0.0209\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 9.0547e-04 - val_mae: 0.0197\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0268 - val_loss: 9.0006e-04 - val_mae: 0.0197\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0046 - mae: 0.0273 - val_loss: 9.0031e-04 - val_mae: 0.0198\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0325e-04 - val_mae: 0.0197\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0290 - val_loss: 9.0576e-04 - val_mae: 0.0203\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 9.0221e-04 - val_mae: 0.0200\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0281 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0272 - val_loss: 9.0357e-04 - val_mae: 0.0197\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0308 - val_loss: 8.9969e-04 - val_mae: 0.0197\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0282 - val_loss: 9.0078e-04 - val_mae: 0.0197\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0288 - val_loss: 9.0148e-04 - val_mae: 0.0197\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0254 - val_loss: 9.1264e-04 - val_mae: 0.0200\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0260 - val_loss: 9.0314e-04 - val_mae: 0.0197\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0280 - val_loss: 9.0827e-04 - val_mae: 0.0206\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0272 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0258 - val_loss: 9.0165e-04 - val_mae: 0.0197\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.0164e-04 - val_mae: 0.0197\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0274 - val_loss: 9.0228e-04 - val_mae: 0.0200\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 9.0074e-04 - val_mae: 0.0197\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0042 - mae: 0.0273 - val_loss: 9.0103e-04 - val_mae: 0.0197\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 9.2092e-04 - val_mae: 0.0202\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0270 - val_loss: 9.0399e-04 - val_mae: 0.0197\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0274 - val_loss: 9.0343e-04 - val_mae: 0.0197\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0268 - val_loss: 8.9998e-04 - val_mae: 0.0197\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0290 - val_loss: 9.2406e-04 - val_mae: 0.0218\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0301 - val_loss: 9.0537e-04 - val_mae: 0.0197\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0271 - val_loss: 8.9980e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 9.0224e-04 - val_mae: 0.0200\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0249 - val_loss: 9.0257e-04 - val_mae: 0.0197\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0272 - val_loss: 9.0028e-04 - val_mae: 0.0198\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0388e-04 - val_mae: 0.0197\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0048 - mae: 0.0278 - val_loss: 9.0895e-04 - val_mae: 0.0207\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0262 - val_loss: 9.0463e-04 - val_mae: 0.0202\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0276 - val_loss: 9.1268e-04 - val_mae: 0.0200\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0047 - mae: 0.0260 - val_loss: 9.0488e-04 - val_mae: 0.0197\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0723e-04 - val_mae: 0.0198\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0257 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0269 - val_loss: 9.0817e-04 - val_mae: 0.0206\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0085e-04 - val_mae: 0.0197\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0262 - val_loss: 8.9938e-04 - val_mae: 0.0197\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0277 - val_loss: 9.0325e-04 - val_mae: 0.0201\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.1292e-04 - val_mae: 0.0200\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0264 - val_loss: 8.9957e-04 - val_mae: 0.0197\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0266 - val_loss: 9.0320e-04 - val_mae: 0.0197\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 9.1261e-04 - val_mae: 0.0200\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 9.1381e-04 - val_mae: 0.0200\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.9999e-04 - val_mae: 0.0197\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0276 - val_loss: 9.0202e-04 - val_mae: 0.0200\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0264 - val_loss: 8.9955e-04 - val_mae: 0.0197\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0255 - val_loss: 9.0071e-04 - val_mae: 0.0197\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0246 - val_loss: 9.0476e-04 - val_mae: 0.0197\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0259 - val_loss: 9.0022e-04 - val_mae: 0.0198\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0270 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 8.9928e-04 - val_mae: 0.0197\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0041 - mae: 0.0255 - val_loss: 9.0000e-04 - val_mae: 0.0197\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 8.9972e-04 - val_mae: 0.0197\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0249 - val_loss: 8.9932e-04 - val_mae: 0.0197\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0253 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0290 - val_loss: 9.5050e-04 - val_mae: 0.0231\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0045 - mae: 0.0279 - val_loss: 9.0189e-04 - val_mae: 0.0197\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0041 - mae: 0.0244 - val_loss: 8.9930e-04 - val_mae: 0.0197\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0270 - val_loss: 8.9947e-04 - val_mae: 0.0197\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0249 - val_loss: 9.0201e-04 - val_mae: 0.0197\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0268 - val_loss: 9.0664e-04 - val_mae: 0.0204\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0250 - val_loss: 9.0014e-04 - val_mae: 0.0198\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0259 - val_loss: 9.0396e-04 - val_mae: 0.0197\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0264 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0042 - mae: 0.0250 - val_loss: 8.9926e-04 - val_mae: 0.0197\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0254 - val_loss: 8.9931e-04 - val_mae: 0.0197\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0273 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.1009e-04 - val_mae: 0.0199\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0256 - val_loss: 9.0205e-04 - val_mae: 0.0200\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0046 - mae: 0.0271 - val_loss: 8.9927e-04 - val_mae: 0.0197\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0046 - mae: 0.0251 - val_loss: 9.0998e-04 - val_mae: 0.0199\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0041 - mae: 0.0257 - val_loss: 8.9951e-04 - val_mae: 0.0197\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0043 - mae: 0.0269 - val_loss: 8.9944e-04 - val_mae: 0.0197\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.0665e-04 - val_mae: 0.0198\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0258 - val_loss: 9.1182e-04 - val_mae: 0.0199\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0242 - val_loss: 9.0843e-04 - val_mae: 0.0198\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0266 - val_loss: 9.0156e-04 - val_mae: 0.0197\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 8.9951e-04 - val_mae: 0.0197\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0045 - mae: 0.0266 - val_loss: 9.0001e-04 - val_mae: 0.0197\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0042 - mae: 0.0245 - val_loss: 9.0175e-04 - val_mae: 0.0197\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0244 - val_loss: 9.0634e-04 - val_mae: 0.0198\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0042 - mae: 0.0285 - val_loss: 9.8444e-04 - val_mae: 0.0243\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0044 - mae: 0.0296 - val_loss: 9.3061e-04 - val_mae: 0.0222\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0044 - mae: 0.0255 - val_loss: 9.0505e-04 - val_mae: 0.0197\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0039 - mae: 0.0233 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 9.0534e-04 - val_mae: 0.0197\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0263 - val_loss: 9.0060e-04 - val_mae: 0.0198\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0268 - val_loss: 9.0103e-04 - val_mae: 0.0197\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0258 - val_loss: 9.2296e-04 - val_mae: 0.0202\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0261 - val_loss: 9.0034e-04 - val_mae: 0.0198\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0157e-04 - val_mae: 0.0197\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0044 - mae: 0.0247 - val_loss: 9.0054e-04 - val_mae: 0.0197\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 8.9956e-04 - val_mae: 0.0197\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0262 - val_loss: 9.0300e-04 - val_mae: 0.0197\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0240 - val_loss: 9.0559e-04 - val_mae: 0.0197\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0044 - mae: 0.0252 - val_loss: 9.0171e-04 - val_mae: 0.0197\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0245 - val_loss: 9.1344e-04 - val_mae: 0.0200\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0247 - val_loss: 8.9933e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 9.0021e-04 - val_mae: 0.0198\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0278 - val_loss: 8.9960e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0244 - val_loss: 9.5172e-04 - val_mae: 0.0207\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0044 - mae: 0.0241 - val_loss: 8.9924e-04 - val_mae: 0.0197\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0253 - val_loss: 8.9953e-04 - val_mae: 0.0197\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0250 - val_loss: 9.0453e-04 - val_mae: 0.0197\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0284 - val_loss: 9.0084e-04 - val_mae: 0.0198\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0258 - val_loss: 9.0288e-04 - val_mae: 0.0197\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0238 - val_loss: 9.0527e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0042 - mae: 0.0240 - val_loss: 9.0006e-04 - val_mae: 0.0197\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0262 - val_loss: 9.0139e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0251 - val_loss: 9.0007e-04 - val_mae: 0.0197\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0241 - val_loss: 8.9984e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0045 - mae: 0.0249 - val_loss: 8.9925e-04 - val_mae: 0.0197\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0043 - mae: 0.0252 - val_loss: 9.0462e-04 - val_mae: 0.0202\n",
            "3/3 [==============================] - 0s 8ms/step\n",
            "Model: \"sequential_34\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_408 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_374 (Dropout)       (None, 40)                0         \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                                                                 \n",
            " dense_409 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_375 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_410 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_376 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_411 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_377 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_412 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_378 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_413 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_379 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_414 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_380 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_415 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_381 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_416 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_382 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_417 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_383 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_418 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_384 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_419 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 18ms/step - loss: 22.6062 - mae: 3.4319 - val_loss: 0.3244 - val_mae: 0.5593\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 8.7614 - mae: 2.0251 - val_loss: 0.0024 - val_mae: 0.0437\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0533 - mae: 1.1442 - val_loss: 0.0046 - val_mae: 0.0591\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.0811 - mae: 1.1224 - val_loss: 0.0017 - val_mae: 0.0326\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.8244 - mae: 1.2516 - val_loss: 0.0083 - val_mae: 0.0830\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.1653 - mae: 0.7987 - val_loss: 0.0142 - val_mae: 0.1128\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.8130 - mae: 0.7143 - val_loss: 0.0106 - val_mae: 0.0953\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7813 - mae: 0.6845 - val_loss: 0.0056 - val_mae: 0.0679\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.9842 - mae: 0.7033 - val_loss: 0.0024 - val_mae: 0.0400\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.7098 - mae: 0.6203 - val_loss: 0.0012 - val_mae: 0.0269\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.6702 - mae: 0.5961 - val_loss: 0.0022 - val_mae: 0.0375\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.6517 - mae: 0.5842 - val_loss: 0.0024 - val_mae: 0.0394\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5007 - mae: 0.4235 - val_loss: 0.0024 - val_mae: 0.0389\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4813 - mae: 0.5016 - val_loss: 0.0022 - val_mae: 0.0370\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3888 - mae: 0.4650 - val_loss: 0.0015 - val_mae: 0.0291\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5074 - mae: 0.5133 - val_loss: 0.0015 - val_mae: 0.0290\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2371 - mae: 0.3742 - val_loss: 0.0015 - val_mae: 0.0287\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2504 - mae: 0.3770 - val_loss: 0.0017 - val_mae: 0.0314\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1825 - mae: 0.3114 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2851 - mae: 0.3923 - val_loss: 0.0017 - val_mae: 0.0311\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2388 - mae: 0.3766 - val_loss: 0.0017 - val_mae: 0.0298\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4178 - mae: 0.3963 - val_loss: 0.0017 - val_mae: 0.0321\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2220 - mae: 0.3377 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2149 - mae: 0.3482 - val_loss: 0.0015 - val_mae: 0.0285\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1245 - mae: 0.2680 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2096 - mae: 0.3405 - val_loss: 0.0017 - val_mae: 0.0314\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1894 - mae: 0.3150 - val_loss: 0.0016 - val_mae: 0.0314\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1141 - mae: 0.2655 - val_loss: 0.0019 - val_mae: 0.0342\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1833 - mae: 0.3129 - val_loss: 0.0020 - val_mae: 0.0349\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1972 - mae: 0.3238 - val_loss: 0.0018 - val_mae: 0.0324\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1477 - mae: 0.2922 - val_loss: 0.0017 - val_mae: 0.0322\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1522 - mae: 0.2736 - val_loss: 0.0016 - val_mae: 0.0307\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1583 - mae: 0.2779 - val_loss: 0.0013 - val_mae: 0.0275\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0966 - mae: 0.2466 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1617 - mae: 0.3032 - val_loss: 0.0013 - val_mae: 0.0265\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1902 - mae: 0.2943 - val_loss: 0.0013 - val_mae: 0.0265\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1171 - mae: 0.2324 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.1135 - mae: 0.2520 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0999 - mae: 0.2132 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1048 - mae: 0.2384 - val_loss: 9.1943e-04 - val_mae: 0.0215\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0792 - mae: 0.2106 - val_loss: 9.8646e-04 - val_mae: 0.0225\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1067 - mae: 0.2364 - val_loss: 9.4634e-04 - val_mae: 0.0214\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0722 - mae: 0.2012 - val_loss: 9.5141e-04 - val_mae: 0.0210\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0864 - mae: 0.2122 - val_loss: 9.9554e-04 - val_mae: 0.0214\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0768 - mae: 0.2125 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0764 - mae: 0.2116 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0921 - mae: 0.2125 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0741 - mae: 0.1903 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1066 - mae: 0.2243 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0750 - mae: 0.2138 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0943 - mae: 0.2144 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0465 - mae: 0.1749 - val_loss: 0.0010 - val_mae: 0.0223\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0550 - mae: 0.1737 - val_loss: 9.5972e-04 - val_mae: 0.0214\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0527 - mae: 0.1811 - val_loss: 9.4619e-04 - val_mae: 0.0211\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0553 - mae: 0.1730 - val_loss: 9.9706e-04 - val_mae: 0.0217\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0720 - mae: 0.1881 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0651 - mae: 0.1905 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0647 - mae: 0.1795 - val_loss: 0.0010 - val_mae: 0.0223\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0694 - mae: 0.1906 - val_loss: 9.2129e-04 - val_mae: 0.0205\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0673 - mae: 0.1942 - val_loss: 9.3582e-04 - val_mae: 0.0210\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0681 - mae: 0.1977 - val_loss: 9.3730e-04 - val_mae: 0.0209\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0732 - mae: 0.1833 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0561 - mae: 0.1622 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0746 - mae: 0.1784 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0824 - mae: 0.1974 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0520 - mae: 0.1640 - val_loss: 0.0013 - val_mae: 0.0273\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0496 - mae: 0.1736 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0539 - mae: 0.1678 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0575 - mae: 0.1593 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0693 - mae: 0.1830 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0454 - mae: 0.1519 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0337 - mae: 0.1422 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0479 - mae: 0.1502 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0469 - mae: 0.1592 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0527 - mae: 0.1585 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0500 - mae: 0.1702 - val_loss: 9.9726e-04 - val_mae: 0.0212\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0330 - mae: 0.1340 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0329 - mae: 0.1303 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0437 - mae: 0.1396 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0300 - mae: 0.1188 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0335 - mae: 0.1232 - val_loss: 0.0011 - val_mae: 0.0245\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0358 - mae: 0.1438 - val_loss: 0.0013 - val_mae: 0.0272\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0286 - mae: 0.1200 - val_loss: 0.0013 - val_mae: 0.0276\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0351 - mae: 0.1294 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0237 - mae: 0.1158 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0360 - mae: 0.1394 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0337 - mae: 0.1310 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0344 - mae: 0.1188 - val_loss: 0.0013 - val_mae: 0.0274\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0264 - mae: 0.1227 - val_loss: 0.0013 - val_mae: 0.0271\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0196 - mae: 0.1014 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0359 - mae: 0.1358 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0341 - mae: 0.1340 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0245 - mae: 0.1161 - val_loss: 9.8430e-04 - val_mae: 0.0209\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0231 - mae: 0.1051 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0360 - mae: 0.1112 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0219 - mae: 0.1092 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0308 - mae: 0.1276 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0323 - mae: 0.1165 - val_loss: 0.0013 - val_mae: 0.0275\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1143 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0308 - mae: 0.1198 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0379 - mae: 0.1300 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0277 - mae: 0.1261 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0324 - mae: 0.1221 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0194 - mae: 0.1051 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 12ms/step - loss: 0.0184 - mae: 0.0994 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0228 - mae: 0.0964 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0374 - mae: 0.1322 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0972 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0210 - mae: 0.1037 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0208 - mae: 0.0982 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0225 - mae: 0.1030 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0201 - mae: 0.1009 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0243 - mae: 0.1057 - val_loss: 9.6052e-04 - val_mae: 0.0208\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0225 - mae: 0.0999 - val_loss: 9.5116e-04 - val_mae: 0.0207\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0187 - mae: 0.0924 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0226 - mae: 0.1039 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0145 - mae: 0.0856 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0198 - mae: 0.0814 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0241 - mae: 0.1014 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 13ms/step - loss: 0.0143 - mae: 0.0819 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 16ms/step - loss: 0.0343 - mae: 0.1110 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 23ms/step - loss: 0.0263 - mae: 0.1100 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0213 - mae: 0.1017 - val_loss: 0.0013 - val_mae: 0.0272\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0119 - mae: 0.0768 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0226 - mae: 0.1061 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0181 - mae: 0.0960 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0914 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0180 - mae: 0.0907 - val_loss: 9.6838e-04 - val_mae: 0.0209\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0195 - mae: 0.0988 - val_loss: 9.7094e-04 - val_mae: 0.0209\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0188 - mae: 0.0990 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0188 - mae: 0.0873 - val_loss: 9.8054e-04 - val_mae: 0.0210\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0823 - val_loss: 9.9111e-04 - val_mae: 0.0211\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0185 - mae: 0.0929 - val_loss: 9.5195e-04 - val_mae: 0.0206\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0869 - val_loss: 9.7511e-04 - val_mae: 0.0209\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0133 - mae: 0.0778 - val_loss: 9.4384e-04 - val_mae: 0.0205\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0197 - mae: 0.0880 - val_loss: 9.2177e-04 - val_mae: 0.0201\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0169 - mae: 0.0886 - val_loss: 9.6039e-04 - val_mae: 0.0208\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0177 - mae: 0.0904 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0267 - mae: 0.1121 - val_loss: 9.5136e-04 - val_mae: 0.0206\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0165 - mae: 0.0908 - val_loss: 9.3267e-04 - val_mae: 0.0203\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0226 - mae: 0.0929 - val_loss: 9.2484e-04 - val_mae: 0.0202\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0193 - mae: 0.0866 - val_loss: 9.7223e-04 - val_mae: 0.0209\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - mae: 0.0941 - val_loss: 9.5421e-04 - val_mae: 0.0207\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0212 - mae: 0.1012 - val_loss: 9.2388e-04 - val_mae: 0.0202\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0158 - mae: 0.0803 - val_loss: 9.0069e-04 - val_mae: 0.0197\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0150 - mae: 0.0882 - val_loss: 9.0331e-04 - val_mae: 0.0200\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0203 - mae: 0.0855 - val_loss: 8.9952e-04 - val_mae: 0.0199\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - mae: 0.0756 - val_loss: 9.0128e-04 - val_mae: 0.0197\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0099 - mae: 0.0708 - val_loss: 9.3771e-04 - val_mae: 0.0205\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0145 - mae: 0.0824 - val_loss: 9.5119e-04 - val_mae: 0.0207\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0171 - mae: 0.0883 - val_loss: 9.5436e-04 - val_mae: 0.0208\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0144 - mae: 0.0758 - val_loss: 9.2606e-04 - val_mae: 0.0203\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0126 - mae: 0.0685 - val_loss: 9.1254e-04 - val_mae: 0.0201\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0231 - mae: 0.0824 - val_loss: 9.2374e-04 - val_mae: 0.0203\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0824 - val_loss: 9.0634e-04 - val_mae: 0.0198\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0118 - mae: 0.0697 - val_loss: 9.1173e-04 - val_mae: 0.0200\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0688 - val_loss: 9.2100e-04 - val_mae: 0.0202\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0739 - val_loss: 9.4101e-04 - val_mae: 0.0206\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0145 - mae: 0.0862 - val_loss: 9.0778e-04 - val_mae: 0.0199\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0739 - val_loss: 9.0073e-04 - val_mae: 0.0197\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0766 - val_loss: 9.0246e-04 - val_mae: 0.0197\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0699 - val_loss: 9.4654e-04 - val_mae: 0.0206\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0172 - mae: 0.0760 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0600 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0125 - mae: 0.0684 - val_loss: 9.7750e-04 - val_mae: 0.0210\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0660 - val_loss: 9.7507e-04 - val_mae: 0.0210\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0633 - val_loss: 9.9133e-04 - val_mae: 0.0212\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0725 - val_loss: 9.7043e-04 - val_mae: 0.0209\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0676 - val_loss: 9.5853e-04 - val_mae: 0.0208\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0646 - val_loss: 9.8021e-04 - val_mae: 0.0211\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0701 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0793 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0116 - mae: 0.0631 - val_loss: 9.8290e-04 - val_mae: 0.0211\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0722 - val_loss: 9.3598e-04 - val_mae: 0.0204\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0130 - mae: 0.0787 - val_loss: 9.8314e-04 - val_mae: 0.0211\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0755 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0716 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0673 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - mae: 0.0787 - val_loss: 9.7680e-04 - val_mae: 0.0210\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0108 - mae: 0.0728 - val_loss: 9.5960e-04 - val_mae: 0.0208\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0659 - val_loss: 9.3957e-04 - val_mae: 0.0205\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0554 - val_loss: 9.1533e-04 - val_mae: 0.0199\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0625 - val_loss: 9.1242e-04 - val_mae: 0.0199\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0686 - val_loss: 9.0765e-04 - val_mae: 0.0197\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.0686 - val_loss: 9.5550e-04 - val_mae: 0.0207\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0610 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0132 - mae: 0.0724 - val_loss: 9.2643e-04 - val_mae: 0.0202\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0095 - mae: 0.0627 - val_loss: 9.1241e-04 - val_mae: 0.0198\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0714 - val_loss: 9.2102e-04 - val_mae: 0.0200\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0621 - val_loss: 9.4244e-04 - val_mae: 0.0205\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0630 - val_loss: 9.3498e-04 - val_mae: 0.0204\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0134 - mae: 0.0654 - val_loss: 9.1829e-04 - val_mae: 0.0200\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0117 - mae: 0.0640 - val_loss: 9.0717e-04 - val_mae: 0.0198\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0633 - val_loss: 9.0679e-04 - val_mae: 0.0198\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0111 - mae: 0.0635 - val_loss: 9.1002e-04 - val_mae: 0.0198\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0102 - mae: 0.0610 - val_loss: 9.1361e-04 - val_mae: 0.0204\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0163 - mae: 0.0740 - val_loss: 9.0749e-04 - val_mae: 0.0198\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0100 - mae: 0.0662 - val_loss: 9.0730e-04 - val_mae: 0.0198\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0129 - mae: 0.0678 - val_loss: 9.0643e-04 - val_mae: 0.0198\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0617 - val_loss: 9.0601e-04 - val_mae: 0.0198\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0561 - val_loss: 9.1982e-04 - val_mae: 0.0201\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0090 - mae: 0.0634 - val_loss: 9.5063e-04 - val_mae: 0.0206\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0635 - val_loss: 9.9836e-04 - val_mae: 0.0213\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0673 - val_loss: 9.7604e-04 - val_mae: 0.0210\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0096 - mae: 0.0615 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0518 - val_loss: 9.5999e-04 - val_mae: 0.0208\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0583 - val_loss: 9.5696e-04 - val_mae: 0.0207\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0133 - mae: 0.0678 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0592 - val_loss: 9.5987e-04 - val_mae: 0.0208\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0099 - mae: 0.0684 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0096 - mae: 0.0655 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0530 - val_loss: 9.3280e-04 - val_mae: 0.0203\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0561 - val_loss: 9.2613e-04 - val_mae: 0.0203\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0531 - val_loss: 9.7970e-04 - val_mae: 0.0210\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0533 - val_loss: 9.6272e-04 - val_mae: 0.0208\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0564 - val_loss: 9.8757e-04 - val_mae: 0.0211\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0488 - val_loss: 9.6779e-04 - val_mae: 0.0209\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0641 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0565 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0490 - val_loss: 9.9023e-04 - val_mae: 0.0211\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0547 - val_loss: 9.1936e-04 - val_mae: 0.0201\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0650 - val_loss: 9.0861e-04 - val_mae: 0.0198\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0622 - val_loss: 9.2000e-04 - val_mae: 0.0201\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0492 - val_loss: 9.3165e-04 - val_mae: 0.0203\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0090 - mae: 0.0538 - val_loss: 9.1030e-04 - val_mae: 0.0198\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0529 - val_loss: 9.8622e-04 - val_mae: 0.0211\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0535 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0566 - val_loss: 9.8250e-04 - val_mae: 0.0210\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0623 - val_loss: 9.3598e-04 - val_mae: 0.0204\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0524 - val_loss: 9.5230e-04 - val_mae: 0.0207\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0503 - val_loss: 9.1752e-04 - val_mae: 0.0200\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0119 - mae: 0.0626 - val_loss: 9.0529e-04 - val_mae: 0.0197\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0550 - val_loss: 9.2351e-04 - val_mae: 0.0201\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0519 - val_loss: 9.3644e-04 - val_mae: 0.0204\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0499 - val_loss: 9.2152e-04 - val_mae: 0.0201\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0551 - val_loss: 9.2454e-04 - val_mae: 0.0202\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0513 - val_loss: 9.7311e-04 - val_mae: 0.0209\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0536 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0504 - val_loss: 9.6634e-04 - val_mae: 0.0209\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0093 - mae: 0.0585 - val_loss: 9.3985e-04 - val_mae: 0.0205\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0540 - val_loss: 9.3518e-04 - val_mae: 0.0204\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - mae: 0.0616 - val_loss: 9.3678e-04 - val_mae: 0.0204\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0505 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0069 - mae: 0.0493 - val_loss: 9.0127e-04 - val_mae: 0.0197\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0467 - val_loss: 9.0279e-04 - val_mae: 0.0197\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 9.0355e-04 - val_mae: 0.0197\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0574 - val_loss: 9.0607e-04 - val_mae: 0.0197\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0458 - val_loss: 9.6722e-04 - val_mae: 0.0209\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0082 - mae: 0.0492 - val_loss: 9.1989e-04 - val_mae: 0.0201\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0078 - mae: 0.0511 - val_loss: 9.2154e-04 - val_mae: 0.0202\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0529 - val_loss: 9.3962e-04 - val_mae: 0.0205\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0073 - mae: 0.0488 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0083 - mae: 0.0530 - val_loss: 9.4798e-04 - val_mae: 0.0206\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0086 - mae: 0.0539 - val_loss: 9.1267e-04 - val_mae: 0.0199\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0520 - val_loss: 9.0850e-04 - val_mae: 0.0198\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0077 - mae: 0.0467 - val_loss: 9.4107e-04 - val_mae: 0.0205\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0484 - val_loss: 9.7816e-04 - val_mae: 0.0210\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0527 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0450 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0457 - val_loss: 9.1051e-04 - val_mae: 0.0199\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0457 - val_loss: 9.0075e-04 - val_mae: 0.0197\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0072 - mae: 0.0490 - val_loss: 9.1276e-04 - val_mae: 0.0199\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0490 - val_loss: 9.1409e-04 - val_mae: 0.0200\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0072 - mae: 0.0490 - val_loss: 9.7269e-04 - val_mae: 0.0209\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - mae: 0.0450 - val_loss: 9.7846e-04 - val_mae: 0.0210\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0432 - val_loss: 9.3305e-04 - val_mae: 0.0204\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0096 - mae: 0.0518 - val_loss: 9.0480e-04 - val_mae: 0.0197\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0532 - val_loss: 9.1608e-04 - val_mae: 0.0201\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0439 - val_loss: 9.6656e-04 - val_mae: 0.0209\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0430 - val_loss: 9.1745e-04 - val_mae: 0.0201\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0456 - val_loss: 9.2083e-04 - val_mae: 0.0202\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0382 - val_loss: 9.6452e-04 - val_mae: 0.0208\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0062 - mae: 0.0398 - val_loss: 9.5540e-04 - val_mae: 0.0207\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0444 - val_loss: 9.6951e-04 - val_mae: 0.0209\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0417 - val_loss: 9.1597e-04 - val_mae: 0.0200\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0077 - mae: 0.0509 - val_loss: 9.1422e-04 - val_mae: 0.0200\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0454 - val_loss: 9.8276e-04 - val_mae: 0.0211\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0402 - val_loss: 9.9171e-04 - val_mae: 0.0211\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0063 - mae: 0.0461 - val_loss: 9.7492e-04 - val_mae: 0.0210\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0451 - val_loss: 9.4894e-04 - val_mae: 0.0206\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0414 - val_loss: 9.8578e-04 - val_mae: 0.0211\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0066 - mae: 0.0440 - val_loss: 9.5981e-04 - val_mae: 0.0208\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0430 - val_loss: 9.9077e-04 - val_mae: 0.0211\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0423 - val_loss: 9.2869e-04 - val_mae: 0.0203\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0486 - val_loss: 9.0137e-04 - val_mae: 0.0199\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0060 - mae: 0.0444 - val_loss: 9.0845e-04 - val_mae: 0.0206\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0467 - val_loss: 9.3144e-04 - val_mae: 0.0222\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0106 - mae: 0.0529 - val_loss: 9.0142e-04 - val_mae: 0.0198\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0441 - val_loss: 9.0084e-04 - val_mae: 0.0198\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0451 - val_loss: 9.0123e-04 - val_mae: 0.0197\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0381 - val_loss: 9.0017e-04 - val_mae: 0.0197\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0426 - val_loss: 9.2114e-04 - val_mae: 0.0202\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0372 - val_loss: 9.1551e-04 - val_mae: 0.0200\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0444 - val_loss: 9.1937e-04 - val_mae: 0.0201\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0084 - mae: 0.0479 - val_loss: 9.3895e-04 - val_mae: 0.0205\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0400 - val_loss: 9.2547e-04 - val_mae: 0.0202\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0406 - val_loss: 9.3562e-04 - val_mae: 0.0204\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0440 - val_loss: 9.7143e-04 - val_mae: 0.0209\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0386 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0410 - val_loss: 9.7541e-04 - val_mae: 0.0210\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0395 - val_loss: 9.2850e-04 - val_mae: 0.0203\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0035 - mae: 0.0369 - val_loss: 9.1721e-04 - val_mae: 0.0201\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0411 - val_loss: 9.0033e-04 - val_mae: 0.0198\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0400 - val_loss: 9.1012e-04 - val_mae: 0.0199\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0435 - val_loss: 9.0616e-04 - val_mae: 0.0204\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0399 - val_loss: 9.1680e-04 - val_mae: 0.0201\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0389 - val_loss: 9.3295e-04 - val_mae: 0.0204\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0381 - val_loss: 9.4704e-04 - val_mae: 0.0206\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0366 - val_loss: 9.1939e-04 - val_mae: 0.0202\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0367 - val_loss: 9.3493e-04 - val_mae: 0.0204\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0469 - val_loss: 9.5159e-04 - val_mae: 0.0207\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0065 - mae: 0.0405 - val_loss: 9.1976e-04 - val_mae: 0.0202\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0358 - val_loss: 9.5913e-04 - val_mae: 0.0208\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0425 - val_loss: 9.5298e-04 - val_mae: 0.0207\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0471 - val_loss: 9.2109e-04 - val_mae: 0.0202\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0403 - val_loss: 9.3560e-04 - val_mae: 0.0205\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0407 - val_loss: 9.2981e-04 - val_mae: 0.0204\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0429 - val_loss: 9.0070e-04 - val_mae: 0.0197\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0381 - val_loss: 9.0650e-04 - val_mae: 0.0198\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0430 - val_loss: 8.9958e-04 - val_mae: 0.0196\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0368 - val_loss: 9.0799e-04 - val_mae: 0.0199\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0369 - val_loss: 9.1499e-04 - val_mae: 0.0201\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0449 - val_loss: 8.9839e-04 - val_mae: 0.0196\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0453 - val_loss: 9.1155e-04 - val_mae: 0.0200\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0373 - val_loss: 9.4669e-04 - val_mae: 0.0206\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0369 - val_loss: 9.0075e-04 - val_mae: 0.0196\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0373 - val_loss: 9.6279e-04 - val_mae: 0.0236\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0456 - val_loss: 9.0178e-04 - val_mae: 0.0200\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0351 - val_loss: 9.0078e-04 - val_mae: 0.0197\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0046 - mae: 0.0376 - val_loss: 9.0011e-04 - val_mae: 0.0197\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0335 - val_loss: 9.0916e-04 - val_mae: 0.0199\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0399 - val_loss: 9.1103e-04 - val_mae: 0.0199\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0435 - val_loss: 9.1767e-04 - val_mae: 0.0201\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0397 - val_loss: 9.0281e-04 - val_mae: 0.0200\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0387 - val_loss: 9.0849e-04 - val_mae: 0.0198\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0387 - val_loss: 9.0560e-04 - val_mae: 0.0197\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0364 - val_loss: 9.0290e-04 - val_mae: 0.0197\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0380 - val_loss: 9.0011e-04 - val_mae: 0.0197\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0327 - val_loss: 9.3191e-04 - val_mae: 0.0204\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0046 - mae: 0.0318 - val_loss: 9.5438e-04 - val_mae: 0.0207\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0061 - mae: 0.0418 - val_loss: 0.0010 - val_mae: 0.0250\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0422 - val_loss: 9.0650e-04 - val_mae: 0.0206\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0405 - val_loss: 9.0230e-04 - val_mae: 0.0197\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0396 - val_loss: 9.3735e-04 - val_mae: 0.0205\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0387 - val_loss: 9.1760e-04 - val_mae: 0.0201\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0055 - mae: 0.0358 - val_loss: 9.8169e-04 - val_mae: 0.0211\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0367 - val_loss: 9.2292e-04 - val_mae: 0.0202\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0419 - val_loss: 9.0542e-04 - val_mae: 0.0197\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0396 - val_loss: 9.2909e-04 - val_mae: 0.0203\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0339 - val_loss: 9.3702e-04 - val_mae: 0.0205\n",
            "3/3 [==============================] - 0s 6ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_35\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_420 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_385 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_421 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_386 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_422 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_387 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_423 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_388 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_424 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_389 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_425 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_390 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_426 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_391 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_427 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_392 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_428 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_393 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_429 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_394 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_430 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_395 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_431 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 4s 18ms/step - loss: 24.9346 - mae: 3.5265 - val_loss: 0.3238 - val_mae: 0.5670\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 5.3165 - mae: 1.7516 - val_loss: 0.1127 - val_mae: 0.3347\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 2.1271 - mae: 1.0706 - val_loss: 0.0733 - val_mae: 0.2678\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.8950 - mae: 1.0190 - val_loss: 0.0254 - val_mae: 0.1533\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.0082 - mae: 0.7797 - val_loss: 0.0260 - val_mae: 0.1598\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.6372 - mae: 0.9333 - val_loss: 0.0253 - val_mae: 0.1584\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 1.1219 - mae: 0.8457 - val_loss: 0.0286 - val_mae: 0.1670\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 1.0144 - mae: 0.7544 - val_loss: 0.0227 - val_mae: 0.1465\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.7790 - mae: 0.6312 - val_loss: 0.0144 - val_mae: 0.1170\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8030 - mae: 0.5925 - val_loss: 0.0133 - val_mae: 0.1135\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.8044 - mae: 0.6281 - val_loss: 0.0127 - val_mae: 0.1108\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5616 - mae: 0.5541 - val_loss: 0.0199 - val_mae: 0.1401\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5639 - mae: 0.5618 - val_loss: 0.0191 - val_mae: 0.1368\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.5537 - mae: 0.5350 - val_loss: 0.0155 - val_mae: 0.1225\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5532 - mae: 0.5637 - val_loss: 0.0144 - val_mae: 0.1173\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3907 - mae: 0.4569 - val_loss: 0.0172 - val_mae: 0.1283\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3896 - mae: 0.4712 - val_loss: 0.0135 - val_mae: 0.1130\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.4683 - mae: 0.5289 - val_loss: 0.0107 - val_mae: 0.1002\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3102 - mae: 0.4084 - val_loss: 0.0102 - val_mae: 0.0975\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.5388 - mae: 0.4877 - val_loss: 0.0065 - val_mae: 0.0746\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2526 - mae: 0.3762 - val_loss: 0.0067 - val_mae: 0.0754\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2660 - mae: 0.3843 - val_loss: 0.0058 - val_mae: 0.0700\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2992 - mae: 0.4144 - val_loss: 0.0062 - val_mae: 0.0733\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2294 - mae: 0.3640 - val_loss: 0.0066 - val_mae: 0.0770\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2270 - mae: 0.3704 - val_loss: 0.0082 - val_mae: 0.0869\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3448 - mae: 0.4360 - val_loss: 0.0097 - val_mae: 0.0945\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2784 - mae: 0.4034 - val_loss: 0.0086 - val_mae: 0.0879\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1633 - mae: 0.3006 - val_loss: 0.0092 - val_mae: 0.0911\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.3256 - mae: 0.4251 - val_loss: 0.0105 - val_mae: 0.0984\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1579 - mae: 0.3026 - val_loss: 0.0103 - val_mae: 0.0979\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2653 - mae: 0.3465 - val_loss: 0.0091 - val_mae: 0.0913\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1094 - mae: 0.2507 - val_loss: 0.0087 - val_mae: 0.0893\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2088 - mae: 0.3431 - val_loss: 0.0087 - val_mae: 0.0898\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1927 - mae: 0.3318 - val_loss: 0.0080 - val_mae: 0.0851\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1498 - mae: 0.3041 - val_loss: 0.0075 - val_mae: 0.0822\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1111 - mae: 0.2334 - val_loss: 0.0070 - val_mae: 0.0784\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1602 - mae: 0.2972 - val_loss: 0.0064 - val_mae: 0.0741\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1554 - mae: 0.3085 - val_loss: 0.0056 - val_mae: 0.0690\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1291 - mae: 0.2544 - val_loss: 0.0050 - val_mae: 0.0631\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1392 - mae: 0.2870 - val_loss: 0.0054 - val_mae: 0.0673\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1595 - mae: 0.2970 - val_loss: 0.0068 - val_mae: 0.0777\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1351 - mae: 0.2309 - val_loss: 0.0064 - val_mae: 0.0747\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.1158 - mae: 0.2574 - val_loss: 0.0054 - val_mae: 0.0674\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1027 - mae: 0.2308 - val_loss: 0.0053 - val_mae: 0.0662\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1231 - mae: 0.2629 - val_loss: 0.0049 - val_mae: 0.0629\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0985 - mae: 0.2322 - val_loss: 0.0045 - val_mae: 0.0605\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1285 - mae: 0.2414 - val_loss: 0.0047 - val_mae: 0.0614\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0801 - mae: 0.2081 - val_loss: 0.0043 - val_mae: 0.0587\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0661 - mae: 0.1975 - val_loss: 0.0044 - val_mae: 0.0595\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1286 - mae: 0.2547 - val_loss: 0.0044 - val_mae: 0.0594\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0797 - mae: 0.2230 - val_loss: 0.0040 - val_mae: 0.0560\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0791 - mae: 0.2143 - val_loss: 0.0038 - val_mae: 0.0535\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0914 - mae: 0.2066 - val_loss: 0.0041 - val_mae: 0.0569\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0859 - mae: 0.2123 - val_loss: 0.0044 - val_mae: 0.0589\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0695 - mae: 0.1973 - val_loss: 0.0049 - val_mae: 0.0631\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0665 - mae: 0.1845 - val_loss: 0.0044 - val_mae: 0.0586\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1301 - mae: 0.2477 - val_loss: 0.0044 - val_mae: 0.0588\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0720 - mae: 0.1973 - val_loss: 0.0049 - val_mae: 0.0630\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1040 - mae: 0.2328 - val_loss: 0.0055 - val_mae: 0.0681\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0731 - mae: 0.2072 - val_loss: 0.0060 - val_mae: 0.0717\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0729 - mae: 0.2104 - val_loss: 0.0049 - val_mae: 0.0634\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0665 - mae: 0.1842 - val_loss: 0.0045 - val_mae: 0.0598\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0724 - mae: 0.1939 - val_loss: 0.0042 - val_mae: 0.0578\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0846 - mae: 0.2136 - val_loss: 0.0036 - val_mae: 0.0521\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0653 - mae: 0.1763 - val_loss: 0.0037 - val_mae: 0.0532\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0749 - mae: 0.2000 - val_loss: 0.0043 - val_mae: 0.0584\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0592 - mae: 0.1745 - val_loss: 0.0040 - val_mae: 0.0560\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0412 - mae: 0.1480 - val_loss: 0.0037 - val_mae: 0.0536\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0569 - mae: 0.1749 - val_loss: 0.0037 - val_mae: 0.0530\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0773 - mae: 0.2050 - val_loss: 0.0035 - val_mae: 0.0509\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0669 - mae: 0.1660 - val_loss: 0.0042 - val_mae: 0.0576\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0788 - mae: 0.1991 - val_loss: 0.0046 - val_mae: 0.0613\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0912 - mae: 0.2075 - val_loss: 0.0045 - val_mae: 0.0605\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0374 - mae: 0.1495 - val_loss: 0.0034 - val_mae: 0.0510\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0803 - mae: 0.1980 - val_loss: 0.0039 - val_mae: 0.0552\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0522 - mae: 0.1645 - val_loss: 0.0046 - val_mae: 0.0616\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0725 - mae: 0.1852 - val_loss: 0.0047 - val_mae: 0.0617\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1002 - mae: 0.1832 - val_loss: 0.0045 - val_mae: 0.0602\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0589 - mae: 0.1623 - val_loss: 0.0043 - val_mae: 0.0587\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0490 - mae: 0.1541 - val_loss: 0.0039 - val_mae: 0.0549\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0507 - mae: 0.1634 - val_loss: 0.0038 - val_mae: 0.0541\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0457 - mae: 0.1518 - val_loss: 0.0034 - val_mae: 0.0506\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0484 - mae: 0.1657 - val_loss: 0.0030 - val_mae: 0.0460\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0567 - mae: 0.1639 - val_loss: 0.0031 - val_mae: 0.0473\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0434 - mae: 0.1522 - val_loss: 0.0033 - val_mae: 0.0493\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0554 - mae: 0.1618 - val_loss: 0.0033 - val_mae: 0.0496\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0319 - mae: 0.1339 - val_loss: 0.0035 - val_mae: 0.0514\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0407 - mae: 0.1386 - val_loss: 0.0035 - val_mae: 0.0514\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0467 - mae: 0.1490 - val_loss: 0.0035 - val_mae: 0.0508\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0315 - mae: 0.1289 - val_loss: 0.0031 - val_mae: 0.0468\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0501 - mae: 0.1558 - val_loss: 0.0030 - val_mae: 0.0464\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0440 - mae: 0.1579 - val_loss: 0.0032 - val_mae: 0.0484\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0242 - mae: 0.1112 - val_loss: 0.0032 - val_mae: 0.0479\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0374 - mae: 0.1500 - val_loss: 0.0034 - val_mae: 0.0505\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 0.1407 - val_loss: 0.0034 - val_mae: 0.0499\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0283 - mae: 0.1279 - val_loss: 0.0034 - val_mae: 0.0497\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0339 - mae: 0.1423 - val_loss: 0.0032 - val_mae: 0.0482\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0320 - mae: 0.1222 - val_loss: 0.0031 - val_mae: 0.0473\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0290 - mae: 0.1289 - val_loss: 0.0029 - val_mae: 0.0452\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0276 - mae: 0.1150 - val_loss: 0.0029 - val_mae: 0.0444\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0284 - mae: 0.1227 - val_loss: 0.0026 - val_mae: 0.0415\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0311 - mae: 0.1201 - val_loss: 0.0028 - val_mae: 0.0435\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0380 - mae: 0.1349 - val_loss: 0.0030 - val_mae: 0.0460\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0287 - mae: 0.1177 - val_loss: 0.0029 - val_mae: 0.0445\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0288 - mae: 0.1108 - val_loss: 0.0028 - val_mae: 0.0438\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0309 - mae: 0.1222 - val_loss: 0.0026 - val_mae: 0.0412\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0246 - mae: 0.1106 - val_loss: 0.0025 - val_mae: 0.0402\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0421 - mae: 0.1370 - val_loss: 0.0024 - val_mae: 0.0391\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0346 - mae: 0.1242 - val_loss: 0.0023 - val_mae: 0.0385\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0355 - mae: 0.1233 - val_loss: 0.0023 - val_mae: 0.0384\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0295 - mae: 0.1212 - val_loss: 0.0024 - val_mae: 0.0392\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0310 - mae: 0.1109 - val_loss: 0.0020 - val_mae: 0.0354\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - mae: 0.1115 - val_loss: 0.0019 - val_mae: 0.0335\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0294 - mae: 0.1230 - val_loss: 0.0021 - val_mae: 0.0354\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0212 - mae: 0.1014 - val_loss: 0.0021 - val_mae: 0.0356\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0171 - mae: 0.0940 - val_loss: 0.0022 - val_mae: 0.0376\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0168 - mae: 0.0934 - val_loss: 0.0024 - val_mae: 0.0388\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0314 - mae: 0.1155 - val_loss: 0.0026 - val_mae: 0.0411\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0193 - mae: 0.1054 - val_loss: 0.0025 - val_mae: 0.0399\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0390 - mae: 0.1303 - val_loss: 0.0024 - val_mae: 0.0397\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0233 - mae: 0.1088 - val_loss: 0.0025 - val_mae: 0.0406\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0230 - mae: 0.1107 - val_loss: 0.0027 - val_mae: 0.0423\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0280 - mae: 0.1220 - val_loss: 0.0029 - val_mae: 0.0450\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0206 - mae: 0.1004 - val_loss: 0.0029 - val_mae: 0.0445\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0170 - mae: 0.0953 - val_loss: 0.0024 - val_mae: 0.0393\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0206 - mae: 0.1025 - val_loss: 0.0023 - val_mae: 0.0385\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0227 - mae: 0.0950 - val_loss: 0.0022 - val_mae: 0.0373\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0247 - mae: 0.1039 - val_loss: 0.0019 - val_mae: 0.0337\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0196 - mae: 0.0954 - val_loss: 0.0019 - val_mae: 0.0335\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.1005 - val_loss: 0.0022 - val_mae: 0.0368\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0205 - mae: 0.1007 - val_loss: 0.0024 - val_mae: 0.0390\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0199 - mae: 0.0975 - val_loss: 0.0025 - val_mae: 0.0406\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0203 - mae: 0.0963 - val_loss: 0.0024 - val_mae: 0.0395\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0222 - mae: 0.0973 - val_loss: 0.0022 - val_mae: 0.0369\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0265 - mae: 0.1020 - val_loss: 0.0022 - val_mae: 0.0370\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - mae: 0.0981 - val_loss: 0.0023 - val_mae: 0.0377\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0178 - mae: 0.0934 - val_loss: 0.0022 - val_mae: 0.0368\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0154 - mae: 0.0904 - val_loss: 0.0022 - val_mae: 0.0366\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0911 - val_loss: 0.0024 - val_mae: 0.0386\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1033 - val_loss: 0.0026 - val_mae: 0.0410\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0187 - mae: 0.0912 - val_loss: 0.0022 - val_mae: 0.0374\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0188 - mae: 0.0969 - val_loss: 0.0020 - val_mae: 0.0351\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0186 - mae: 0.0900 - val_loss: 0.0023 - val_mae: 0.0381\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0755 - val_loss: 0.0023 - val_mae: 0.0376\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0111 - mae: 0.0710 - val_loss: 0.0020 - val_mae: 0.0353\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0187 - mae: 0.0935 - val_loss: 0.0019 - val_mae: 0.0338\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0909 - val_loss: 0.0019 - val_mae: 0.0334\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0193 - mae: 0.0911 - val_loss: 0.0020 - val_mae: 0.0350\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0226 - mae: 0.1031 - val_loss: 0.0022 - val_mae: 0.0374\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0254 - mae: 0.0893 - val_loss: 0.0019 - val_mae: 0.0339\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - mae: 0.0976 - val_loss: 0.0021 - val_mae: 0.0361\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0143 - mae: 0.0797 - val_loss: 0.0024 - val_mae: 0.0388\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0251 - mae: 0.0912 - val_loss: 0.0021 - val_mae: 0.0358\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0156 - mae: 0.0802 - val_loss: 0.0022 - val_mae: 0.0365\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0156 - mae: 0.0914 - val_loss: 0.0023 - val_mae: 0.0379\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0636 - val_loss: 0.0023 - val_mae: 0.0380\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0127 - mae: 0.0787 - val_loss: 0.0022 - val_mae: 0.0366\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0173 - mae: 0.0851 - val_loss: 0.0022 - val_mae: 0.0363\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0794 - val_loss: 0.0020 - val_mae: 0.0347\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0116 - mae: 0.0700 - val_loss: 0.0020 - val_mae: 0.0350\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0157 - mae: 0.0827 - val_loss: 0.0018 - val_mae: 0.0328\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0074 - mae: 0.0613 - val_loss: 0.0018 - val_mae: 0.0320\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0223 - mae: 0.0995 - val_loss: 0.0017 - val_mae: 0.0317\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0674 - val_loss: 0.0017 - val_mae: 0.0314\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0133 - mae: 0.0827 - val_loss: 0.0019 - val_mae: 0.0330\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0185 - mae: 0.0908 - val_loss: 0.0020 - val_mae: 0.0345\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0138 - mae: 0.0840 - val_loss: 0.0017 - val_mae: 0.0319\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.0738 - val_loss: 0.0018 - val_mae: 0.0328\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0125 - mae: 0.0783 - val_loss: 0.0018 - val_mae: 0.0323\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.0876 - val_loss: 0.0022 - val_mae: 0.0365\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0140 - mae: 0.0825 - val_loss: 0.0023 - val_mae: 0.0383\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0842 - val_loss: 0.0020 - val_mae: 0.0341\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0127 - mae: 0.0810 - val_loss: 0.0017 - val_mae: 0.0316\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0109 - mae: 0.0688 - val_loss: 0.0016 - val_mae: 0.0301\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0118 - mae: 0.0755 - val_loss: 0.0016 - val_mae: 0.0305\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0110 - mae: 0.0704 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0104 - mae: 0.0705 - val_loss: 0.0018 - val_mae: 0.0324\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0207 - mae: 0.0951 - val_loss: 0.0018 - val_mae: 0.0327\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0103 - mae: 0.0701 - val_loss: 0.0017 - val_mae: 0.0313\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0105 - mae: 0.0724 - val_loss: 0.0016 - val_mae: 0.0304\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0103 - mae: 0.0715 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0154 - mae: 0.0872 - val_loss: 0.0017 - val_mae: 0.0314\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0085 - mae: 0.0602 - val_loss: 0.0016 - val_mae: 0.0303\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0115 - mae: 0.0677 - val_loss: 0.0015 - val_mae: 0.0297\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.0750 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0084 - mae: 0.0560 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0115 - mae: 0.0745 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0100 - mae: 0.0668 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0114 - mae: 0.0695 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0090 - mae: 0.0667 - val_loss: 0.0017 - val_mae: 0.0311\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0131 - mae: 0.0742 - val_loss: 0.0016 - val_mae: 0.0305\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0128 - mae: 0.0785 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0114 - mae: 0.0664 - val_loss: 0.0013 - val_mae: 0.0264\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0107 - mae: 0.0638 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0112 - mae: 0.0687 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0687 - val_loss: 0.0015 - val_mae: 0.0288\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0596 - val_loss: 0.0015 - val_mae: 0.0290\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0120 - mae: 0.0698 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0666 - val_loss: 0.0016 - val_mae: 0.0301\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0654 - val_loss: 0.0018 - val_mae: 0.0326\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0131 - mae: 0.0702 - val_loss: 0.0017 - val_mae: 0.0314\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0127 - mae: 0.0744 - val_loss: 0.0014 - val_mae: 0.0275\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0118 - mae: 0.0685 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0568 - val_loss: 0.0013 - val_mae: 0.0271\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0613 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0679 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0134 - mae: 0.0731 - val_loss: 0.0016 - val_mae: 0.0300\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0144 - mae: 0.0742 - val_loss: 0.0018 - val_mae: 0.0328\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0110 - mae: 0.0695 - val_loss: 0.0018 - val_mae: 0.0327\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0095 - mae: 0.0640 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0082 - mae: 0.0586 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0657 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0611 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0142 - mae: 0.0663 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0808 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0075 - mae: 0.0570 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0107 - mae: 0.0652 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0525 - val_loss: 0.0012 - val_mae: 0.0253\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0108 - mae: 0.0603 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0567 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0429 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0611 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0128 - mae: 0.0610 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0611 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0601 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0561 - val_loss: 0.0013 - val_mae: 0.0265\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0076 - mae: 0.0541 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0529 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0104 - mae: 0.0610 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0556 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0572 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0091 - mae: 0.0543 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0105 - mae: 0.0677 - val_loss: 0.0014 - val_mae: 0.0276\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.0614 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0080 - mae: 0.0548 - val_loss: 0.0014 - val_mae: 0.0281\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0567 - val_loss: 0.0014 - val_mae: 0.0275\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0540 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0091 - mae: 0.0633 - val_loss: 0.0014 - val_mae: 0.0276\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0529 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0079 - mae: 0.0512 - val_loss: 0.0013 - val_mae: 0.0259\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0094 - mae: 0.0582 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0076 - mae: 0.0486 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0061 - mae: 0.0439 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0550 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0101 - mae: 0.0639 - val_loss: 0.0013 - val_mae: 0.0259\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0520 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0504 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0510 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0486 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0571 - val_loss: 0.0013 - val_mae: 0.0265\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0603 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0525 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0080 - mae: 0.0532 - val_loss: 0.0013 - val_mae: 0.0260\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0530 - val_loss: 0.0014 - val_mae: 0.0275\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0501 - val_loss: 0.0013 - val_mae: 0.0270\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0501 - val_loss: 0.0012 - val_mae: 0.0253\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0093 - mae: 0.0542 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0114 - mae: 0.0625 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0598 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0494 - val_loss: 0.0013 - val_mae: 0.0272\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0618 - val_loss: 0.0014 - val_mae: 0.0274\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0535 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0467 - val_loss: 0.0012 - val_mae: 0.0251\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0503 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0093 - mae: 0.0507 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0511 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0509 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0465 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0097 - mae: 0.0549 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0414 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0478 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0487 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0475 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0503 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0400 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0463 - val_loss: 9.1923e-04 - val_mae: 0.0200\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0072 - mae: 0.0473 - val_loss: 9.6749e-04 - val_mae: 0.0209\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0517 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0451 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0081 - mae: 0.0506 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0074 - mae: 0.0466 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0060 - mae: 0.0462 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0422 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0075 - mae: 0.0510 - val_loss: 9.6840e-04 - val_mae: 0.0209\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0421 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0093 - mae: 0.0547 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0054 - mae: 0.0417 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0066 - mae: 0.0454 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0076 - mae: 0.0494 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0084 - mae: 0.0495 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0075 - mae: 0.0459 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - mae: 0.0411 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0066 - mae: 0.0456 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0472 - val_loss: 9.4386e-04 - val_mae: 0.0206\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0063 - mae: 0.0460 - val_loss: 9.6204e-04 - val_mae: 0.0208\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0407 - val_loss: 9.9521e-04 - val_mae: 0.0212\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0064 - mae: 0.0433 - val_loss: 9.5128e-04 - val_mae: 0.0207\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0067 - mae: 0.0523 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0058 - mae: 0.0418 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0077 - mae: 0.0479 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0410 - val_loss: 9.9114e-04 - val_mae: 0.0212\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0429 - val_loss: 9.2679e-04 - val_mae: 0.0203\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0456 - val_loss: 9.6668e-04 - val_mae: 0.0209\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0075 - mae: 0.0519 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0070 - mae: 0.0444 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0073 - mae: 0.0498 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0420 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0437 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0411 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0455 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0432 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0428 - val_loss: 0.0010 - val_mae: 0.0221\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0089 - mae: 0.0552 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0379 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0361 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0459 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0069 - mae: 0.0402 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0058 - mae: 0.0436 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0075 - mae: 0.0489 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0384 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0401 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0062 - mae: 0.0470 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0409 - val_loss: 0.0011 - val_mae: 0.0236\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0446 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0390 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0371 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0404 - val_loss: 9.9149e-04 - val_mae: 0.0211\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0442 - val_loss: 9.9143e-04 - val_mae: 0.0211\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0430 - val_loss: 9.7691e-04 - val_mae: 0.0210\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0061 - mae: 0.0419 - val_loss: 9.9345e-04 - val_mae: 0.0212\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0445 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0456 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0425 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0411 - val_loss: 0.0010 - val_mae: 0.0216\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0402 - val_loss: 9.3485e-04 - val_mae: 0.0204\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0418 - val_loss: 9.7249e-04 - val_mae: 0.0209\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0423 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0108 - mae: 0.0448 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0412 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0368 - val_loss: 9.7479e-04 - val_mae: 0.0210\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0390 - val_loss: 9.5517e-04 - val_mae: 0.0207\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0443 - val_loss: 9.4934e-04 - val_mae: 0.0206\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0369 - val_loss: 9.9978e-04 - val_mae: 0.0212\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0065 - mae: 0.0399 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0060 - mae: 0.0415 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0074 - mae: 0.0391 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0387 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0048 - mae: 0.0371 - val_loss: 9.6842e-04 - val_mae: 0.0209\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0412 - val_loss: 9.5058e-04 - val_mae: 0.0207\n",
            "3/3 [==============================] - 0s 6ms/step\n",
            "Model: \"sequential_36\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_432 (Dense)           (None, 40)                240       \n",
            "                                                                 \n",
            " dropout_396 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_433 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_397 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_434 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " dropout_398 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_435 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_399 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_436 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_400 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_437 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_401 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_438 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_402 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_439 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_403 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_440 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_404 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_441 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_405 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_442 (Dense)           (None, 40)                1640      \n",
            "                                                                 \n",
            " dropout_406 (Dropout)       (None, 40)                0         \n",
            "                                                                 \n",
            " dense_443 (Dense)           (None, 1)                 41        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 16681 (65.16 KB)\n",
            "Trainable params: 16681 (65.16 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n",
            "Epoch 1/350\n",
            "18/18 [==============================] - 3s 28ms/step - loss: 14.2113 - mae: 2.7586 - val_loss: 0.0256 - val_mae: 0.1189\n",
            "Epoch 2/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 4.0734 - mae: 1.5328 - val_loss: 0.0276 - val_mae: 0.1632\n",
            "Epoch 3/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 2.4005 - mae: 1.1009 - val_loss: 0.0044 - val_mae: 0.0604\n",
            "Epoch 4/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 1.3169 - mae: 0.8295 - val_loss: 0.0056 - val_mae: 0.0625\n",
            "Epoch 5/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.6561 - mae: 0.8608 - val_loss: 0.0048 - val_mae: 0.0617\n",
            "Epoch 6/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 1.1701 - mae: 0.7608 - val_loss: 0.0076 - val_mae: 0.0610\n",
            "Epoch 7/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.8727 - mae: 0.6594 - val_loss: 0.0042 - val_mae: 0.0431\n",
            "Epoch 8/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.5009 - mae: 0.5189 - val_loss: 0.0028 - val_mae: 0.0359\n",
            "Epoch 9/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.4744 - mae: 0.5173 - val_loss: 0.0020 - val_mae: 0.0299\n",
            "Epoch 10/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.3483 - mae: 0.4525 - val_loss: 0.0017 - val_mae: 0.0356\n",
            "Epoch 11/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4613 - mae: 0.4709 - val_loss: 0.0025 - val_mae: 0.0462\n",
            "Epoch 12/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3540 - mae: 0.4585 - val_loss: 0.0031 - val_mae: 0.0520\n",
            "Epoch 13/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3600 - mae: 0.4591 - val_loss: 0.0027 - val_mae: 0.0476\n",
            "Epoch 14/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3422 - mae: 0.4418 - val_loss: 0.0019 - val_mae: 0.0395\n",
            "Epoch 15/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2330 - mae: 0.3692 - val_loss: 0.0015 - val_mae: 0.0353\n",
            "Epoch 16/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2758 - mae: 0.3618 - val_loss: 0.0022 - val_mae: 0.0428\n",
            "Epoch 17/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2045 - mae: 0.3265 - val_loss: 0.0019 - val_mae: 0.0393\n",
            "Epoch 18/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.3492 - mae: 0.3907 - val_loss: 0.0022 - val_mae: 0.0426\n",
            "Epoch 19/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.2542 - mae: 0.3846 - val_loss: 0.0014 - val_mae: 0.0318\n",
            "Epoch 20/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.4807 - mae: 0.3957 - val_loss: 0.0011 - val_mae: 0.0248\n",
            "Epoch 21/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.2225 - mae: 0.3358 - val_loss: 0.0012 - val_mae: 0.0293\n",
            "Epoch 22/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1659 - mae: 0.2774 - val_loss: 9.8177e-04 - val_mae: 0.0245\n",
            "Epoch 23/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.2484 - mae: 0.3352 - val_loss: 0.0010 - val_mae: 0.0210\n",
            "Epoch 24/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.2511 - mae: 0.3660 - val_loss: 0.0011 - val_mae: 0.0211\n",
            "Epoch 25/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1538 - mae: 0.2759 - val_loss: 0.0011 - val_mae: 0.0210\n",
            "Epoch 26/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1320 - mae: 0.2664 - val_loss: 0.0011 - val_mae: 0.0214\n",
            "Epoch 27/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1259 - mae: 0.2615 - val_loss: 0.0011 - val_mae: 0.0211\n",
            "Epoch 28/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1029 - mae: 0.2239 - val_loss: 0.0011 - val_mae: 0.0218\n",
            "Epoch 29/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0923 - mae: 0.2210 - val_loss: 0.0011 - val_mae: 0.0215\n",
            "Epoch 30/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0902 - mae: 0.2225 - val_loss: 0.0010 - val_mae: 0.0211\n",
            "Epoch 31/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0965 - mae: 0.2312 - val_loss: 0.0011 - val_mae: 0.0247\n",
            "Epoch 32/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1053 - mae: 0.2330 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 33/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.1197 - mae: 0.2312 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 34/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0712 - mae: 0.1985 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 35/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0748 - mae: 0.1928 - val_loss: 0.0010 - val_mae: 0.0227\n",
            "Epoch 36/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0708 - mae: 0.2006 - val_loss: 9.8715e-04 - val_mae: 0.0231\n",
            "Epoch 37/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0905 - mae: 0.2140 - val_loss: 9.3925e-04 - val_mae: 0.0200\n",
            "Epoch 38/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0959 - mae: 0.2288 - val_loss: 9.9518e-04 - val_mae: 0.0211\n",
            "Epoch 39/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0554 - mae: 0.1679 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 40/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0735 - mae: 0.2023 - val_loss: 0.0010 - val_mae: 0.0211\n",
            "Epoch 41/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0529 - mae: 0.1858 - val_loss: 9.8655e-04 - val_mae: 0.0210\n",
            "Epoch 42/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0473 - mae: 0.1691 - val_loss: 0.0011 - val_mae: 0.0219\n",
            "Epoch 43/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0605 - mae: 0.1832 - val_loss: 0.0011 - val_mae: 0.0220\n",
            "Epoch 44/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.1371 - mae: 0.1754 - val_loss: 8.9678e-04 - val_mae: 0.0196\n",
            "Epoch 45/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0555 - mae: 0.1697 - val_loss: 9.6504e-04 - val_mae: 0.0206\n",
            "Epoch 46/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0424 - mae: 0.1522 - val_loss: 9.2750e-04 - val_mae: 0.0201\n",
            "Epoch 47/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0530 - mae: 0.1642 - val_loss: 8.9666e-04 - val_mae: 0.0197\n",
            "Epoch 48/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0416 - mae: 0.1538 - val_loss: 9.3150e-04 - val_mae: 0.0201\n",
            "Epoch 49/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0456 - mae: 0.1615 - val_loss: 9.8852e-04 - val_mae: 0.0207\n",
            "Epoch 50/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0510 - mae: 0.1712 - val_loss: 9.5893e-04 - val_mae: 0.0203\n",
            "Epoch 51/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0419 - mae: 0.1600 - val_loss: 9.3715e-04 - val_mae: 0.0202\n",
            "Epoch 52/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0463 - mae: 0.1524 - val_loss: 9.2834e-04 - val_mae: 0.0197\n",
            "Epoch 53/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0607 - mae: 0.1759 - val_loss: 0.0010 - val_mae: 0.0207\n",
            "Epoch 54/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0558 - mae: 0.1531 - val_loss: 0.0011 - val_mae: 0.0214\n",
            "Epoch 55/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0407 - mae: 0.1481 - val_loss: 0.0010 - val_mae: 0.0207\n",
            "Epoch 56/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0412 - mae: 0.1499 - val_loss: 0.0010 - val_mae: 0.0207\n",
            "Epoch 57/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0378 - mae: 0.1439 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 58/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0552 - mae: 0.1616 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 59/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0384 - mae: 0.1283 - val_loss: 0.0013 - val_mae: 0.0251\n",
            "Epoch 60/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0396 - mae: 0.1470 - val_loss: 0.0015 - val_mae: 0.0286\n",
            "Epoch 61/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0562 - mae: 0.1604 - val_loss: 0.0016 - val_mae: 0.0296\n",
            "Epoch 62/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0596 - mae: 0.1525 - val_loss: 0.0013 - val_mae: 0.0262\n",
            "Epoch 63/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0350 - mae: 0.1242 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 64/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0465 - mae: 0.1417 - val_loss: 0.0011 - val_mae: 0.0221\n",
            "Epoch 65/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0313 - mae: 0.1297 - val_loss: 0.0012 - val_mae: 0.0233\n",
            "Epoch 66/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0284 - mae: 0.1266 - val_loss: 0.0012 - val_mae: 0.0241\n",
            "Epoch 67/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0699 - mae: 0.1651 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 68/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0503 - mae: 0.1492 - val_loss: 0.0013 - val_mae: 0.0260\n",
            "Epoch 69/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0306 - mae: 0.1253 - val_loss: 0.0013 - val_mae: 0.0250\n",
            "Epoch 70/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0366 - mae: 0.1189 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 71/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0249 - mae: 0.1114 - val_loss: 0.0011 - val_mae: 0.0225\n",
            "Epoch 72/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0387 - mae: 0.1301 - val_loss: 0.0011 - val_mae: 0.0215\n",
            "Epoch 73/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0612 - mae: 0.1394 - val_loss: 0.0011 - val_mae: 0.0219\n",
            "Epoch 74/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0207 - mae: 0.1002 - val_loss: 0.0011 - val_mae: 0.0216\n",
            "Epoch 75/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0238 - mae: 0.1140 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 76/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0360 - mae: 0.1298 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 77/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0298 - mae: 0.1149 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 78/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0220 - mae: 0.1063 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 79/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0221 - mae: 0.1049 - val_loss: 0.0013 - val_mae: 0.0253\n",
            "Epoch 80/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.0945 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 81/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0304 - mae: 0.1028 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 82/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0284 - mae: 0.1066 - val_loss: 0.0013 - val_mae: 0.0255\n",
            "Epoch 83/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0218 - mae: 0.1122 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 84/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0144 - mae: 0.0871 - val_loss: 0.0015 - val_mae: 0.0286\n",
            "Epoch 85/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0209 - mae: 0.0925 - val_loss: 0.0014 - val_mae: 0.0274\n",
            "Epoch 86/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0212 - mae: 0.1032 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 87/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0175 - mae: 0.0958 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 88/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0262 - mae: 0.1165 - val_loss: 0.0015 - val_mae: 0.0294\n",
            "Epoch 89/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0191 - mae: 0.0974 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 90/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0730 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 91/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0132 - mae: 0.0824 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 92/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0182 - mae: 0.0996 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 93/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0201 - mae: 0.0929 - val_loss: 0.0012 - val_mae: 0.0253\n",
            "Epoch 94/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0295 - mae: 0.1012 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 95/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0190 - mae: 0.0859 - val_loss: 0.0015 - val_mae: 0.0285\n",
            "Epoch 96/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0121 - mae: 0.0822 - val_loss: 0.0015 - val_mae: 0.0296\n",
            "Epoch 97/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0218 - mae: 0.0959 - val_loss: 0.0015 - val_mae: 0.0286\n",
            "Epoch 98/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0146 - mae: 0.0778 - val_loss: 0.0014 - val_mae: 0.0275\n",
            "Epoch 99/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0159 - mae: 0.0909 - val_loss: 0.0014 - val_mae: 0.0280\n",
            "Epoch 100/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0219 - mae: 0.1065 - val_loss: 0.0015 - val_mae: 0.0286\n",
            "Epoch 101/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0191 - mae: 0.1022 - val_loss: 0.0016 - val_mae: 0.0306\n",
            "Epoch 102/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0177 - mae: 0.0895 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 103/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0375 - mae: 0.1062 - val_loss: 0.0014 - val_mae: 0.0272\n",
            "Epoch 104/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0158 - mae: 0.0839 - val_loss: 0.0013 - val_mae: 0.0260\n",
            "Epoch 105/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0197 - mae: 0.0913 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 106/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0198 - mae: 0.0976 - val_loss: 0.0011 - val_mae: 0.0223\n",
            "Epoch 107/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0198 - mae: 0.0969 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 108/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0214 - mae: 0.0963 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 109/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0129 - mae: 0.0749 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 110/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0169 - mae: 0.0777 - val_loss: 0.0011 - val_mae: 0.0220\n",
            "Epoch 111/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0120 - mae: 0.0725 - val_loss: 0.0011 - val_mae: 0.0217\n",
            "Epoch 112/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0217 - mae: 0.0977 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 113/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - mae: 0.0674 - val_loss: 0.0011 - val_mae: 0.0221\n",
            "Epoch 114/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0178 - mae: 0.0815 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 115/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0162 - mae: 0.0897 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 116/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0147 - mae: 0.0866 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 117/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0135 - mae: 0.0744 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 118/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0273 - mae: 0.0744 - val_loss: 0.0012 - val_mae: 0.0246\n",
            "Epoch 119/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0116 - mae: 0.0741 - val_loss: 0.0012 - val_mae: 0.0252\n",
            "Epoch 120/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0215 - mae: 0.0828 - val_loss: 0.0013 - val_mae: 0.0268\n",
            "Epoch 121/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0183 - mae: 0.0915 - val_loss: 0.0013 - val_mae: 0.0262\n",
            "Epoch 122/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0775 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 123/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0148 - mae: 0.0823 - val_loss: 0.0013 - val_mae: 0.0261\n",
            "Epoch 124/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0769 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 125/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0115 - mae: 0.0696 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 126/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0149 - mae: 0.0702 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 127/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0716 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 128/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0185 - mae: 0.0713 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 129/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0693 - val_loss: 9.8801e-04 - val_mae: 0.0210\n",
            "Epoch 130/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0111 - mae: 0.0770 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 131/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0114 - mae: 0.0740 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 132/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0160 - mae: 0.0873 - val_loss: 0.0011 - val_mae: 0.0240\n",
            "Epoch 133/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0100 - mae: 0.0717 - val_loss: 0.0013 - val_mae: 0.0260\n",
            "Epoch 134/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0121 - mae: 0.0690 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 135/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0122 - mae: 0.0742 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 136/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0122 - mae: 0.0703 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 137/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0677 - val_loss: 0.0012 - val_mae: 0.0249\n",
            "Epoch 138/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0748 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 139/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0698 - val_loss: 0.0012 - val_mae: 0.0243\n",
            "Epoch 140/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0106 - mae: 0.0697 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 141/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0161 - mae: 0.0796 - val_loss: 0.0013 - val_mae: 0.0266\n",
            "Epoch 142/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0179 - mae: 0.0686 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 143/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0110 - mae: 0.0653 - val_loss: 0.0014 - val_mae: 0.0284\n",
            "Epoch 144/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0136 - mae: 0.0651 - val_loss: 0.0015 - val_mae: 0.0289\n",
            "Epoch 145/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0121 - mae: 0.0624 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 146/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0628 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 147/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0087 - mae: 0.0617 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 148/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0616 - val_loss: 0.0012 - val_mae: 0.0245\n",
            "Epoch 149/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0126 - mae: 0.0641 - val_loss: 0.0011 - val_mae: 0.0234\n",
            "Epoch 150/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0120 - mae: 0.0652 - val_loss: 0.0011 - val_mae: 0.0224\n",
            "Epoch 151/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0090 - mae: 0.0614 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 152/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0101 - mae: 0.0604 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 153/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0130 - mae: 0.0679 - val_loss: 0.0013 - val_mae: 0.0271\n",
            "Epoch 154/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0128 - mae: 0.0770 - val_loss: 0.0014 - val_mae: 0.0282\n",
            "Epoch 155/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0107 - mae: 0.0693 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 156/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0100 - mae: 0.0682 - val_loss: 0.0014 - val_mae: 0.0277\n",
            "Epoch 157/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0098 - mae: 0.0593 - val_loss: 0.0015 - val_mae: 0.0295\n",
            "Epoch 158/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0102 - mae: 0.0706 - val_loss: 0.0013 - val_mae: 0.0263\n",
            "Epoch 159/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0097 - mae: 0.0653 - val_loss: 0.0013 - val_mae: 0.0269\n",
            "Epoch 160/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0589 - val_loss: 0.0014 - val_mae: 0.0285\n",
            "Epoch 161/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0580 - val_loss: 0.0015 - val_mae: 0.0298\n",
            "Epoch 162/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0081 - mae: 0.0647 - val_loss: 0.0014 - val_mae: 0.0286\n",
            "Epoch 163/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0730 - val_loss: 0.0015 - val_mae: 0.0291\n",
            "Epoch 164/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0117 - mae: 0.0617 - val_loss: 0.0016 - val_mae: 0.0305\n",
            "Epoch 165/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0072 - mae: 0.0499 - val_loss: 0.0017 - val_mae: 0.0312\n",
            "Epoch 166/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0121 - mae: 0.0717 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 167/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0113 - mae: 0.0620 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 168/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0105 - mae: 0.0665 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 169/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0520 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 170/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0541 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 171/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0079 - mae: 0.0582 - val_loss: 0.0012 - val_mae: 0.0244\n",
            "Epoch 172/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0088 - mae: 0.0553 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 173/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0098 - mae: 0.0625 - val_loss: 0.0013 - val_mae: 0.0262\n",
            "Epoch 174/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0584 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 175/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0062 - mae: 0.0502 - val_loss: 0.0012 - val_mae: 0.0256\n",
            "Epoch 176/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0564 - val_loss: 0.0012 - val_mae: 0.0257\n",
            "Epoch 177/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0094 - mae: 0.0620 - val_loss: 0.0014 - val_mae: 0.0283\n",
            "Epoch 178/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0559 - val_loss: 0.0014 - val_mae: 0.0278\n",
            "Epoch 179/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0523 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 180/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0085 - mae: 0.0565 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 181/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0070 - mae: 0.0495 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 182/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0081 - mae: 0.0551 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 183/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0086 - mae: 0.0579 - val_loss: 0.0011 - val_mae: 0.0231\n",
            "Epoch 184/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0086 - mae: 0.0507 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 185/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0496 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 186/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0554 - val_loss: 0.0012 - val_mae: 0.0254\n",
            "Epoch 187/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0084 - mae: 0.0516 - val_loss: 0.0012 - val_mae: 0.0259\n",
            "Epoch 188/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0507 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 189/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0502 - val_loss: 0.0011 - val_mae: 0.0233\n",
            "Epoch 190/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0155 - mae: 0.0678 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 191/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0078 - mae: 0.0540 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 192/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0068 - mae: 0.0496 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 193/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0435 - val_loss: 0.0012 - val_mae: 0.0242\n",
            "Epoch 194/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0053 - mae: 0.0433 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 195/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0083 - mae: 0.0552 - val_loss: 0.0011 - val_mae: 0.0241\n",
            "Epoch 196/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0123 - mae: 0.0565 - val_loss: 0.0012 - val_mae: 0.0255\n",
            "Epoch 197/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0082 - mae: 0.0490 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 198/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0410 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 199/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0089 - mae: 0.0535 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 200/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0090 - mae: 0.0509 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 201/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0060 - mae: 0.0460 - val_loss: 0.0011 - val_mae: 0.0242\n",
            "Epoch 202/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0077 - mae: 0.0492 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 203/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0539 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 204/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0089 - mae: 0.0524 - val_loss: 0.0011 - val_mae: 0.0230\n",
            "Epoch 205/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0065 - mae: 0.0479 - val_loss: 0.0011 - val_mae: 0.0232\n",
            "Epoch 206/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0074 - mae: 0.0480 - val_loss: 0.0012 - val_mae: 0.0247\n",
            "Epoch 207/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0064 - mae: 0.0518 - val_loss: 0.0011 - val_mae: 0.0238\n",
            "Epoch 208/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0082 - mae: 0.0509 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 209/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0425 - val_loss: 0.0012 - val_mae: 0.0250\n",
            "Epoch 210/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0083 - mae: 0.0484 - val_loss: 0.0012 - val_mae: 0.0258\n",
            "Epoch 211/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0061 - mae: 0.0418 - val_loss: 0.0011 - val_mae: 0.0239\n",
            "Epoch 212/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0505 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 213/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0039 - mae: 0.0392 - val_loss: 0.0011 - val_mae: 0.0228\n",
            "Epoch 214/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0076 - mae: 0.0502 - val_loss: 0.0010 - val_mae: 0.0220\n",
            "Epoch 215/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0080 - mae: 0.0499 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 216/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0066 - mae: 0.0471 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 217/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0064 - mae: 0.0477 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 218/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0073 - mae: 0.0512 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 219/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0457 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 220/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0068 - mae: 0.0467 - val_loss: 0.0012 - val_mae: 0.0248\n",
            "Epoch 221/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0060 - mae: 0.0430 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 222/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0056 - mae: 0.0437 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 223/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0428 - val_loss: 9.9561e-04 - val_mae: 0.0212\n",
            "Epoch 224/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0092 - mae: 0.0550 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 225/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0063 - mae: 0.0460 - val_loss: 0.0010 - val_mae: 0.0222\n",
            "Epoch 226/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0509 - val_loss: 0.0011 - val_mae: 0.0235\n",
            "Epoch 227/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0481 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 228/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0448 - val_loss: 9.8968e-04 - val_mae: 0.0211\n",
            "Epoch 229/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0083 - mae: 0.0490 - val_loss: 8.9591e-04 - val_mae: 0.0197\n",
            "Epoch 230/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0063 - mae: 0.0533 - val_loss: 9.3127e-04 - val_mae: 0.0204\n",
            "Epoch 231/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0440 - val_loss: 0.0010 - val_mae: 0.0217\n",
            "Epoch 232/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0440 - val_loss: 0.0011 - val_mae: 0.0227\n",
            "Epoch 233/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0073 - mae: 0.0478 - val_loss: 0.0011 - val_mae: 0.0237\n",
            "Epoch 234/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0452 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 235/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0439 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 236/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0072 - mae: 0.0515 - val_loss: 9.6863e-04 - val_mae: 0.0209\n",
            "Epoch 237/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0460 - val_loss: 9.7045e-04 - val_mae: 0.0209\n",
            "Epoch 238/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0471 - val_loss: 9.3338e-04 - val_mae: 0.0204\n",
            "Epoch 239/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0457 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 240/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0396 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 241/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0449 - val_loss: 9.6814e-04 - val_mae: 0.0209\n",
            "Epoch 242/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0074 - mae: 0.0458 - val_loss: 9.9054e-04 - val_mae: 0.0211\n",
            "Epoch 243/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0420 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 244/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0067 - mae: 0.0433 - val_loss: 9.4609e-04 - val_mae: 0.0206\n",
            "Epoch 245/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0471 - val_loss: 9.6220e-04 - val_mae: 0.0208\n",
            "Epoch 246/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0396 - val_loss: 9.5131e-04 - val_mae: 0.0207\n",
            "Epoch 247/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0066 - mae: 0.0430 - val_loss: 9.5780e-04 - val_mae: 0.0208\n",
            "Epoch 248/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0078 - mae: 0.0491 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 249/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0068 - mae: 0.0433 - val_loss: 0.0011 - val_mae: 0.0226\n",
            "Epoch 250/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0367 - val_loss: 0.0010 - val_mae: 0.0215\n",
            "Epoch 251/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0420 - val_loss: 9.5108e-04 - val_mae: 0.0207\n",
            "Epoch 252/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0056 - mae: 0.0415 - val_loss: 9.6782e-04 - val_mae: 0.0209\n",
            "Epoch 253/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0426 - val_loss: 9.7515e-04 - val_mae: 0.0210\n",
            "Epoch 254/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0069 - mae: 0.0504 - val_loss: 9.4887e-04 - val_mae: 0.0206\n",
            "Epoch 255/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0064 - mae: 0.0437 - val_loss: 0.0010 - val_mae: 0.0218\n",
            "Epoch 256/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0416 - val_loss: 0.0010 - val_mae: 0.0212\n",
            "Epoch 257/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0059 - mae: 0.0409 - val_loss: 9.7346e-04 - val_mae: 0.0209\n",
            "Epoch 258/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0432 - val_loss: 9.3337e-04 - val_mae: 0.0204\n",
            "Epoch 259/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0055 - mae: 0.0416 - val_loss: 9.3589e-04 - val_mae: 0.0204\n",
            "Epoch 260/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0372 - val_loss: 9.7578e-04 - val_mae: 0.0210\n",
            "Epoch 261/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0055 - mae: 0.0396 - val_loss: 0.0010 - val_mae: 0.0219\n",
            "Epoch 262/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0057 - mae: 0.0418 - val_loss: 0.0011 - val_mae: 0.0222\n",
            "Epoch 263/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0389 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 264/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0061 - mae: 0.0381 - val_loss: 9.9421e-04 - val_mae: 0.0212\n",
            "Epoch 265/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0404 - val_loss: 9.3789e-04 - val_mae: 0.0205\n",
            "Epoch 266/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0077 - mae: 0.0468 - val_loss: 9.2508e-04 - val_mae: 0.0203\n",
            "Epoch 267/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0407 - val_loss: 9.5612e-04 - val_mae: 0.0208\n",
            "Epoch 268/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0069 - mae: 0.0446 - val_loss: 9.2196e-04 - val_mae: 0.0202\n",
            "Epoch 269/350\n",
            "18/18 [==============================] - 0s 5ms/step - loss: 0.0073 - mae: 0.0444 - val_loss: 9.1444e-04 - val_mae: 0.0201\n",
            "Epoch 270/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0404 - val_loss: 9.4137e-04 - val_mae: 0.0205\n",
            "Epoch 271/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0064 - mae: 0.0429 - val_loss: 9.5760e-04 - val_mae: 0.0208\n",
            "Epoch 272/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0417 - val_loss: 9.3317e-04 - val_mae: 0.0204\n",
            "Epoch 273/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0378 - val_loss: 9.6808e-04 - val_mae: 0.0209\n",
            "Epoch 274/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0087 - mae: 0.0499 - val_loss: 9.1819e-04 - val_mae: 0.0201\n",
            "Epoch 275/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0377 - val_loss: 9.4635e-04 - val_mae: 0.0206\n",
            "Epoch 276/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0405 - val_loss: 9.1728e-04 - val_mae: 0.0201\n",
            "Epoch 277/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0355 - val_loss: 9.2828e-04 - val_mae: 0.0203\n",
            "Epoch 278/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0057 - mae: 0.0405 - val_loss: 9.4259e-04 - val_mae: 0.0206\n",
            "Epoch 279/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0388 - val_loss: 9.0699e-04 - val_mae: 0.0198\n",
            "Epoch 280/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0056 - mae: 0.0403 - val_loss: 9.2992e-04 - val_mae: 0.0203\n",
            "Epoch 281/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0411 - val_loss: 9.1332e-04 - val_mae: 0.0200\n",
            "Epoch 282/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0366 - val_loss: 9.4095e-04 - val_mae: 0.0205\n",
            "Epoch 283/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0066 - mae: 0.0397 - val_loss: 9.6442e-04 - val_mae: 0.0209\n",
            "Epoch 284/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0373 - val_loss: 9.0461e-04 - val_mae: 0.0197\n",
            "Epoch 285/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0448 - val_loss: 9.1931e-04 - val_mae: 0.0201\n",
            "Epoch 286/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0071 - mae: 0.0468 - val_loss: 9.4475e-04 - val_mae: 0.0206\n",
            "Epoch 287/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0065 - mae: 0.0394 - val_loss: 9.9906e-04 - val_mae: 0.0212\n",
            "Epoch 288/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0382 - val_loss: 0.0010 - val_mae: 0.0213\n",
            "Epoch 289/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0428 - val_loss: 9.7315e-04 - val_mae: 0.0210\n",
            "Epoch 290/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0347 - val_loss: 9.5196e-04 - val_mae: 0.0207\n",
            "Epoch 291/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0348 - val_loss: 9.2922e-04 - val_mae: 0.0203\n",
            "Epoch 292/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0054 - mae: 0.0376 - val_loss: 9.1554e-04 - val_mae: 0.0201\n",
            "Epoch 293/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0389 - val_loss: 9.2252e-04 - val_mae: 0.0202\n",
            "Epoch 294/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0376 - val_loss: 9.2553e-04 - val_mae: 0.0203\n",
            "Epoch 295/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0050 - mae: 0.0354 - val_loss: 9.6202e-04 - val_mae: 0.0208\n",
            "Epoch 296/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0401 - val_loss: 9.0596e-04 - val_mae: 0.0198\n",
            "Epoch 297/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0384 - val_loss: 9.0917e-04 - val_mae: 0.0199\n",
            "Epoch 298/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0400 - val_loss: 8.9953e-04 - val_mae: 0.0197\n",
            "Epoch 299/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0391 - val_loss: 9.2366e-04 - val_mae: 0.0202\n",
            "Epoch 300/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0050 - mae: 0.0367 - val_loss: 9.6656e-04 - val_mae: 0.0209\n",
            "Epoch 301/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0058 - mae: 0.0404 - val_loss: 9.3523e-04 - val_mae: 0.0204\n",
            "Epoch 302/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0047 - mae: 0.0337 - val_loss: 9.1921e-04 - val_mae: 0.0201\n",
            "Epoch 303/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0391 - val_loss: 9.2465e-04 - val_mae: 0.0202\n",
            "Epoch 304/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0057 - mae: 0.0388 - val_loss: 9.2747e-04 - val_mae: 0.0203\n",
            "Epoch 305/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0050 - mae: 0.0324 - val_loss: 0.0011 - val_mae: 0.0229\n",
            "Epoch 306/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0056 - mae: 0.0352 - val_loss: 9.9073e-04 - val_mae: 0.0211\n",
            "Epoch 307/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0055 - mae: 0.0360 - val_loss: 9.3931e-04 - val_mae: 0.0205\n",
            "Epoch 308/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0385 - val_loss: 9.0776e-04 - val_mae: 0.0198\n",
            "Epoch 309/350\n",
            "18/18 [==============================] - 0s 11ms/step - loss: 0.0047 - mae: 0.0367 - val_loss: 9.1474e-04 - val_mae: 0.0200\n",
            "Epoch 310/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0045 - mae: 0.0352 - val_loss: 9.1270e-04 - val_mae: 0.0200\n",
            "Epoch 311/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0043 - mae: 0.0373 - val_loss: 9.8219e-04 - val_mae: 0.0211\n",
            "Epoch 312/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0323 - val_loss: 9.6265e-04 - val_mae: 0.0208\n",
            "Epoch 313/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0054 - mae: 0.0373 - val_loss: 9.6789e-04 - val_mae: 0.0209\n",
            "Epoch 314/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0370 - val_loss: 9.4901e-04 - val_mae: 0.0206\n",
            "Epoch 315/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - mae: 0.0382 - val_loss: 9.1705e-04 - val_mae: 0.0201\n",
            "Epoch 316/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0370 - val_loss: 9.0836e-04 - val_mae: 0.0198\n",
            "Epoch 317/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0058 - mae: 0.0372 - val_loss: 9.4054e-04 - val_mae: 0.0205\n",
            "Epoch 318/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0059 - mae: 0.0371 - val_loss: 9.6875e-04 - val_mae: 0.0209\n",
            "Epoch 319/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0052 - mae: 0.0393 - val_loss: 9.0461e-04 - val_mae: 0.0202\n",
            "Epoch 320/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0062 - mae: 0.0404 - val_loss: 9.2250e-04 - val_mae: 0.0202\n",
            "Epoch 321/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0057 - mae: 0.0376 - val_loss: 9.6321e-04 - val_mae: 0.0208\n",
            "Epoch 322/350\n",
            "18/18 [==============================] - 0s 10ms/step - loss: 0.0048 - mae: 0.0362 - val_loss: 9.6644e-04 - val_mae: 0.0209\n",
            "Epoch 323/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0052 - mae: 0.0365 - val_loss: 9.3036e-04 - val_mae: 0.0203\n",
            "Epoch 324/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0047 - mae: 0.0330 - val_loss: 9.5805e-04 - val_mae: 0.0208\n",
            "Epoch 325/350\n",
            "18/18 [==============================] - 0s 9ms/step - loss: 0.0059 - mae: 0.0377 - val_loss: 9.5688e-04 - val_mae: 0.0207\n",
            "Epoch 326/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0053 - mae: 0.0352 - val_loss: 0.0010 - val_mae: 0.0214\n",
            "Epoch 327/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0343 - val_loss: 9.4597e-04 - val_mae: 0.0206\n",
            "Epoch 328/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0051 - mae: 0.0388 - val_loss: 9.1567e-04 - val_mae: 0.0201\n",
            "Epoch 329/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0053 - mae: 0.0366 - val_loss: 9.1258e-04 - val_mae: 0.0200\n",
            "Epoch 330/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0386 - val_loss: 9.5088e-04 - val_mae: 0.0207\n",
            "Epoch 331/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0060 - mae: 0.0396 - val_loss: 9.1367e-04 - val_mae: 0.0200\n",
            "Epoch 332/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0363 - val_loss: 8.9935e-04 - val_mae: 0.0197\n",
            "Epoch 333/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0062 - mae: 0.0395 - val_loss: 9.0781e-04 - val_mae: 0.0198\n",
            "Epoch 334/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0054 - mae: 0.0371 - val_loss: 9.6929e-04 - val_mae: 0.0209\n",
            "Epoch 335/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0059 - mae: 0.0347 - val_loss: 9.0516e-04 - val_mae: 0.0197\n",
            "Epoch 336/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0051 - mae: 0.0361 - val_loss: 9.1654e-04 - val_mae: 0.0201\n",
            "Epoch 337/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0346 - val_loss: 9.5781e-04 - val_mae: 0.0208\n",
            "Epoch 338/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0067 - mae: 0.0402 - val_loss: 9.6985e-04 - val_mae: 0.0209\n",
            "Epoch 339/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0052 - mae: 0.0348 - val_loss: 9.4993e-04 - val_mae: 0.0207\n",
            "Epoch 340/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0367 - val_loss: 9.5815e-04 - val_mae: 0.0208\n",
            "Epoch 341/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0049 - mae: 0.0341 - val_loss: 9.1424e-04 - val_mae: 0.0200\n",
            "Epoch 342/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0341 - val_loss: 9.1645e-04 - val_mae: 0.0201\n",
            "Epoch 343/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0053 - mae: 0.0360 - val_loss: 9.4482e-04 - val_mae: 0.0206\n",
            "Epoch 344/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0058 - mae: 0.0332 - val_loss: 9.0317e-04 - val_mae: 0.0197\n",
            "Epoch 345/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0049 - mae: 0.0342 - val_loss: 8.9946e-04 - val_mae: 0.0197\n",
            "Epoch 346/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0045 - mae: 0.0314 - val_loss: 9.0312e-04 - val_mae: 0.0197\n",
            "Epoch 347/350\n",
            "18/18 [==============================] - 0s 8ms/step - loss: 0.0049 - mae: 0.0323 - val_loss: 9.0545e-04 - val_mae: 0.0197\n",
            "Epoch 348/350\n",
            "18/18 [==============================] - 0s 6ms/step - loss: 0.0052 - mae: 0.0350 - val_loss: 9.1929e-04 - val_mae: 0.0201\n",
            "Epoch 349/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0043 - mae: 0.0316 - val_loss: 9.1969e-04 - val_mae: 0.0202\n",
            "Epoch 350/350\n",
            "18/18 [==============================] - 0s 7ms/step - loss: 0.0051 - mae: 0.0351 - val_loss: 9.4016e-04 - val_mae: 0.0205\n",
            "3/3 [==============================] - 0s 4ms/step\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/numpy/core/fromnumeric.py:3430: FutureWarning: In a future version, DataFrame.mean(axis=None) will return a scalar mean over the entire DataFrame. To retain the old behavior, use 'frame.mean(axis=0)' or just 'frame.mean()'\n",
            "  return mean(axis=axis, dtype=dtype, out=out, **kwargs)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, len(funcoes)):\n",
        "  for j in range(0, len(taxas)):\n",
        "    plt.plot(resultados_a[j]['loss'])\n",
        "    plt.plot(resultados_a[j]['val_loss'])\n",
        "  plt.title(funcoes[i])\n",
        "  plt.ylabel('Loss (MSE)')\n",
        "  plt.xlabel('Épocas de treinamento')\n",
        "  plt.legend(['0.005 (loss)', '0.01 (loss)', '0.05 (loss)', '0.005 (val_loss)', '0.01 (val_loss)', '0.05 (val_loss)'])\n",
        "  plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "CwYqxXzrTN58",
        "outputId": "c122db02-c1d6-4a01-fc78-d3b0e8fc7f64"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAHJCAYAAABtzYa7AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACkY0lEQVR4nOzdd3hUVfrA8e/MZGYy6SEhFUhCDxA6oSqWQEBFsSKLS5HFXVDRRVGxACu6iJQfUgRlRXEFQSysBZGy4FICSO89JEBI78kkk5m5vz+GDAwpEAgzlPfzPPPI3HvOuWeGLHn3nPeco1IURUEIIYQQ4g6idnUHhBBCCCGcTQIgIYQQQtxxJAASQgghxB1HAiAhhBBC3HEkABJCCCHEHUcCICGEEELccSQAEkIIIcQdRwIgIYQQQtxxJAASQgghxB1HAiAhxE1p6NChREZGurob1Tp9+jQqlYovvvjiimVvhc8jxJ1EAiAhhBBC3HHcXN0BIYSozIIFC7Bara7uRrUiIiIwGo1otVpXd0UIUUMSAAkhbkq3QlChUqlwd3d3dTeEENdApsCEEC5RUFDAyy+/TGRkJHq9nqCgIHr16sWuXbuAynNmsrKy+POf/4yPjw9+fn4MGTKEvXv3VsjDGTp0KF5eXiQnJ/PQQw/h5eVFeHg4c+fOBWD//v3cd999eHp6EhERwZIlSyr079SpUzz55JPUqVMHDw8PunTpwi+//OJQpqocoBUrVtCqVSvc3d1p1aoVP/zww/V/YUKIWiUBkBDCJf72t78xb948Hn/8cT7++GNeffVVDAYDhw8frrS81WqlX79+fP311wwZMoT333+f8+fPM2TIkErLWywW+vbtS/369fnwww+JjIzkhRde4IsvvqBPnz507NiRKVOm4O3tzeDBg0lMTLTXTUtLo1u3bvz222+MGjWK999/n5KSEh5++OErBjOrV6/m8ccfR6VSMXnyZPr378+wYcPYsWPHtX9ZQojapwghhAv4+voqzz//fJX3hwwZokRERNjff/fddwqgzJw5037NYrEo9913nwIon3/+uUNdQPnnP/9pv5aTk6MYDAZFpVIpS5cutV8/cuSIAigTJkywX3v55ZcVQNm4caP9WkFBgRIVFaVERkYqFotFURRFSUxMrPDstm3bKqGhoUpubq792urVqxXA4fMIIVxLRoCEEC7h5+fHtm3bSElJuaryq1atQqvVMmLECPs1tVrN888/X2Wdv/zlLw7Pa9asGZ6enjz11FP2682aNcPPz49Tp07Zr61cuZLY2Fh69Ohhv+bl5cVzzz3H6dOnOXToUKXPO3/+PHv27GHIkCH4+vrar/fq1YsWLVpc1ecUQjiHBEBCCJf48MMPOXDgAPXr1yc2NpaJEyc6BCGXS0pKIjQ0FA8PD4frjRs3rrS8u7s7devWdbjm6+tLvXr1UKlUFa7n5OQ4PKtZs2YV2oyOjrbfr6qPAE2aNKlwr7L2hBCuIwGQEMIlnnrqKU6dOsXs2bMJCwtj6tSptGzZkl9//bVW2tdoNDW6rihKrTxXCHFrkABICOEyoaGhjBo1ihUrVpCYmEhAQADvv/9+pWUjIiI4f/48xcXFDtdPnDhR6/2KiIjg6NGjFa4fOXLEfr+qegDHjx+vcK+y9oQQriMBkBDC6SwWC3l5eQ7XgoKCCAsLo7S0tNI68fHxlJWVsWDBAvs1q9VqX9pemx544AG2b99OQkKC/VpRURGffvopkZGRVebzhIaG0rZtWxYtWuTw+dasWVNl3pAQwjVkI0QhhNMVFBRQr149nnjiCdq0aYOXlxdr167ljz/+YPr06ZXW6d+/P7GxsbzyyiucOHGC5s2b8+OPP5KdnQ1QIa/nerzxxht8/fXX9O3bl9GjR1OnTh0WLVpEYmIi3333HWp11f/fcfLkyTz44IP06NGDZ599luzsbGbPnk3Lli0pLCystT4KIa6PjAAJIZzOw8ODUaNGsWfPHiZMmMDf//53jh49yscff8yYMWMqraPRaPjll18YMGAAixYt4q233iIsLMw+AlSbOzIHBwezZcsWevXqxezZsxk3bhw6nY6ffvqJRx99tNq6ffr0Yfny5VgsFsaNG8f333/P559/TseOHWutf0KI66dSJPNPCHELW7FiBY8++iibNm2ie/furu6OEOIWIQGQEOKWYTQaMRgM9vcWi4XevXuzY8cOUlNTHe4JIUR1JAdICHHLePHFFzEajXTt2pXS0lK+//57tmzZwj//+U8JfoQQNSIjQEKIW8aSJUuYPn06J06coKSkhMaNGzNy5EheeOEFV3dNCHGLkQBICCGEEHccWQUmhBBCiDuOBEBCCCGEuONIEnQlrFYrKSkpeHt71+rmakIIIYS4cRRFoaCggLCwsGo3LAUJgCqVkpJC/fr1Xd0NIYQQQlyDM2fOUK9evWrLSABUCW9vb8D2Bfr4+Li4N0IIIYS4Gvn5+dSvX9/+e7w6EgBVonzay8fHRwIgIYQQ4hZzNekrkgQthBBCiDuOBEBCCCGEuONIACSEEEKIO47kAAkhhLguFouFsrIyV3dD3AG0Wi0ajaZW2pIASAghxDVRFIXU1FRyc3Nd3RVxB/Hz8yMkJOS69+mTAEgIIcQ1KQ9+goKC8PDwkI1jxQ2lKArFxcWkp6cDEBoael3tSQAkhBCixiwWiz34CQgIcHV3xB3CYDAAkJ6eTlBQ0HVNh0kStBBCiBorz/nx8PBwcU/Enab8Z+56884kABJCCHHNZNpLOFtt/cxJACSEEEKIO44EQEIIIcRNbt26dURHR2OxWACYOHEibdu2dcqzu3TpwnfffeeUZzmTBEBCCCHuOHPnziUyMhJ3d3c6d+7M9u3br1hn+fLlNG/eHHd3d2JiYli5cqXDfUVRGD9+PKGhoRgMBuLi4jh+/LhDmcjISFQqlcPrgw8+uOKzX3vtNd5+++1a2wOnJt5++23eeOMNrFar0599I0kA5EQFJWWczSkmu8jk6q4IIcQda9myZYwZM4YJEyawa9cu2rRpQ3x8vH15dWW2bNnCwIEDGT58OLt376Z///7079+fAwcO2Mt8+OGHzJo1i/nz57Nt2zY8PT2Jj4+npKTEoa13332X8+fP218vvvhitf3dtGkTJ0+e5PHHH7++D36N+vbtS0FBAb/++qtLnn+jSADkRF8mJNFjynqm/HrE1V0RQog71owZMxgxYgTDhg2jRYsWzJ8/Hw8PDxYuXFhlnY8++og+ffowduxYoqOjmTRpEu3bt2fOnDmAbfRn5syZvP322zzyyCO0bt2aL7/8kpSUFFasWOHQlre3NyEhIfaXp6dntf1dunQpvXr1wt3dvcoyVquVd999l3r16qHX62nbti2rVq2y3zeZTLzwwguEhobi7u5OREQEkydPtvd94sSJNGjQAL1eT1hYGKNHj7bX1Wg0PPDAAyxdurTaft5qJAByIo3alrluURQX90QIIWqfoigUm8xOfyk1+DfVZDKxc+dO4uLi7NfUajVxcXEkJCRUWS8hIcGhDkB8fLy9TmJiIqmpqQ5lfH196dy5c4V2P/jgAwICAmjXrh1Tp07FbDZX2+eNGzfSsWPHast89NFHTJ8+nWnTprFv3z7i4+N5+OGH7VNws2bN4scff+Sbb77h6NGjLF68mMjISAC+++47/u///o9PPvmE48ePs2LFCmJiYhzaj42NZePGjdX24VYjGyE6kebC0j2LVQIgIcTtx1hmocX435z+3EPvxuOhu7pfZ5mZmVgsFoKDgx2uBwcHc+RI1aPzqampldZJTU213y+/VlUZgNGjR9O+fXvq1KnDli1bGDduHOfPn2fGjBlVPjspKYmwsLBqP9e0adN4/fXXefrppwGYMmUK69evZ+bMmcydO5fk5GSaNGlCjx49UKlURERE2OsmJycTEhJCXFwcWq2WBg0aEBsb69B+WFgYZ86cwWq1olbfHmMnt8enuEXYR4AkABJCiDvSmDFjuOeee2jdujV/+9vfmD59OrNnz6a0tLTKOkajsdrpr/z8fFJSUujevbvD9e7du3P48GEAhg4dyp49e2jWrBmjR49m9erV9nJPPvkkRqORhg0bMmLECH744YcKo1IGgwGr1VptP281MgLkRBIACSFuZwathkPvxrvkuVcrMDAQjUZDWlqaw/W0tDRCQkKqrBcSElJtnfL/pqWlOZxRlZaWVu1y9c6dO2M2mzl9+jTNmjWrss85OTnVfq4rad++PYmJifz666+sXbuWp556iri4OL799lvq16/P0aNHWbt2LWvWrGHUqFFMnTqV33//Ha1WC0B2djaenp72oyhuBzIC5ERqCYCEELcxlUqFh87N6a+a7Ays0+no0KED69ats1+zWq2sW7eOrl27Vlmva9euDnUA1qxZY68TFRVFSEiIQ5n8/Hy2bdtWbbt79uxBrVYTFBRUZZl27dpx6NChKu/7+PgQFhbG5s2bHa5v3ryZFi1aOJQbMGAACxYsYNmyZXz33XdkZ2cDthGefv36MWvWLDZs2EBCQgL79++31z1w4ADt2rWrsg+3IhkBciI3SYIWQgiXGzNmDEOGDKFjx47ExsYyc+ZMioqKGDZsmL3M4MGDCQ8Pt6+Ueumll+jZsyfTp0/nwQcfZOnSpezYsYNPP/0UsAV/L7/8Mu+99x5NmjQhKiqKd955h7CwMPr37w/YEqm3bdvGvffei7e3NwkJCfz973/nmWeewd/fv8r+xsfHs2jRomo/09ixY5kwYQKNGjWibdu2fP755+zZs4fFixcDtpVvoaGhtGvXDrVazfLlywkJCcHPz48vvvgCi8VC586d8fDw4KuvvsJgMDjkCW3cuJHevXtf0/d9s5IAyIkkCVoIIVxvwIABZGRkMH78eFJTU+1Lxi9NYE5OTnZI9u3WrRtLlizh7bff5s0336RJkyasWLGCVq1a2cu89tprFBUV8dxzz5Gbm0uPHj1YtWqVPX9Hr9ezdOlSJk6cSGlpKVFRUfz9739nzJgx1fZ30KBBvPbaaxw9erTKabLRo0eTl5fHK6+8Qnp6Oi1atODHH3+kSZMmgG3p/Ycffsjx48fRaDR06tSJlStXolar8fPz44MPPmDMmDFYLBZiYmL46aefCAgIAODcuXNs2bKFr7766tq+8JuUSqnJ+sE7RH5+Pr6+vuTl5eHj41Nr7X638yyvLN9Lz6Z1WfRs7JUrCCHETaqkpITExESioqKqTdAVtWPs2LHk5+fzySefOP3Zr7/+Ojk5OfbRLler7mevJr+/JQfIiSQJWgghxLV46623iIiIcMlxFEFBQUyaNMnpz73RZArMiSQJWgghxLXw8/PjzTffdMmzX3nlFZc890aTESAncpMASAghhLgpSADkRGqVrAITQgghbgYSADmRjAAJIYQQNwcJgJxIkqCFEEKIm4MEQE4kAZAQQghxc7gpAqC5c+cSGRmJu7s7nTt3Zvv27VWW/f777+nYsSN+fn54enrStm1b/v3vfzuUURSF8ePHExoaisFgIC4ujuPHj9/oj3FFEgAJIYQQNweXB0DLli1jzJgxTJgwgV27dtGmTRvi4+NJT0+vtHydOnV46623SEhIYN++fQwbNoxhw4bx22+/2ct8+OGHzJo1i/nz57Nt2zY8PT2Jj4+npKTEWR+rUpIELYQQQtwcXB4AzZgxgxEjRjBs2DBatGjB/Pnz8fDwYOHChZWWv+eee3j00UeJjo6mUaNGvPTSS7Ru3ZpNmzYBttGfmTNn8vbbb/PII4/QunVrvvzyS1JSUlixYoUTP1lFbhpbAGSVESAhhBAXmEwmGjduzJYtWwA4ffo0KpWKPXv23PBnz58/n379+t3w59yMXBoAmUwmdu7cSVxcnP2aWq0mLi6OhISEK9ZXFIV169Zx9OhR7r77bgASExNJTU11aNPX15fOnTtfVZs3UvkIkFkCICGEcKmapF6UW758Oc2bN8fd3Z2YmBhWrlzpcP/777+nd+/eBAQE1CiAmT9/PlFRUXTr1u1aPsp1efbZZ9m1axcbN250+rNdzaUBUGZmJhaLxeEAOoDg4GBSU1OrrJeXl4eXlxc6nY4HH3yQ2bNn06tXLwB7vZq0WVpaSn5+vsPrRpBl8EII4Xo1Tb0A2LJlCwMHDmT48OHs3r2b/v37079/fw4cOGAvU1RURI8ePZgyZcpV90VRFObMmcPw4cOv6zNdK51Ox5/+9CdmzZrlkue7ksunwK6Ft7c3e/bs4Y8//uD9999nzJgxbNiw4Zrbmzx5Mr6+vvZX/fr1a6+zl5AkaCGEcL2apl4AfPTRR/Tp04exY8cSHR3NpEmTaN++PXPmzLGX+fOf/8z48eMdZiCuZOfOnZw8eZIHH3yw2nK///47sbGx6PV6QkNDeeONNzCbzfb73377LTExMRgMBgICAoiLi6OoqAiADRs2EBsbi6enJ35+fnTv3p2kpCR73X79+vHjjz9iNBqvut+3A5cGQIGBgWg0GtLS0hyup6WlERISUmU9tVpN48aNadu2La+88gpPPPEEkydPBrDXq0mb48aNIy8vz/46c+bM9XysqvstSdBCiNuZooCpyPmvGvybeq2pFwkJCRUCm/j4+OtOrdi4cSNNmzbF29u7yjLnzp3jgQceoFOnTuzdu5d58+bx2Wef8d577wFw/vx5Bg4cyLPPPsvhw4fZsGEDjz32GIqiYDab6d+/Pz179mTfvn0kJCTw3HPPobrw+wigY8eOmM1mtm3bdl2f5Vbj0sNQdTodHTp0YN26dfTv3x8Aq9XKunXreOGFF666HavVSmlpKQBRUVGEhISwbt062rZtC0B+fj7btm1j5MiRldbX6/Xo9frr+ixXozwJWkaAhBC3pbJi+GeY85/7ZgroPK+qaHWpF0eOHKmyXmpqao3TNa5GUlISYWHVf2cff/wx9evXZ86cOahUKpo3b05KSgqvv/4648eP5/z585jNZh577DEiIiIAiImJASA7O5u8vDweeughGjVqBEB0dLRD+x4eHvj6+jqMCt0JXH4a/JgxYxgyZAgdO3YkNjaWmTNnUlRUxLBhwwAYPHgw4eHh9hGeyZMn07FjRxo1akRpaSkrV67k3//+N/PmzQNApVLx8ssv895779GkSROioqJ45513CAsLswdZrmIfAZIASAghBGA0GnF3d6+2zOHDh+natavDqE337t0pLCzk7NmztGnThvvvv5+YmBji4+Pp3bs3TzzxBP7+/tSpU4ehQ4cSHx9Pr169iIuL46mnniI0NNThGQaDgeLi4hvyGW9WLg+ABgwYQEZGBuPHjyc1NZW2bduyatUqe6SdnJyMWn1xpq6oqIhRo0Zx9uxZDAYDzZs356uvvmLAgAH2Mq+99hpFRUU899xz5Obm0qNHD1atWnXFH7IbrTwJWpbBCyFuS1oP22iMK557la419SIkJKTGda62P/v377+uNjQaDWvWrGHLli2sXr2a2bNn89Zbb7Ft2zaioqL4/PPPGT16NKtWrWLZsmW8/fbbrFmzhi5dutjbyM7Opm7dutfVj1uOIirIy8tTACUvL69W203OKlIiXv9Zaf72r7XarhBCOJvRaFQOHTqkGI1GV3elxmJjY5UXXnjB/t5isSjh4eHK5MmTq6zz1FNPKQ899JDDta5duyp//etfK5RNTExUAGX37t1X7Mvy5csVf39/xWq1Vln/zTffVJo1a+ZQZu7cuYq3t7disVgqtGk2m5Xw8HBl+vTplT6zS5cuyosvvmh/f+LECQVQTpw4ccX+3gyq+9mrye/vW3IV2K3KvgpMkqCFEMJlxowZw4IFC1i0aBGHDx9m5MiRDqkXYEu/GDdunP39Sy+9xKpVq5g+fTpHjhxh4sSJ7NixwyFfNTs7mz179nDo0CEAjh49yp49e6rNE7r33nspLCzk4MGDVZYZNWoUZ86c4cUXX+TIkSP85z//YcKECYwZMwa1Ws22bdv45z//yY4dO0hOTub7778nIyOD6OhoEhMTGTduHAkJCSQlJbF69WqOHz/ukAe0ceNGGjZsaM8RumPciOjsVnejRoBS84xKxOs/Kw3H/VKr7QohhLPdyiNAiqIos2fPVho0aKDodDolNjZW2bp1q8P9nj17KkOGDHG49s033yhNmzZVdDqd0rJlS+WXXxz/Lf/8888VoMJrwoQJ1fblqaeeUt544w37+8pGkDZs2KB06tRJ0el0SkhIiPL6668rZWVliqIoyqFDh5T4+Hilbt26il6vV5o2barMnj1bURRFSU1NVfr376+EhoYqOp1OiYiIUMaPH+8wctS7d+9qR79uNrU1AqRSFBmOuFx+fj6+vr7k5eXh4+NTa+1mFJTS6f21AJz+oPo9H4QQ4mZWUlJCYmIiUVFRLs+vvNXt27ePXr16cfLkSby8vJz67IMHD3Lfffdx7NgxfH19nfrsa1Xdz15Nfn/LFJgTlSdBgyRCCyGEsGndujVTpkwhMTHR6c8+f/48X3755S0T/NQml68Cu5OoLwmAzFYF3SXvhRBC3LmGDh3qkufWZNfq242MADmRwwiQzDwKIYQQLiMBkBNpLhsBEkIIIYRrSADkROpLdvGU3aCFEEII15EAyIkunQKTAEgIIYRwHQmAnEgtAZAQQghxU5AAyMns54FJErQQQgjhMhIAOVn5KJAkQQshhBCuIwGQk8mJ8EIIIS6VlZVFUFAQp0+fBmDDhg2oVCpyc3Nv+LPfeOMNXnzxxRv+nJuRBEBOplHJCJAQQrja3LlziYyMxN3dnc6dO7N9+/Yr1lm+fDnNmzfH3d2dmJgYVq5c6XB/6NChqFQqh1efPn2u2O7777/PI488QmRk5LV+nGv26quvsmjRIk6dOuX0Z7uaBEBOVj4FJknQQgjhGsuWLWPMmDFMmDCBXbt20aZNG+Lj40lPT6+yzpYtWxg4cCDDhw9n9+7d9O/fn/79+3PgwAGHcn369OH8+fP219dff11tX4qLi/nss88YPnx4rXy2mgoMDCQ+Pp558+a55PmuJAGQk0kStBBCuNaMGTMYMWIEw4YNo0WLFsyfPx8PDw8WLlxYZZ2PPvqIPn36MHbsWKKjo5k0aRLt27dnzpw5DuX0ej0hISH2l7+/f7V9WblyJXq9ni5dulRb7rvvvqNly5bo9XoiIyOZPn26w/2PP/6YJk2a4O7uTnBwME888YT93rfffktMTAwGg4GAgADi4uIoKiqy3+/Xrx9Lly6t9vm3IzkLzMnsSdAWCYCEELcXRVEwmo1Of67BzYBKdXVnK5pMJnbu3Mm4cePs19RqNXFxcSQkJFRZLyEhgTFjxjhci4+PZ8WKFQ7XNmzYQFBQEP7+/tx333289957BAQEVNnuxo0b6dChQ7V93rlzJ0899RQTJ05kwIABbNmyhVGjRhEQEMDQoUPZsWMHo0eP5t///jfdunUjOzubjRs3ArbDTgcOHMiHH37Io48+SkFBARs3bkS55P+Ex8bGcvbsWU6fPu2SaThXkQDIyWQESAhxuzKajXRe0tnpz932p214aD2uqmxmZiYWi4Xg4GCH68HBwRw5cqTKeqmpqZXWSU1Ntb/v06cPjz32GFFRUZw8eZI333yTvn37kpCQgEajqbTdpKQkwsLCqu3zjBkzuP/++3nnnXcAaNq0KYcOHWLq1KkMHTqU5ORkPD09eeihh/D29iYiIoJ27doBtgDIbDbz2GOPERERAUBMTIxD++XPT0pKuqMCIJkCczK1JEELIcRt6emnn+bhhx8mJiaG/v378/PPP/PHH3+wYcOGKusYjUbc3d2rbffw4cN0797d4Vr37t05fvw4FouFXr16ERERQcOGDfnzn//M4sWLKS4uBqBNmzbcf//9xMTE8OSTT7JgwQJycnIc2jIYDAD2OncKGQFyMo0kQQshblMGNwPb/rTNJc+9WoGBgWg0GtLS0hyup6WlERISUmW9kJCQGtdp2LAhgYGBnDhxgvvvv7/K/lwekNSUt7c3u3btYsOGDaxevZrx48czceJE/vjjD/z8/FizZg1btmxh9erVzJ49m7feeott27YRFRUFQHZ2NgB169a9rn7camQEyMncJAASQtymVCoVHloPp7+uNv8HQKfT0aFDB9atW2e/ZrVaWbduHV27dq2yXteuXR3qAKxZs6baOmfPniUrK4vQ0NAqy7Rr145Dhw5V2+fo6Gg2b97scG3z5s00bdrUPrXm5uZGXFwcH374Ifv27eP06dP897//BWx/L927d+cf//gHu3fvRqfT8cMPP9jbOnDgAFqtlpYtW1bbj9uNjAA5mSyDF0II1xozZgxDhgyhY8eOxMbGMnPmTIqKihg2bJi9zODBgwkPD2fy5MkAvPTSS/Ts2ZPp06fz4IMPsnTpUnbs2MGnn34KQGFhIf/4xz94/PHHCQkJ4eTJk7z22ms0btyY+Pj4KvsSHx/PuHHjyMnJqXLF2CuvvEKnTp2YNGkSAwYMICEhgTlz5vDxxx8D8PPPP3Pq1Cnuvvtu/P39WblyJVarlWbNmrFt2zbWrVtH7969CQoKYtu2bWRkZBAdHW1vf+PGjdx11132qbA7hiIqyMvLUwAlLy+v1tuO/7/flYjXf1Y2Hc+o9baFEMJZjEajcujQIcVoNLq6K9dk9uzZSoMGDRSdTqfExsYqW7dudbjfs2dPZciQIQ7XvvnmG6Vp06aKTqdTWrZsqfzyyy/2e8XFxUrv3r2VunXrKlqtVomIiFBGjBihpKamXrEvsbGxyvz58+3v169frwBKTk6O/dq3336rtGjRQtFqtUqDBg2UqVOn2u9t3LhR6dmzp+Lv768YDAaldevWyrJlyxRFUZRDhw4p8fHxSt26dRW9Xq80bdpUmT17tsPzmzVrpnz99ddX7OfNorqfvZr8/lYpiixHulx+fj6+vr7k5eXh4+NTq20/8NFGDp3PZ9GzsfRsemfNtwohbh8lJSUkJiYSFRV1xSReUb1ffvmFsWPHcuDAAdRq52am/Prrr7zyyivs27cPN7dbY1Koup+9mvz+vjU+7W3ETSNngQkhhLjowQcf5Pjx45w7d4769es79dlFRUV8/vnnt0zwU5vuvE/sYrIMXgghxOVefvlllzz30h2j7zSyCszJZBm8EEII4XoSADmZRnaCFkIIIVxOAiAn08gUmBBCCOFyEgA5mSRBCyGEEK4nAZCTSRK0EEII4XoSADmZPQdIAiAhhBDCZSQAcrLyAEhGgIQQQgjXkQDIycqToC2yCkwIIcRVWrduHdHR0Vgsllprc+jQofTv3/+qyt5zzz1O2asoMzOToKAgzp49e8OfJQGQk2kkCVoIIVxu7ty5REZG4u7uTufOndm+ffsV6yxfvpzmzZvj7u5OTEwMK1eudLivKArjx48nNDQUg8FAXFwcx48fdygTGRmJSqVyeH3wwQdXfPZrr73G22+/bT/9/XYVGBjI4MGDmTBhwg1/lgRATibL4IUQwrWWLVvGmDFjmDBhArt27aJNmzbEx8eTnp5eZZ0tW7YwcOBAhg8fzu7du+nfvz/9+/fnwIED9jIffvghs2bNYv78+Wzbtg1PT0/i4+MpKSlxaOvdd9/l/Pnz9teLL75YbX83bdrEyZMnefzxx6/vg98ihg0bxuLFi8nOzr6hz5EAyMncJAlaCCFcasaMGYwYMYJhw4bRokUL5s+fj4eHBwsXLqyyzkcffUSfPn0YO3Ys0dHRTJo0ifbt2zNnzhzANvozc+ZM3n77bR555BFat27Nl19+SUpKCitWrHBoy9vbm5CQEPvL09Oz2v4uXbqUXr162Q/+PHbsGCqViiNHjjiU+7//+z8aNWoEgMViYfjw4URFRWEwGGjWrBkfffRRTb+qKuXk5DB48GD8/f3x8PCgb9++DqNdSUlJ9OvXD39/fzw9PWnZsqV9xCwnJ4dBgwZRt25dDAYDTZo04fPPP7fXbdmyJWFhYfzwww+11t/KSADkZGpJghZC3KYURcFaXOz0l1KDnEqTycTOnTuJi4uzX1Or1cTFxZGQkFBlvYSEBIc6APHx8fY6iYmJpKamOpTx9fWlc+fOFdr94IMPCAgIoF27dkydOhWz2Vxtnzdu3EjHjh3t75s2bUrHjh1ZvHixQ7nFixfzpz/9CQCr1Uq9evVYvnw5hw4dYvz48bz55pt888031T7rag0dOpQdO3bw448/kpCQgKIoPPDAA5SVlQHw/PPPU1payv/+9z/279/PlClT8PLyAuCdd97h0KFD/Prrrxw+fJh58+YRGBjo0H5sbCwbN26slb5WRQ5DdbLyKTA5CkMIcbtRjEaOtu/g9Oc227UTlYfHVZXNzMzEYrEQHBzscD04OLjCiMqlUlNTK62Tmppqv19+raoyAKNHj6Z9+/bUqVOHLVu2MG7cOM6fP8+MGTOqfHZSUhJhYWEO1wYNGsScOXOYNGkSYBsV2rlzJ1999RUAWq2Wf/zjH/byUVFRJCQk8M033/DUU09V+ayrcfz4cX788Uc2b95Mt27dAFvwVb9+fVasWMGTTz5JcnIyjz/+ODExMQA0bNjQXj85OZl27drZg7rIyMgKzwgLC2P37t3X1c8rkQDIycqToOUwVCGEuPOMGTPG/ufWrVuj0+n461//yuTJk9Hr9ZXWMRqN9umvck8//TSvvvoqW7dupUuXLixevJj27dvTvHlze5m5c+eycOFCkpOTMRqNmEwm2rZte92f4fDhw7i5udG5c2f7tYCAAJo1a8bhw4cBW6A3cuRIVq9eTVxcHI8//jitW7cGYOTIkTz++OPs2rWL3r17079/f3sgVc5gMFBcXHzdfa2OBEBOJknQQojblcpgoNmunS557tUKDAxEo9GQlpbmcD0tLY2QkJAq64WEhFRbp/y/aWlphIaGOpSpLujo3LkzZrOZ06dP06xZsyr7nJOTU6E/9913H0uWLKFLly4sWbKEkSNH2u8vXbqUV199lenTp9O1a1e8vb2ZOnUq27Ztq7Ivtekvf/kL8fHx/PLLL6xevZrJkyczffp0XnzxRfr27UtSUhIrV65kzZo13H///Tz//PNMmzbNXj87O5u6deve0D5KDpCTyU7QQojblUqlQu3h4fSX6sL/sbwaOp2ODh06sG7dOvs1q9XKunXr6Nq1a5X1unbt6lAHYM2aNfY6UVFRhISEOJTJz89n27Zt1ba7Z88e1Go1QUFBVZZp164dhw4dqnB90KBBLFu2jISEBE6dOsXTTz9tv1c+PTVq1CjatWtH48aNOXnyZJXPqIno6GjMZrNDMJWVlcXRo0dp0aKF/Vr9+vX529/+xvfff88rr7zCggUL7Pfq1q3LkCFD+Oqrr5g5cyaffvqpwzMOHDhAu3btaqW/VbkpAqCa7MewYMEC7rrrLvz9/fH39ycuLq5C+aFDh1bYZ6FPnz43+mNcFdkJWgghXGvMmDEsWLCARYsWcfjwYUaOHElRURHDhg2zlxk8eDDjxo2zv3/ppZdYtWoV06dP58iRI0ycOJEdO3bwwgsvALbg7+WXX+a9997jxx9/ZP/+/QwePJiwsDD7ZoMJCQnMnDmTvXv3curUKRYvXszf//53nnnmGfz9/avsb3x8PJs2bapw/bHHHqOgoICRI0dy7733OuQJNWnShB07dvDbb79x7Ngx3nnnHf7444/r/ersbT/yyCOMGDGCTZs2sXfvXp555hnCw8N55JFHAHj55Zf57bffSExMZNeuXaxfv57o6GgAxo8fz3/+8x9OnDjBwYMH+fnnn+33AIqLi9m5cye9e/eulf5WxeUBUE33Y9iwYQMDBw5k/fr1JCQkUL9+fXr37s25c+ccyvXp08dhn4Wvv/7aGR/niuwjQJIELYQQLjFgwACmTZvG+PHjadu2LXv27GHVqlUOCczJycmcP3/e/r5bt24sWbKETz/9lDZt2vDtt9+yYsUKWrVqZS/z2muv8eKLL/Lcc8/RqVMnCgsLWbVqlT1/R6/Xs3TpUnr27EnLli15//33+fvf/15h9ONygwYN4uDBgxw9etThure3N/369WPv3r0MGjTI4d5f//pXHnvsMQYMGEDnzp3Jyspi1KhR1/ydXe7zzz+nQ4cOPPTQQ3Tt2hVFUVi5ciVarRawLcN//vnniY6Opk+fPjRt2pSPP/4YsI3CjRs3jtatW3P33Xej0WhYunSpve3//Oc/NGjQgLvuuqvW+lsZlVKT9YM3QOfOnenUqZN9LwWr1Ur9+vV58cUXeeONN65Y32Kx4O/vz5w5cxg8eDBgGwHKzc2tsPfC1crPz8fX15e8vDx8fHyuqY2qTFl1hHkbTvJs9yjG92tx5QpCCHETKikpITExkaioqAoJuqL2jR07lvz8fD755BNXd+WG69KlC6NHj7Yv6b9cdT97Nfn97dIRoGvdj+FSxcXFlJWVUadOHYfrGzZsICgoiGbNmjFy5EiysrJqte/XSpbBCyGEqKm33nqLiIgIrFarq7tyQ2VmZvLYY48xcODAG/4sl64Cu9b9GC71+uuvExYW5hBE9enTh8cee4yoqChOnjzJm2++Sd++fUlISKj0HJXS0lJKS0vt7/Pz86/xE11Z+RSYLIMXQghxtfz8/HjzzTdvSNvJyckOycuXO3ToEA0aNLghz75cYGAgr732mlOedUsvg//ggw9YunQpGzZscBgGuzQTPiYmhtatW9OoUSM2bNjA/fffX6GdyZMnO2wYdSNJErQQQoibSVhYGHv27Kn2/u3IpQHQte7HADBt2jQ++OAD1q5da99cqSoNGzYkMDCQEydOVBoAjRs3zmFzqvz8fOrXr1+DT3L1ZBm8EEKIm4mbmxuNGzd2dTeczqU5QNe6H8OHH37IpEmTWLVqlcP5KFU5e/YsWVlZDptTXUqv1+Pj4+PwulFkBEgIIYRwPZcvg7/SfgyX78UwZcoU3nnnHRYuXEhkZCSpqamkpqZSWFgIQGFhIWPHjmXr1q2cPn2adevW8cgjj9C4cWPi4+Nd8hkvJUnQQgghhOu5PAdowIABZGRkMH78eFJTU2nbtq3DfgzJycmo1RfjtHnz5mEymXjiiScc2pkwYQITJ05Eo9Gwb98+Fi1aRG5uLmFhYfTu3ZtJkyZVec6KM0kStBBCCOF6Lg+AAF544QX7bpqX27Bhg8P706dPV9uWwWDgt99+q6We1T4JgIQQQgjXc/kU2J1GAiAhhBDC9SQAcjJJghZCCHEpk8lE48aN2bJlS621uWHDBlQqFbm5uVcs+8UXX+Dn51drz67O008/zfTp053yrCuRAMjJJAlaCCFcryaHcJdbvnw5zZs3x93dnZiYGFauXOlw//vvv6d3794EBASgUqmq3VvnUvPnzycqKopu3bpdy0e5pbz99tu8//775OXluborEgA5m4wACSGEa9X0EG6ALVu2MHDgQIYPH87u3bvp378//fv358CBA/YyRUVF9OjRgylTplx1XxRFYc6cOQwfPvy6PtOtolWrVjRq1IivvvrK1V2RAMjZZCNEIYRwrRkzZjBixAiGDRtGixYtmD9/Ph4eHixcuLDKOh999BF9+vRh7NixREdHM2nSJNq3b28/yBvgz3/+M+PHj3c4mulKdu7cycmTJ3nwwQft17p168brr7/uUC4jIwOtVsv//vc/AP7973/TsWNHvL29CQkJ4U9/+lO1AVxNzZs3j0aNGqHT6WjWrBn//ve/7fcURWHixIk0aNAAvV5PWFgYo0ePtt//+OOPadKkCe7u7gQHB1dYtd2vXz+H099dRQIgJ5MkaCHE7UpRFMpKLU5/KTVIKbjWQ7gTEhIqBDbx8fFXfXB3VTZu3EjTpk3x9va2Xxs0aBBLly51+FzLli0jLCyMu+66C4CysjImTZrE3r17WbFiBadPn2bo0KHX1ZdyP/zwAy+99BKvvPIKBw4c4K9//SvDhg1j/fr1AHz33Xf83//9H5988gnHjx9nxYoVxMTEALBjxw5Gjx7Nu+++y9GjR1m1ahV33323Q/uxsbFs377d4QxOV7gplsHfSSQAEkLcrswmK5++9LvTn/vcRz3R6isedF2Zaz2EOzU1tdI6qampNe/wJZKSkiqctfXUU0/x8ssvs2nTJnvAs2TJEgYOHIjqQh7ps88+ay/fsGFDZs2aRadOnSgsLMTLy+u6+jRt2jSGDh3KqFGjANuGxVu3bmXatGnce++9JCcnExISQlxcHFqtlgYNGhAbGwvY9u7z9PTkoYcewtvbm4iICNq1a+fQflhYGCaTidTUVCIiIq6rr9dDRoCczB4ASRK0EELc8YxGo8Nh3gB169ald+/eLF68GIDExEQSEhIYNGiQvczOnTvp168fDRo0wNvbm549ewK2AOR6HT58mO7duztc6969O4cPHwbgySefxGg00rBhQ0aMGMEPP/yA2WwGoFevXkRERNCwYUP+/Oc/s3jxYoqLix3aMhgMABWuO5uMADlZ+SowSYIWQtxu3HRqnvuop0uee7Wu9RDukJCQazq4+2r6s3///grXBw0axOjRo5k9ezZLliwhJibGPs1UVFREfHw88fHxLF68mLp165KcnEx8fDwmk+m6+nM16tevz9GjR1m7di1r1qxh1KhRTJ06ld9//x1vb2927drFhg0bWL16NePHj2fixIn88ccf9qX22dnZgC3QcyUZAXIySYIWQtyuVCoVWr3G6a/yaaGrca2HcHft2tWhDsCaNWuqrXM12rVrx5EjRyrkMT3yyCOUlJSwatUqlixZ4jD6c+TIEbKysvjggw+46667aN68ea0mQEdHR7N582aHa5s3b6ZFixb29waDgX79+jFr1iw2bNhAQkKCPZBzc3MjLi6ODz/8kH379nH69Gn++9//2useOHCAevXqERgYWGt9vhYyAuRkkgMkhBCuNWbMGIYMGULHjh2JjY1l5syZDodwg+0g7vDwcCZPngzASy+9RM+ePZk+fToPPvggS5cuZceOHXz66af2OtnZ2SQnJ5OSkgLA0aNHAdvoUVUjRffeey+FhYUcPHiQVq1a2a97enrSv39/3nnnHQ4fPszAgQPt9xo0aIBOp2P27Nn87W9/48CBA0yaNKnWvp+xY8fy1FNP0a5dO+Li4vjpp5/4/vvvWbt2LWDbONFisdC5c2c8PDz46quvMBgMRERE8PPPP3Pq1Cnuvvtu/P39WblyJVarlWbNmtnb37hxI7179661/l4zRVSQl5enAEpeXl6tt73peIYS8frPSu8Zv9d620II4SxGo1E5dOiQYjQaXd2VazJ79mylQYMGik6nU2JjY5WtW7c63O/Zs6cyZMgQh2vffPON0rRpU0Wn0yktW7ZUfvnlF4f7n3/+uQJUeE2YMKHavjz11FPKG2+8UeH6ypUrFUC5++67K9xbsmSJEhkZqej1eqVr167Kjz/+qADK7t27FUVRlPXr1yuAkpOTc8Xv4vPPP1d8fX0drn388cdKw4YNFa1WqzRt2lT58ssv7fd++OEHpXPnzoqPj4/i6empdOnSRVm7dq2iKIqyceNGpWfPnoq/v79iMBiU1q1bK8uWLbPXNRqNiq+vr5KQkHDFflWlup+9mvz+VimKZONeLj8/H19fX/Ly8vDx8anVtreeyuLpT7fSOMiLtWOcP1cuhBC1oaSkhMTERKKioiok8Yqa2bdvH7169eLkyZPXvYLrZjdv3jx++OEHVq9efc1tVPezV5Pf35ID5GQyBSaEEOJSrVu3ZsqUKSQmJrq6KzecVqtl9uzZru4GIAGQ06lVEgAJIYRwNHToUPsqr9rWt29fvLy8Kn3985//vCHPrMpf/vIXh3wgV5IkaCeyKlbADFgkABJCCOEU//rXvzAajZXeq1OnjpN7c/OQAMiJPtv/GbN2z0If2hFL0TOu7o4QQog7QHh4uKu7cFOSKTAnKt+rQoUiGyEKIYQQLiQBkBNpVOVn1ShYrFaX9kUIIYS4k0kA5ERq1YWvW2XFbJERICGEEMJVJAByInsAhEKZjAAJIYQQLiMBkBNdHAFSZARICCGEcCEJgJzo4giQFbNVqXD4nRBCiDtPVlYWQUFBnD59utba/OKLL+ynr1/JxIkTadu2ba09uzpdunThu+++c8qzrkQCICe6NAkaZDNEIYRwlblz5xIZGYm7uzudO3dm+/btV6yzfPlymjdvjru7OzExMaxcudLh/tChQ1GpVA6vPn36XLHd999/n0ceeYTIyMhr/Ti3jLfffps33ngD602QBiIBkBOVL4NHZfuLl6XwQgjhfMuWLWPMmDFMmDCBXbt20aZNG+Lj40lPT6+yzpYtWxg4cCDDhw9n9+7d9O/fn/79+3PgwAGHcn369OH8+fP219dff11tX4qLi/nss88YPnx4rXy2m13fvn0pKCjg119/dXVXJABypvIRINWFEaAyi+sjYCGEuNPMmDGDESNGMGzYMFq0aMH8+fPx8PBg4cKFVdb56KOP6NOnD2PHjiU6OppJkybRvn175syZ41BOr9cTEhJif/n7+1fbl5UrV6LX6+nSpQsAVquVevXqMW/ePIdyu3fvRq1Wk5SUZP8MMTExeHp6Ur9+fUaNGkVhYeG1fB0VWK1W3n33XerVq4der6dt27asWrXKft9kMvHCCy8QGhqKu7s7ERERTJ48GQBFUZg4cSINGjRAr9cTFhbG6NGj7XU1Gg0PPPAAS5curZW+Xg8JgJzo0iRoQBKhhRC3FUVRKCspcfqrJvmUJpOJnTt3EhcXZ7+mVquJi4sjISGhynoJCQkOdQDi4+Mr1NmwYQNBQUE0a9aMkSNHkpWVVW1/Nm7cSIcOHRz6MnDgQJYsWeJQbvHixXTv3p2IiAh7uVmzZnHw4EEWLVrEf//7X1577bXqP/xV+uijj5g+fTrTpk1j3759xMfH8/DDD3P8+HEAZs2axY8//sg333zD0aNHWbx4sX367rvvvuP//u//+OSTTzh+/DgrVqyocMZZbGwsGzdurJW+Xg85CsOJLk2CBpkCE0LcXsylpcwa8oTTnzt60bdo3d2vqmxmZiYWi4Xg4GCH68HBwRw5cqTKeqmpqZXWSU1Ntb/v06cPjz32GFFRUZw8eZI333yTvn37kpCQgEajubxJAJKSkggLC3O4NmjQIKZPn05ycjINGjTAarWydOlS3n77bXuZl19+2f7nyMhI3nvvPf72t7/x8ccfX/E7uJJp06bx+uuv8/TTTwMwZcoU1q9fz8yZM5k7dy7Jyck0adKEHj16oFKp7EEZQHJyMiEhIcTFxaHVamnQoAGxsbEO7YeFhXHmzBmsVitqtevGYWQEyInKAyBV+QjQTZAEJoQQonY8/fTTPPzww8TExNC/f39+/vln/vjjDzZs2FBlHaPRiPtlwVvbtm2Jjo62jwL9/vvvpKen8+STT9rLrF27lvvvv5/w8HC8vb3585//TFZWFsXFxdf1GfLz80lJSaF79+4O17t3787hw4cBW7L3nj17aNasGaNHj2b16tX2ck8++SRGo5GGDRsyYsQIfvjhB8xms0NbBoMBq9VKaWnpdfX1eskIkBOpuSwAkikwIcRtxE2vZ/Sib13y3KsVGBiIRqMhLS3N4XpaWhohISFV1gsJCalxnYYNGxIYGMiJEye4//77q+xPTk5OheuDBg1iyZIlvPHGGyxZsoQ+ffoQEBAAwOnTp3nooYcYOXIk77//PnXq1GHTpk0MHz4ck8mEh4dHlX2qDe3btycxMZFff/2VtWvX8tRTTxEXF8e3335L/fr1OXr0KGvXrmXNmjWMGjWKqVOn8vvvv6PVagHIzs7G09MTg8FwQ/t5JTIC5ETlQ31qlSRBCyFuPyqVCq27u9Nf9hW2V0Gn09GhQwfWrVtnv2a1Wlm3bh1du3atsl7Xrl0d6gCsWbOm2jpnz54lKyuL0NDQKsu0a9eOQ4cOVbj+pz/9iQMHDrBz506+/fZbBg0aZL+3c+dOrFYr06dPp0uXLjRt2pSUlJQqn1ETPj4+hIWFsXnzZofrmzdvpkWLFg7lBgwYwIIFC1i2bBnfffcd2dnZgG2Ep1+/fsyaNYsNGzaQkJDA/v377XUPHDhAu3btaqW/10NGgJzIvgrMPgUmI0BCCOFsY8aMYciQIXTs2JHY2FhmzpxJUVERw4YNs5cZPHgw4eHh9tVNL730Ej179mT69Ok8+OCDLF26lB07dvDpp58CUFhYyD/+8Q8ef/xxQkJCOHnyJK+99hqNGzcmPj6+yr7Ex8czbtw4cnJyHFaMRUZG0q1bN4YPH47FYuHhhx+232vcuDFlZWXMnj2bfv36sXnzZubPn19r38/YsWOZMGECjRo1om3btnz++efs2bOHxYsXA7YVaKGhobRr1w61Ws3y5csJCQnBz8+PL774AovFQufOnfHw8OCrr77CYDA45Alt3LiR3r1711p/r5WMADlR+RSYrAITQgjXGTBgANOmTWP8+PG0bduWPXv2sGrVKock5+TkZM6fP29/361bN5YsWcKnn35KmzZt+Pbbb1mxYgWtWrUCbMu79+3bx8MPP0zTpk0ZPnw4HTp0YOPGjeirmaKLiYmhffv2fPPNNxXuDRo0iL179/Loo486TBe1adOGGTNmMGXKFFq1asXixYvtgVptGD16NGPGjOGVV14hJiaGVatW8eOPP9KkSRMAvL29+fDDD+nYsSOdOnXi9OnTrFy5ErVajZ+fHwsWLKB79+60bt2atWvX8tNPP9mn786dO8eWLVscgk1XUSlyHkMF+fn5+Pr6kpeXh4+PT621uz55PaPXj0ZtiiDv5Eh+fKE7rev51Vr7QgjhLCUlJSQmJhIVFVUhiVfUzC+//MLYsWM5cOCAS1dFOcPrr79OTk6OfeTsWlT3s1eT398yBeZEl68CK5MRICGEuOM9+OCDHD9+nHPnzlG/fn1Xd+eGCgoKYsyYMa7uBiBTYE51MQC6sA+QJEELIYTAtq/PjQp+WrZsiZeXV6Wv8rweZ3nllVcq7KfkKjIC5ERyGKoQQghnW7lyJWVlZZXeu1mCEVeQAMiJypdq2qfAJAASQghxg126AktcJFNgTnT5CJBMgQkhhBCuIQGQE9k367qQAyRJ0EKIW51VjvQRTlZbP3MyBeZE9o0QkbPAhBC3Np1Oh1qtJiUlhbp166LT6Wq0I7MQNaUoCiaTiYyMDNRqNTqd7rrakwDIieynwaskCVoIcWtTq9VERUVx/vz5WjuGQYir4eHhQYMGDa57z6SbIgCaO3cuU6dOJTU1lTZt2jB79mxiY2MrLbtgwQK+/PJLDhw4AECHDh345z//6VBeURQmTJjAggULyM3NpXv37sybN8++i6Wr2AMgZApMCHHr0+l0NGjQALPZjMVicXV3xB1Ao9Hg5uZWK6ONLg+Ali1bxpgxY5g/fz6dO3dm5syZxMfHc/ToUYKCgiqU37BhAwMHDqRbt264u7szZcoUevfuzcGDBwkPDwfgww8/ZNasWSxatIioqCjeeecd4uPjOXTokEt3LLUnQaskCVoIcXtQqVRotVr7Sd9C3CpcngQ9Y8YMRowYwbBhw2jRogXz58/Hw8ODhQsXVlp+8eLFjBo1irZt29K8eXP+9a9/2U/yBdvoz8yZM3n77bd55JFHaN26NV9++SUpKSmsWLHCiZ+sogojQDIFJoQQQriESwMgk8nEzp07iYuLs19Tq9XExcWRkJBwVW0UFxdTVlZGnTp1AEhMTCQ1NdWhTV9fXzp37lxlm6WlpeTn5zu8boTyAEiRZfBCCCGES7k0AMrMzMRisVTYiTI4OJjU1NSrauP1118nLCzMHvCU16tJm5MnT8bX19f+ulHbkV8+AiRJ0EIIIYRruHwK7Hp88MEHLF26lB9++OG6cnvGjRtHXl6e/XXmzJla7OVFFwMgOQxVCCGEcCWXJkEHBgai0WhIS0tzuJ6WlkZISEi1dadNm8YHH3zA2rVrad26tf16eb20tDRCQ0Md2mzbtm2lben1evR6/TV+iqt3+QiQTIEJIYQQruHSESCdTkeHDh3sCcyAPaG5a9euVdb78MMPmTRpEqtWraJjx44O96KioggJCXFoMz8/n23btlXbpjOUrwIrzwGSJGghhBDCNVy+DH7MmDEMGTKEjh07Ehsby8yZMykqKmLYsGEADB48mPDwcCZPngzAlClTGD9+PEuWLCEyMtKe1+Pl5YWXlxcqlYqXX36Z9957jyZNmtiXwYeFhdG/f39XfUzg4lEYiowACSGEEC7l8gBowIABZGRkMH78eFJTU2nbti2rVq2yJzEnJyc77PY4b948TCYTTzzxhEM7EyZMYOLEiQC89tprFBUV8dxzz5Gbm0uPHj1YtWqVS/cAgksPQ5UkaCGEEMKVVIqiyG/hy+Tn5+Pr60teXh4+Pj611m5qUSq9vu2FGg15h9/n2e5RjO/XotbaF0IIIe5kNfn9fUuvArvVVNgHSA5DFUIIIVyixlNgubm5/PDDD2zcuJGkpCSKi4upW7cu7dq1Iz4+nm7dut2Ift4WLgZAchaYEEII4UpXPQKUkpLCX/7yF0JDQ3nvvfcwGo20bduW+++/n3r16rF+/Xp69epFixYtWLZs2Y3s8y3r4jJ4AKskQQshhBAuctUjQO3atWPIkCHs3LmTFi0qz1sxGo2sWLGCmTNncubMGV599dVa6+jt4GISNIAiSdBCCCGEi1x1AHTo0CECAgKqLWMwGBg4cCADBw4kKyvrujt3uylfBm97o8g+QEIIIYSLXPUU2JWCn+stfye4fARIpsCEEEII16jRKrBRo0ZRWFhof//1119TVFRkf5+bm8sDDzxQe727zVyeAyRJ0EIIIYRr1CgA+uSTTyguLra//+tf/+pwjldpaSm//fZb7fXuNuMQAKkUWQYvhBBCuEiNAqDL90yUPRRr5vIRIEmCFkIIIVxDNkJ0IvUlX7dKpVAmOUBCCCGES0gA5ESOI0AKZskBEkIIIVyixjtBjx8/Hg8PDwBMJhPvv/8+vr6+AA75QaIilUqFWqXGqlhBZZVl8EIIIYSL1CgAuvvuuzl69Kj9fbdu3Th16lSFMqJqatRYsSLL4IUQQgjXqVEAtGHDhhvUjTuHWqXGdhaq7AQthBBCuEqt5ACZzWaH/YFE1TTqC5shqqySBC2EEEK4SI0CoJ9++okvvvjC4dr777+Pl5cXfn5+9O7dm5ycnNrs321HRflxGApmGQESQgghXKJGAdCMGTMcdn7esmUL48eP55133uGbb77hzJkzTJo0qdY7eTuxH4ehssoqMCGEEMJFahQAHTx4kG7dutnff/vtt/Tq1Yu33nqLxx57jOnTp/PTTz/VeidvJ+UHoqqQfYCEEEIIV6lRAFRQUOBwyOmmTZu4//777e9btmxJSkpK7fXuNnTxQFRJghZCCCFcpUYBUHh4OIcPHwagsLCQvXv3OowIZWVl2fcIEpWzb4YoSdBCCCGEy9QoAHryySd5+eWX+fe//82IESMICQmhS5cu9vs7duygWbNmtd7J28nF3aAlCVoIIYRwlRrtAzR+/HjOnTvH6NGjCQkJ4auvvkKj0djvf/311/Tr16/WO3k7uXQEyGyWAEgIIYRwhRoFQAaDgS+//LLK++vXr7/uDt3uLh0BKrPKFJgQQgjhCnIYqpNdGgApClhlGkwIIYRwuhqNAN13331XVe6///3vNXXmTlC+Ckylso3+lFmt6NWa6qoIIYQQopbV+CywiIgIHnzwQbRa7Y3q023t0hEgALNFQV+jvwUhhBBCXK8a/eqdMmUKn3/+OcuXL2fQoEE8++yztGrV6kb17bZ0aRI0ILtBCyGEEC5QoxygsWPHcujQIVasWEFBQQHdu3cnNjaW+fPnk5+ff6P6eFu5fARIEqGFEEII57umJOiuXbuyYMECzp8/z/PPP8/ChQsJCwuTIOgqlAdAarUtAJLdoIUQQgjnu65VYLt27eL333/n8OHDtGrVSvKCrkJ5ErTmwjcvu0ELIYQQzlfjACglJYV//vOfNG3alCeeeII6deqwbds2tm7disFguBF9vK2UH4bqduGblxwgIYQQwvlqlAT9wAMPsH79enr37s3UqVN58MEHcXOTJUw1YR8B0lxYBSY5QEIIIYTT1Sh6WbVqFaGhoSQnJ/OPf/yDf/zjH5WW27VrV6107nZUPgJUngMk54EJIYQQzlejAGjChAk3qh93jPIRoPIpsDI5D0wIIYRwOgmAnKx8FZhWYxsJMpZZXNkdIYQQ4o4kZ4E5WXkApLsQekoAJIQQQjjfVQdAffr0YevWrVcsV1BQwJQpU5g7d+51dex2dTEAujACZDK7sjtCCCHEHemqp8CefPJJHn/8cXx9fenXrx8dO3YkLCwMd3d3cnJyOHToEJs2bWLlypU8+OCDTJ069Ub2+5alvhBzai9888UmGQESQgghnO2qA6Dhw4fzzDPPsHz5cpYtW8ann35KXl4eYFvZ1KJFC+Lj4/njjz+Ijo6+YR2+1anVjlNgEgAJIYQQzlejJGi9Xs8zzzzDM888A0BeXh5Go5GAgADZBfoqla8CsydBSwAkhBBCON117WLo6+uLr69vbfXljnBxCswWAMkIkBBCCOF8sgrMyS4ug7ft/1NcJknQQgghhLO5PACaO3cukZGRuLu707lzZ7Zv315l2YMHD/L4448TGRmJSqVi5syZFcpMnDgRlUrl8GrevPkN/AQ1o1GXT4HZ3ssUmBBCCOF8Lg2Ali1bxpgxY5gwYQK7du2iTZs2xMfHk56eXmn54uJiGjZsyAcffEBISEiV7bZs2ZLz58/bX5s2bbpRH6HGVNimvspzgGQKTAghhHA+lwZAM2bMYMSIEQwbNowWLVowf/58PDw8WLhwYaXlO3XqxNSpU3n66afR6/VVtuvm5kZISIj9FRgYeKM+Qo3Zj8K4MAUmI0BCCCGE811TAHTmzBnOnj1rf799+3ZefvllPv3006tuw2QysXPnTuLi4i52Rq0mLi6OhISEa+mW3fHjxwkLC6Nhw4YMGjSI5OTkasuXlpaSn5/v8LpRyg9DdbOPAEkOkBBCCOFs1xQA/elPf2L9+vUApKam0qtXL7Zv385bb73Fu+++e1VtZGZmYrFYCA4OdrgeHBxMamrqtXQLgM6dO/PFF1+watUq5s2bR2JiInfddRcFBQVV1pk8ebJ9RZuvry/169e/5udfyeUjQDIFJoQQQjjfNQVABw4cIDY2FoBvvvmGVq1asWXLFhYvXswXX3xRm/2rsb59+/Lkk0/SunVr4uPjWblyJbm5uXzzzTdV1hk3bhx5eXn215kzZ25Y/8pXgWkufPNyFpgQQgjhfNe0D1BZWZk9B2ft2rU8/PDDADRv3pzz589fVRuBgYFoNBrS0tIcrqelpVWb4FxTfn5+NG3alBMnTlRZRq/XV5tTVJvKAyC3C6vAZARICCGEcL5rGgFq2bIl8+fPZ+PGjaxZs4Y+ffoAkJKSQkBAwFW1odPp6NChA+vWrbNfs1qtrFu3jq5du15LtypVWFjIyZMnCQ0NrbU2r0eFESAJgIQQQginu6YAaMqUKXzyySfcc889DBw4kDZt2gDw448/2qfGrsaYMWNYsGABixYt4vDhw4wcOZKioiKGDRsGwODBgxk3bpy9vMlkYs+ePezZsweTycS5c+fYs2ePw+jOq6++yu+//87p06fZsmULjz76KBqNhoEDB17LR611FUeAJAlaCCGEcLZrmgK75557yMzMJD8/H39/f/v15557Dg8Pj6tuZ8CAAWRkZDB+/HhSU1Np27Ytq1atsidGJycn2w8PBdsIU7t27ezvp02bxrRp0+jZsycbNmwA4OzZswwcOJCsrCzq1q1Ljx492Lp1K3Xr1r2Wj1rrLo4ASRK0EEII4SrXFAAZjUYURbEHP0lJSfzwww9ER0cTHx9fo7ZeeOEFXnjhhUrvlQc15SIjI1EUpdr2li5dWqPnO1v5KjD1hQCo1GzFalVQq1Wu7JYQQghxR7mmKbBHHnmEL7/8EoDc3Fw6d+7M9OnT6d+/P/PmzavVDt5u7FNgl3zzshJMCCGEcK5rCoB27drFXXfdBcC3335LcHAwSUlJfPnll8yaNatWO3i7KQ+AVCqFC3siyjSYEEII4WTXFAAVFxfj7e0NwOrVq3nsscdQq9V06dKFpKSkWu3g7aY8AFJQMFw4EVVWggkhhBDOdU0BUOPGjVmxYgVnzpzht99+o3fv3gCkp6fj4+NTqx283ZQHQBbFgofOFgAVl8lKMCGEEMKZrikAGj9+PK+++iqRkZHExsba9+1ZvXq1wyotUVF5ErRVsWIoD4BkBEgIIYRwqmtaBfbEE0/Qo0cPzp8/b98DCOD+++/n0UcfrbXO3Y7KD0O1KlY8tLavX6bAhBBCCOe6pgAIICQkhJCQEPup8PXq1avRJoh3KhkBEkIIIVzvmqbArFYr7777Lr6+vkRERBAREYGfnx+TJk3CarXWdh9vKw4jQPYASHKAhBBCCGe6phGgt956i88++4wPPviA7t27A7Bp0yYmTpxISUkJ77//fq128nZy6QhQeQAkU2BCCCGEc11TALRo0SL+9a9/2U+BB2jdujXh4eGMGjVKAqBqXLoKzKCzff0yBSaEEEI41zVNgWVnZ9O8efMK15s3b052dvZ1d+p2Vh4A2ZKgL4wAyU7QQgghhFNdUwDUpk0b5syZU+H6nDlzHFaFiYounQLz1NtGgApKJAdICCGEcKZrmgL78MMPefDBB1m7dq19D6CEhATOnDnDypUra7WDtxsVF5OgfQzlAVCZK7skhBBC3HGuaQSoZ8+eHDt2jEcffZTc3Fxyc3N57LHHOHr0qP2MMFE5jfriCJC3uxaQESAhhBDC2a55H6CwsLAKyc5nz57lueee49NPP73ujt2uLk2C9na3ff35MgIkhBBCONU1jQBVJSsri88++6w2m7ztqC985Yqi4CMjQEIIIYRL1GoAJK5Mrb44AuTjLjlAQgghhCtIAORk5avAFEWx5wDlG2UESAghhHAmCYCcrHwV2KU5QDICJIQQQjhXjZKgH3vssWrv5+bmXk9f7giXrgLzMdhGgIpMFswWK24aiUeFEEIIZ6hRAOTr63vF+4MHD76uDt3uLt0HqHwECKCw1Iyfh85V3RJCCCHuKDUKgD7//PMb1Y87xqU7QWs1aty1akrKrBSUSAAkhBBCOIvMuThZ+SowK1aAi4nQkgckhBBCOI0EQE50dFsqKV+70TrlXixW2wGo5UvhZSWYEEII4TwSADlRUW4pxiQ1AUVhWBXHESBZCSaEEEI4jwRATuTuZQt23M2el0yByYnwQgghhLNJAOREhksDIKstACpfCi85QEIIIYTzSADkRO6eFwKgMi/7CJCPjAAJIYQQTicBkBM5TIFJDpAQQgjhMhIAOZHBy7bPj95iwGpRAPDWyyowIYQQwtkkAHIinYcbFzaCxs2kBy7mABWUygiQEEII4SwSADmRWq3Czd0WAWlKbaNBsgpMCCGEcD4JgJzMzdMWAJWPAF3cCVoCICGEEMJZJAByMq2H7SsvD4A8dLazwUpMFpf1SQghhLjTSADkZLoLAZDW5A6Au9YWABWXyQiQEEII4SwSADmZ9rIAqHwEyGiyuqxPQgghxJ1GAiAn03naAh63CwGQQVseAMkIkBBCCOEsEgA5WXkApCszAJeMAJVZUBTFZf0SQggh7iQSADmZ3tO27F1rsgVA7hcCIKsCpWaZBhNCCCGcQQIgJyvfDbp8BKh8CgygpExWggkhhBDOIAGQk3l4OwZAWo0arca2N5BRAiAhhBDCKSQAcjKDwbb/j9ast1+zL4WXvYCEEEIIp3B5ADR37lwiIyNxd3enc+fObN++vcqyBw8e5PHHHycyMhKVSsXMmTOvu01n02ltOz+rFTUWqy3gubgUXgIgIYQQwhlcGgAtW7aMMWPGMGHCBHbt2kWbNm2Ij48nPT290vLFxcU0bNiQDz74gJCQkFpp09m09gBIg1mxLX23L4WXKTAhhBDCKVwaAM2YMYMRI0YwbNgwWrRowfz58/Hw8GDhwoWVlu/UqRNTp07l6aefRq/XV1qmpm06m/6SAKjMYjsB3qCzrQyTESAhhBDCOVwWAJlMJnbu3ElcXNzFzqjVxMXFkZCQ4NQ2S0tLyc/Pd3jdKOVTYBrFDZPFBIBBa/trkBwgIYQQwjlcFgBlZmZisVgIDg52uB4cHExqaqpT25w8eTK+vr72V/369a/p+VfDzc3N/meT2TYC5HFhBEiWwQshhBDO4fIk6JvBuHHjyMvLs7/OnDlzw56lvrDkHcBksgVAsgpMCCGEcC63Kxe5MQIDA9FoNKSlpTlcT0tLqzLB+Ua1qdfrq8wpqm0at4sxp8lsmwK79DgMIYQQQtx4LhsB0ul0dOjQgXXr1tmvWa1W1q1bR9euXW+aNmtbZSNA5avAZApMCCGEcA6XjQABjBkzhiFDhtCxY0diY2OZOXMmRUVFDBs2DIDBgwcTHh7O5MmTAVuS86FDh+x/PnfuHHv27MHLy4vGjRtfVZuuplKpsKosqBUNprLyVWDlU2ByIrwQQgjhDC4NgAYMGEBGRgbjx48nNTWVtm3bsmrVKnsSc3JyMmr1xUGqlJQU2rVrZ38/bdo0pk2bRs+ePdmwYcNVtXkzUFRWUDT2JGiDfSNEOQxVCCGEcAaXBkAAL7zwAi+88EKl98qDmnKRkZEoinJdbd4MrGorGuvFVWAXN0KUESAhhBDCGWQVmAsoattIT9mFgEeOwhBCCCGcSwIgF1BUjgGQLIMXQgghnEsCIFdQ26bxysyXjQDJKjAhhBDCKSQAcgH7FJjZ8TDUy5fBZxWWsv9snnM7J4QQQtwBJAByhQsjQObyAEhX+RTY80t20W/OJk5mFDq3f0IIIcRtTgIgF1DsAZAt4Lm4CswxADqTbQQgKavIib0TQgghbn8SALmA6vIAqIpVYOUbIxaUyPJ4IYQQojZJAOQKtnjHHgBVlQRdPiUmAZAQQghRuyQAcoHLR4DKl8HnFpexOzkHRVGwWBVKzbZkaQmAhBBCiNolAZArXPjWLRcCHA/dxQ25H/14C+uPpjusCCsoKXNq94QQQojbnQRALqC6MAVmsTgmQZdbcyjdYUWYjAAJIYQQtUsCIBdQaVTAxREgd62aRnU97ff/OJ3tkBAtI0BCCCFE7ZIAyAXKD7i3WGy5QCqVil9G38Wm1+8F4ER6IWdyiu3lZQRICCGEqF0SALmAys02AmS9MAIEtkToev4eNAv2BuD3Yxn2e+UB0Hc7zzJvw0kn9lQIIYS4PUkA5AJq9YUpMIu1wr3ODesAsP5Iuv1a/oUpsHf+c4Apq46Qkmt0Qi+FEEKI25cEQC6gvpADZL0wBXap5iE+AA7HXxSWmjFbrPbE6OwikxN6KYQQQty+JAByAfWFKTClkgDI16AFwHrJrYISs8MmiflGSYoWQgghrocEQC6g1ti+9spGgHwMbhWuFZaaHVaF5UkAJIQQQlwXCYBcQGOfAqt4r3wE6FIWq0LWJdNe+bIsXgghhLguEgC5gMbN9rVbLBaOZh/FqlxMhvZxrxgAAaQXlNr/LCNAQgghxPWRAMgFyqfA0grSeeKnJ/jx5I/2e5WNAAGk55fY/ywBkBBCCHF9JAByAbcLI0BqxXYExum80/Z73u4Vc4DAcQQo3ygbIwohhBDXQwIgF9C42QKf8gCosOziknc3jRovfcUgSEaAhBBCiNojAZALuGkuBEBW23+Lyooc7lc2DZZReMkIkCRBCyGEENdFAiAX0Fw2BXZ5AFTZNFh6viRBCyGEELVFAiAXcLtsCqy6ESDNhWMzHHOAJAASQgghrocEQC6gdbON8GgqyQEC8LkkAKrrpQcgzSEHSJKghRBCiOshAZALuGkdR4CKy4od7l86AhTs6w5A6SUnx+cby1CUirtICyGEEOLqSADkAuUjQOVJ0BVGgC5shti2VEOXsxY0l8U6JovVISASQgghRM1IAOQC9gDoCjlAvYw6fHLMxJg0FdqQRGghhBDi2kkA5AKXB0BGsxHLJQeDXX4gqlZRVWhDEqGFEEKIaycBkAto3WwjPOUBEECR+eIokK9BC5dMe1lUFfN9ZARICCGEuHYSALmATmcLgDSXBECXJkL7uGu5dAyokkPjZTNEIYQQ4jpIAOQClydBAxSaLiZC+3po0V8y6FNZunOesQyT2UqZRZKhhRBCiJqSAMgFdNqKU2CXrgTzcdeiuyTv59LRIMOFJfRJWcXcO20Dj8zZLEvihRBCiBqSAMgFygMgN6sWv+JgUBynwCICPIjwdre/13IxGGpb3w+Ar7Ymcy7XyKHz+eQWy3SYEEIIURMSALmA24UpMIPZm6f3vkm304/y17V/5emfn6bMUoa7VsNHT7Sxl/fQXPxr6hjpD0DmJYejns0xOqnnQgghxO1BAiAXKD8MtVzr1HuIzI7hYNZB9mTsAcBccjH12dPt4lRZhwj/Cu2dzSmucE0IIYQQVZMAyAXUmor7+rRNuQ+AhJQEAEovOe/LcMkIUD1/D0J83B3qnsuVESAhhBCiJtyuXETUNo2mYtzpWeoHwH9O/IcCUwEds3rb7xnUavtaeA+dhlbhPqRecjiqTIEJIYQQNSMjQC6gdqs4AmQo8wYF0o3pLD26lP+d2mS/p1dfLG/QamgR5utQV6bAhBBCiJqRAMgF1JWMALkpWnQWg/19Rl62/c961SUBkE7DQ61D8ffQ0qNxICAjQEIIIURN3RQB0Ny5c4mMjMTd3Z3OnTuzffv2assvX76c5s2b4+7uTkxMDCtXrnS4P3ToUFQqlcOrT58+N/Ij1Ijm0hwgjUKpxhbADIoYTGxILAA688VgqHwZvEoFejc1TYO92T2+NxMfbgnYAiDZC0gIIYS4ei4PgJYtW8aYMWOYMGECu3btok2bNsTHx5Oenl5p+S1btjBw4ECGDx/O7t276d+/P/379+fAgQMO5fr06cP58+ftr6+//toZH+eqXJoErXK3YNQWANA//Ak+i/+MZ1s9i85yMdFZo1jRB63E4HsM1SWjQfX8bUFSYamZj9Yd59kv/uDr7clO+hRCCCHErcvlAdCMGTMYMWIEw4YNo0WLFsyfPx8PDw8WLlxYafmPPvqIPn36MHbsWKKjo5k0aRLt27dnzpw5DuX0ej0hISH2l79/xeXjrqK6JKfHoi+jWJtv+3OR7fo99e9xCICyS0+jC/gfmrrfOrTjrtXg427LY5+59jj/PZLO9NVHb3T3hRBCiFueSwMgk8nEzp07iYuLs19Tq9XExcWRkJBQaZ2EhASH8gDx8fEVym/YsIGgoCCaNWvGyJEjycrKqrIfpaWl5OfnO7xupEtHcYLq1KFMb5sCMxaYAIgJjMHd6mkvYzFf2OnZLZ+M4gyHttpc2Bna38O2u3RmoYmSssqOTxVCCCFEOZcGQJmZmVgsFoKDgx2uBwcHk5qaWmmd1NTUK5bv06cPX375JevWrWPKlCn8/vvv9O3bF4ul8sBg8uTJ+Pr62l/169e/zk929fz9vOnbwrbkvTjfFgC5qd3wVi6u9NJYtfY/78vc51B/5oC2fD2iCzvf7oWX3jYaJEnRQgghRPVcPgV2Izz99NM8/PDDxMTE0L9/f37++Wf++OMPNmzYUGn5cePGkZeXZ3+dOXPGaX1199Lh5Wub7irILiE33bak3d3qYS/jZtUSpO4AwL4MxwAowEtP10YBqNUqwv1sOUGyMaIQQghRPZcGQIGBgWg0GtLS0hyup6WlERISUmmdkJCQGpUHaNiwIYGBgZw4caLS+3q9Hh8fH4eXs7h7afHw0QFwbFsai8dvJeV4Luqyi3tUGlQePN/lYQD2Z+6vsq3ypOhzMgIkhBBCVMulAZBOp6NDhw6sW7fOfs1qtbJu3Tq6du1aaZ2uXbs6lAdYs2ZNleUBzp49S1ZWFqGhobXT8VpUJ9TTHgCVO/D7WayXHPCuVwy0DmwNwMHMg1islU/lhZcHQLmyMaIQQghRHZdPgY0ZM4YFCxawaNEiDh8+zMiRIykqKmLYsGEADB48mHHjxtnLv/TSS6xatYrp06dz5MgRJk6cyI4dO3jhhRcAKCwsZOzYsWzdupXTp0+zbt06HnnkERo3bkx8fLxLPmNlev+lJW17NaBRu7oYLguASo2OAY6boqWhX0PcNe4Um4tJKUyptE37FJiMAAkhhBDVcvlZYAMGDCAjI4Px48eTmppK27ZtWbVqlT3ROTk5GbX6YpzWrVs3lixZwttvv82bb75JkyZNWLFiBa1atQJAo9Gwb98+Fi1aRG5uLmFhYfTu3ZtJkyah1+td8hkr06RjME062j7j5SNAaafzHN5byhTUKjUBhgDOFZ4jqySL+j4VE7XLR4AkCVoIIYSonssDIIAXXnjBPoJzucoSl5988kmefPLJSssbDAZ+++232uzeDXd5AFRaZDsJ3j/Eg5zUYhSrgtVivRgAGStf0i9J0EIIIcTVcfkUmAA3rYZ7BjWj88NRcMkpGeFNL27eaC6zEuAeAMDp/NO8t/U99qTvcWinnr9t5VhafglGk4X/W3OM+b+fJCmr6IZ/BiGEEOJWIgHQTaLlXeF0fCAKb/+LO0CHN7sYAKWezCNQZZsyW3JkCcuOLuPTfZ86tBHopUPvpsaqwOJtSXy07jgf/HqEfrM3UWaxOpQtKjWz7nAapWbZNFEIIcSdRwKgm4xf8MVDUEMa+qJxs/0V/TR7L3U2xQCQXmw7Jy3TmOlQV6VSUdfblud04NzFPKL8EjOZhaUOZedtOMnwRTtYsk3ODhNCCHHnkQDoJuMXZJvG8vLX4+WvR6O9+FekzjU4lM0uya5Qv46nLZ/oZIbjtFdWocnh/cmMQgASM2V6TAghxJ1HAqCbTN0Ib+Di9JfbJQGQUqwG5WKSUHZJNoqiONT39ygPgAodrmdcNgKUUWB7f/nIkBBCCHEnuClWgYmLmnUJxU2noX7zOgAOI0AoKvRmA6Va20aHZdYyisqK8NJ52YsEXBgBKjY55vZcPgKUXh4AXTiA9fdjGSzdnsx7/VsR4HXzbBcghBBC3AgyAnSTUatVNOkYjLuX7QDUS0eAADzKvB3eXz4N5u/puKS+/OD5S0d6FEWpMAL0r42n+PVAKr8ddDxmRAghhLgdSQB0k9NcFgAZrhAA1bksAGoaZCufdSHQKSmzkGcsw1hmGyEqnxorD4jS8ktqqedCCCHEzUumwG5yblqNw3svi5/D++ySbEwWE6uTVnNv/XvtOUDlGgd7cTStgMxCEzlFJnr93++4X9JmQYmZkjILWUW2qbDyqTEhhBDidiYB0E1Oo1U5vA9Qgh3eZ5dk88XBL5i9ezaDWwwmxvPPDvebBNnygzILS9mWmE3mZblA5fdyLgRAGRIACSGEuAPIFNhNzmxy3MDQTwlweJ9dks321O0A7EzbWWEKrMmFKbDMQhP7z+VW+oxTGUWYrbbVZBkFMgUmhBDi9icB0E2utNjs8N7HbFsdptfYVmplGjM5kHkAgKM5R8kwHUXjeQQAnUZNgzq2fYWyCkvZfy6/0mccTS2w/1mmwIQQQtwJJAC6yZUUljm8b6CNolNIJ55o+gRgG/UpKrNtZmi2mnlj63N4NPgClTYLf08tgd62EaGsIhN7z+RW+oyjaRcDoIyCUqxWpdJyQgghxO1CAqCbXEmxYwDkafZhYfxCWga0BOBYzrFK66n1afh76AjwtI0UWawKecaySsseuyQAMlsVcqsod/h8Pu/+dIjCUnOl94UQQohbhQRAN7vLBmOK823JyuUnw5crnxIrp9bmUMdTh85NjY/7xVx3D93FFWCBFzY8vHQKDCC9ijygGWuOsXBzIou2nK7RRxBCCCFuNhIA3eTuGdQMgNb31gPAWGAbnfF3v3hSvH9xMAMTX+OBQ3+jUWY7ANTabPuSeNMlJ8E/1j7c/ufyg1NLzY6J1un5lecBnUi3Ha/xx+mKZ5AJIYQQtxIJgJwoZ+kyTj70EBmzZl91nZZ3hfPstB7EPtwQgLJSC2WlFup61KVebjPC8prQ/+wo3M8F0iAvmh7JjwOg0uXg72nbTTo2yjZa1KiuJ6/3aU64n+1Q1Ydah1b6zMoSoU1mK8nZtiM4diblYJE8ISGEELcw2QfIiaxFRZhOnMTU4kyN6hm8dCiKgt7TjdIiMz9+tJtez7bkoaMjweq4T5Ch1Bu1VYNam02dCyNAE/u1YOupbB5rH467VsPK0XeRXWwi31jG1N+OVnheZVNgZ3KK7UFPQYmZY2kFRIf61OhzCCGEEDcLGQFyIo2/bdrKkpNb47oqlYr7B0ejM7iReiqfzd+dcAh+uj7aCI2b7a/T0+SHxj2V1Xlv8K/9/6JhXS/+1LmBfQdoXw8tUYGetAr3xc9Da28jzNcdqHwzxFMZRQ7vd8g0mBBCiFuYBEBOpPHzA8CSk3NN9aPa1KXNfbZcoKT9WQDoDG70/FMz2sbVx6uOLafHu9S2V9C54hN8tOsjlh9bXnl/1CrualLX/r5FmG1E52BKxf2CTmUUOrzfligBkBBCiFuXBEBOpPH3A8CSm3vNbdQJsx1tYbmQuBzdLZRWd4ej1qjxrmMbwQmyhjnUeX/r+3x16CumbJ9CUn6Sw72eTS8GQE91rI9Wo2J7YjYJJ7McypWPAHVtaMsn2nwi0z4lZrUqTPvtKL/uP8/G4xk8MW8Lx9McV5YJIYQQNxPJAXIiN/sU2LWNAAEEhHs6vPcP8bD/uTwAUhfp4cIisX4N+/HTqZ+Ytm06zdO6oqz+H03dW+Bdx537Bkdzd9NAe/22DfwY0Kk+X21N5v/WHKNro672e4mZtgDoiQ71OHAuj5ziMtYfSceg02C2KsxZfwJvdzdahvmwIymHmeuOM/dP7a/5cwohhBA3kgRATlQ+BWYtKkIxmVDpdNVXqIRvXQNqNxVWs2305dIAyOtCANTGvSO7WM0z0c8wpsMYMo2ZGHd40CX5YQDOk8d58mjcMZio1oFMfiwGo8lCkLc7L9zbhCXbktl+OptzuUbC/QwYTRb7btFNg73p0SSQXw+k8pcvd9ieV9/2uQpKzGw9ZZsaW3MwjdxiE1tPZfPTvhTe798KP4+af14hhBDiRpApMCdS+/iA2vaVm69xGkytUeMfcnEUyC/44p+9L+QARWqaMOveWYztNJYz+3MZF/I+fZUBAByuuxWtp60P545msypxFd2bw7M9ogAI8XWnQ4Rt+Oi/h9MAmLb6KHnGMkJ93Wka4sU9zS5OmwGVHrFhslhZsj2Z17/bxy/7zvNlQlKFMkIIIYSrSADkRCq1+pJE6NxrbicgzBb06D3cMHhfXMVVPgVWkmvm3gb3cjQhlV/n72flx/vJOWNEQWF7g59ZGbYQgIP7TzP2f2N5bs1zlFkvHn9xf3QwAO/85yB3f7iezzYlAvDPR2PQu2m4p1kQbmrH5feX0mps96b9dtR+/MaK3edQFNk7SAghxM1BAiAnu96VYAB1LgRAfsEeqFQXA5HyKbCCrBIykgvY8JXjHj/qkFKMugLO+5wEoCxdjb7Mg3OF5/jy4Jck5yejKAr3Nw+y10nOLkajVjHqnkbce+F6sI87X/2lM8v/1tV+nEZ5QKQ2JNGs9fc0q2fi0r0ST2UWse9sHgBnc4qZ9ttRsgrl5HkhhBCuIQGQk9n3ArqOlWCN2gXhF+xBdDfHnZy9/G3BiLnMSsKKk1itCvWaXzwyo0Er2/L4Yl0+OYZUVKgJzW8MwMxdM3nk20f55+fz8FWZqRv5C56NPqRnTBl7J/TmtT7N7e2UWcqYfXg0nxx7jfiWtumwPq1C8NRp0NX5H0kl24jrdIbmId7EhPvSt1UIAN/vOktJmYXhX+xgzvoTfPK/U6TmlbDlZCYpuUaHz6IoCim5Rhk1EkIIcUNIErSTXVwKf+0jQH7BHgz6R5cK1920GnzrGsjLMHLmkC0ZueujjSjMLuXErnTufqAp2YljCfYM5reze/E/E8I9Z58koZ6Fk8XHiD82HL/c5nx2ciUlTTeiBs5oZ1No7kJ6STFbzm3BolhoEdCCfZn7AJh370g89Q0Z3DWCR9uFM2HXdPLMkFl6jl9fehGVSsX/jmXw64FUfth9DpNFsSdU/+9YBj/sPkdGQSkqFfw9rinBPnoiAzw5lVnEuO/38/aD0fzlrobX/F0JIYQQlZEAyMlqYwqsOj2easIvc23BSVCkD0ERPgRFQMN2tpGawS0HA1D2iMLBf+XgVezPsKxxeAboOJh7HgCfrFCCChqQ7p1MhjGdf+3/F2uS1pBdYguqwr0uHqi6PeN33nxgDAB+nlbytqcCcKbgjH16rkfjQOr5GzibY+Tr7cn2ukcuOYVeUWynzYPtxPqSMgsA7/1ymJIyCznFZbz9YLTDlJ8QQghxrWQKzMncamEKrDqRMYG0j48AFXTsG1FluYda9WH4q70BSNqfzfEt6bYb/ra8nDYp9zGqzSgAVpxYYQ9+AM4VnrP/eV3SOvs01YncE/bryQUXAx21WsXA2Ab290O7RVK/jsH+/s9dInjrgWjK86qLTRaH/KFpq4/x2aZEDp2/uEO1oigyPSaEEOKaSQDkZBo/WwBkvkEjQGCb9nruo55EtalbbbnAet7UbeCNYlUwlVjw9NPz+Ejb1Fqj7HbcbXkQtUpNqcUWFLWu29peNzI7hojsViTnJ3Mo6xAAx3KO2e/nleaRV5pnf/9kx3rU8dTRup4vb/RtTmxkgP1e31YhjLi7IXsn9GZAx/pV9vfI+QLMFisz1x6j2wf/pfXE1fxr4ymsVoWNxzP4bFOifeRICCGEqI5MgTlZbSyDvxpaneaqyjXpFExGcoH9zyEN/Glzf332rjtDwpLTdOzUne0lm2h9vie96YvJv4yiUwp9jv4FgOOBO5i5/SM+7fsJR7MdV52dKTiDr94XgCBvd7a8cR8atQqtRk3nhnX4ft9B/HS+dKjnB4C3u5aezeqybMcZAGKj6mDQavj9WAYA+87msupgKmsOpdmf8f5vWzmams+Pe89TaraydHsyi0d0Jsjb/dq/PCGEELc9CYCcTONrO3D0ilNgpmLQ6EBzY/+KmnQMYsv3J0CBprG2/X+69m9EyvFcMpILaJfQnzBtB0IKoyhMgns6P0bBqYt9apLZkVObtCxOXUOGpRR0EFTQgPtOPMMeJYUWQ1qw/sx6Vp9eTR33OrTK6IFnbgB1YtPxaTSNAQffYum72xg4vjM6dze6NwpErQKrAr2igxlxd0OW/ZHM69/tZ9GFzRQDtAX8tWcjTpQd5Nf06fzndB9M5nsAOJ5eyOebTxPfMgSL1UqHiDrkFZcxcvFOogI9+UuPKBZsPsgL97RmR1IOhSVmBsbWJy2/lLreejTV7G8EYDJbcVOrUF+hnBBCiJubBEDOdG4XmvVjASg9doy0yR8Q9PprqNSXzUSWFsKstuAfBX9Zc0O75OXvzv1DoikrsVC3vjcAGq2afqPb8POcfaSfziekNOpihW1BeANaX4gbGMPKT/fRMLsNeduhGfdRUM9E68y70ZV4kLcV3lNms1z9LwCCCiLwONABNSmcTNxBI/fWeBf6U0gpJw+kssdrI+2D2tOrRTAbjmZwf7Rt36HmIT72x3tosnkmuw7FP2SS12MXAFr/BExZd/Nwm3r8uDeF9UfS+XxzIiVlVr4b2Y1/bTzFlpNZbDmZxcrT32Ou8y2/f/VnUs61RFHgWFoBX2w5zcDY+kx+7OI0XzmLVeFEeiG+Bi1PfrIFg1bDytF34aaRGWQhhLhVqRTJJK0gPz8fX19f8vLy8PHxuXKFq/XLK1g2f8bJX0KwlNpGECKXLcXQpo1jubM74F/32/78ZgroPHEFs8nCqb0ZHD5znCatwtj3TRZZZwvxCXSn799iCKznzeHt51i9eC/ZbukEFV1MdC7VGNFbDJhVZfzcai692/VE95+muOVV/llyohJZFjITtUrNM9FDGB79PHUubLJYXGKm5YTfUFQKXd130yO1OwAFuhy+bf0hpdpionmDDx54hPumbwAujs4YtBqMl+QFGSLm4+ZxGktJKMWJL1Xox88v9iAiwIPfDqbhplZxd9O6vPfLIb7fdQ4PnYZik62tRc/G0rNpXYwmC3o3dYURoaOpBXyz4wzH0goYcVdD7m5aeT5WmcWKVgIpIYSoFTX5/S0jQM7UaxKaxP/R6KHjJG9tTMm5IkxnzlYMgPLOXPxzThIEt3BuPy9w02lo2imEpp1sGxlGvFiPxL2ZNOkYhN7DdgRHdGw4ke3rMG/3PHyPB+GVGkKhLpePtR/S7fSjROW05tHEFwguCiA1Lw+dl5risHTcjgU6PEt7zh91iBqrYuU/O38m+4iRjKBELJludDzQn+fz9eysu5tOGe3sdbxN/rRI78bu8LUEhG9i/m8neELlx6agXWQUdMBS3AhjmQWNWsWrvZvxr81HKHW3fbca9/N4B22hjHwUzJRmxoHVnXHf78diVewrzvw9tOQU247zKDaZMNRfBKhYsTuEUF93npqfgJ+HllkD29G6nh+peSV8vjmRzzYlYr6wlO1QSj7/feUevN3dyCgsJdjHlp/07k+HWLwtiVd6N2XEXQ1lib8QQjiRBEDOpPOgtO8slv1jHN4+JpqfK6Ls3DnOHT2Mf2gYHj62hGHyzl6sk3P6ygHQ8bWwfAg8PBtaPXbDuu/pq6fV3eEVrhvcDIzpNAY62d6XWcuwHh7OzojdWP/bBHW+gdTCPNz0Gh5+vh1BEd4c35nGwf+l4NtUw4FVqXiZ/BgXMQmrCdJXaNFa9RTVVdMwqx1YdRiAHukdAFDcLGyu9wM9Tj9B64ye7Av5ncxdZlqdust2X2VldbMFxNbpTyefPxNVL5O7I8IICTrL+D8uWSUW8CPlJ6l1CfAnN8VEeGoobiZ/MoLPolU15ny2BlQ6HmjVADwOsDHfttJtTcoyUr58iMfT1GRqzDz1cQKDukXw74QkTBYrAPc3DyIxq4jE7FQembeO/GIN2UUm/tazEdGh3izcfOGMtZVHKC2z8mTH+mw6kYnZYiXUz4BGpcJstRLqa6BpsBelZlu77tqrS3Avl19SRnJWMU2DvdG5OY42nckuxk2jItjb/brzmr7enkxydjHPdIkg3M9w5QpCCOFCMgVWiRs2BQYc2rieX+dMR6Uo9N5/irIYP/6rCiC4YRMG/XMGKpUK80+v8u132/DVldB32FDo+nz1jU70veTPeVWXcwFjgYlDm1PISC6k9b3hhDXxr1Dm10/3c2pXBmo3FVZzxR/HM75HOBWwl1bpdxFQGEb7+Ai+NMygyU8PoLcYQGuFMsdf7EvaTsLkZqS90p28LCOtc3tg8HPjmzpz8PDT4pbqQ1h+YxoEh3M6PZnYMw851D8YvInEOvtof7Y3viVBeARoOVF/K+s0K4hJ7UnT9E54GsPwUGzByH6dmVWGMlBB86hU+nmHE5UXRm7LfP55cjQobpTlt8ZLnctdSf05pfiyT6emU6Q/f5zOwUerIdxdR15OKVoFzrlZMavAz6IiukyDf+s6JJzNQYfCX7tZSffeT0FGB7w14ZgMW/j57Kf8vc1Emvp0xmJVMGg1nM4qIqfYxP+tOUZOcRleejemPdkab3ctBSW2Ua2/fWXLo2oZ5sPCoZ3so1NVsVqsqDVqFEVh95lcTqYX0qCOB2F+BnrOWoRKbUJT2oS5gzrQOMgLb3c3+3lxVdmZlM32xByG94iqEKDd6hRFYdOJTCIDPKlfx8PV3RHitleT398SAFXiRgZAv8yaypHNvwPQ4+gZzjTwIslgCwoeefVtGnfqwtnZT7FsUzEAo55uiuHRGVU3WFoIky8ZlbnJAqCrUZxv4rcFB0g5notKrSK6WyilxWZO7konvJkfp7r9zvmSFF6PfZ06ujqoNWoKTYWs//owyQm2Jfxe/npa9Ajj9JEc0o/nYvIoRVUCWqvjL98ydSleTRRKj1b8RZ/ulUS98GBMldyzl/FMIqjo4gaT+fosvEr9UaNmVfAezM0PUpqdSv8DL6NRNBj1+eRrsyl1K+Zo3e3EnO9JSGEUFpWFE+GHCM4KwsPki87i+MwiLewPUtMy04p3KSRrTWz3SSY+PwjvMh/2hq5nc9gGjGeH4ltvISHFoVjMniTl3kXbEk9aFvuz3/8o56y+ZHmkojGk4ZcRizFwGz3Odce9zI+NflZSzWZUbvkoVjfCvOsQ1yKY6FAfsgpLScoqpMQM9f0N3N0okOx1KZw9kkOnJxvz7t7T7E7OBXUJal0WdYNPUGRYhUqlYC5simJsRGleDH7aYJb/rSv1/D3Yfy6PnCITPgYtLcO8OJl/GKPRh+GfHaPYZOGl+5vQpWEA9fwNFYKFnCITxjILob7uJJzKwmxRaB/hj0alwqDTUFhq5ps/znAio5CH24ThqXMjyEdvD+hMZiunMgvx0LrRIMCx7TPZxRxNLaBdAz8CLgRru5JzePP7/bSP8OfNB6Lx0tdssPzw+XxS80tIzCji3Z8PEeStZ83fe+Lrob1yZcBqVdh+OhuDVkNMuC8HU/JpEuzlMPqXnFVMHS9djfpWvorRZLGSVVBKuARl4jYjAdB1ulEBkNVqYd6IZygptP3SjjmTzpGwAMo0tn/UgqIa8czkmex+537WH7f9w/R4Fx2Rf/++6kYP/wTLnrnwRgVvnnNZ0vT1sFqsJB/KJrCeF17+7lgtVs6fyCOkoS8abeWjAiajmX0bzhLUwJt60XVQq1WcP5HLD9N3Uf5TnWtIwy/Ai2OGPXinhhBa0Mhev1G7upw7nktJYRnnGx6iyxORPNTwIdYsPMix7Wlo3FS0uDuM1JBjbN6yl4ZJHXFTdACcCTlAouEQSYH7aZnWnfbJfTC6FbKtwU90OtMXzzI/rFhR12CvUbPKRLEuH61Fj8HsfcXyJwJ2UeJWTLOMWLRWW7+KtQV4lDnWzddnku6VTOOs9g59KtEYUStqNIqGUo2RfJUbZquWbM+zpAfsAKxEpt9NA6M/KlT2Z1hR2OSXRGrQRgKs4GnyJbggCp1FT6mbkTz3DKwqC3qzJz6FUVhx46DvaZoV+xJUVA+sGlJ9TmHR5pFtSCNLY0FtMRBY6otvYRSZ+jI0LQopTqpHM0Mox4wlFGeWEmJRkRmiJbH0MGpFRTOjH81L9aQG53JInY7R6A0l4YS7pYHVHUVbQKiXCrdCX/b7bKZIl0WD3JY0VrfDHO5FmdaHs0kZYDxBqv8+Cq3BdDU3xd/kwe9mN/I8d2Mw+dCcYBrUMbOxLJFGwXVpqQnCdFaPqjAAvxgtCSV/cL4wFa3KC19zB+qk6zhVUMApXSkqizvBFhUWdRlRob7oLG7szSuibYQfQfkW8rNysDYw0bJxA4IC8ikyZpNySM2Z5ExOaTJJ0RcRVSeAU+f0tNc15eFO3pj8izieFMBPOw6j9s2kVZSFXFM2p9JLaOrVlXbBTTiZkUS+9hTq0iga1PEhPNDE4bPFnN2joiz8MK3Tg4jIDyW/rY6CkHx8tD50Cm9OQUkZRSYLdzcJxNug8PP+s5xMs9C7RTDh/gYOp+TjV6JQz1tL3XBvjuUfYceRA3hoYjiQo6JeHU8ebhPGzqRsWgf54O+tY8fZPE6m5dE01I89B9JxK1Xo07ke9RvoOJxzGONxL/IzVJibFONvCKJteDBqtxJO5SSTnuVP+rliisxWfAPdeaRtOCqVlfVHMjGWmWgbqWHHSQWVSkWorzseOg0ZRUVodBl0DG+ESnHncGIubZoEoHdTYzJbMZZZ8DVcDETLc+/KfxWWvzdbrJiKykjMKuZscSlNg72JuBAwKoBGraKkzMJ/j6RTVJZPdH01LQMbo1KpKDVbsFrBoNNQXFpGVpEJs8UCmmLq+wZVuoLUbLFyJsdIbrGJ6FAf3LUaFEWhyGRx2PXeXauxL5zIKTKhAHU8dVf896KcxWrbad9ssfXvapSYTWjVGjTqysubLVZy80rx9dSh1V/9FL3VqtT6liISAF2nGxUApRw7wtfvvGp/71ViotBdh0FTRpnGE7PJZAuApg7hYLZtVKhHRAGdP/y96kZXPA97vrr4fsR/IbxDrfX5VlSQXUJGUgF6Tzc8G6jwc/dDURRyinPZ98t5jidkEvtQFG3ur09JYRlZKYWENfG7+A+fycLJ3RnUa+aPp59tRMBsNbPz6H7S/gsGDx0NHtLy6cFPeLTJozT2bswPU/Zgzbr4j5Daz8zONv8hOrUbsS3boMrTc/5kHm5aNY27B/D74qOoytyIuN+DZh3DWbgzCU9PN/SBG1myfyndTz9KdHo3AI4F7qBxZjusGjNlUdlofRui3lmM+pLVbmYvI6WlJjzLbNOhSf4HCCwLQ2v0qDC6ZHQrpNStGL+SoBp9r6WaYs76HqNRdtsa/53UlEVlRqNUHNlQUFBR838wLSoLKgXU2P5xNqtMZHmkE1QUhupCQHje+xShBbaDd8vUpaR6JxKW39jej1JNMaCyTbteYMVCmaYUN6ueUrciStyKqWO0LRo463uUgKJwDGavCp/NqrLaA0oFKzmGNCxqM3WKQx0+d5rXaYq1+YTlN0Zv8bDXN2lKMZg9KdLmkeGVjH9xCAX6HExuJYTmN0JncWdv6H/xNPli1BVQpMujdco9eJvqUKY22Z9tVplI90rGrDFRpCnFjBqLphiLWxF1i8LxLQkkzess3iVBFKktGMwGwo0XVzReGlAneyWRasikXnEwblgJKmqARWWhVFOKu9mdLEM6dS98N+XfnVFbaP+ZLdLmYtKUUqgtxg2oUxwMqNFf+Pkt1OVi0pRQqM9Gb/IBlUKORwpeJUG4lXmhRo0aK4q6lFOBuzntc5Kup5+kQWE4yT7H8S8JRFFZOeNzksicluR6nCdfn43G6oXW3Yvi4hJy3LPRacsIKgjEUOpDcLFtdD1Tn026RwpeZT5kaU3kaotpWuJLYFEwJrWJLM8zpHknojP742v0J1ufw16fczQqqUPXlO6AikzDeXI9U8CqpUyl4F1aB51VT47neQwmX/JRkeqZjKe6mOjUe7F4qDnic5A0XSJ1ioOJyGtGmdpMlns+Bg931GXFRGXWQ2/Vkm3IJMsjg2JtIe6lwfgY6+GumCjUFZCv0VGmeGBQZeNfplBgOEeyz3GS3KwYiu+ii64eOSW7gUK0bgZSlRICLHXQ69TkGvIptOThU2LEjArvsqaEljbivFsWGfozFFgNZBc1JkKTzENpbShxM7Kv/na8iusSZAoiQ59Hmkc2Pmo3cizZaC0BGA0KOYbzFJpz6BMVx9QH/lzj/z1XRwKg63SjAqDN33zF1u+W4qbVYS4z2a83V6dT1qgLJ4+fIrbfIySuXkxGqe0fzcbe2Tzy0Y/w/XPQsCd0v2TpttkE05pASS6o1JTkqHF75H3c7v3bxTJ7l9r+2+bpih3KOAYL46HV4/DgNIdb1qIiLLm5aMMrJj3f6hRFqfUVV/mZRv74JZGsc0WEN/Wj00NR6NyrnprIyzBSVmohsJ5XhXv/Tf4v7ya8S+uC7twTeD8RXXyJ0jXG18cbzYUcmTOHs/ltwQFUBitN+nnTI7Ydv5/eiHGrJ756X9o/XB+D1p0tB3ay75N8LGUKQXepaBvTjF9yfiDVfI4Wpp6ovHNpEtyYXw+tZkfiHrQWPRHG5rSydKKwtIiDHtto1TGC9qFdOFl6jj/S91BypIw2iV3QqDQERfpQqtLwn7NZRIR5Mbh9AwqySrBarGQrmaSqzpB7HLxTgtBFmjgasYUCYyFtVF1p4tWC9OQ8inONmBULWbpCcnSnaJAcg5tVi9GtgDz3TAKL6mFRl5HjkUrIhQBFQaHUrZjCBmn4JIfjZnXDigWVoibPJxWLpgyNxR2V2g2LqoTAbNsRKyU+BeQr2QQVXJzGLPDKwKsoEJVi+5ko1OfgVXoxVy3HIw2N2YCPyfZvQammlHN+R1FZVUTlxFT4+7s0wLCVt01nu1l1mNUmeyBToiki2/M8YfmNHernGrIwe5USkBWCynpxpMDoVoha0TgEYDVlxWIPAosMeXgafa9Qo6IydSlFujx8SwJRoaZQm4/B7FFpwHo5BSu57hl4mfwdgrBSN6M9ELqcWWVCrbjVaDRVXFmRNg83q9b+83itrNgWZ1zt34+ClXO+xzFpSjAGafj45dHX9fzL3XIB0Ny5c5k6dSqpqam0adOG2bNnExsbW2X55cuX884773D69GmaNGnClClTeOCBB+z3FUVhwoQJLFiwgNzcXLp37868efNo0qTJVfXnRgVAZw8f4Mjm/6H38GD7f761X+9x9AxFnjp21wvG29+PopxsrJf8MIXrLGSbLTTxzSbuH1+iKs7EvGI0Fo8gdCnbOEck/0tpSPjeJMKtBTR8zIK62f3QrA98+ywAxs4zyPzqJ/yHjsCr14O2hn8YCXuXgEoNL+6EOrZfLtbSUk4/PZDSY8do8K8FeHbtSklhIWo3DTp3Wd3jDFcTpFnKrKjdVFcsl5FcQNa5Qpp2Dql2uPlM/hm2p27nnvr3EGCwndVWZi1Dq66Yt2K1KigWxT49eTKjkGAf9yrzUYyFJtw9tVcVeBZkl1CUW4p3PS2Hsw+BWYWfhx8WzJw8l0y7+q0J8raNQmguJGQDZJdkcyTrCJ3DOuOmduxHdkoRGq0K37oeKIpCSmI2+xOP4BtkoEurdmSdK2THytPUbeBNo55+JOzZQ93CBoRG+BPe1B+rxUpqYj56Dzf8gj0otZZwKOsQgSXheGu90Xu4UZBdwvHEZIIae6LK1ZORWIxvIw1hjfzx0ntyJPsIBzIPEqVugk6jo04dHyLrRGDMLyPldDZuKjf8gz3xC7b9QirMKeHc0RyK8koJa+JHsX82XjpvlAINh88dp2WjJmQcLMFYYCIo0oei3FJOpSdh9S4h0BrKyf/lUKeRnpJcC0qpikYd6+IZbSXlf6Xo3bV07BvJkb1n0aGnoKiIM+kpFBmN6BR3zmdawd2dnp1COXMqlVQyyDtfiNroRoNeBjy8I6HUhNGooUDxpq4qhaTvjFixorQpoF39pmT55HIs6wAGdHRv0I3Eo6kYQlW4BZkpKCnFozgSr1Ifjqo2kV52hr7uj6PRqtl+6BilZWqaNW2C3iOToDB/dFY9KWfzOHImF89SAyqvbAqKyihO9cUnLIdit1xQK/gZfAm1NuBsQjFZmfmYPApp0TuIrEOgravBXXEj/2wxaeHJ+JlC8VB7cDrvDFm52QR4+eCV7YfVqsYa7kZYuI7igDxKVTmo03R45geQRyEFJ0yoS90gCsKb1UGjLkKX5oM125MUYyq+gV4Yj5VhydSARqHe3d4UhZ9FSdcRTkOyjLnkFxRTpivForVgzXSnzGCkKC8Hz5w6aMv07Kn7O4b/b+/Oo6Mq78ePv++9s2bfN9awBWSrIKZRC1bylXDULxRt1XIK+FVRigsVqmKroqeeVFutxSra9legHisWj2KLiLKjGEGCLCqmQMNmEiKEbJPMdu/z+yNkZEgCUYGQzOd1zj1k7vPcZ57ncx+Sz9x55k4gjh41A4kOxEBsgKrUQ02JYE0UQa+F3WEnrp9BbKaNujId7bgNs1Hxpf+/HLWXkRifTIwvkbpjdRhBG65oFwkZ8ST5Mqgv8WH6PFjBcrzuGLyJJomudBobA7g9NvxRPpSpsNcG0ZUdd0YcpmVS46/hiPsgyd4Mon1x6I12dGWgVBCtrxfTZsOq1AkkNPCV/RjJVcnYfQ789gBuzUnA8uGujkdZjVjBMlJHpXPzjP894++Eb6JTJUCvvfYaU6ZM4cUXXyQ3N5dnn32WpUuXUlJSQlpay0v0H374IaNHj6awsJBrr72Wf/zjHzz55JNs27aNIUOGAPDkk09SWFjI4sWLyc7O5uGHH2bXrl18/vnnuFxn/o6oc7kIGiDg8zJ/yg0AJNY3krevjKCusXpwb6wTd4W2mRbBVt4nHtZYjS3Jz47GFEx0Yk0ffocLn6kwTIsR+yugh0VNtJOermrig158QRtlB+JpwIHPYSMtdzDdk+zw+b+pbXRjN4KoKp3G6miMuBh0h50vj3modzmwuV1UJ8dT5fViaHBxn0y6pXfH6VTUVFTgOVZDcoKOnpaNsqChvp5aDKINF26zFpvuw+Z2oyVn4z98GE23YcS40TwVEJ3a9HUfphcsE5wxUFeGpkGjLYHjARuJiYlEuZ2EFvVoCo2mDWURNE2qjtegGxDjdmKzGdh0CJpBVCCI5vfia6jGZgax2Z0Qm4pKyCJY24DmdKBHuVAKdEPH0A00TQv9QVVKQcALpv/EM+qAhtI0/AGT+voG4mJcRDkNfPXV1NccxxEdj9PtQtd1fEFFwARXdBxOG9BY1fQVJ9HJYI8GTQNNR7MCcPQ/qIAPFZWOntgNpRn4GjwE/X6cdtuJxEWBpjUdpkxorEKzu7CMGCyPF3QNzW5Ht9vAZkez28CywFIoS6EZBujaief9et1DfV09oBEdE920uOFUKlT9a81vF1Yew19WgaNHJkZ8PJr3OPiOQ0IPsLfxyjLQiBb0gCsBWkmuTnraEz9YoQdf71MndbXpJzNoYpomuq5jGAb4/GjBIFpMNErTUJbVtJ0Yt67r2GwGemhdw0nn/eR+tPgV2VwPmm66qaBpRjbt9NUBJkp3Ns1vDbAszECAYDCIy+VE12jqi2pa36FME6XrKM2GOnGFRtN1DH8dmr8OLSYNdBuYwabnMAzQjNDzK8tsemNQWSfFTIFuNL3AQQcNGhu8bN+xE4/HQ3x8PD26dyMpORm/30/18WoaGhqIi4tDAaZpYrMZGIYNm2FgGAaNjY0cP36ctNRU4uPjwuaLpZp6ozX/2jo5bqeEMDymivCHikAggN/vx2E3cAbrMdE47oVjx6tJiIsjLjYGFTRpqK3D6/HgB/y6RuBEnKOcLg4ePkxtXR1RUW4cNjvJSYnEOl1YXh/RyUm4Y2Oob/DgaWjE4bBjaDqlBw7gqfcQ73TRLTOD9O7dULpOdU01nkYvTtPE7mi6cmU2+tCcdrz+AMqycLmcxKSl4Ha7Cfr9HD5UxtGjX5GRkkKczU7QsqgL+qk5XkNychIJKck0+P3UHqvC8jSg6TrH6uupq/fQq8FHvN2BlZZMtd3gyLEq4qOjyExKxqXrHK6spKyujqS4WHr37Em1t5GysjISo6KJVWDV1mHVeVD+AAGHHZ/TjnI6SOqWiamg6ugxKqqrT7ylDD2TkkiIj6eyqorjNbWkxsRQp2tU1zbdD83lcpGemUF6t0zsmkbp5yXQ6EX5fNRYFg3KIis6hh7JyZCShNvtxqZr/Gfff6nzeIiNiSEjI506j4cvDx+htr7pwzoXDb2M8b9+iLOpUyVAubm5jBo1ij/96U8AWJZFjx49uPvuu3nwwQdb1L/xxhvxeDwsX748tO/73/8+3/ve93jxxRdRSpGVlcXs2bOZM6dpvU1NTQ3p6eksWrSIm25q5a2gU5zrBAjgtccepPzzz7jsiwPE+gIkDfKytr4nZUlNC1iTPY0ENY2aKBcZNfVE+QL8N63lR8hDVGt/pYQQQojWufwBvI7TfDIx9MLz7P9tifb6GZTqZsxf3zqr7XaaO0H7/X6Ki4uZO3duaJ+u6+Tn51NUVNTqMUVFRdx3331h+8aNG8eyZcsAKC0tpaKigvz8/FB5fHw8ubm5FBUVtZoA+Xw+fD5f6HHtiaz3XJr0wDxqd+7A+9pSUq7/AY4huVz1/xaybeU7VLgcXHL5JcSn9eerTWsZMikHf9IY1r6zjMNlR7D5gww0DXrF17GTWI75HQyu87K/bzpfHa3G5g+Qis4RFSBos2HTdNxWkMRBA9F276LKD3V2O6Bw2R0EgwGCGmgOB1gmylTE2RXdYzzUfRkk1eYlVXNSHnBRatOpN2xYaDiUwm2DOktHsyzQwKYUsT4fjQ4bQd3ARMcEUOqkV4bw9Svn5p+bC5peSRtKEev3UW+3Ezzpu9LUKQtgNaWICQRQaPgMHUvTMTUN48R/XEvXcJy4mmY190MpQhdUmutpGpamtehR03M07/v6tYKhFK5gkAa7nYCuY7MU7mCQoKYRMHQUGg7TxFAKn2EQ1LVTxnkq7aTipjjYLRMdRUA32rgwo4Ud3rL8lCLVWim4giZKA7/R9qc32nqV1HwxSamTK2mnOeJ0JWEth9U8dQzhw23aqSuFYammc6mfOJ+ahqbUiXPY9K92InIWX9dr2W54L1uEt9V+NBd8fZ5PLteVQlcKv2GEamknDtFQLeaZAtSJedleLWIbOjlf9ze9oYFMTz01DidHo9w02OwYlkVMwI/LNPHY7OgoDKUwTzy/qWmYmo6hLGICAY47XQS+wVe4nByV9jCUwm6ZBDWdgGGgKYgKBogP+Ki32fEZTVe/HJg4MbEHLWw+E1vQQjcUjXY7MUE/Gd4GfDaDgK5zzObCb7ehGQqvacOnGzhMk+iAH1PXCeg6iT4fycpLXbSDcj2aWt2BrlRTbAJBAk4bZvOc0gELHJaJpoEPAy8GfsNoOiYYINnv5ZjLhd9mYCgLdyBIjApwzHARQMduWkSbfuwOUBo4gyZ2y+JgYtMib7vfwu0Lkk4DtbqDSt1NUNdJxEdWwEO5FkW9smMPmKQHG6lzOQg4DDQH6A5AB4cycZomViMcb3RgUxZxRoA0eyOJmp/jAQf7iMNn2UgKekmN97GvIRa9waLPV9U4HBbVNidVhovjLic+u41My0N0lInu1rD7TYyvguxLTCBg6Rh+C59hw2/oJPm9ZHg91BpOqhwuogIBUgKNpNJIlMMiNueH32BWnH0dmgAdPXoU0zRJT08P25+ens4XX3zR6jEVFRWt1q+oqAiVN+9rq86pCgsLeeyxx77VGL4tu8tF8qW5cGluaF/6L+Yy/hdzw+r1uPU2ABzA//5Py/dKe53086hz0dGT9AdGn+PnEEIIcf5kAINO2TfkW7Rz8ZmrXHBkWT0wd+5campqQtuhQ4fOfJAQQgghOq0OTYBSUlIwDIMjR46E7T9y5AgZGRmtHpORkXHa+s3/fpM2nU4ncXFxYZsQQgghuq4OTYAcDgcjR45kzZo1oX2WZbFmzRry8vJaPSYvLy+sPsCqVatC9bOzs8nIyAirU1tby+bNm9tsUwghhBCRpcO/Df6+++5j6tSpXHLJJVx66aU8++yzeDwebrnlFgCmTJlCt27dKCwsBODee+9lzJgxPP3001xzzTUsWbKErVu38uc//xlouo35rFmz+M1vfkP//v1DH4PPyspi4sSJHTVMIYQQQlxAOjwBuvHGG/nqq6945JFHqKio4Hvf+x4rV64MLWI+ePAg+kmfArrsssv4xz/+wa9//Wseeugh+vfvz7Jly0L3AAK4//778Xg8TJ8+nerqaq644gpWrlzZrnsACSGEEKLr6/D7AF2Izsd9gIQQQghxdn2Tv9/yKTAhhBBCRBxJgIQQQggRcSQBEkIIIUTEkQRICCGEEBFHEiAhhBBCRBxJgIQQQggRcSQBEkIIIUTEkQRICCGEEBGnw+8EfSFqvjdkbW1tB/dECCGEEO3V/He7Pfd4lgSoFXV1dQD06NGjg3sihBBCiG+qrq6O+Pj409aRr8JohWVZlJWVERsbi6ZpZ7Xt2tpaevTowaFDhyLyazYiffwgMYj08YPEACQGkT5+ODcxUEpRV1dHVlZW2PeItkauALVC13W6d+9+Tp8jLi4uYic9yPhBYhDp4weJAUgMIn38cPZjcKYrP81kEbQQQgghIo4kQEIIIYSIOJIAnWdOp5NHH30Up9PZ0V3pEJE+fpAYRPr4QWIAEoNIHz90fAxkEbQQQgghIo5cARJCCCFExJEESAghhBARRxIgIYQQQkQcSYCEEEIIEXEkATqPnn/+eXr37o3L5SI3N5ctW7Z0dJfOiXnz5qFpWtg2cODAULnX62XmzJkkJycTExPD9ddfz5EjRzqwx9/dxo0bue6668jKykLTNJYtWxZWrpTikUceITMzE7fbTX5+Pnv27AmrU1VVxeTJk4mLiyMhIYFbb72V+vr68ziK7+ZMMZg2bVqLeVFQUBBWpzPHoLCwkFGjRhEbG0taWhoTJ06kpKQkrE575v7Bgwe55ppriIqKIi0tjV/+8pcEg8HzOZRvpT3jv/LKK1vMgTvvvDOsTmcdP8CCBQsYNmxY6MZ+eXl5vPPOO6Hyrnz+m50pBhfSHJAE6Dx57bXXuO+++3j00UfZtm0bw4cPZ9y4cVRWVnZ0186JwYMHU15eHto++OCDUNkvfvEL/v3vf7N06VI2bNhAWVkZkyZN6sDefncej4fhw4fz/PPPt1r+1FNPMX/+fF588UU2b95MdHQ048aNw+v1hupMnjyZzz77jFWrVrF8+XI2btzI9OnTz9cQvrMzxQCgoKAgbF68+uqrYeWdOQYbNmxg5syZfPTRR6xatYpAIMDVV1+Nx+MJ1TnT3DdNk2uuuQa/38+HH37I4sWLWbRoEY888khHDOkbac/4AW6//fawOfDUU0+Fyjrz+AG6d+/Ob3/7W4qLi9m6dStXXXUVEyZM4LPPPgO69vlvdqYYwAU0B5Q4Ly699FI1c+bM0GPTNFVWVpYqLCzswF6dG48++qgaPnx4q2XV1dXKbrerpUuXhvbt3r1bAaqoqOg89fDcAtSbb74ZemxZlsrIyFC/+93vQvuqq6uV0+lUr776qlJKqc8//1wB6uOPPw7Veeedd5SmaerLL788b30/W06NgVJKTZ06VU2YMKHNY7paDCorKxWgNmzYoJRq39xfsWKF0nVdVVRUhOosWLBAxcXFKZ/Pd34H8B2dOn6llBozZoy699572zymK42/WWJiovrrX/8acef/ZM0xUOrCmgNyBeg88Pv9FBcXk5+fH9qn6zr5+fkUFRV1YM/OnT179pCVlUWfPn2YPHkyBw8eBKC4uJhAIBAWi4EDB9KzZ88uG4vS0lIqKirCxhwfH09ubm5ozEVFRSQkJHDJJZeE6uTn56PrOps3bz7vfT5X1q9fT1paGjk5OcyYMYNjx46FyrpaDGpqagBISkoC2jf3i4qKGDp0KOnp6aE648aNo7a2NuwVdGdw6vibvfLKK6SkpDBkyBDmzp1LQ0NDqKwrjd80TZYsWYLH4yEvLy/izj+0jEGzC2UOyJehngdHjx7FNM2wEwqQnp7OF1980UG9Ondyc3NZtGgROTk5lJeX89hjj/GDH/yATz/9lIqKChwOBwkJCWHHpKenU1FR0TEdPseax9Xa+W8uq6ioIC0tLazcZrORlJTUZeJSUFDApEmTyM7OZt++fTz00EOMHz+eoqIiDMPoUjGwLItZs2Zx+eWXM2TIEIB2zf2KiopW50lzWWfR2vgBfvrTn9KrVy+ysrLYuXMnDzzwACUlJbzxxhtA1xj/rl27yMvLw+v1EhMTw5tvvslFF13E9u3bI+b8txUDuLDmgCRA4qwbP3586Odhw4aRm5tLr169+Oc//4nb7e7AnomOdNNNN4V+Hjp0KMOGDaNv376sX7+esWPHdmDPzr6ZM2fy6aefhq19iyRtjf/k9VxDhw4lMzOTsWPHsm/fPvr27Xu+u3lO5OTksH37dmpqanj99deZOnUqGzZs6OhunVdtxeCiiy66oOaAvAV2HqSkpGAYRovV/keOHCEjI6ODenX+JCQkMGDAAPbu3UtGRgZ+v5/q6uqwOl05Fs3jOt35z8jIaLEgPhgMUlVV1WXj0qdPH1JSUti7dy/QdWJw1113sXz5ctatW0f37t1D+9sz9zMyMlqdJ81lnUFb429Nbm4uQNgc6Ozjdzgc9OvXj5EjR1JYWMjw4cP54x//GDHnH9qOQWs6cg5IAnQeOBwORo4cyZo1a0L7LMtizZo1Ye+LdlX19fXs27ePzMxMRo4cid1uD4tFSUkJBw8e7LKxyM7OJiMjI2zMtbW1bN68OTTmvLw8qqurKS4uDtVZu3YtlmWFfkF0NYcPH+bYsWNkZmYCnT8GSinuuusu3nzzTdauXUt2dnZYeXvmfl5eHrt27QpLBFetWkVcXFzoLYQL1ZnG35rt27cDhM2Bzjr+tliWhc/n6/Ln/3SaY9CaDp0DZ3VJtWjTkiVLlNPpVIsWLVKff/65mj59ukpISAhb6d5VzJ49W61fv16VlpaqTZs2qfz8fJWSkqIqKyuVUkrdeeedqmfPnmrt2rVq69atKi8vT+Xl5XVwr7+buro69cknn6hPPvlEAeqZZ55Rn3zyiTpw4IBSSqnf/va3KiEhQb311ltq586dasKECSo7O1s1NjaG2igoKFAXX3yx2rx5s/rggw9U//791c0339xRQ/rGTheDuro6NWfOHFVUVKRKS0vV6tWr1YgRI1T//v2V1+sNtdGZYzBjxgwVHx+v1q9fr8rLy0NbQ0NDqM6Z5n4wGFRDhgxRV199tdq+fbtauXKlSk1NVXPnzu2IIX0jZxr/3r171eOPP662bt2qSktL1VtvvaX69OmjRo8eHWqjM49fKaUefPBBtWHDBlVaWqp27typHnzwQaVpmnrvvfeUUl37/Dc7XQwutDkgCdB59Nxzz6mePXsqh8OhLr30UvXRRx91dJfOiRtvvFFlZmYqh8OhunXrpm688Ua1d+/eUHljY6P6+c9/rhITE1VUVJT60Y9+pMrLyzuwx9/dunXrFNBimzp1qlKq6aPwDz/8sEpPT1dOp1ONHTtWlZSUhLVx7NgxdfPNN6uYmBgVFxenbrnlFlVXV9cBo/l2TheDhoYGdfXVV6vU1FRlt9tVr1691O23397iBUBnjkFrYwfUwoULQ3XaM/f379+vxo8fr9xut0pJSVGzZ89WgUDgPI/mmzvT+A8ePKhGjx6tkpKSlNPpVP369VO//OUvVU1NTVg7nXX8Sin1f//3f6pXr17K4XCo1NRUNXbs2FDyo1TXPv/NTheDC20OaEopdXavKQkhhBBCXNhkDZAQQgghIo4kQEIIIYSIOJIACSGEECLiSAIkhBBCiIgjCZAQQgghIo4kQEIIIYSIOJIACSGEECLiSAIkRCd37733Mn36dCzL6uiuCCFEpyEJkBCd2KFDh8jJyeGll15C1+W/sxBCtJfcCVoIcUHr3bs3s2bNYtasWR3dFQCmTZtGdXU1y5Yt6+iuCCG+A3nJKEQnNG3aNDRNa7EVFBR0dNcuOPv370fTtNC3Tn9Xf/zjH1m0aNFZaetCMG3aNCZOnNjR3RDivLN1dAeEEN9OQUEBCxcuDNvndDo7qDedn9/vx+FwnLFefHz8eeiNEOJckytAQnRSTqeTjIyMsC0xMTFUrmkaCxYsYPz48bjdbvr06cPrr78e1sauXbu46qqrcLvdJCcnM336dOrr68Pq/O1vf2Pw4ME4nU4yMzO56667QmXPPPMMQ4cOJTo6mh49evDzn/887PgDBw5w3XXXkZiYSHR0NIMHD2bFihVtjqmyspLrrrsOt9tNdnY2r7zySos61dXV3HbbbaSmphIXF8dVV13Fjh072mwzOzsbgIsvvhhN07jyyiuBr698PPHEE2RlZZGTkwM0rav6yU9+QkJCAklJSUyYMIH9+/eH2jv1ismVV17JPffcw/33309SUhIZGRnMmzcvrA9nitOiRYtISEhg+fLl5OTkEBUVxQ033EBDQwOLFy+md+/eJCYmcs8992CaZug4n8/HnDlz6NatG9HR0eTm5rJ+/foW7b777rsMGjSImJgYCgoKKC8vB2DevHksXryYt956K3QVsfn49swNITozSYCE6MIefvhhrr/+enbs2MHkyZO56aab2L17NwAej4dx48aRmJjIxx9/zNKlS1m9enVYgrNgwQJmzpzJ9OnT2bVrF//617/o169fqFzXdebPn89nn33G4sWLWbt2Lffff3+ofObMmfh8PjZu3MiuXbt48skniYmJabO/06ZN49ChQ6xbt47XX3+dF154gcrKyrA6P/7xj6msrOSdd96huLiYESNGMHbsWKqqqlptc8uWLQCsXr2a8vJy3njjjVDZmjVrKCkpYdWqVSxfvpxAIMC4ceOIjY3l/fffZ9OmTaGkwe/3t9nvxYsXEx0dzebNm3nqqad4/PHHWbVqVbvjBNDQ0MD8+fNZsmQJK1euZP369fzoRz9ixYoVrFixgpdffpmXXnopLIm96667KCoqYsmSJezcuZMf//jHFBQUsGfPnrB2f//73/Pyyy+zceNGDh48yJw5cwCYM2cOP/nJT0JJUXl5OZdddlm75oYQnZ4SQnQ6U6dOVYZhqOjo6LDtiSeeCNUB1J133hl2XG5urpoxY4ZSSqk///nPKjExUdXX14fK3377baXruqqoqFBKKZWVlaV+9atftbtfS5cuVcnJyaHHQ4cOVfPmzWvXsSUlJQpQW7ZsCe3bvXu3AtQf/vAHpZRS77//voqLi1Nerzfs2L59+6qXXnqp1XZLS0sVoD755JOw/VOnTlXp6enK5/OF9r388ssqJydHWZYV2ufz+ZTb7Vbvvvtu6LgJEyaEyseMGaOuuOKKsLZHjRqlHnjggTbHemqcFi5cqAC1d+/e0L477rhDRUVFqbq6utC+cePGqTvuuEMppdSBAweUYRjqyy+/DGt77Nixau7cuW22+/zzz6v09PSwOJw8HqXaNzeE6OxkDZAQndQPf/hDFixYELYvKSkp7HFeXl6Lx82LgXfv3s3w4cOJjo4OlV9++eVYlkVJSQmaplFWVsbYsWPb7MPq1aspLCzkiy++oLa2lmAwiNfrpaGhgaioKO655x5mzJjBe++9R35+Ptdffz3Dhg1rta3du3djs9kYOXJkaN/AgQNJSEgIPd6xYwf19fUkJyeHHdvY2Mi+ffva7Gdbhg4dGrbuZ8eOHezdu5fY2Niwel6v97TtnzqmzMzMsCtXZ4oTQFRUFH379g0dk56eTu/evcOumKWnp4fa3bVrF6ZpMmDAgLDn9vl8YfE5td1T+9aaM82N9PT00x4vRGcgCZAQnVR0dHTY21Fnm9vtPm35/v37ufbaa5kxYwZPPPEESUlJfPDBB9x66634/X6ioqK47bbbGDduHG+//TbvvfcehYWFPP3009x9993fqk/19fVkZmaGrXNpdnKi1F4n/4Fvbn/kyJGtrj1KTU1tsx273R72WNO00I0p2xOntto4Xbv19fUYhkFxcTGGYYTVOzlpaq0NJXc/EULWAAnRlX300UctHg8aNAiAQYMGsWPHDjweT6h806ZN6LpOTk4OsbGx9O7dmzVr1rTadnFxMZZl8fTTT/P973+fAQMGUFZW1qJejx49uPPOO3njjTeYPXs2f/nLX1ptb+DAgQSDQYqLi0P7SkpKqK6uDj0eMWIEFRUV2Gw2+vXrF7alpKS02m7zFZ6TFw+3ZcSIEezZs4e0tLQW7X/bT3+1N07f1MUXX4xpmlRWVrboa0ZGRrvbcTgcLWJzprkhRFcgCZAQnZTP56OioiJsO3r0aFidpUuX8re//Y3//Oc/PProo2zZsiW0kHXy5Mm4XC6mTp3Kp59+yrp167j77rv52c9+FnqLY968eTz99NPMnz+fPXv2sG3bNp577jkA+vXrRyAQ4LnnnuO///0vL7/8Mi+++GLY88+aNYt3332X0tJStm3bxrp160IJ2KlycnIoKCjgjjvuYPPmzRQXF3PbbbeFXYnKz88nLy+PiRMn8t5777F//34+/PBDfvWrX7F169ZW201LS8PtdrNy5UqOHDlCTU1NmzGdPHkyKSkpTJgwgffff5/S0lLWr1/PPffcw+HDh89wRlrXnjh9GwMGDGDy5MlMmTKFN954g9LSUrZs2UJhYSFvv/12u9vp3bs3O3fupKSkhKNHjxIIBNo1N4To7CQBEqKTWrlyJZmZmWHbFVdcEVbnscceY8mSJQwbNoy///3vvPrqq1x00UVA09qQd999l6qqKkaNGsUNN9zA2LFj+dOf/hQ6furUqTz77LO88MILDB48mGuvvTb0CaPhw4fzzDPP8OSTTzJkyBBeeeUVCgsLw57fNE1mzpzJoEGDKCgoYMCAAbzwwgttjmnhwoVkZWUxZswYJk2axPTp00lLSwuVa5rGihUrGD16NLfccgsDBgzgpptu4sCBA23+YbbZbMyfP5+XXnqJrKwsJkyY0ObzR0VFsXHjRnr27MmkSZMYNGgQt956K16vl7i4uDaPO532xOnbWrhwIVOmTGH27Nnk5OQwceJEPv74Y3r27NnuNm6//XZycnK45JJLSE1NZdOmTe2aG0J0dvJVGEJ0UZqm8eabb8pdfoUQohVyBUgIIYQQEUcSICGEEEJEHPkYvBBdlLy7LYQQbZMrQEIIIYSIOJIACSGEECLiSAIkhBBCiIgjCZAQQgghIo4kQEIIIYSIOJIACSGEECLiSAIkhBBCiIgjCZAQQgghIo4kQEIIIYSIOP8fSr9M423nctYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    }
  ]
}